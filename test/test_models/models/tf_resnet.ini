[model]
batch_size = 1
continue_train = false
epochs = 1
loss = mse
memory_optimization = true
type = NeuralNetwork

[optimizer]
type = adam

[input0]
input_shape = 1:3:32:32
name = input0
normalization = false
standardization = false
type = input

[conv0]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 64
input_layers = input0(0)
kernel_size = 3,3
name = conv0
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[first_bn_relu]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv0(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = first_bn_relu
trainable = true
type = batch_normalization
weight_decay = 0.000000

[first_bn_relu/activation_realized]
activation = relu
input_layers = first_bn_relu(0)
name = first_bn_relu/activation_realized
trainable = true
type = activation

[first_bn_relu/generated_out_0]
input_layers = first_bn_relu/activation_realized(0)
name = first_bn_relu/generated_out_0
trainable = true
type = multiout

[conv1_0/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 64
input_layers = first_bn_relu/generated_out_0(0)
kernel_size = 3,3
name = conv1_0/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv1_0/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv1_0/a1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv1_0/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv1_0/a2/activation_realized]
activation = relu
input_layers = conv1_0/a2(0)
name = conv1_0/a2/activation_realized
trainable = true
type = activation

[conv1_0/a3]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 64
input_layers = conv1_0/a2/activation_realized(0)
kernel_size = 3,3
name = conv1_0/a3
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv1_0/c1]
input_layers = conv1_0/a3(0),first_bn_relu/generated_out_0(1)
name = conv1_0/c1
trainable = true
type = addition

[conv1_0]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv1_0/c1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv1_0
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv1_0/activation_realized]
activation = relu
input_layers = conv1_0(0)
name = conv1_0/activation_realized
trainable = true
type = activation

[conv1_0/generated_out_0]
input_layers = conv1_0/activation_realized(0)
name = conv1_0/generated_out_0
trainable = true
type = multiout

[conv1_1/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 64
input_layers = conv1_0/generated_out_0(0)
kernel_size = 3,3
name = conv1_1/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv1_1/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv1_1/a1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv1_1/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv1_1/a2/activation_realized]
activation = relu
input_layers = conv1_1/a2(0)
name = conv1_1/a2/activation_realized
trainable = true
type = activation

[conv1_1/a3]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 64
input_layers = conv1_1/a2/activation_realized(0)
kernel_size = 3,3
name = conv1_1/a3
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv1_1/c1]
input_layers = conv1_1/a3(0),conv1_0/generated_out_0(1)
name = conv1_1/c1
trainable = true
type = addition

[conv1_1]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv1_1/c1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv1_1
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv1_1/activation_realized]
activation = relu
input_layers = conv1_1(0)
name = conv1_1/activation_realized
trainable = true
type = activation

[conv1_1/generated_out_0]
input_layers = conv1_1/activation_realized(0)
name = conv1_1/generated_out_0
trainable = true
type = multiout

[conv2_0/b1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 128
input_layers = conv1_1/generated_out_0(0)
kernel_size = 1,1
name = conv2_0/b1
padding = same
stride = 2,2
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv2_0/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 128
input_layers = conv1_1/generated_out_0(1)
kernel_size = 3,3
name = conv2_0/a1
padding = same
stride = 2,2
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv2_0/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv2_0/a1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv2_0/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv2_0/a2/activation_realized]
activation = relu
input_layers = conv2_0/a2(0)
name = conv2_0/a2/activation_realized
trainable = true
type = activation

[conv2_0/a3]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 128
input_layers = conv2_0/a2/activation_realized(0)
kernel_size = 3,3
name = conv2_0/a3
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv2_0/c1]
input_layers = conv2_0/a3(0),conv2_0/b1(0)
name = conv2_0/c1
trainable = true
type = addition

[conv2_0]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv2_0/c1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv2_0
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv2_0/activation_realized]
activation = relu
input_layers = conv2_0(0)
name = conv2_0/activation_realized
trainable = true
type = activation

[conv2_0/generated_out_0]
input_layers = conv2_0/activation_realized(0)
name = conv2_0/generated_out_0
trainable = true
type = multiout

[conv2_1/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 128
input_layers = conv2_0/generated_out_0(0)
kernel_size = 3,3
name = conv2_1/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv2_1/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv2_1/a1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv2_1/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv2_1/a2/activation_realized]
activation = relu
input_layers = conv2_1/a2(0)
name = conv2_1/a2/activation_realized
trainable = true
type = activation

[conv2_1/a3]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 128
input_layers = conv2_1/a2/activation_realized(0)
kernel_size = 3,3
name = conv2_1/a3
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv2_1/c1]
input_layers = conv2_1/a3(0),conv2_0/generated_out_0(1)
name = conv2_1/c1
trainable = true
type = addition

[conv2_1]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv2_1/c1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv2_1
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv2_1/activation_realized]
activation = relu
input_layers = conv2_1(0)
name = conv2_1/activation_realized
trainable = true
type = activation

[conv2_1/generated_out_0]
input_layers = conv2_1/activation_realized(0)
name = conv2_1/generated_out_0
trainable = true
type = multiout

[conv3_0/b1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 256
input_layers = conv2_1/generated_out_0(0)
kernel_size = 1,1
name = conv3_0/b1
padding = same
stride = 2,2
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv3_0/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 256
input_layers = conv2_1/generated_out_0(1)
kernel_size = 3,3
name = conv3_0/a1
padding = same
stride = 2,2
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv3_0/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv3_0/a1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv3_0/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv3_0/a2/activation_realized]
activation = relu
input_layers = conv3_0/a2(0)
name = conv3_0/a2/activation_realized
trainable = true
type = activation

[conv3_0/a3]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 256
input_layers = conv3_0/a2/activation_realized(0)
kernel_size = 3,3
name = conv3_0/a3
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv3_0/c1]
input_layers = conv3_0/a3(0),conv3_0/b1(0)
name = conv3_0/c1
trainable = true
type = addition

[conv3_0]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv3_0/c1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv3_0
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv3_0/activation_realized]
activation = relu
input_layers = conv3_0(0)
name = conv3_0/activation_realized
trainable = true
type = activation

[conv3_0/generated_out_0]
input_layers = conv3_0/activation_realized(0)
name = conv3_0/generated_out_0
trainable = true
type = multiout

[conv3_1/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 256
input_layers = conv3_0/generated_out_0(0)
kernel_size = 3,3
name = conv3_1/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv3_1/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv3_1/a1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv3_1/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv3_1/a2/activation_realized]
activation = relu
input_layers = conv3_1/a2(0)
name = conv3_1/a2/activation_realized
trainable = true
type = activation

[conv3_1/a3]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 256
input_layers = conv3_1/a2/activation_realized(0)
kernel_size = 3,3
name = conv3_1/a3
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv3_1/c1]
input_layers = conv3_1/a3(0),conv3_0/generated_out_0(1)
name = conv3_1/c1
trainable = true
type = addition

[conv3_1]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv3_1/c1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv3_1
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv3_1/activation_realized]
activation = relu
input_layers = conv3_1(0)
name = conv3_1/activation_realized
trainable = true
type = activation

[conv3_1/generated_out_0]
input_layers = conv3_1/activation_realized(0)
name = conv3_1/generated_out_0
trainable = true
type = multiout

[conv4_0/b1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 512
input_layers = conv3_1/generated_out_0(0)
kernel_size = 1,1
name = conv4_0/b1
padding = same
stride = 2,2
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv4_0/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 512
input_layers = conv3_1/generated_out_0(1)
kernel_size = 3,3
name = conv4_0/a1
padding = same
stride = 2,2
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv4_0/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv4_0/a1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv4_0/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv4_0/a2/activation_realized]
activation = relu
input_layers = conv4_0/a2(0)
name = conv4_0/a2/activation_realized
trainable = true
type = activation

[conv4_0/a3]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 512
input_layers = conv4_0/a2/activation_realized(0)
kernel_size = 3,3
name = conv4_0/a3
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv4_0/c1]
input_layers = conv4_0/a3(0),conv4_0/b1(0)
name = conv4_0/c1
trainable = true
type = addition

[conv4_0]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv4_0/c1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv4_0
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv4_0/activation_realized]
activation = relu
input_layers = conv4_0(0)
name = conv4_0/activation_realized
trainable = true
type = activation

[conv4_0/generated_out_0]
input_layers = conv4_0/activation_realized(0)
name = conv4_0/generated_out_0
trainable = true
type = multiout

[conv4_1/a1]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 512
input_layers = conv4_0/generated_out_0(0)
kernel_size = 3,3
name = conv4_1/a1
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv4_1/a2]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv4_1/a1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv4_1/a2
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv4_1/a2/activation_realized]
activation = relu
input_layers = conv4_1/a2(0)
name = conv4_1/a2/activation_realized
trainable = true
type = activation

[conv4_1/a3]
bias_decay = 0.000000
bias_initializer = zeros
dilation = 1,1
disable_bias = false
filters = 512
input_layers = conv4_1/a2/activation_realized(0)
kernel_size = 3,3
name = conv4_1/a3
padding = same
stride = 1,1
trainable = true
type = conv2d
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[conv4_1/c1]
input_layers = conv4_1/a3(0),conv4_0/generated_out_0(1)
name = conv4_1/c1
trainable = true
type = addition

[conv4_1]
beta_initializer = zeros
bias_decay = 0.000000
epsilon = 0.001000
gamma_initializer = ones
input_layers = conv4_1/c1(0)
momentum = 0.990000
moving_mean_initializer = zeros
moving_variance_initializer = ones
name = conv4_1
trainable = true
type = batch_normalization
weight_decay = 0.000000

[conv4_1/activation_realized]
activation = relu
input_layers = conv4_1(0)
name = conv4_1/activation_realized
trainable = true
type = activation

[last_p1]
input_layers = conv4_1/activation_realized(0)
name = last_p1
padding = valid
pool_size = 4,4
pooling = average
stride = 1,1
trainable = true
type = pooling2d

[last_f1]
input_layers = last_p1(0)
name = last_f1
target_shape = 1:1:1:512
trainable = true
type = flatten

[fully_connected0]
bias_decay = 0.000000
bias_initializer = zeros
disable_bias = false
input_layers = last_f1(0)
name = fully_connected0
trainable = true
type = fully_connected
unit = 100
weight_decay = 0.000000
weight_initializer = xavier_uniform
weight_regularizer = none
weight_regularizer_constant = 1.000000

[fully_connected0/activation_realized]
activation = softmax
input_layers = fully_connected0(0)
name = fully_connected0/activation_realized
trainable = true
type = activation

