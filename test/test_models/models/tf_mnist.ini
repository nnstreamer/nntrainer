# Network Section : Network
[Model]
Type = NeuralNetwork	                # Network Type : Regression, KNN, NeuralNetwork
Epochs = 1		                        # Epochs
Loss = mse 		                        # Loss function : mse (mean squared error)
                                        # cross ( for cross entropy )
; Save_Path = "mnist_tf_test.bin" 	    # model path to save / read
batch_size = 1		                    # batch size
memory_optimization = true

[Optimizer]
Type = adam

[LearningRateScheduler]
type=constant
Learning_rate = 1e-4 	  # Learning Rate

# Layer Section : Name
[inputlayer]
Type = input
Input_Shape = 1:1:28:28

# Layer Section : Name
[conv2d_c1_layer]
Type = conv2d
input_layers = inputlayer
kernel_size = 5,5
bias_initializer=zeros
Activation=relu
weight_initializer = xavier_uniform
filters = 6
stride = 1,1
padding = same

[pooling2d_p1]
Type=pooling2d
input_layers = conv2d_c1_layer
pool_size = 2,2
stride =2,2
padding = same
pooling = average

[conv2d_c2_layer]
Type = conv2d
input_layers = pooling2d_p1
kernel_size = 5,5
bias_initializer=zeros
Activation=relu
weight_initializer = xavier_uniform
filters = 12
stride = 1,1
padding = same

[pooling2d_p2]
Type=pooling2d
input_layers = conv2d_c2_layer
pool_size = 2,2
stride =2,2
padding = same
pooling = average

[flatten]
Type=flatten
input_layers = pooling2d_p2

[outputlayer]
Type = fully_connected
input_layers = flatten
Unit = 10		                         # Output Layer Dimension ( = Weight Width )
weight_initializer = xavier_uniform
bias_initializer = zeros
Activation = softmax                    # activation : sigmoid, softmax
