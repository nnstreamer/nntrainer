/home/donghak/workspace/nntrainer/Applications/CausalLM/res/ernie-21b-a3b
/home/donghak/workspace/nntrainer/Applications/CausalLM/res/ernie-21b-a3b/ernie-21b-q6k-q40-x86.bin
vocab size : 103424
1
input token id : 
4, 
 ================================================
layer0_wq's input 
<N9nntrainer6TensorE at 0x5d72fa7c33b0>
data addr: 0x710ce3dd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0390968 0.011421 0.009617670.00688766 -0.014032 -0.00682504 -0.0458092 0.0170063 -0.0140508]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5d72fb0f35e0>
data addr: 0x710ce47d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.37266 -1.35065 1.5629-0.115576 1.02755 1.20341 -0.821475 -0.998549 1.11229]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5d72fa6b3d10>
data addr: 0x710ce3dd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0390968 0.011421 0.009617670.00688766 -0.014032 -0.00682504 -0.0458092 0.0170063 -0.0140508]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5d72faa006b0>
data addr: 0x710ce51d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.41955 0.0621528 -0.176475-1.60675 0.483507 -1.27642 -2.29036 1.10468 0.322717]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5d72fd3c2b00>
data addr: 0x710ce3dd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0390968 0.011421 0.009617670.00688766 -0.014032 -0.00682504 -0.0458092 0.0170063 -0.0140508]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5d72fa7a60d0>
data addr: 0x710ce53d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.053305 0.00771223 -0.0100112-0.0486309 -0.00931963 -0.0100265 0.00694275 -0.0454739 -0.0127418]
============================
/home/donghak/workspace/nntrainer/Applications/CausalLM/res/ernie-21b-a3b
/home/donghak/workspace/nntrainer/Applications/CausalLM/res/ernie-21b-a3b/ernie-21b-q6k-q40-x86.bin
vocab size : 103424
1
input token id : 
4, 
 ================================================
layer0_wq's input 
<N9nntrainer6TensorE at 0x5682dde663b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0390968 0.011421 0.009617670.00688766 -0.014032 -0.00682504 -0.0458092 0.0170063 -0.0140508]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5682de7965e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.37266 -1.35065 1.5629-0.115576 1.02755 1.20341 -0.821475 -0.998549 1.11229]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5682ddd56d10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0390968 0.011421 0.009617670.00688766 -0.014032 -0.00682504 -0.0458092 0.0170063 -0.0140508]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5682de0a36b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.41955 0.0621528 -0.176475-1.60675 0.483507 -1.27642 -2.29036 1.10468 0.322717]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5682e0a65b00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0390968 0.011421 0.009617670.00688766 -0.014032 -0.00682504 -0.0458092 0.0170063 -0.0140508]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5682dde490d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.053305 0.00771223 -0.0100112-0.0486309 -0.00931963 -0.0100265 0.00694275 -0.0454739 -0.0127418]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.37266 -1.35065 1.5629-0.115576 1.02755 1.20341 -0.821475 -0.998549 1.11229]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a259e120
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer0_attention_out's input 
<N9nntrainer6TensorE at 0x5682e0a64030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer0_attention_out's output 
<N9nntrainer6TensorE at 0x5682e0a638e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer0_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dde13420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0248771 0.00710773 0.007107730.00444233 -0.0079962 -0.00444233 -0.0275425 0.0124385 -0.0106616]

layer0_ffn_gate's input 
<N9nntrainer6TensorE at 0x5682ddfb82c0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.174621 0.0494909 0.04868950.0294291 -0.0554519 -0.0286777 -0.191777 0.0859079 -0.071832]
==============================
layer0_ffn_gate's output 
<N9nntrainer6TensorE at 0x5682dde852c0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.132286 0.0132908 -0.03649170.151055 0.050984 0.218058 0.0435897 0.100621 0.0251803]
============================
layer0_ffn_up's input 
<N9nntrainer6TensorE at 0x5682de34f990>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.174621 0.0494909 0.04868950.0294291 -0.0554519 -0.0286777 -0.191777 0.0859079 -0.071832]
==============================
layer0_ffn_up's output 
<N9nntrainer6TensorE at 0x5682dde690c0>
data addr: 0x7fc0a7fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.103681 -0.113098 -0.1742640.0172123 -0.325196 -0.114223 -0.140906 -0.224046 -0.0604897]
============================
layer0_ffn_down's input 
<N9nntrainer6TensorE at 0x5682dc3e1140>
data addr: 0x7fc0aafd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[0.00640485 -0.000756571 0.003121590.001398 -0.00850118 -0.0138061 -0.00313796 -0.0118386 -0.000771161]
==============================
layer0_ffn_down's output 
<N9nntrainer6TensorE at 0x5682dc3e0770>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.140574 -0.02972 -0.04167140.040287 0.0439178 0.016722 0.0584707 0.0626124 0.00110611]
============================
layer0_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3e1bb0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.165451 -0.0226122 -0.03456370.0447294 0.0359216 0.0122797 0.0309282 0.075051 -0.00955549]

layer1_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e48b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.210349 -0.0276757 -0.03590870.0606868 0.0344225 0.0104274 0.0357997 0.073343 -0.0134178]
==============================
layer1_wq's output 
<N9nntrainer6TensorE at 0x5682dc3e2330>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.90796 1.8688 1.77724-0.88751 2.99915 0.762249 -0.880532 1.59703 1.4623]
============================
layer1_wk's input 
<N9nntrainer6TensorE at 0x5682dc3e6610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.210349 -0.0276757 -0.03590870.0606868 0.0344225 0.0104274 0.0357997 0.073343 -0.0134178]
==============================
layer1_wk's output 
<N9nntrainer6TensorE at 0x5682dc3e6380>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.97697 0.793183 1.41371.96941 -0.0557459 1.77157 -2.11228 -0.0798004 1.47466]
============================
layer1_wv's input 
<N9nntrainer6TensorE at 0x5682dc3e7400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.210349 -0.0276757 -0.03590870.0606868 0.0344225 0.0104274 0.0357997 0.073343 -0.0134178]
==============================
layer1_wv's output 
<N9nntrainer6TensorE at 0x5682dc3e7190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.123531 0.115138 -0.0230383-0.103703 -0.0200799 0.0957974 -0.0328801 -0.00549203 0.135476]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.90796 1.8688 1.77724-0.88751 2.99915 0.762249 -0.880532 1.59703 1.4623]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a34c3998
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer1_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ea340>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer1_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ea2a0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer1_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3eb440>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.165451 -0.0226122 -0.03456370.0447294 0.0359216 0.0122797 0.0309282 0.075051 -0.00955549]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.195436 -0.0832416 -0.1213350.194367 0.128829 0.0556904 0.135569 0.311886 -0.0271982]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7817794681 -0.2843957543 0.1236723661 -0.009888570756 1.568264842 -0.6377072334 -0.3560228348 1.870408416 1.380344152 0.8260735273 -0.3570490777 -0.3026487231 0.06771949679 -0.2899051905 -0.576308012 1.029055476 0.1707009673 0.1788969934 1.030142665 0.1924364865 -0.2107731998 -0.1875340194 0.8709299564 -0.6714256406 -0.3029053807 -0.3551596105 -0.7869133949 -1.098073959 -1.253934383 3.185444832 -0.079467237 -0.1758170575 -0.8292342424 -1.084969163 -0.9093784094 -0.0822493881 -0.478249073 -0.497797966 0.1200062633 -1.164438725 -0.4674391448 -1.687569618 0.8551266193 -0.07146995515 -0.07996142656 -0.02397076413 -0.176510334 0.3934653699 -0.01867367327 -0.3603721261 -0.9061475396 -0.5649647713 0.076642178 -0.1817573607 -0.3263569474 -0.4952473938 0.1547974646 -0.1174689457 0.5314019918 -0.01213094406 2.358139753 -0.7334964871 -0.2152439356 -0.1919798553 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.004377963487 0.007199182641 0.01082692016 0.009473273531 0.04590747878 0.005056405906 0.00670155976 0.06210158765 0.03804262727 0.02185515501 0.006694686599 0.007068966981 0.01023775712 0.00715962844 0.005376594607 0.0267736651 0.01134825777 0.01144164894 0.02680278942 0.0115976166 0.007749202661 0.007931395434 0.02285781503 0.004888754804 0.007067154162 0.006707348395 0.004355545156 0.003190855961 0.002730347216 0.2313213795 0.008836544119 0.008024876006 0.00417506136 0.003232947085 0.0038535106 0.008811994456 0.005930532701 0.005815723445 0.01078729983 0.002985969419 0.005994989071 0.001769670867 0.02249942534 0.008907495998 0.008832178079 0.00934080407 0.008019314148 0.0141799422 0.009390415624 0.006672476418 0.003865981707 0.005437929649 0.0103295166 0.007977345958 0.006903346628 0.005830575712 0.01116920821 0.008507042192 0.01627719961 0.009452055208 0.1011397243 0.00459453091 0.007714636624 0.007896212861 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
62.86045074 62.86231613 62.86689758 62.86363602 62.90007019 62.86017609 62.86182022 62.91722107 62.89316177 62.8769722 62.86181259 62.86218643 62.86535645 62.86227798 62.86049271 62.87998581 62.86646652 62.86655807 62.88191986 62.86671448 62.86286545 62.86304855 62.87320709 62.86096191 62.86218643 62.86182404 62.85947418 62.85926056 62.85594177 63.08548737 62.86490631 62.86314392 62.86024475 62.85834885 62.85992432 62.86392975 62.86104965 62.85902786 62.86590576 62.85810471 62.8611145 62.85784149 62.87570953 62.86402512 62.86394882 62.86445999 62.86122894 62.86929703 62.86355591 62.8617897 62.85898209 62.86055756  62.865448 62.86309433 62.8620224 62.85999298 62.86533356 62.86362457 62.87139511 62.86457062 62.95625687 62.85971069 62.86283112 62.86301422 

-------
======================
selected experts : 4, 7, 8, 18, 29, 60, 
layer1_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e0a3ef10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0527855 -0.0351481 0.00184116-0.00732021 -0.0186702 -0.0317964 -0.0359847 -0.000147288 0.0521691]

layer1_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3ee080>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.112666 -0.0577603 -0.03272250.0374092 0.0172514 -0.0195167 -0.00505648 0.0749037 0.0426136]

layer2_wq's input 
<N9nntrainer6TensorE at 0x5682dc3ee2c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.421751 -0.16164 -0.08205850.116924 0.0385592 -0.0610003 -0.0147935 0.208254 0.113057]
==============================
layer2_wq's output 
<N9nntrainer6TensorE at 0x5682dc3ee260>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.525385 0.306824 -1.095070.66499 -0.573709 0.5654 1.0104 0.18883 -0.0691185]
============================
layer2_wk's input 
<N9nntrainer6TensorE at 0x5682dc3edf00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.421751 -0.16164 -0.08205850.116924 0.0385592 -0.0610003 -0.0147935 0.208254 0.113057]
==============================
layer2_wk's output 
<N9nntrainer6TensorE at 0x5682dc3ede70>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.25082 -1.00542 0.404725-2.00867 -0.179249 -1.75783 -1.15584 1.59573 -1.4719]
============================
layer2_wv's input 
<N9nntrainer6TensorE at 0x5682dc3ee380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.421751 -0.16164 -0.08205850.116924 0.0385592 -0.0610003 -0.0147935 0.208254 0.113057]
==============================
layer2_wv's output 
<N9nntrainer6TensorE at 0x5682dc3ee3b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0925847 -0.194358 0.00919470.325599 0.161226 0.062639 0.450223 0.356985 -0.406541]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.525385 0.306824 -1.095070.66499 -0.573709 0.5654 1.0104 0.18883 -0.0691185]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0855838
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer2_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ee500>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer2_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ee620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer2_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3fefb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.112666 -0.0577603 -0.03272250.0374092 0.0172514 -0.0195167 -0.00505648 0.0749037 0.0426136]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.188355 -0.224616 -0.1218990.157712 0.0652057 -0.0836981 -0.0211336 0.308978 0.143258]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5393598676 0.3065061271 1.632752776 0.01977047324 -0.1364536285 0.9332344532 -0.4155723453 0.3021198511 -0.679473877 0.4863083661 -0.09480930865 -0.1530562937 0.4645893276 -0.01566750929 -0.4507685006 0.4203961492 -0.7026180029 -0.369237572 -0.4716656804 1.100968719 0.1638905555 -0.2328214794 0.4180307388 0.1102633178 -0.3306826949 -0.1520757973 -0.1885959208 0.001360251568 -1.467154622 0.06844066828 0.4022039771 0.3606787324 0.44662413 0.559935987 -0.09121275693 0.03920219839 0.01415581256 -0.6673025489 0.9213477969 0.118910104 0.06186952442 -0.3433542848 -0.3906027079 0.9744204283 -0.2279674262 1.084323525 0.2476737797 -0.7137119174 0.04825887084 0.43885988 -0.8921022415 -0.7601677179 -0.6774482131 -0.5039997101 1.463033319 -0.869222343 -0.6102601886 -0.4081148803 -0.4463916123 0.5802536011 -0.6460955739 0.08627721667 -0.7295505404 -0.123994641 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007652105298 0.01782936789 0.06716105342 0.01338468585 0.01144882478 0.03336726129 0.008660464548 0.01775133237 0.006651661824 0.02134140395 0.01193567086 0.01126031298 0.02088288777 0.01291866507 0.008360950276 0.01998010464 0.006499483716 0.009071188048 0.008188043721 0.03946086764 0.01545961853 0.01039702073 0.01993289776 0.01465239935 0.009427756071 0.0112713594 0.01086715329 0.0131405266 0.00302583212 0.01405223459 0.01961990632 0.01882187091 0.02051107213 0.0229720138 0.01197867561 0.01364731696 0.01330974698 0.006733117625 0.03297298402 0.01477964409 0.01396019757 0.009309044108 0.00887943618 0.03477021679 0.01044761203 0.03880947083 0.01681068167 0.006427777931 0.01377147809 0.02035243623 0.005377579946 0.006135999691 0.006665151101 0.007927525789 0.05667731538 0.005502037704 0.007128356025 0.008725292049 0.008397625759 0.02344352566 0.006877430249 0.01430512778 0.006326772738 0.01159235928 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
53.42141342 53.43159103 53.4809227 53.42714691 53.42520905 53.44522095 53.4224205 53.43151093 53.42041397 53.43510437 53.42569733 53.4221611 53.43464279 53.42668152 53.42212296 53.43374252 53.41930771 53.42283249 53.42194748 53.45226669 53.42922211 53.42225266 53.43369293 53.42745972 53.42318726 53.42503357 53.42367554 53.42690277 53.41678619 53.42781448 53.43338013 53.43258286 53.43427277 53.43673325 53.42573929 53.42741013 53.42707062 53.41954041 53.44673538 53.42853928 53.42772293  53.423069 53.42264175 53.4485321 53.42420959 53.45257187 53.43057251 53.4201889 53.42467117 53.43411255 53.41913986 53.41799164 53.42042542 53.42168808 53.46948624 53.41926193 53.42089081 53.42248535 53.42120361 53.43720627 53.41968536 53.42711258 53.42008972  53.425354 

-------
======================
selected experts : 2, 5, 19, 43, 45, 54, 
layer2_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e09f8dd0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0389339 -0.0123542 0.0364094-0.0268617 0.0143552 0.0652299 0.0226236 -0.00810289 -0.00843483]

layer2_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc401970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0737316 -0.0701145 0.003686880.0105475 0.0316066 0.0457132 0.0175671 0.0668008 0.0341788]

layer3_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e86c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.368104 -0.2105 0.01063360.0288196 0.079964 0.116424 0.0468147 0.178018 0.114719]
==============================
layer3_wq's output 
<N9nntrainer6TensorE at 0x5682dc409160>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.192372 -0.499486 1.39592-0.67761 -0.0516295 1.28197 -2.10971 0.452767 0.468927]
============================
layer3_wk's input 
<N9nntrainer6TensorE at 0x5682dc41f6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.368104 -0.2105 0.01063360.0288196 0.079964 0.116424 0.0468147 0.178018 0.114719]
==============================
layer3_wk's output 
<N9nntrainer6TensorE at 0x5682dc41f440>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[3.29492 0.373159 1.512861.00895 -2.08491 0.0940608 0.386318 1.15527 0.213131]
============================
layer3_wv's input 
<N9nntrainer6TensorE at 0x5682dc4204c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.368104 -0.2105 0.01063360.0288196 0.079964 0.116424 0.0468147 0.178018 0.114719]
==============================
layer3_wv's output 
<N9nntrainer6TensorE at 0x5682dc420250>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.169668 -0.0947111 -0.0942688-0.247212 0.16223 -0.00522964 0.0521958 -0.068851 -0.504399]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.192372 -0.499486 1.39592-0.67761 -0.0516295 1.28197 -2.10971 0.452767 0.468927]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a16788a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer3_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc422910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer3_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc422870>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer3_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc423990>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0737316 -0.0701145 0.003686880.0105475 0.0316066 0.0457132 0.0175671 0.0668008 0.0341788]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.139282 -0.280273 0.01417810.0451862 0.122611 0.197382 0.0743701 0.273787 0.11933]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.010005713 0.1733671278 0.5382600427 0.2063477635 0.6173712015 0.3004335165 1.133434772 0.8312776089 -0.3091078997 -0.3217302859 0.6968637109 0.366424948 0.5123087168 -0.4017805457 0.2144218981 0.3034566641 -0.9765267372 -0.07306501269 0.4197853506 -0.4801820219 0.9144462347 0.04692407697 -0.1224423274 -0.03427955136 0.04719026387 0.05534995347 0.4272965193 -0.6981166005 0.2038174123 -0.412535727 -0.2734984159 0.3085193932 -0.3308204412 -0.2442800999 0.9073200226 -0.4978688955 -0.09799677134 0.8228957653 -1.062630892 0.8692058325 0.2227101475 0.07652042806 -0.6768066883 -0.1163792089 -0.3334343135 -1.343546033 -0.7751011252 -0.7504715919 0.4988332987 0.4361985326 -0.2130984068 0.4295841753 -0.4224520326 0.2586997449 0.8273189068 -0.6868230104 -0.3298393488 -0.1501202881 -0.0948086828 -0.02141787112 0.5860110521 -0.01965791732 -0.3426232934 0.1900829375 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.004887925927 0.01596088149 0.02298941463 0.01649605855 0.02488200925 0.01812346093 0.04168780148 0.03081653453 0.009851914831 0.009728342295 0.02694068104 0.0193597991 0.02240048163 0.008979939856 0.01662978902 0.0181783326 0.005054338835 0.01247477625 0.0204209052 0.008302791044 0.03348909691 0.01406511851 0.01187376585 0.01296812203 0.01406886242 0.01418412942 0.02057486773 0.006676922552 0.01645437256 0.008883877657 0.01020905841 0.01827059872 0.00964030996 0.01051175036 0.03325129673 0.008157231845 0.01216760464 0.03055931441 0.004637348931 0.03200779855 0.01676819474 0.01448761672 0.006820734125 0.01194597688 0.009615144692 0.003501627361 0.006182190031 0.006336345337 0.02210064977 0.02075884305 0.01084468793 0.02062198892 0.008796217851 0.01738266647 0.03069478273 0.006752755959 0.009649773128 0.01154963113 0.01220645662 0.01313599199 0.02411381155 0.01315912977 0.009527196176 0.01622992381 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
42.54010773 42.5473671 42.55821228 42.55171585 42.5591507 42.55334473 42.57309341 42.5669899 42.54507446 42.54590225 42.56120682 42.55458069 42.55475998 42.5442009 42.55184937 42.55339813 42.54027557 42.54674149 42.55659485 42.54161835 42.56871033 42.55023956 42.54804993 42.54819107 42.5492897 42.54940414 42.55579758 42.54189682 42.55167389 42.54410553 42.54542923 42.5534935 42.54199982 42.54573441 42.56847382 42.54337692 42.54738998 42.56578064 42.53985977 42.56723022 42.55199051 42.54970932 42.54299545 42.54716873 42.5429306 42.53872299 42.54140472 42.54155731 42.55827713 42.55598068 42.54701996 42.55584335 42.54306412 42.55260468 42.56591415 42.54101944 42.54487228 42.54772568 42.54647446 42.54454422 42.5593338 42.54838181 42.5447464 42.55145264 

-------
======================
selected experts : 6, 7, 20, 34, 39, 54, 
layer3_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc426710>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.110848 0.0367942 0.0224334-0.0480031 0.0232495 -0.0144183 -0.0164468 0.00230735 0.0182626]

layer3_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc426050>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0371165 -0.0333203 0.0261203-0.0374556 0.0548562 0.031295 0.00112032 0.0691082 0.0524413]

layer4_wq's input 
<N9nntrainer6TensorE at 0x5682dc44b9a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.103166 -0.105315 0.0813137-0.12493 0.153344 0.105376 0.00362996 0.231602 0.173247]
==============================
layer4_wq's output 
<N9nntrainer6TensorE at 0x5682dc492890>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187916 0.338662 -0.8289350.562296 0.803585 -0.216635 0.731176 0.327018 0.455132]
============================
layer4_wk's input 
<N9nntrainer6TensorE at 0x5682dc44d700>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.103166 -0.105315 0.0813137-0.12493 0.153344 0.105376 0.00362996 0.231602 0.173247]
==============================
layer4_wk's output 
<N9nntrainer6TensorE at 0x5682dc44d470>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.352055 -1.04343 1.10334-0.227808 -1.28097 0.394795 -1.00643 -0.546746 -0.402952]
============================
layer4_wv's input 
<N9nntrainer6TensorE at 0x5682dc44e4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.103166 -0.105315 0.0813137-0.12493 0.153344 0.105376 0.00362996 0.231602 0.173247]
==============================
layer4_wv's output 
<N9nntrainer6TensorE at 0x5682dc44e280>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.392109 0.23975 0.06126490.333475 1.30311 0.115465 -0.280677 -0.352487 0.101133]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.187916 0.338662 -0.8289350.562296 0.803585 -0.216635 0.731176 0.327018 0.455132]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1e8c8e8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer4_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc450940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer4_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4508a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer4_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4519c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0371165 -0.0333203 0.0261203-0.0374556 0.0548562 0.031295 0.00112032 0.0691082 0.0524413]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0748688 -0.139715 0.104961-0.166573 0.230017 0.141164 0.00508906 0.298557 0.199068]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.8132423759 -0.06724674255 2.456307173 -0.2669496834 -0.7029411197 -0.01731226593 -1.094008684 -0.4773612618 0.5170549154 -0.7154075503 0.9468927979 -0.5813125968 -1.240051985 -0.1634942591 -0.7149249315 -0.2245002091 -0.2141408026 0.1285609305 0.4554028511 -0.2685112059 -0.2016077638 -0.9045439363 -0.04722516984 0.02510893345 -0.4794512689 0.09292164445 0.2698838711 -1.06320703 -0.6373182535 -0.8138420582 -0.3803229034 0.4733799696 -0.1758622229 -0.3690091968 1.643751383 -0.2983230948 0.1740457416 -0.3480183184 0.2149201781 -0.7591479421 1.377782583 -0.9262016416 0.3878186643 -0.8201656342 -0.2348257005 0.5954198241 -0.573725462 0.03818821907 -0.7397670746 1.456204534 -0.2540842295 3.005970955 -0.477173686 -0.6264100671 0.08972050995 -0.07830742002 0.2005089223 -0.05552828312 -1.052940011 -0.9087193608 -0.3655261397 -0.8506566882 -1.973542213 -0.5016500354 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.02370375022 0.009827102534 0.1225719303 0.008048141375 0.005204115063 0.01033027098 0.003519723658 0.006521012634 0.01762724854 0.005139640998 0.02709322236 0.00587718701 0.003041462973 0.008925357834 0.005142122973 0.008397135884 0.008484576829 0.01195263676 0.01657331176 0.008035583422 0.00859158393 0.004253945779 0.01002583839 0.01077792142 0.006507398095 0.01153415442 0.01376700401 0.003629822517 0.005557079334 0.004657825921 0.007185519673 0.01687394828 0.008815649897 0.007267276756 0.05438793078 0.007799562998 0.01250885334 0.007421434857 0.0130307395 0.004919677507 0.04168633744 0.004162805621 0.01549022831 0.00462846458 0.008310877718 0.0190641731 0.00592194777 0.01091981586 0.005015954841 0.04508706555 0.008152354509 0.2123767436 0.006522234529 0.005618028808 0.01149728987 0.009719006717 0.01284429431 0.009942939505 0.003667282639 0.004236220848 0.007292632479 0.004489467479 0.001460601925 0.006364532281 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
 40.841362 40.82748413 40.93927383 40.82666016 40.82381439 40.82894135 40.82213211 40.82322311 40.83147049 40.82374954 40.84474945 40.82448959 40.82165146 40.82658386 40.82375336 40.82700729 40.82518768 40.82865524  40.835186 40.8266449 40.82624817 40.82286453 40.82577515 40.82748032 40.82416534 40.83014679 40.82951736 40.82033539 40.82416916 40.82326889 40.82579803 40.83548355 40.82742691 40.82587814 40.87299728 40.82450485 40.82825851 40.82316971 40.83164215 40.82162476 40.85934448 40.82277298 40.83410263 40.8222847 40.82692337 40.8338623 40.82453156 40.82857895 40.8226738 40.85606766 40.82580948 41.02812576 40.82513428 40.82327652 40.82915497 40.82833099 40.83145523 40.82855225 40.81941605 40.82284546 40.82590485 40.82310104 40.82007217 40.82497406 

-------
======================
selected experts : 2, 10, 34, 40, 49, 51, 
layer4_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc454a40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0932778 -0.0183288 0.004022710.114314 0.0293998 -0.0807807 0.0457271 0.0444447 0.0303181]

layer4_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc454380>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.130394 -0.0516491 0.0301430.0768581 0.0842559 -0.0494857 0.0468474 0.113553 0.0827595]

layer5_wq's input 
<N9nntrainer6TensorE at 0x5682dc4a0910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.268001 -0.145703 0.07531580.205461 0.189018 -0.140265 0.127752 0.327962 0.222349]
==============================
layer5_wq's output 
<N9nntrainer6TensorE at 0x5682dc454560>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.379054 -0.973061 -0.8766771.30107 -0.789984 -0.254401 1.11626 0.70609 -1.36618]
============================
layer5_wk's input 
<N9nntrainer6TensorE at 0x5682dc4a2670>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.268001 -0.145703 0.07531580.205461 0.189018 -0.140265 0.127752 0.327962 0.222349]
==============================
layer5_wk's output 
<N9nntrainer6TensorE at 0x5682dc4a23e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.64257 0.503956 -1.74353-0.982877 -0.229747 -1.67854 -0.345354 0.854065 -1.60261]
============================
layer5_wv's input 
<N9nntrainer6TensorE at 0x5682dc4a3460>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.268001 -0.145703 0.07531580.205461 0.189018 -0.140265 0.127752 0.327962 0.222349]
==============================
layer5_wv's output 
<N9nntrainer6TensorE at 0x5682dc4a31f0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.157558 0.265959 0.380002-0.241391 -0.0792118 -0.0626539 -0.0112686 -0.427132 -0.265216]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.379054 -0.973061 -0.8766771.30107 -0.789984 -0.254401 1.11626 0.70609 -1.36618]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1c878d8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer5_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc4a58b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer5_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4a5810>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer5_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a6930>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.130394 -0.0516491 0.0301430.0768581 0.0842559 -0.0494857 0.0468474 0.113553 0.0827595]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.248733 -0.197046 0.1101390.311805 0.305598 -0.199429 0.188796 0.448469 0.289053]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1722858697 -0.2472653985 -1.086831808 0.6700445414 -0.8990160227 0.5276929736 0.6937334538 -0.02306292951 -0.4161561728 0.3043164015 3.171190977 -0.453109175 -0.1277999431 0.3210380375 -0.7312656045 -0.7448005676 -0.007326574996 2.327578306 -0.7059780955 -0.7231946588 0.3921387494 -1.577430964 -0.6240006089 0.3936064839 -0.04840561748 -1.128615499 -0.4111546874 -0.5024377704 -0.09568846971 -1.356244564 0.5840353966 -0.6074923873 0.7982002497 -0.2665049434 -0.1423997581 -0.4879265428 -0.8135122061 0.03372339532 -0.1080175862 0.583243072 -0.8655079603 -1.65727067 -0.4935808182 -0.3709255457 -0.7069357634 -0.7296361923 -1.200747728 -0.8280388713 -0.7166796923 -0.2008628696 -0.2497996688 -1.277897477 0.284250319 -0.8644000292 -0.123164162 1.564619064 -0.2715055645 -0.5201078653 0.0818176046 -1.176019669 -1.068121195 -0.4056496918 -0.09066803753 0.1686960608 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01336081978 0.008782625198 0.003793196054 0.02197895572 0.00457691215 0.01906270534 0.02250582725 0.01098991279 0.007417816203 0.01524660829 0.2680656016 0.00714870682 0.009897089563 0.01550370175 0.005412846804 0.005340077914 0.01116422191 0.1153094098 0.005551469047 0.0054567107 0.01664615981 0.002322420245 0.006025739945 0.01667060889 0.01071489882 0.003637967398 0.007455007639 0.006804627366 0.01022005733 0.002897349652 0.02016757615 0.00612603873 0.02498413622 0.008615266532 0.009753643535 0.006904091686 0.004985474981 0.01163204946 0.01009482704 0.02015160397 0.004732875619 0.002144207712 0.006865164265 0.007761030458 0.005546156317 0.005421673879 0.003384793876 0.004913575016 0.005492376164 0.009199763648 0.00876039546 0.003133476712 0.01494371798 0.004738120828 0.009943077341 0.05376699567 0.008572291583 0.006685445085 0.01220515464 0.003469536081 0.003864837112 0.007496161386 0.01027149707 0.01331294607 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.25122833 33.24855804 33.24547577 33.26366425 33.24435425 33.2569313 33.26419067 33.24599838 33.24814987 33.2569313 33.50879669 33.24787903 33.25157928 33.25432587 33.24709702 33.24702454 33.25284958 33.34841156 33.24723434 33.24713898 33.24879456 33.24400711 33.24771118 33.25835419 33.24763107 33.24532318 33.24913788 33.24848938 33.25190353 33.24362946 33.26185226 33.24590302 33.26094437 33.25029755 33.25143814 33.24763489 33.24666977 33.25331497 33.24796295 33.25897598  33.246418 33.24382782 33.24759674 33.24944687 33.24532318 33.24710464 33.2450676 33.24564362 33.24622345 33.25088501 33.24853516 33.24481583 33.25281143 33.24546814 33.24876785 33.29163742 33.25025558 33.24360275 33.25389099 33.24515533 33.24554825 33.24441147 33.25004959 33.24832153 

-------
======================
selected experts : 3, 6, 10, 17, 32, 55, 
layer5_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc4a9a10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.072616 -0.063843 -0.04593020.02907 -0.0355848 0.0744575 -0.078752 -0.0216349 0.0929583]

layer5_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a9350>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.20301 -0.115492 -0.01578720.105928 0.0486711 0.0249717 -0.0319046 0.091918 0.175718]

layer6_wq's input 
<N9nntrainer6TensorE at 0x5682dc4e8620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.680335 -0.406256 -0.05478260.380166 0.145756 0.083686 -0.103887 0.290561 0.559636]
==============================
layer6_wq's output 
<N9nntrainer6TensorE at 0x5682dc4a9530>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.35799 -0.270979 -1.693740.501729 -0.780424 -1.86995 0.788817 1.2726 -2.17875]
============================
layer6_wk's input 
<N9nntrainer6TensorE at 0x5682dc4ea380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.680335 -0.406256 -0.05478260.380166 0.145756 0.083686 -0.103887 0.290561 0.559636]
==============================
layer6_wk's output 
<N9nntrainer6TensorE at 0x5682dc4ea0f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.13293 0.349449 -0.6148630.364376 0.223944 -1.20401 -0.255103 0.378788 -0.679097]
============================
layer6_wv's input 
<N9nntrainer6TensorE at 0x5682dc4eb170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.680335 -0.406256 -0.05478260.380166 0.145756 0.083686 -0.103887 0.290561 0.559636]
==============================
layer6_wv's output 
<N9nntrainer6TensorE at 0x5682dc4eaf00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0407917 -0.286242 -0.02386910.324638 -0.0381688 -0.0445804 0.125369 -0.399223 0.0903463]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.35799 -0.270979 -1.693740.501729 -0.780424 -1.86995 0.788817 1.2726 -2.17875]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1a828c8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer6_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc41beb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer6_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc41be10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer6_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc41cf30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.20301 -0.115492 -0.01578720.105928 0.0486711 0.0249717 -0.0319046 0.091918 0.175718]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.340167 -0.417236 -0.05515780.39779 0.168892 0.0955564 -0.122086 0.342993 0.588871]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.8331232071 -0.4195683599 -0.5091871619 -1.243418336 -0.9667362571 -0.05293739587 -0.1423278898 -1.061101079 1.616311431 0.8336926699 -0.5191482306 0.3933537304 0.1018915847 0.3617275357 -0.2046324909 -0.9576299787 -0.9153476954 -0.8131294847 -0.2887512743 0.8913898468 0.3249123693 0.1402931809 -0.8040626645 -0.1888639033 0.300464958 -0.2243929803 -0.3668664992 -1.222608089 -1.191039324 -1.542430401 0.4432680309 1.227882266 -0.7058930397 -0.04020388424 -0.2475553453 -0.7742134929 -0.01464089006 -0.3300853968 0.2997540236 -0.3901584148 -0.3087825179 -0.4847961068 -0.4299241304 -0.2754814029 -0.1626215577 -0.9159584045 0.06409667432 1.612407207 -1.123750329 -0.9844642878 -1.170946956 -0.3291932642 -0.2936621606 -0.3142455518 0.4013791382 -0.964084506 -0.4653893113 -0.757515192 0.9177049398 -0.6994716525 0.02918760292 -0.1713843942 1.254682541 -0.04540139437 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03381031752 0.009660779499 0.008832654916 0.00423856359 0.005589593668 0.01393920556 0.01274724118 0.005086254794 0.07399179786 0.03382957727 0.008745108731 0.02178009599 0.01627344266 0.02110205404 0.01197726466 0.005640725605 0.005884343293 0.006517645903 0.01101096533 0.03583885357 0.02033930458 0.01691052131 0.006577008869 0.01216762699 0.01984808967 0.01174291223 0.01018357743 0.004327693023 0.004466493148 0.003143108683 0.02289482392 0.05017540976 0.007255426608 0.01411783509 0.01147404406 0.006776287686 0.01448338106 0.01056511328 0.01983398199 0.009949123487 0.01079259533 0.00905074086 0.009561251849 0.01115805283 0.01249116007 0.005880749784 0.01566986553 0.07370348275 0.004777380731 0.005491374061 0.0045571425 0.01057454385 0.01095702313 0.01073379628 0.02195559256 0.005604435224 0.009228102863 0.006890390068 0.03679447621 0.00730216736 0.01513228193 0.01238218043 0.05153830722 0.01404464711 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.15719223 40.1330452 40.1245842 40.1276207 40.1289711 40.13732147 40.13708496 40.12846756 40.19737625 40.1572113 40.13212585 40.14230347 40.13965607 40.1435318 40.13536072 40.12902451 40.12926865 40.12990189 40.13439178 40.15922165 40.14372253 40.14029312 40.12995911 40.13555145 40.14323044 40.13512421 40.13452148 40.12770844 40.12784958 40.12652588 40.14341736 40.17260361 40.13063812 40.13750076 40.13485718 40.13015747 40.13786697 40.13394928 40.14321518 40.1333313 40.13417435 40.13243484 40.13198853 40.13454056 40.13587189 40.13021851 40.13809967 40.19708633 40.1272049 40.12887573 40.12794113 40.13395691 40.13433838 40.13411713 40.14247894 40.12898636 40.13165665 40.13027191 40.15826797 40.1306839 40.13851547 40.13290405 40.17491913 40.13742828 

-------
======================
selected experts : 8, 19, 31, 47, 58, 62, 
layer6_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc47b4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0851444 -0.00988513 -0.0199321-0.00964849 0.0697438 -0.063095 0.0460943 0.0790374 0.139412]

layer6_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc47ae20>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.288155 -0.125377 -0.03571930.0962795 0.118415 -0.0381232 0.0141897 0.170955 0.31513]

layer7_wq's input 
<N9nntrainer6TensorE at 0x5682dc5555c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.792839 -0.412782 -0.1125590.294341 0.33695 -0.112962 0.04338 0.488464 1.00786]
==============================
layer7_wq's output 
<N9nntrainer6TensorE at 0x5682dc47b000>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0610732 -0.390954 1.243880.359743 0.39285 -0.148613 0.661328 0.145725 0.136648]
============================
layer7_wk's input 
<N9nntrainer6TensorE at 0x5682dc557b30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.792839 -0.412782 -0.1125590.294341 0.33695 -0.112962 0.04338 0.488464 1.00786]
==============================
layer7_wk's output 
<N9nntrainer6TensorE at 0x5682dc5578a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.36549 0.247457 1.03693-0.987458 -0.665091 1.13239 0.025131 -0.465913 -0.441207]
============================
layer7_wv's input 
<N9nntrainer6TensorE at 0x5682dc558920>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.792839 -0.412782 -0.1125590.294341 0.33695 -0.112962 0.04338 0.488464 1.00786]
==============================
layer7_wv's output 
<N9nntrainer6TensorE at 0x5682dc5586b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.267755 -0.558653 0.15506-0.0486669 0.23608 -0.117349 -0.484291 0.196834 0.247247]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0610732 -0.390954 1.243880.359743 0.39285 -0.148613 0.661328 0.145725 0.136648]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a187d8b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer7_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc55ad70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer7_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc55acd0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer7_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55bdf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.288155 -0.125377 -0.03571930.0962795 0.118415 -0.0381232 0.0141897 0.170955 0.31513]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.501454 -0.483544 -0.1327190.384907 0.439984 -0.15241 0.0580624 0.667366 1.14126]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.2584476471 0.2994202971 -0.7896024585 -0.5091286302 -0.4906716943 -0.3289880157 -0.9978346229 -0.3329618275 0.4938589931 0.2607843876 -0.08542820066 -0.8094866872 -0.3819433749 -1.074421883 -1.060858965 -0.1925330609 -0.6358811259 -0.7428978086 0.3254183531 -0.02847060375 0.08462746441 -0.02331365272 0.17507644 0.7893079519 -0.3061019778 -0.5532314777 -1.212183237 -1.13897872 -0.5224350691 -0.1544954181 1.455132365 -0.4735291004 0.295297116 0.3578023016 -0.2142077535 0.1278983951 -0.5067626834 2.436692476 -0.07436158508 -0.5299661756 0.902264595 -0.5127347708 -0.5123338103 -0.07716787606 -1.413381815 0.1877791882 0.09510587156 -0.6859236956 0.4544893205 -0.523291409 1.272097468 -0.922789216 -1.210297108 -0.5086890459 -0.9009073973 -1.270249844 -0.6225808263 -0.4170702994 -0.5060836673 -1.342434168 0.1707802862 -0.6604554653 -0.5408644676 0.06382969022 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01883162558 0.01961923204 0.006602758076 0.008740447462 0.008903267793 0.01046568714 0.005361561663 0.01042418089 0.02383009158 0.01887568086 0.01335194055 0.006472765468 0.009925890714 0.004966265056 0.005034081172 0.0119958045 0.007699911017 0.006918453611 0.0201359801 0.01413451228 0.01582700014 0.01420758851 0.01732527651 0.03202119097 0.01070796605 0.008363345638 0.004327139817 0.004655788187 0.008624914102 0.01246088464 0.06231625751 0.009057207964 0.019538505 0.02079873905 0.01173859835 0.01652688533 0.008761150762 0.1662981808 0.01350052282 0.008560203016 0.03585039452 0.008708985522 0.008712477051 0.01346268784 0.003538518678 0.01754675806 0.0159937162 0.007324069738 0.02291013487 0.008617531508 0.0518931821 0.005779404659 0.004335308913 0.008744289167 0.005907263607 0.004083033185 0.007803007495 0.009583277628 0.008767100982 0.003798688296 0.01725100167 0.007512997836 0.00846741721 0.01550123468 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
35.94319534 35.94874954 35.93478012 35.93405533 35.93612671 35.93959808 35.91732788 35.93764877 35.95200729  35.947052 35.94248199 35.9356041 35.9390564 35.93218994 35.93416595 35.9401741 35.93682861 35.93605042 35.94736099 35.94231033 35.94400406 35.94238281 35.94359589 35.95924377 35.92934799 35.93558502 35.93345642 35.93283081 35.92535782 35.94159317 35.99049377 35.93723297 35.94771576 35.94992828 35.94086838 35.94088745 35.93693924 36.09352112 35.94167709 35.93673706 35.96212006 35.93593216 35.93593597 35.94259262 35.93267059 35.94286346 35.94417191 35.93645477 35.95108795 35.93297958 35.98006821 35.93014145 35.93346405 35.93692017 35.93503952 35.93130493 35.93598175 35.93871307 35.93789673 35.93292999 35.94447327 35.93664169 35.93759918 35.94367981 

-------
======================
selected experts : 8, 23, 30, 37, 40, 50, 
layer7_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5969b0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0352125 -0.0907986 -0.01977620.0720823 0.0910303 0.0716572 0.00196552 0.0521129 -0.0490076]

layer7_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55e510>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.323367 -0.216176 -0.05549550.168362 0.209445 0.0335339 0.0161552 0.223068 0.266122]

layer8_wq's input 
<N9nntrainer6TensorE at 0x5682dc59a250>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.698869 -0.56914 -0.1362930.430025 0.491751 0.083016 0.0396761 0.536885 0.674494]
==============================
layer8_wq's output 
<N9nntrainer6TensorE at 0x5682dc5d3620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0639148 0.410825 -0.417121-0.0726356 -0.147468 0.344579 0.150297 0.278308 0.180766]
============================
layer8_wk's input 
<N9nntrainer6TensorE at 0x5682dc59bfb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.698869 -0.56914 -0.1362930.430025 0.491751 0.083016 0.0396761 0.536885 0.674494]
==============================
layer8_wk's output 
<N9nntrainer6TensorE at 0x5682dc59bd20>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.93573 -1.81147 1.159780.99642 -0.145511 -1.30763 0.334001 -1.64482 -0.606057]
============================
layer8_wv's input 
<N9nntrainer6TensorE at 0x5682dc59cda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.698869 -0.56914 -0.1362930.430025 0.491751 0.083016 0.0396761 0.536885 0.674494]
==============================
layer8_wv's output 
<N9nntrainer6TensorE at 0x5682dc59cb30>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.17077 0.0889638 0.009054320.233684 0.306174 0.141184 0.230212 0.112509 -0.163188]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0639148 0.410825 -0.417121-0.0726356 -0.147468 0.344579 0.150297 0.278308 0.180766]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1473898
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer8_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc59f1f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer8_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc59f150>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer8_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a0270>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.323367 -0.216176 -0.05549550.168362 0.209445 0.0335339 0.0161552 0.223068 0.266122]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.517798 -0.751774 -0.1809980.615267 0.691332 0.123206 0.0590381 0.784509 0.862725]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5882452726 -0.6442487836 -0.8421914577 -0.4300321937 1.341192722 -0.4877629876 -1.064007401 -0.08338573575 -0.5618849397 -0.4335744679 -0.6063557267 -1.417790413 -0.8882192969 1.479222417 0.1135633513 -0.9720777273 -1.591812491 0.1699660867 -0.2588843703 0.7174573541 0.06095259637 -0.2706263661 -0.07068607211 -0.7212471962 0.5205098987 0.6559413671 -0.4026866257 -1.943585038 -1.496576786 -0.6514189243 -0.3940841556 -1.273926854 0.3555283844 -0.02895525098 2.930223227 0.117078118 0.6315217018 -0.02730123699 -0.6881129146 0.2710784674 -0.3329880238 -0.4232544303 0.01007864997 0.05309870094 -1.225707769 -1.13024807 -1.405498147 0.2140850425 0.9443829656 -0.9357936382 -0.7312394977 -1.330650687 0.7643644214 -0.455119133 -0.2044192255 -0.8547347188 -0.6892370582 0.2319948375 -0.7416234016 -0.617618084 0.4457293749 0.2035500705 1.137711167 0.1976065338 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006955304183 0.006576488726 0.005395462271 0.008147551678 0.04789170995 0.007690507919 0.00432210369 0.01152321883 0.007141085807 0.008118743077 0.006830473896 0.00303423428 0.005152748898 0.05498014763 0.01403161604 0.004738270305 0.002549602184 0.01484578103 0.009668424726 0.02566702291 0.013312486 0.009555562399 0.01167049259 0.006089113653 0.02107862942 0.02413567528 0.008373426273 0.00179349212 0.002804353833 0.006529503036 0.008445767686 0.003503711428 0.01787276566 0.01216781698 0.2346213609 0.01408102084 0.02355343103 0.01218795869 0.00629425142 0.01642538607 0.008977862075 0.008202961646 0.01265216619 0.01320833992 0.003676796798 0.004045080394 0.003071762389 0.01551542804 0.03220535442 0.004913350567 0.006028572097 0.003310499946 0.02689967491 0.007945697755 0.01020962186 0.005328208674 0.006287180353 0.01579580829 0.00596629642 0.006753978319 0.01955985464 0.01535282936 0.03907414153 0.01526185125 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.07928467 34.07986069 34.07772446 34.08143234  34.120224 34.08097458 34.0776062 34.08480835 34.07947159 34.08044815 34.08011627 34.07059479 34.07462311 34.12826538 34.08731461 34.07611465 34.07487869 34.08813095 34.05529785 34.09132004 34.08564377 34.08188629 34.08495331 34.07841873 34.09341049 34.09646606 34.08165741 34.07412338 34.07608795 34.07886124 34.08172989 34.07678604 34.09020233 34.08450317 34.30123138 34.08545685 34.09683609 34.08451843 34.07862473 34.08780289 34.08130646 34.08148575 34.08498383 34.08362961 34.07696152 34.07732773 34.07635498 34.08784485 34.10453415 34.07819748 34.07931137 34.07564163 34.09827805 34.08123016 34.07872391 34.07861328 34.07957077 34.08812714 34.07829666 34.08003998 34.0928421 34.08768463 34.10663605 34.07519531 

-------
======================
selected experts : 4, 13, 34, 48, 52, 62, 
layer8_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5a3350>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0774167 0.111238 -0.07532610.0933187 -0.109616 0.125867 0.0124732 0.0449115 0.0937873]

layer8_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a2c90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.400784 -0.104938 -0.1308220.261681 0.099829 0.159401 0.0286284 0.26798 0.35991]

layer9_wq's input 
<N9nntrainer6TensorE at 0x5682dc5e1750>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.29979 -0.286306 -0.3389680.749877 0.251812 0.426694 0.0756519 0.698953 1.03754]
==============================
layer9_wq's output 
<N9nntrainer6TensorE at 0x5682dc5a2e70>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.5445 -0.142553 0.636839-0.200393 0.0452707 0.61193 0.689305 -0.0733743 0.121827]
============================
layer9_wk's input 
<N9nntrainer6TensorE at 0x5682dc5e3c80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.29979 -0.286306 -0.3389680.749877 0.251812 0.426694 0.0756519 0.698953 1.03754]
==============================
layer9_wk's output 
<N9nntrainer6TensorE at 0x5682dc5e39f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.549294 0.22006 -0.5727080.308242 0.0753529 -0.686648 -0.595744 -0.222494 0.104868]
============================
layer9_wv's input 
<N9nntrainer6TensorE at 0x5682dc5e4a70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.29979 -0.286306 -0.3389680.749877 0.251812 0.426694 0.0756519 0.698953 1.03754]
==============================
layer9_wv's output 
<N9nntrainer6TensorE at 0x5682dc5e4800>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.742602 -0.574154 -0.0629760.168007 -0.61729 -0.487047 0.487573 0.043117 1.56709]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.5445 -0.142553 0.636839-0.200393 0.0452707 0.61193 0.689305 -0.0733743 0.121827]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a126e888
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer9_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc5e6ec0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer9_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc5e6e20>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer9_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5e7f40>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.400784 -0.104938 -0.1308220.261681 0.099829 0.159401 0.0286284 0.26798 0.35991]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.594879 -0.336725 -0.3973330.880095 0.303202 0.538838 0.0967755 0.864494 1.08077]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.006179130636 -1.523411155 -0.8046867847 -0.8045324087 -1.153357267 -0.8564960957 -0.6683631539 -0.7449077368 -0.09588294476 -0.4846624136 -1.993807673 -0.7978251576 -0.1174750328 -1.399905682 -1.619934678 -0.5128343701 0.09977246821 -0.5754458308 -0.2466420233 -0.4138587415 0.9207069278 -1.327341199 -0.1334742308 1.478416443 -0.1926675439 -0.9325324893 -1.08990097 -1.606923223 -0.1914881468 -2.246004105 -0.1075429693 -1.942753315 -0.8624118567 -0.6464453936 -0.1713717878 2.198638678 -0.4614202976 -1.153713465 0.3645452857 -1.405581594 -0.4403051138 -0.4783839881 1.477433443 1.517270088 -0.4992600083 -1.359681129 -0.4399275184 0.1417278051 -0.5657800436 -1.068803072 0.352959007 -0.8462823033 -0.4534936249 1.207513928 -0.402115047 0.5043896437 -1.090843558 -0.1466698349 0.4715595841 -1.042772651 -1.733769536 -1.042459726 -0.3781226277 -0.4061432779 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01573678665 0.003451362718 0.007081554271 0.00708264811 0.004996926058 0.006724005565 0.008115834557 0.00751779275 0.01438660081 0.00975244306 0.00215625437 0.007130312268 0.01407929324 0.003905065358 0.003133796854 0.009481530637 0.01749565639 0.008906080388 0.01237326488 0.01046798378 0.03976102546 0.00419896841 0.01385582983 0.06944926828 0.0130594587 0.006231690291 0.005324289203 0.00317483861 0.01307487115 0.00167560752 0.01421982516 0.002269199351 0.006684346125 0.008295677602 0.01334055327 0.1427105963 0.00998176448 0.004995145835 0.02279920131 0.003882962745 0.01019477285 0.009813864715 0.06938103586 0.07220073044 0.00961111486 0.004065346438 0.01019862201 0.01824530587 0.008992584422 0.005437813699 0.02253656834 0.00679303566 0.01006120071 0.05296832323 0.01059164014 0.02622123994 0.005319273099 0.01367419213 0.02537437342 0.005581221078 0.002796616871 0.005582967307 0.01084883418 0.01054906193 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.46762848 34.45534515 34.45325089 34.45802307 34.45593643 34.45861816 34.43807602 34.45941162 34.46627808 34.46069336 34.45404816 34.45902252 34.4659729 34.4557991 34.45502853 34.46137619 34.46843338 34.46080017 34.46331406 34.46236038 34.4859314 34.45609283 34.46479416 34.51943588 34.46495056 34.45812607 34.45721817 34.45506668 34.4544754 34.4535675 34.46611404 34.4541626 34.45762253 34.45923615 34.46523285 34.58602142 34.45615387 34.45593262 34.4746933 34.45577621 34.43824387 34.46170807 34.5165062 34.52313995 34.46150208 34.45595932 34.46209335 34.46537018 34.45897675 34.4573288 34.46966171 34.45868683 34.46195221 34.50485992 34.45962524 34.47620773 34.45434952 34.46461487 34.47536087 34.45652008 34.45278168 34.45747757 34.46274185 34.46053314 

-------
======================
selected experts : 20, 23, 35, 42, 43, 53, 
layer9_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5eb020>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0904395 0.106096 0.0329668-0.067995 -0.0565526 0.215214 0.0986228 -0.0225595 -0.0549224]

layer9_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5ea960>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.491223 0.00115802 -0.09785470.193685 0.0432764 0.374614 0.127251 0.24542 0.304987]

layer10_wq's input 
<N9nntrainer6TensorE at 0x5682ded33210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.816478 0.00295847 -0.2469830.512705 0.0972401 0.974345 0.325096 0.566557 0.722844]
==============================
layer10_wq's output 
<N9nntrainer6TensorE at 0x5682dc5eab40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.27117 -0.76001 0.5036690.0460609 -1.57391 0.646051 -0.38179 -1.13534 -1.09235]
============================
layer10_wk's input 
<N9nntrainer6TensorE at 0x5682ded34f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.816478 0.00295847 -0.2469830.512705 0.0972401 0.974345 0.325096 0.566557 0.722844]
==============================
layer10_wk's output 
<N9nntrainer6TensorE at 0x5682ded34ce0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.41918 -0.651348 0.6707770.339412 -1.02395 -1.2338 1.04715 -0.894345 0.244532]
============================
layer10_wv's input 
<N9nntrainer6TensorE at 0x5682ded35d60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.816478 0.00295847 -0.2469830.512705 0.0972401 0.974345 0.325096 0.566557 0.722844]
==============================
layer10_wv's output 
<N9nntrainer6TensorE at 0x5682ded35af0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.297858 -0.398831 0.343820.410285 -0.388908 0.124749 -0.0654683 -0.30852 0.618231]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.27117 -0.76001 0.5036690.0460609 -1.57391 0.646051 -0.38179 -1.13534 -1.09235]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1069878
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer10_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded38210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer10_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded38170>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer10_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded39290>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.491223 0.00115802 -0.09785470.193685 0.0432764 0.374614 0.127251 0.24542 0.304987]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.653939 0.00349313 -0.2771030.614053 0.122549 1.19343 0.411266 0.744078 0.85427]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7786639333 -1.393615365 -0.7004893422 -0.9211307764 -0.9374949336 -2.091054916 0.4917023778 -1.508368373 0.5114474893 -1.150796533 -0.9004326463 -0.4219582975 -0.1097989976 0.05985205621 -0.5949621797 -0.5383629799 -0.6902923584 -1.185661674 -1.31589818 -0.8943351507 0.2607395053 -0.2165581137 -1.943270922 1.862397194 -0.3483964205 -0.4082939625 0.07045843452 -0.9987672567 -1.201955318 0.1878198981 0.2695377767 -1.897437453 -1.008196712 -1.089570045 -0.3202297091 0.2417682111 0.03358387202 -0.653794229 -1.06272471 -0.6459861994 0.3563322425 -0.3481343687 -0.2136586607 -0.3151677847 -0.07099556178 0.8761122823 -0.852571547 -0.8716993332 -0.9818502069 -1.701415181 -0.05301491171 -1.084397197 -0.2493259907 -1.28319943 -0.5454171896 -0.5405090451 -0.218074739 1.507466793 0.5079182982 -1.455028176 -0.4884186387 -0.1428133845 -1.1280092 -1.31279099 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.008762597106 0.004737648647 0.009475096129 0.007599067409 0.007475725841 0.002358677797 0.03121374361 0.004224021453 0.0318361856 0.006039732601 0.007757992484 0.01251837984 0.01710476726 0.02026728913 0.01052963827 0.01114279591 0.009572206996 0.005832783878 0.005120530259 0.007805439644 0.02477650158 0.0153727727 0.002734326757 0.1229224131 0.01347397268 0.01269060839 0.02048339508 0.007031420711 0.005738517269 0.0230341088 0.02499545552 0.002862566616 0.006965429988 0.006421078928 0.01385888271 0.02431089059 0.01974183694 0.009928028099 0.006595790386 0.01000585128 0.02726185508 0.01347750425 0.01541741285 0.01392921247 0.01778153703 0.04584510624 0.008138327859 0.007984138094 0.007151384838 0.003482467495 0.01810415089 0.006454379298 0.01487720478 0.005290733185 0.01106446702 0.01111890841 0.0153494766 0.08619593084 0.03172403201 0.004455449991 0.01171344798 0.01654928178 0.006178941112 0.005136466119 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.11120987 33.10813904 33.11287689 33.11100006 33.11087799 33.09622192 33.13461304 33.10762405 33.1333313 33.10943985 33.11116028 33.11496735 33.12050629 33.11794662 33.11011505 33.11454391 33.11297226 33.10828018 33.10184479 33.10834503 33.12722397 33.11877441 33.10613632 33.22060013 33.11401367 33.11132431 33.12293243 33.11043167 33.10818481 33.12643433 33.12744141 33.10626221 33.11036682 33.10982132 33.11725998 33.1258049 33.12123489 33.11333084 33.1099968 33.11340714 33.11254501 33.09780502 33.11882019 33.11732864 33.12118149 33.14733887 33.11058426 33.11138535 33.10578537  33.106884 33.11769104 33.10985565 33.1182785 33.10678482 33.11446381 33.11452103 33.11684418 33.18482971 33.13321686 33.10690308 33.11511612 33.11804199 33.10958099 33.10853577 

-------
======================
selected experts : 6, 8, 23, 45, 57, 58, 
layer10_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded3c110>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.142326 -0.136676 -0.01333690.116226 0.176949 0.0824564 0.0209849 0.0304001 -0.0524755]

layer10_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded3bb90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.63355 -0.135518 -0.1111920.309911 0.220225 0.457071 0.148236 0.27582 0.252512]

layer11_wq's input 
<N9nntrainer6TensorE at 0x5682ded7c3b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.08442 -0.323715 -0.2520710.792157 0.482496 1.14049 0.354094 0.595908 0.595495]
==============================
layer11_wq's output 
<N9nntrainer6TensorE at 0x5682ded3ba40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.148604 0.308885 0.792914-0.0842849 0.0246652 -0.317564 0.745845 -0.455112 -0.630629]
============================
layer11_wk's input 
<N9nntrainer6TensorE at 0x5682ded7e110>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.08442 -0.323715 -0.2520710.792157 0.482496 1.14049 0.354094 0.595908 0.595495]
==============================
layer11_wk's output 
<N9nntrainer6TensorE at 0x5682ded7de80>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.0911 -0.00431846 -0.757862-1.29814 -0.390949 2.34579 -0.946156 0.00387446 1.37274]
============================
layer11_wv's input 
<N9nntrainer6TensorE at 0x5682ded7ef00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.08442 -0.323715 -0.2520710.792157 0.482496 1.14049 0.354094 0.595908 0.595495]
==============================
layer11_wv's output 
<N9nntrainer6TensorE at 0x5682ded7ec90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0607408 0.794152 0.0421951-0.793839 -0.32465 -0.538328 0.00378029 0.00901464 -0.0420296]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.148604 0.308885 0.792914-0.0842849 0.0246652 -0.317564 0.745845 -0.455112 -0.630629]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0e64868
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer11_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded813b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer11_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded81310>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer11_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded82430>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.63355 -0.135518 -0.1111920.309911 0.220225 0.457071 0.148236 0.27582 0.252512]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.82416 -0.424747 -0.3214331.01377 0.646679 1.52993 0.496183 0.856094 0.72612]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.9364411235 -1.007618189 -0.4109774232 -0.3015242815 0.05015375465 0.6887173653 1.120311499 -1.99619925 -0.851175487 0.119799763 -1.46455884 -2.967864037 0.3732702136 -0.7175021172 -1.278898358 0.4428830743 -0.09781496227 -0.5728917718 1.250388145 -0.9006448984 -1.56584692 -0.8735644221 0.3899318874 -0.9240915775 1.679631591 -0.7035691738 -0.9576157331 -1.116815209 0.4433086216 -1.781309605 -1.135971904 -1.465826035 -0.6551713943 -0.6809907556 0.4057626724 -0.3687110543 -0.5232410431 -1.230549097 0.03563097119 -0.4856950641 -0.9370869398 -0.9710419774 0.4367691278 3.685584068 -0.6272659898 -0.6984556913 1.351345181 -1.109172821 -1.663878679 -0.3376826346 -1.190114141 -0.1241203249 -0.868250668 -0.694755733 -0.6910074353 -1.273615479 0.7286296487 -1.818000317 -0.4761559963 0.7851735353 -1.560478449 -1.130072832 -1.52071929 -0.9397082329 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.004175823648 0.00388893229 0.007062331308 0.007879216224 0.01119991671 0.02120994031 0.03265715763 0.001447088202 0.004547498189 0.0120077515 0.002462541452 0.0005476541119 0.01547185984 0.005197877996 0.002964932704 0.01658727042 0.009659457952 0.006006611977 0.0371937491 0.004328009672 0.002225331031 0.004446816165 0.01573180594 0.004227713216 0.05713313445 0.00527080521 0.004088330548 0.00348663656 0.01659433171 0.001793991425 0.003420478897 0.002459422452 0.005532175768 0.005391167011 0.01598283276 0.007367228158 0.006312372163 0.003111807397 0.01103843749 0.006553882733 0.004173126537 0.004033806268 0.01648616605 0.4246802926 0.005688727833 0.005297827069 0.04114480317 0.003513384378 0.00201753038 0.007599404082 0.003240211401 0.009408676997 0.004470506683 0.005317466799 0.00533743389 0.002980637364 0.02207359672 0.001729361597 0.006616697181 0.02335768379 0.002237310167 0.003440717235 0.002328054747 0.004162202589 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.54592133 28.5465889 28.55023956 28.53913498 28.54865456 28.55103493 28.56772804 28.54510117 28.54581642 28.55184746 28.54611588 28.5442009 28.55388069 28.54837418 28.54614067 28.5526123 28.55283546 28.54918289 28.57274055 28.54321289 28.54587936 28.54523849 28.55890846 28.53834534 28.59744835 28.5451088 28.54297256 28.53521919 28.55404854 28.54497147 28.54278183 28.54468155 28.54870796 28.54856873 28.5586834 28.54482269 28.54948997 28.54342651 28.55278397 28.5497303 28.54734993 28.54578018 28.55966187 28.9607048 28.54695892 28.54656792 28.58146095 28.54668999 28.54567146 28.54553032 28.5459404 28.54972458 28.54717064 28.54849434 28.54851341  28.545681 28.56477356 28.54490662 28.54502487 28.56653404 28.54493713 28.54614067 28.54502869 28.54686165 

-------
======================
selected experts : 6, 18, 24, 43, 46, 59, 
layer11_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded85530>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0730588 -0.140434 0.110713-0.267418 0.281402 -0.126401 0.168741 -0.0560705 0.426874]

layer11_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded84d30>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.706608 -0.275953 -0.0004788790.0424936 0.501627 0.33067 0.316977 0.21975 0.679386]

layer12_wq's input 
<N9nntrainer6TensorE at 0x5682dedc4470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.47562 -0.595809 -0.001022650.0972628 1.00021 0.737357 0.721783 0.445942 1.41877]
==============================
layer12_wq's output 
<N9nntrainer6TensorE at 0x5682ded84be0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0380779 0.0594935 -0.483155-0.117966 -0.371258 -0.724986 0.343947 -0.204362 0.276778]
============================
layer12_wk's input 
<N9nntrainer6TensorE at 0x5682dedc61d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.47562 -0.595809 -0.001022650.0972628 1.00021 0.737357 0.721783 0.445942 1.41877]
==============================
layer12_wk's output 
<N9nntrainer6TensorE at 0x5682dedc5f40>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.547337 2.95539 -1.899011.17854 0.230702 -0.80326 0.876232 1.71168 0.208942]
============================
layer12_wv's input 
<N9nntrainer6TensorE at 0x5682dedc6fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.47562 -0.595809 -0.001022650.0972628 1.00021 0.737357 0.721783 0.445942 1.41877]
==============================
layer12_wv's output 
<N9nntrainer6TensorE at 0x5682dedc6d50>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.138164 -0.0977206 0.388362-0.344724 0.102137 0.528402 0.245832 -0.897009 0.351429]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0380779 0.0594935 -0.483155-0.117966 -0.371258 -0.724986 0.343947 -0.204362 0.276778]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0c5f858
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer12_attention_out's input 
<N9nntrainer6TensorE at 0x5682dedc9470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer12_attention_out's output 
<N9nntrainer6TensorE at 0x5682dedc93d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer12_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dedca4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.706608 -0.275953 -0.0004788790.0424936 0.501627 0.33067 0.316977 0.21975 0.679386]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.675282 -0.673948 -0.00105090.108794 1.12449 0.870003 0.833977 0.526315 1.51496]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.9369933605 -0.9108066559 -1.315687418 -0.7814069986 -0.4721452594 -0.2175236046 -0.3420130908 1.171661973 0.006449535489 -1.010374784 -1.280986905 1.745340943 -0.8167315722 0.103787981 -0.5195167661 -0.7081641555 -0.8970544934 -0.2988212705 -1.859523058 -1.080811739 1.357624054 -0.8167452216 -0.570982039 -1.389030933 -1.135742545 2.567747593 -0.4001145363 -0.9823791981 1.175984025 -0.3039234579 -1.533406973 0.330381006 -0.2126948982 -0.5499356985 -0.2744215131 1.221174479 -0.7014297247 -0.06336640567 0.6457877159 0.1698617041 -0.719833374 1.866277814 -1.375406861 -0.8482971787 -0.4086071849 -2.634113312 1.070423484 0.2768325806 -0.8969842792 -0.9433320761 -0.7721428871 -1.223296165 -0.5955258012 0.03921855986 -0.8929018974 0.9159421921 -1.052577138 1.183049679 -0.5805519819 0.4790596068 -0.3881127238 -0.632043004 0.1592775732 -0.3780774176 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.00482202135 0.004949962255 0.003301903605 0.005633775145 0.007675560657 0.009901269339 0.008742301725 0.03971975297 0.01238685753 0.004480845761 0.003418493085 0.07049399614 0.005438237917 0.01365320757 0.007320435718 0.006061894819 0.005018505733 0.009128171951 0.001916811801 0.004176087677 0.04783753678 0.005438162945 0.006953218486 0.003068398219 0.003952878062 0.1604422778 0.008248835802 0.004608062096 0.03989179432 0.009081716649 0.002655890305 0.01712548174 0.00994919613 0.007101107854 0.009353635833 0.04173587635 0.006102855317 0.01155155618 0.02347589843 0.01458579861 0.005991568323 0.07955625653 0.003110488877 0.005269257352 0.008179077879 0.0008834446198 0.03589543328 0.01623256132 0.005018857308 0.004791552201 0.005686209071 0.003621507669 0.006784636993 0.01279948838 0.005039388314 0.03075734526 0.004295678809 0.04017465562 0.006886993069 0.01987070031 0.00834843237 0.006541351322 0.01443223562 0.008432633244 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
30.80915642 30.80976105 30.80763626 30.80949211 30.81105614 30.81232834 30.81355286 30.84405518 30.8133831 30.80929184 30.80822945 30.87101364 30.81024933 30.81655693 30.81022453 30.81039619 30.80982971 30.81298637 30.80672836 30.80803299 30.84883499 30.81024933 30.81176376 30.80740356 30.8087635 30.96525383 30.81210709 30.80941963 30.84279633 30.81246185 30.80698967 30.82193756 30.81380653 30.80714417 30.81368828 30.84273338 30.81043816 30.81540871 30.82781029 30.81892014 30.81032562 30.88436699 30.80506134 30.80960464 30.81251335 30.80521774 30.83927727 30.81246185 30.80792236 30.80960274 30.81002235 30.80557251 30.81111908 30.81475067 30.80985069 30.83556938 30.80862999 30.84307861 30.81122208 30.8242054 30.81315994 30.81135368 30.80780029 30.81181335 

-------
======================
selected experts : 11, 20, 25, 35, 41, 57, 
layer12_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dedcd730>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.105371 -0.0180421 0.159890.120279 0.107959 0.101716 -0.308858 0.346877 -0.239852]

layer12_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dedccdf0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.81198 -0.293995 0.1594110.162772 0.609586 0.432386 0.00811923 0.566627 0.439535]

layer13_wq's input 
<N9nntrainer6TensorE at 0x5682dee397f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.01552 -0.578276 0.3081180.360881 1.04655 1.00288 0.0174472 1.01146 0.814574]
==============================
layer13_wq's output 
<N9nntrainer6TensorE at 0x5682dedccca0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0489869 -0.00789521 0.0149930.0753686 0.293756 -0.565717 0.151002 0.213927 0.0946267]
============================
layer13_wk's input 
<N9nntrainer6TensorE at 0x5682dc471a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.01552 -0.578276 0.3081180.360881 1.04655 1.00288 0.0174472 1.01146 0.814574]
==============================
layer13_wk's output 
<N9nntrainer6TensorE at 0x5682dc4717a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.186268 1.21648 -0.1455040.873823 0.16289 1.31311 -1.21244 0.100976 0.299573]
============================
layer13_wv's input 
<N9nntrainer6TensorE at 0x5682dc472820>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.01552 -0.578276 0.3081180.360881 1.04655 1.00288 0.0174472 1.01146 0.814574]
==============================
layer13_wv's output 
<N9nntrainer6TensorE at 0x5682dc4725b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.153347 -0.202984 0.722418-0.153462 -1.17068 0.152368 0.0601711 -0.215706 -0.795785]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0489869 -0.00789521 0.0149930.0753686 0.293756 -0.565717 0.151002 0.213927 0.0946267]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0a5a848
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer13_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc474cd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer13_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc474c30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer13_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc475da0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.81198 -0.293995 0.1594110.162772 0.609586 0.432386 0.00811923 0.566627 0.439535]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.752406 -0.708639 0.3443670.4127 1.32379 1.13562 0.0208628 1.33358 0.9545]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.1110203862 -0.4752250314 0.3691485226 -0.08553976566 0.39738518 -0.6024389267 0.08975658566 -0.9990121722 -1.018274188 -0.8622924685  1.1496948 1.513578415 -0.5035985112 0.01711911149 -0.188542366 -1.521476269 2.553497314 -1.03619194 2.392742634 -2.313237667 1.039719343 -0.837351203 -0.3671983182 -0.4118401408 -1.741893291 -0.4054136872 -0.578335464 -1.00726819 -1.121797204 -1.646620512 -0.4338321686 -1.701471329 -1.758183479 -0.8070631623 -0.5688951612 1.09580636 -1.059471011 0.8938375115 -0.8789498806 -0.107321173 0.7055851221 -0.3230214119 -0.9850828052 -0.8946176171 0.05689048767 -0.4733243585 -0.3868416846 0.6686237454 0.2741550803 -0.4745544493 -1.130087972 -0.8646947742 -1.445032001 0.2284796536 0.03573527932 -0.6914933324 -0.04297377914 0.2078676224 0.6134063005 -0.9224937558 -0.1313919872 -1.013681054 -1.286917448 -0.8313987851 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01136652194 0.007896879688 0.018372247 0.01165986806 0.01889841072 0.006953560282 0.01389389113 0.004677110352 0.004587881733 0.005362338386 0.04010044783 0.05770080537 0.007675967179 0.01292045694 0.01051865425 0.002773795044 0.1632348597 0.004506409634 0.1389946342 0.001256657066 0.0359242335 0.005497763399 0.008797736838 0.00841362495 0.002225094475 0.008467870764 0.007123200689 0.004638655577 0.004136688542 0.002447511768 0.008230612613 0.002316879807 0.002189141 0.005666828249 0.007190764882 0.03799669072 0.004402715713 0.03104786761 0.005273756105 0.01140864566 0.02572022937 0.009195105173 0.004742715508 0.005191772245 0.01344467606 0.007911902852 0.008626604453 0.02478692681 0.01670733467 0.007902176119 0.004102534149 0.005349472165 0.002994150622 0.0159613844 0.0131632397 0.00636108825 0.01216689683 0.01563575678 0.02345535904 0.005049044266 0.01113730948 0.004609004129 0.003507049987 0.005530586932 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.73335648 28.73084068  28.740839 28.73460388 28.74041176 28.72894478 28.73636055 28.7266674 28.72800827 28.72878265 28.75922966 28.77253914 28.72871208 28.73491096 28.73155594 28.72619438 28.88617897 28.72315979 28.86241531 28.72467804 28.75839233 28.72653389 28.73078918 28.73135757 28.72612381 28.73141289 28.72720718 28.72710609 28.7270813 28.72443771 28.73069763 28.72526169 28.7251339 28.72861099 28.72536659 28.75951004 28.72734642 28.75160789 28.72869492 28.73435211 28.74914169 28.73213959 28.72482681 28.72813606 28.73400497 28.7303791 28.7315712 28.74248505 28.73917389 28.73132324 28.7275238 28.72829437 28.7259388 28.73890495 28.73610687 28.7297821 28.7346344 28.73715019 28.74592209 28.7265625 28.73408127 28.72707558 28.72692871 28.72895241 

-------
======================
selected experts : 10, 11, 16, 18, 20, 35, 
layer13_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee45420>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.124128 -0.0304531 0.124557-0.000418139 -0.0498628 -0.120125 -0.0544955 -0.0342196 -0.0681884]

layer13_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc478790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.936108 -0.324448 0.2839680.162354 0.559723 0.312261 -0.0463762 0.532408 0.371346]

layer14_wq's input 
<N9nntrainer6TensorE at 0x5682dee98c10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.16274 -0.604495 0.5038810.3367 1.01181 0.702995 -0.0951494 0.903388 0.687756]
==============================
layer14_wq's output 
<N9nntrainer6TensorE at 0x5682dc478730>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.925835 -1.65919 -0.509461-0.027278 0.323247 -0.17274 -2.85208 -0.995943 -0.450064]
============================
layer14_wk's input 
<N9nntrainer6TensorE at 0x5682dee9aab0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.16274 -0.604495 0.5038810.3367 1.01181 0.702995 -0.0951494 0.903388 0.687756]
==============================
layer14_wk's output 
<N9nntrainer6TensorE at 0x5682dee9a7d0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.65403 -0.0479634 1.71517-0.758535 1.14686 0.79515 1.01221 1.55394 0.273196]
============================
layer14_wv's input 
<N9nntrainer6TensorE at 0x5682dee9b8a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.16274 -0.604495 0.5038810.3367 1.01181 0.702995 -0.0951494 0.903388 0.687756]
==============================
layer14_wv's output 
<N9nntrainer6TensorE at 0x5682dee9b630>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.212829 -0.412458 -0.2901150.672619 0.305955 0.680764 0.10023 -0.471276 0.704301]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.925835 -1.65919 -0.509461-0.027278 0.323247 -0.17274 -2.85208 -0.995943 -0.450064]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2eb4968
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer14_attention_out's input 
<N9nntrainer6TensorE at 0x5682dee9dda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer14_attention_out's output 
<N9nntrainer6TensorE at 0x5682dee9dd00>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer14_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dee9ee70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.936108 -0.324448 0.2839680.162354 0.559723 0.312261 -0.0463762 0.532408 0.371346]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.892818 -0.805993 0.6172540.417724 1.22907 0.844979 -0.12138 1.26356 0.815423]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.9732452035 0.4532384276 -1.31806767 0.9211859703 -1.456565142 -0.220458746 -1.224868417 -0.280090183 -0.7514868379 -1.930510521 -0.5585358143 -1.20518589 -0.5108226538 1.087217927 -0.3256520629 -1.237738967 -0.7662792206 -0.3498860896 -2.10525012 -1.318520069 -0.7351091504 -1.526698351 -1.351339102 -1.289128661 -0.5504180789 -0.0507973507 -0.4164956212 -0.1352203041 -0.6214087009 0.4142746329 -1.617215633 -1.372260094 -0.2571694255 -0.215110153 -0.5584106445 0.2156661004 -0.6439974308 -0.5376098156 -0.488969475 -0.3424399793 -1.518152714 0.8637148738 -0.2374040782 -0.1609793305 -0.01160876453 -0.7531714439 -0.5510340929 0.8272921443 -0.3381497264 1.347340703 -0.5929352641 -0.1979361176 -0.2368918061 -0.07480574399 -0.427413404 -0.3483141363 -1.18042469 -0.2133716345 1.622606039 -0.4039781094 -0.5461530685 0.3707953691 -0.1051061451 -0.4592855573 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.04618712515 0.02745901048 0.004671069328 0.04384417459 0.004066939 0.01399915665 0.005127341487 0.01318876818 0.008231506683 0.002531837672 0.009983363561 0.005229260772 0.010471249 0.05176290125 0.01260134764 0.005061774049 0.008110638708 0.01229963731 0.002125922358 0.004668957088 0.008367429487 0.00379148405 0.004518214148 0.004808221478 0.01006473508 0.0165876504 0.01150705479 0.01524475496 0.009375005029 0.02640968002 0.003463363508 0.004424670245 0.01349455677 0.01407423336 0.009984612465 0.02165252157 0.009165610187 0.01019447669 0.01070259511 0.01239156257 0.003824023297 0.0413954407 0.01376393437 0.01485708077 0.01725060306 0.008217651397 0.01005853619 0.03991483152 0.01244483981 0.06714111567 0.009645780548 0.01431803219 0.01377098821 0.01619415171 0.01138210576 0.01231898647 0.005360359792 0.01409872342 0.08841679245 0.01165199932 0.01010775287 0.02528600954 0.01571082138 0.01102505438 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.20653915 27.18828773 27.16454697 27.20181274 27.16251183 27.17435265 27.1659565 27.17211151 27.16906166 27.1633606 27.1693821 27.16415215 27.17177773 27.20687103 27.16818619 27.16446114 27.16798592 27.17217636 27.16343307 27.16216087 27.16872025 27.16462135 27.16534805 27.16039276 27.17089462 27.17694092 27.17233658 27.17607498 27.17020416 27.18771553 27.16333961 27.16430092 27.17432404 27.1739502 27.17033768 27.18105125 27.16761017 27.17007065 27.17153168 27.17274475 27.16465378 27.20174789 27.17220879 27.17425537 27.17807961 27.16856956 27.1708889 27.19645309 27.17184448 27.22797012 27.16904449 27.1737175 27.17412376 27.17702293 27.1722126 27.17219543 27.16618919 27.17445183 27.24352455 27.17152786 27.17045975 27.1865921 27.16652679 27.17185402 

-------
======================
selected experts : 0, 3, 13, 41, 49, 58, 
layer14_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deea2ef0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.112761 0.00406018 -0.30293-0.102251 -0.0692943 -0.135377 0.0581638 -0.279451 0.102313]

layer14_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deea2970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.04887 -0.320388 -0.01896270.0601026 0.490429 0.176884 0.0117876 0.252956 0.473659]

layer15_wq's input 
<N9nntrainer6TensorE at 0x5682deedb770>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1529 -0.59365 -0.0303720.122061 0.785505 0.401818 0.0233221 0.410449 0.813189]
==============================
layer15_wq's output 
<N9nntrainer6TensorE at 0x5682deea2820>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.22752 0.502912 -0.249862-0.00132078 0.440942 -0.0610139 0.0142935 -1.11261 0.0709303]
============================
layer15_wk's input 
<N9nntrainer6TensorE at 0x5682deedd610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1529 -0.59365 -0.0303720.122061 0.785505 0.401818 0.0233221 0.410449 0.813189]
==============================
layer15_wk's output 
<N9nntrainer6TensorE at 0x5682deedd330>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.40233 -2.00609 0.4947062.44032 -1.09563 1.4417 1.48847 -0.213559 1.74716]
============================
layer15_wv's input 
<N9nntrainer6TensorE at 0x5682deede400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1529 -0.59365 -0.0303720.122061 0.785505 0.401818 0.0233221 0.410449 0.813189]
==============================
layer15_wv's output 
<N9nntrainer6TensorE at 0x5682deede190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.392245 0.111275 -0.465297-0.0957397 0.496652 0.147801 -0.0265817 -0.758209 -0.320546]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.22752 0.502912 -0.249862-0.00132078 0.440942 -0.0610139 0.0142935 -1.11261 0.0709303]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2bad150
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer15_attention_out's input 
<N9nntrainer6TensorE at 0x5682deee0900>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer15_attention_out's output 
<N9nntrainer6TensorE at 0x5682deee0860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer15_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682deee19d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.04887 -0.320388 -0.01896270.0601026 0.490429 0.176884 0.0117876 0.252956 0.473659]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.02663 -0.781472 -0.03970190.150374 1.04221 0.464775 0.0297388 0.57198 1.00161]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.9199334979 -0.3262065649 -0.2713866532 -0.7613444328 -0.2140652239 0.2691545188 -0.3526677191 -0.6297745109 -1.45824039 -1.548754454 -0.6674299836 -0.2677235901 -0.8474997282 -0.470990479 0.06626295298 0.9327532053 0.4159124494 -1.411634326 -1.344177842 0.04744973034 -1.722919941 -0.5409225225 1.282070756 -1.04397285 -0.4650891125 -1.045165539 -0.1594385505 -1.436890244 -1.226370573 0.08622334898 0.7112942338 0.05230513215 -1.379427671 -0.0636234358 -0.1214737371 -0.1771821082 -0.7386420965 -0.9860671163 -0.111091435 -0.07532097399 -0.725059092 0.0968426019 0.08149397373 -3.786122799 -1.422596455 -0.9403844476 -0.05599314347 -1.068671465 1.149869204 1.192879915 1.009731889 -0.9922481775 1.244369745 -0.8950816989 -0.07063116133 -1.174194098 -0.0453803353 -0.7509018183 2.068914413 -1.73846674 -0.4594594836 -0.2400514781 -1.168467402 -0.685243547 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006320077926 0.01144391857 0.01208878867 0.007406223565 0.01280197967 0.02075567469 0.01114507113 0.008447669446 0.003689255333 0.003369993065 0.0081354836 0.01213315222 0.006794851739 0.009901385754 0.01694424264 0.04030269384 0.0240365956 0.003865266684 0.004135000519 0.01662844792 0.002831326099 0.009232616983 0.05715322867 0.005582809914 0.009959989227 0.005576155614 0.01352076326 0.00376886921 0.00465198746 0.01728585549 0.032296516 0.01670938171 0.003991780803 0.01488035172 0.01404394582 0.01328297146 0.00757628493 0.005915630143 0.0141905155 0.01470730361 0.007679896895 0.01747039519 0.01720429584 0.0003597098112 0.003823126899 0.006192140281 0.01499432884 0.005446611438 0.05007562414 0.05227640271 0.04352767766 0.005879178643 0.05503860489 0.0064791115 0.01477643847 0.004901155829 0.01515430771 0.007483970374 0.1255343705 0.002787648467 0.01001621783 0.01247358974 0.004929303192 0.007991843857 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.89733505 25.90245819 25.89451981 25.89746666 25.90238571 25.90795517 25.90263557 25.89993858 25.89565659 25.89247704 25.90010262 25.89885521 25.89780807 25.90091515 25.90891266 25.93083954 25.91600418 25.89583397 25.89657974 25.90764236 25.89432144 25.89834023 25.94626045 25.89707375 25.89859009 25.89754486 25.90501213 25.89573669 25.89471245 25.90686989 25.92378807 25.90724754 25.89548302 25.90589523 25.90601158 25.9033432 25.89763641 25.89788246 25.90615845 25.89141655 25.89964676 25.90419388 25.90869522 25.89328194 25.8957901 25.89768219 25.90553093 25.88883209 25.94156647 25.94424438 25.9345417 25.89260101 25.94557571 25.89844704 25.90531349 25.89686966 25.90712166 25.89659119 26.01464081 25.89141846 25.90198326  25.903965 25.89403534 25.88994598 

-------
======================
selected experts : 22, 48, 49, 50, 52, 58, 
layer15_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deee4f80>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.279516 -0.0103575 0.0264675-0.0218827 -0.177067 -0.156316 0.066848 0.0483318 -0.228713]

layer15_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deee44b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.769352 -0.330745 0.007504850.0382199 0.313362 0.0205678 0.0786356 0.301288 0.244946]

layer16_wq's input 
<N9nntrainer6TensorE at 0x5682def24710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.51659 -0.746084 0.01380260.0885453 0.569955 0.0539199 0.172589 0.554118 0.482851]
==============================
layer16_wq's output 
<N9nntrainer6TensorE at 0x5682deee4360>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.837615 -0.187112 -0.9891540.47041 -0.777931 -0.670921 1.13206 0.162357 -0.0342349]
============================
layer16_wk's input 
<N9nntrainer6TensorE at 0x5682def26470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.51659 -0.746084 0.01380260.0885453 0.569955 0.0539199 0.172589 0.554118 0.482851]
==============================
layer16_wk's output 
<N9nntrainer6TensorE at 0x5682def261e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.35698 -0.299983 0.368275-0.58111 1.33147 0.362773 -0.624779 0.280671 0.374549]
============================
layer16_wv's input 
<N9nntrainer6TensorE at 0x5682def27260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.51659 -0.746084 0.01380260.0885453 0.569955 0.0539199 0.172589 0.554118 0.482851]
==============================
layer16_wv's output 
<N9nntrainer6TensorE at 0x5682def26ff0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.98979 -1.16204 -0.415350.869068 0.5571 -0.0467949 0.287996 0.47727 -1.08044]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.837615 -0.187112 -0.9891540.47041 -0.777931 -0.670921 1.13206 0.162357 -0.0342349]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a20918f8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer16_attention_out's input 
<N9nntrainer6TensorE at 0x5682def29710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer16_attention_out's output 
<N9nntrainer6TensorE at 0x5682def29670>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer16_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def2a790>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.769352 -0.330745 0.007504850.0382199 0.313362 0.0205678 0.0786356 0.301288 0.244946]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.848196 -0.820021 0.01639540.0978659 0.684583 0.0555918 0.198957 0.68882 0.535119]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8346393704 -0.7524975538 -1.677309275 0.8526527286 -1.129030585 -1.006575704 -0.6597629786 -0.34393695 -0.4856821895 2.246144056 -1.521499634 1.517365575 -2.100584507 -0.9596991539 0.4516881704 -0.3548716307 -0.8559594154 -0.2815335691 -0.6271209121 0.1502730846 0.1619182378 -0.2574121952 -2.057955027 0.3895992637 -0.9810782075 -1.251689076 -1.644615293 -0.8297048807 -0.7415381074 -1.296451092 -0.4573958814 -0.200415045 0.6809696555 -0.7872546315 -0.7021667957 -1.632329464 0.07336928695 -2.207718134 -0.6469236612 1.958521843 0.4336287081 -1.328159809 -1.706025243 -1.417601109 -0.2802706957 -2.039836407 -0.02497340739 -0.1619679183 -1.398960829 -0.4656209946 0.09412627667 -0.4869368672 1.63336134 -0.7445211411 -0.5878745317 -1.471665502 -0.778105855 0.1511812508 -0.1073545441 -1.234058142 -0.7608661652 0.3204005063 -0.8982285261 -0.498549968 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006739675533 0.007316658273 0.002901830943 0.03642676771 0.00502095744 0.005675026681 0.008027619682 0.01100901235 0.009554086253 0.1467594951 0.003391090315 0.07081116736 0.001900404808 0.005947387312 0.02439405024 0.01088928897 0.006597505882 0.01171790157 0.008293981664 0.01804600284 0.01825737953 0.01200398803 0.001983169001 0.02292551473 0.005821587518 0.0044413656 0.00299827056 0.006773013622 0.007397285197 0.004246945493 0.009828195907 0.01270805486 0.03068030253 0.007066720631 0.007694334723 0.003035334637 0.01671021804 0.001707333839 0.008131353185 0.1100762114 0.02395746112 0.004114393145 0.002819686662 0.003762373701 0.01173270494 0.002019429347 0.0151451109 0.0132061569 0.003833162831 0.009747687727 0.01706069708 0.009542107582 0.07952030748 0.007375251502 0.00862596184 0.003564363578 0.007131667808 0.01806239784 0.01394744683 0.004520365968 0.007255682722 0.02139274031 0.006324447691 0.009431933984 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
23.53741455 23.52893257 23.53357506 23.56710052 23.52520561 23.53682518 23.53917885 23.53405571 23.53450775 23.67790985 23.53215981 23.60100746 23.5325737 23.53423882 23.54458046 23.53250504 23.53631783 23.54001045 23.53801346 23.54824257 23.54273415 23.54315567 23.53265762 23.55312347 23.53649521 23.52796555 23.53271866 23.53792381 23.53807068 23.5330162 23.54050255 23.54290581 23.55992508 23.53726387 23.53741455 23.53370857 23.54404831 23.53333473 23.53928185 23.63979721 23.55415535 23.53145218 23.5330162 23.53396034 23.54050064 23.53126526 23.54581833 23.54340363 23.53450775 23.53899384 23.54392242 23.54069328 23.60685921 23.52994537 23.53977585 23.53519249 23.53780556 23.54397011 23.54366684 23.53471756 23.53792953 23.55111313 23.53747559 23.54105949 

-------
======================
selected experts : 3, 9, 11, 32, 39, 52, 
layer16_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def2d9d0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0738136 0.122227 0.1356930.0541837 0.0115974 -0.178614 -0.155583 -0.344363 0.0770779]

layer16_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def2d090>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.843166 -0.208518 0.1431980.0924036 0.324959 -0.158046 -0.0769474 -0.0430751 0.322024]

layer17_wq's input 
<N9nntrainer6TensorE at 0x5682def6d870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.908591 -0.427562 0.2286530.190278 0.484857 -0.380612 -0.161808 -0.0661496 0.542293]
==============================
layer17_wq's output 
<N9nntrainer6TensorE at 0x5682def2cf40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.202539 0.153867 -0.288137-0.081287 -0.14635 0.267984 0.285021 0.368045 -0.474438]
============================
layer17_wk's input 
<N9nntrainer6TensorE at 0x5682def6f5d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.908591 -0.427562 0.2286530.190278 0.484857 -0.380612 -0.161808 -0.0661496 0.542293]
==============================
layer17_wk's output 
<N9nntrainer6TensorE at 0x5682def6f340>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.30831 0.219559 2.084320.205235 0.66934 -0.153184 -1.48898 -0.445064 1.40334]
============================
layer17_wv's input 
<N9nntrainer6TensorE at 0x5682def703c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.908591 -0.427562 0.2286530.190278 0.484857 -0.380612 -0.161808 -0.0661496 0.542293]
==============================
layer17_wv's output 
<N9nntrainer6TensorE at 0x5682def70150>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.814724 -0.577507 -0.517755-0.0118889 -0.859291 -1.51372 -0.70231 -0.428057 -0.604583]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.202539 0.153867 -0.288137-0.081287 -0.14635 0.267984 0.285021 0.368045 -0.474438]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2296908
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer17_attention_out's input 
<N9nntrainer6TensorE at 0x5682def72870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer17_attention_out's output 
<N9nntrainer6TensorE at 0x5682def727d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer17_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def738f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.843166 -0.208518 0.1431980.0924036 0.324959 -0.158046 -0.0769474 -0.0430751 0.322024]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.923305 -0.473048 0.2898770.211241 0.660653 -0.38337 -0.175907 -0.0920833 0.646256]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.2268188 -2.262929916 -0.2616381049 2.009143114 0.713481009 -0.256752491 -1.939337969 -1.414891481 -1.395924926 -1.107269883 -1.891952515 -1.584647894 -0.5895740986 -0.4085955024 -0.9025616646 -0.4105265737 -1.024103403 -0.7288991809 -1.024314642 -0.5831988454 -0.9107356668 -0.9247203469 -0.9531878233 -0.1807185262 -0.188715145 -0.6758002043 -0.95202142 0.005725130439 0.8046452999 -1.26765275 -1.578557611 -0.6067065597 0.3085666895 -0.45854038 0.3071811497 1.196630955 -0.7890125513 -1.168319225 -1.467679381 -0.173876375 -1.548350692 -0.8650257587 -1.180683136 -0.5738669038 -0.6254805326 -1.532449961 2.319978952 -0.8088185787 -0.831402719 -0.9098861217 -1.060331464 -1.486480236 -0.6965551972 -1.156231523 1.924260378 2.103116512 -2.476085663 -0.1378445327 -0.6135014296 -1.426946163 -1.117075801 -0.7862915397 -0.4848812819 -0.6376023293 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.004368291236 0.001550009358 0.01146790851 0.1110892296 0.03040696308 0.01152407285 0.002142241457 0.003619367024 0.003688669531 0.004923012573 0.002246196615 0.003054276574 0.008261585608 0.009900597855 0.006041359156 0.009881497361 0.005349950399 0.007187126204 0.005348819774 0.008314424194 0.00599217834 0.00590896327 0.005743122194 0.01243446767 0.01233542804 0.007579070516 0.005749823991 0.01498299371 0.03330927715 0.004193509463 0.003072934225 0.008121249266 0.02028248087 0.009418258443 0.02025439404 0.04929494858 0.006767813116 0.004631456453 0.003433264093 0.01251983736 0.003167175222 0.006272436585 0.004574546125 0.008392376825 0.007970205508 0.003217937658 0.1515884995 0.006635088939 0.006486920174 0.005997270811 0.005159599707 0.003369318089 0.007423387375 0.004687779583 0.1020487919 0.1220349148 0.001252454589 0.01297917496 0.008066255599 0.003575998824 0.004874974955 0.006786253769 0.009173413739 0.007874174044 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
22.10834885 22.11363792 22.12498474 22.21697807 22.14106369 22.11884308 22.11565971 22.11713791 22.11672974 22.11844063 22.11385727 22.11609459 22.11367226 22.12246513 22.1190815 22.12387657 22.11886787 22.12118149 22.10503769 22.12135506 22.11569595 22.11465836 22.1168766 22.12309074 22.12537575 22.11680603 22.11974525 22.12849998 22.13824463 22.11628151 22.11611366 22.12116241 22.13284683 22.12293625 22.1337719 22.15423012 22.1198082 22.11767197 22.11361313 22.12556076 22.11668587 22.11216164 22.11809158 22.1180954 22.11338234 22.1172123 22.26176834 22.12015343 22.11523628 22.11951447 22.11867714 22.1164093 22.10186768 22.11009979 22.20984459 22.23221397 22.11524773 22.12268257 22.11967659 22.11232567 22.11791611 22.11982727 22.12316895 22.11900711 

-------
======================
selected experts : 3, 28, 35, 46, 54, 55, 
layer17_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def76b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.257155 0.134696 0.08468260.0990494 0.147598 0.300976 -0.113636 -0.525714 -0.119761]

layer17_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def761f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.10032 -0.0738217 0.2278810.191453 0.472558 0.142929 -0.190583 -0.568789 0.202262]

layer18_wq's input 
<N9nntrainer6TensorE at 0x5682defb6420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.75954 -0.142001 0.374970.366795 0.711866 0.306955 -0.366601 -0.839255 0.339066]
==============================
layer18_wq's output 
<N9nntrainer6TensorE at 0x5682def760a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.75469 -0.557973 1.733921.42436 0.726144 -2.69749 3.54083 2.12541 -0.834091]
============================
layer18_wk's input 
<N9nntrainer6TensorE at 0x5682defb8180>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.75954 -0.142001 0.374970.366795 0.711866 0.306955 -0.366601 -0.839255 0.339066]
==============================
layer18_wk's output 
<N9nntrainer6TensorE at 0x5682defb7ef0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.29335 0.585765 -1.106581.8796 0.885979 0.679468 -0.400313 1.59011 -1.37874]
============================
layer18_wv's input 
<N9nntrainer6TensorE at 0x5682defb8f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.75954 -0.142001 0.374970.366795 0.711866 0.306955 -0.366601 -0.839255 0.339066]
==============================
layer18_wv's output 
<N9nntrainer6TensorE at 0x5682defb8d00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0175369 -0.390914 -0.58896-0.599807 0.0733459 -1.34885 -0.172012 -0.400167 -0.916417]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.75469 -0.557973 1.733921.42436 0.726144 -2.69749 3.54083 2.12541 -0.834091]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a249b918
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer18_attention_out's input 
<N9nntrainer6TensorE at 0x5682defbb420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer18_attention_out's output 
<N9nntrainer6TensorE at 0x5682defbb380>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer18_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682defbc4a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.10032 -0.0738217 0.2278810.191453 0.472558 0.142929 -0.190583 -0.568789 0.202262]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.19003 -0.150556 0.4260220.396375 0.883444 0.309164 -0.394574 -1.0985 0.373441]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.2204697132 0.05708098412 -0.6286705732 0.1580707133 -0.8080906868 -1.732628345 1.464083791 0.6101697683 1.571468234 -1.527314305 0.6054287553 -1.315793157 -1.313452244 -0.9276530147 -4.416215897 -0.427164793 -0.7021472454 -0.2263818532 -0.1188104749 -0.8551011682 -0.6734161973 0.2396320999 -1.125132203 -0.127858758 -0.5630725622 -0.435248971 1.719634295 0.5754171014 -0.3415616453 0.2562609315 -0.7031995058 2.186743975 -0.3855905533 -0.008224125952 -0.8646745086 -0.2860595286 -0.9639882445 1.119273186 -1.158209562 -0.409832865 1.247918963 -1.089880466 -0.7522906065 -0.9474794865 -0.1158987284 -0.6079394817 -0.7956529856 0.8073605895 -0.02888942696 0.05589308962 -0.1749845594 -1.421471477 -0.2133081555 -0.5136784315 -0.6711642146 -0.5371653438 -0.7847716212 -0.1978637576 -0.9546427727 -0.4693275392 -1.077966571 -0.3230507076 -0.7847182751 -0.7804819942 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01761343144 0.01495840028 0.007534719538 0.01654796116 0.006297176238 0.002498183167 0.06108557805 0.02600689791 0.0680103749 0.003067545127 0.02588388883 0.003790124087 0.003799007274 0.00558753917 0.0001706699695 0.009216793813 0.007000942715 0.01126623526 0.01254574582 0.006007994059 0.007205004804 0.01795420237 0.004586236086 0.01243273821 0.008045554161 0.009142582305 0.07887200266 0.02511861175 0.01004053559 0.01825525239 0.006993578281 0.1258305311 0.00960805174 0.01401275583 0.005950751249 0.01061355975 0.005388158839 0.04327024519 0.00443701772 0.009377929382 0.04921069369 0.004750793334 0.006658548955 0.005477848928 0.01258232631 0.007692551706 0.006375987083 0.03167578951 0.01372614782 0.01494064275 0.01186042931 0.003410028527 0.01141449437 0.008452935144 0.007221247535 0.008256712928 0.006445745472 0.01159215067 0.005438750144 0.008836268447 0.004807732534 0.01022812538 0.006446090061 0.006473455112 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
24.23064232 24.21940422 24.21960831 24.22623825 24.21932602 24.21600342 24.2741127 24.23951149 24.28008461 24.21657181 24.23509789 24.21634102 24.21492004 24.21718407 24.21367455 24.22224426 24.21240044 24.22286415 24.22462082 24.21855927 24.21403313 24.22430611 24.21761513 24.22498322 24.22059631 24.22073936 24.29094696 24.23099327 24.20733261 24.23128319 24.21859169 24.33933449 24.22120476 24.21893501 24.21897888 24.22316551 24.21889305 24.24199295 24.21651077 24.22145271 24.26176262 24.21777916 24.21873283 24.21802902 24.22608757 24.21642876 24.2165432 24.24327278 24.22675323 24.22701454 24.22488785 24.21691513 24.21538162 24.22148132 24.22072601 24.21794701 24.21947289 24.22462082 24.21846581 24.2218647 24.21497536 24.22230148 24.21899796 24.2195015 

-------
======================
selected experts : 6, 8, 26, 31, 37, 40, 
layer18_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682defbf6e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.264015 -0.295356 -0.489484-0.459204 -0.152953 -0.188538 0.109055 0.0291591 -0.145855]

layer18_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682defbeda0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.36434 -0.369178 -0.261603-0.267751 0.319604 -0.0456091 -0.0815285 -0.53963 0.0564072]

layer19_wq's input 
<N9nntrainer6TensorE at 0x5682deffefd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.84779 -0.598125 -0.364235-0.428715 0.422742 -0.0831305 -0.131057 -0.713771 0.0846056]
==============================
layer19_wq's output 
<N9nntrainer6TensorE at 0x5682defbec50>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.480685 0.205119 0.263901-0.0480382 -0.46984 -0.184554 0.518358 -0.460543 0.404972]
============================
layer19_wk's input 
<N9nntrainer6TensorE at 0x5682df001130>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.84779 -0.598125 -0.364235-0.428715 0.422742 -0.0831305 -0.131057 -0.713771 0.0846056]
==============================
layer19_wk's output 
<N9nntrainer6TensorE at 0x5682df001100>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.532142 -1.53325 0.9742060.292803 0.440881 -0.517969 1.08597 0.712349 -0.795798]
============================
layer19_wv's input 
<N9nntrainer6TensorE at 0x5682df002000>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.84779 -0.598125 -0.364235-0.428715 0.422742 -0.0831305 -0.131057 -0.713771 0.0846056]
==============================
layer19_wv's output 
<N9nntrainer6TensorE at 0x5682df001d90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.805222 0.812916 0.260965-0.279579 1.04645 0.663818 -0.397772 -0.174736 -0.463196]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.480685 0.205119 0.263901-0.0480382 -0.46984 -0.184554 0.518358 -0.460543 0.404972]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a28a5938
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer19_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0044b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer19_attention_out's output 
<N9nntrainer6TensorE at 0x5682df004410>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer19_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df005580>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.36434 -0.369178 -0.261603-0.267751 0.319604 -0.0456091 -0.0815285 -0.53963 0.0564072]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.36425 -0.635508 -0.423837-0.467689 0.51174 -0.0831305 -0.145504 -0.881114 0.0903174]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
2.187695742 1.447409391 0.3685434759 0.2311182022 -0.6378395557 -0.8959373832 -1.139359117 -0.6715271473 0.6730311513 -1.184586763 -0.747297287 1.740148067 -0.7962062955 -0.3254615963 -0.3229257464 -1.652545929 -1.022817373 -0.127592504 -0.5995640159 -1.031918645 -0.06882922351 -0.487526536 -0.0328296572 -1.709587932 -0.7257996202 -0.7993424535 -0.4838096499 -1.096491218 -0.5483450294 -0.5050562024 -0.5785835385 -0.9470683336 -0.171995312 -0.877153635 -0.7952628136 -1.332151771 -0.2243990898 -0.07374745607 -0.9910962582 -0.670137167 -0.1781454384 -0.4395591617 -1.72401464 0.2772509158 -1.653368711 -0.2487790585 -0.7666526437 -1.196279049 -0.4604766071 -0.01531075686 -0.9707286954 -0.6197733879 -1.005095363 -0.1823915541 0.2265905291 -0.6413432956 0.02323836833 -0.02275555208 0.1329594105 -0.3192728758 -0.1021564826 0.8793703318 0.2902856469 0.2031020969 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1447649151 0.06904958189 0.02347553708 0.020461265 0.008581217378 0.006629158743 0.005196867976 0.008296952583 0.03183118626 0.004967062268 0.007691517472 0.092532821 0.007324384525 0.01172770187 0.01175747998 0.003110767575 0.005839224905 0.01429375727 0.008916035295 0.005786321126 0.01515887398 0.009973072447 0.01571452804 0.002938289428 0.007858658209 0.007301450241 0.01001021173 0.005424492061 0.009384602308 0.009799773805 0.009105074219 0.006298723165 0.01367295813 0.006754857022 0.007331297733 0.004285613541 0.01297489461 0.01508450415 0.006027420517 0.008308493532 0.01358912699 0.01046311483 0.002896203892 0.021427311 0.003108208999 0.01266239211 0.007544077467 0.00490932446 0.01024652645 0.01599225588 0.006151443347 0.008737656288 0.005943630822 0.01353154611 0.02036883309 0.008551203646 0.01662078127 0.01587363891 0.01854823716 0.01180050895 0.01466199849 0.03912594542 0.02170843631 0.01989597641 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.39150047 26.31006241 26.26305771 26.26671982 26.25579262 26.24430466 26.25050163 26.25503159 26.27856636 26.25170135 26.24870491 26.33831406 26.25262833 26.25846291 26.25849152 26.25032234 26.25257301 26.25816727 26.25517464 26.25204468 26.26237106 26.25623131 26.25720406 26.24824333 26.25506973 26.25403595 26.25674438 26.25168228 26.25564194 26.25415039 26.25631714 26.25350952 26.26088524 26.25396538 26.25215912 26.25006676 26.25780296 26.25943565 26.25276184 26.2469368 26.26032448 26.25719833 26.24962997 26.26530075 26.24364471 26.25939751 26.25427818 26.25164413 26.25602722 26.2584362 26.25240898 26.25451851 26.25220108 26.25645065 26.25375175 26.2557621 26.26287842 26.26308441 26.26576042 26.25376701 26.26187325 26.28347588 26.26844215 26.2656765 

-------
======================
selected experts : 0, 1, 2, 8, 11, 61, 
layer19_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df008b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.179115 0.0618926 0.2482740.0920345 0.133749 0.0987592 -0.308044 0.129654 -0.580239]

layer19_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df008060>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.54345 -0.307285 -0.0133286-0.175717 0.453353 0.0531501 -0.389573 -0.409976 -0.523832]

layer20_wq's input 
<N9nntrainer6TensorE at 0x5682df047b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.46387 -0.443271 -0.0189243-0.244496 0.584462 0.0790859 -0.559761 -0.502927 -0.699122]
==============================
layer20_wq's output 
<N9nntrainer6TensorE at 0x5682df007f10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.209666 -0.174239 -0.698067-0.426345 1.3059 -1.10042 1.5287 -0.790625 0.593357]
============================
layer20_wk's input 
<N9nntrainer6TensorE at 0x5682df0498e0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.46387 -0.443271 -0.0189243-0.244496 0.584462 0.0790859 -0.559761 -0.502927 -0.699122]
==============================
layer20_wk's output 
<N9nntrainer6TensorE at 0x5682df049650>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.294627 -1.32325 0.917926-1.27884 -0.0145845 0.563909 0.745254 1.00116 0.682824]
============================
layer20_wv's input 
<N9nntrainer6TensorE at 0x5682df04a6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.46387 -0.443271 -0.0189243-0.244496 0.584462 0.0790859 -0.559761 -0.502927 -0.699122]
==============================
layer20_wv's output 
<N9nntrainer6TensorE at 0x5682df04a460>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.802622 -1.17615 -1.06041-0.674554 -0.367546 0.197995 -1.33737 0.00954578 0.483289]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.209666 -0.174239 -0.698067-0.426345 1.3059 -1.10042 1.5287 -0.790625 0.593357]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2caf958
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer20_attention_out's input 
<N9nntrainer6TensorE at 0x5682df04cb80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer20_attention_out's output 
<N9nntrainer6TensorE at 0x5682df04cae0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer20_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df04dc00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.54345 -0.307285 -0.0133286-0.175717 0.453353 0.0531501 -0.389573 -0.409976 -0.523832]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.60412 -0.492135 -0.0204382-0.283416 0.679727 0.0893489 -0.646048 -0.628659 -0.791347]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.09170983732 -0.6412956715 -0.3429809213 -1.756096601 -0.8803435564 1.898794889 -0.6485963464 0.4552803338 -2.069771528 -1.231388927 0.180351153 0.2696457803 0.01692332327 0.3815532029 -0.744210422 -0.4021382928 -0.7598877549 0.1573241353 -0.6239827871 -0.1105014384 1.589914799 -1.260778785 -0.1743986905 -0.1459704638 -1.018254042 -0.2639369965 0.593426168 0.1253865659 -0.4515971243 -1.182953477 -0.7072587013 -0.4050803781 0.9726856947 -0.1491184533 0.5424735546 -0.4475238919 -0.303393662 2.118340492 -1.196415663 -0.6566010714 -1.201580524 0.7300586104 -1.746617794 -1.232227087 0.1263009161 -0.5067939162 -1.045363545 -0.3927505314 0.114782311 -1.917745113 -0.6606517434 -0.911488235 -0.270152986 -0.2175203413 0.383605063 -0.4428945184 -0.4834873676 -1.399068475 -0.03281845897 -1.352754474 -0.9316740036 -0.2386547923 0.6864907742 -0.4994234145 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01624699496 0.007806076203 0.01051935833 0.002560241148 0.006146327127 0.09898744524 0.007749294396 0.02337059006 0.0018709125 0.004326716997 0.01775290631 0.01941107586 0.01507626288 0.02170952968 0.007042672019 0.009915109724 0.006933123339 0.01734877937 0.007942397147 0.0132725304 0.0726833865 0.004201405682 0.01245098095 0.01281002071 0.005354535766 0.01138459519 0.02683278173 0.01680345647 0.009436648339 0.00454144273 0.007307779044 0.009885981679 0.03920811415 0.01276975684 0.0254998263 0.009475165047 0.01094414294 0.1232899129 0.004480713978 0.007687511388 0.004457631148 0.03076127917 0.002584624803 0.004323092755 0.01681882888 0.008929889649 0.005211327691 0.01000862848 0.01662621088 0.002178100171 0.007656434551 0.005957850721 0.01131404657 0.01192548685 0.02175411955 0.009519131854 0.009140459821 0.003658779897 0.01434468571 0.00383221684 0.005838792771 0.01167609077 0.02944985032 0.008995950222 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.41039848 25.40291214 25.40753174 25.40004921 25.40220451 25.49647713 25.3999939 25.42038345 25.39888382 25.39513969 25.41428947 25.41356277 25.41208839 25.41824532 25.40405464 25.4054966 25.39822388 25.40863991 25.40304756 25.40933228 25.46969604 25.4012146 25.40421867 25.40839195 25.39902878 25.40839767 25.41907692 25.41333961 25.40072823 25.40155411 25.40431976 25.40737534 25.43526649 25.40882874 25.42251205 25.40601158 25.40795708 25.51124191 25.39720154 25.40279198 25.40147018 25.42634392 25.39768982 25.40181351 25.4124012 25.40641975 25.40222359 25.40702057 25.41316223 25.39871407 25.40228462 25.40297127 25.39402199 25.40893745 25.41781235 25.40557861 25.40662956 25.39733315 25.40897369 25.39750671 25.40142059 25.40725899 25.4216938 25.4012394 

-------
======================
selected experts : 5, 20, 32, 37, 41, 62, 
layer20_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df050e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.00167e-06 0.621226 0.379011-0.281559 0.621723 0.0162228 0.444404 0.302891 0.730591]

layer20_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df050500>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.54346 0.313941 0.365682-0.457276 1.07508 0.0693729 0.0548316 -0.107084 0.206759]

layer21_wq's input 
<N9nntrainer6TensorE at 0x5682df091030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.03618 0.399601 0.420233-0.551411 1.21883 0.0950941 0.0672496 -0.119748 0.248257]
==============================
layer21_wq's output 
<N9nntrainer6TensorE at 0x5682df0503b0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.19223 -0.103388 0.04141770.123554 0.413289 0.0313738 -0.0796988 -0.0182527 -0.0483133]
============================
layer21_wk's input 
<N9nntrainer6TensorE at 0x5682df092d90>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.03618 0.399601 0.420233-0.551411 1.21883 0.0950941 0.0672496 -0.119748 0.248257]
==============================
layer21_wk's output 
<N9nntrainer6TensorE at 0x5682df092b00>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.346188 -0.953345 0.6664870.806524 1.05338 0.491897 0.840397 -0.387425 -1.0359]
============================
layer21_wv's input 
<N9nntrainer6TensorE at 0x5682df093b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.03618 0.399601 0.420233-0.551411 1.21883 0.0950941 0.0672496 -0.119748 0.248257]
==============================
layer21_wv's output 
<N9nntrainer6TensorE at 0x5682df093910>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.910646 -0.346919 0.5431210.442861 -0.230548 1.13933 0.447911 0.340745 1.2376]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.19223 -0.103388 0.04141770.123554 0.413289 0.0313738 -0.0796988 -0.0182527 -0.0483133]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1f8f0f0
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer21_attention_out's input 
<N9nntrainer6TensorE at 0x5682df096030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer21_attention_out's output 
<N9nntrainer6TensorE at 0x5682df095f90>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer21_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0970b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.54346 0.313941 0.365682-0.457276 1.07508 0.0693729 0.0548316 -0.107084 0.206759]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.55895 0.48858 0.550261-0.716363 1.59556 0.114399 0.0892894 -0.162239 0.306859]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.2305278331 -0.1797519326 -1.213610649 0.4362524152 -0.5211807489 -0.6563258171 -0.05973146856 -0.3596717119 0.2964907885 -0.4582329392 0.3491931856 0.2064505666 -0.7385697365 -0.7206205726 -0.8867766261 -1.047058582 0.7185162902 -1.004470229 -0.860804379 -0.3251317739 -0.8159899712 -0.4493183494 -0.8819920421 -1.446178079 -0.8967041373 0.1250834614 1.476002455 -0.7976415157 -1.15431869 -0.09781856835 0.9815244675 -1.56043458 -1.547937155 -0.09203445166 -0.468577981 -1.011660814 -1.829463124 -0.4177188277 -0.3436193168 -0.01525250077 -1.00077033 -1.364393592 -0.1718159914 0.198431626 -0.3370253742 -0.6245774627 0.5988739133 -0.355263412 -0.3307803273 -0.6005148888 0.5447741151 0.515016675 -0.5712896585 0.07823970169 -0.5309761763 1.845778823 0.2094653547 2.406648397 0.921882391 0.5708159208 -0.3614951372 0.161547631 -0.4775575101 -0.5740100741 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01730068773 0.01147839427 0.004082084633 0.0212524198 0.008158314042 0.007127015851 0.01294211857 0.00958832819 0.01848037541 0.008688371629 0.01948045194 0.01688910834 0.006564318668 0.006683206186 0.00566010084 0.004821860231 0.02818344533 0.005031651817 0.005809032824 0.009925297461 0.006075282115 0.00876616966 0.005687247496 0.003235036507 0.005604187958 0.0155693125 0.06011268497 0.006187783089 0.004331439268 0.01245845947 0.03666207939 0.002885747002 0.002922037849 0.01253073011 0.008598951623 0.00499560032 0.002205061028 0.009047600441 0.009743486531 0.01353076287 0.005050302483 0.003510733368 0.01156984735 0.01675421931 0.009807948023 0.007356916554 0.02500541136 0.00963069126 0.009869390167 0.007536090445 0.02368856408 0.02299404144 0.007759583648 0.01485680602 0.008078792132 0.08700775355 0.01694010198 0.1524545997 0.03453940526 0.02431356162 0.009570861235 0.01614751481 0.008522084914 0.007738503627 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.65559196 25.64976883 25.64189529 25.65906525 25.64454079 25.64494133 25.65123177 25.64549446 25.65629387 25.6460247 25.6468029 25.64612007 25.6410408 25.64258957 25.64395142 25.64263535 25.66647339 25.64332199 25.64123917 25.64821625 25.64388847 25.64705658 25.64350128 25.64009476 25.6438942 25.65290642 25.69792557 25.64304733 25.64262199 25.65074921 25.67495155 25.63974571 25.64025879 25.65034485 25.64545822 25.64233208 25.6404953 25.64686203 25.64564896 25.65086746 25.64334106 25.64180183 25.64842987 25.65456772 25.64380646 25.64517021 25.66329575 25.64744377 25.64291382 25.64296532 25.66197968 25.6574707 25.63794327 25.65314674 25.64636993 25.72339058 25.64998436 25.79026794 25.66472435 25.66212654 25.64643097 25.65396118 25.64490509 25.64507484 

-------
======================
selected experts : 16, 26, 30, 55, 57, 58, 
layer21_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df09a2f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.182466 0.143523 -0.2025560.473019 0.173133 0.0263096 -0.478186 0.369479 -0.299706]

layer21_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df0999b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.36099 0.457464 0.1631260.0157436 1.24821 0.0956826 -0.423355 0.262395 -0.0929469]

layer22_wq's input 
<N9nntrainer6TensorE at 0x5682df0d9be0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.63379 0.491956 0.1659060.0169307 1.2955 0.110873 -0.425276 0.262492 -0.101505]
==============================
layer22_wq's output 
<N9nntrainer6TensorE at 0x5682df099860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.17094 0.181875 -0.521885-0.744125 1.06031 1.55124 -0.00522413 0.674167 -1.59911]
============================
layer22_wk's input 
<N9nntrainer6TensorE at 0x5682df0db940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.63379 0.491956 0.1659060.0169307 1.2955 0.110873 -0.425276 0.262492 -0.101505]
==============================
layer22_wk's output 
<N9nntrainer6TensorE at 0x5682df0db6b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.834725 2.32634 0.917110.461463 -1.56595 -0.151383 1.01935 -0.820651 0.295413]
============================
layer22_wv's input 
<N9nntrainer6TensorE at 0x5682df0dc730>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.63379 0.491956 0.1659060.0169307 1.2955 0.110873 -0.425276 0.262492 -0.101505]
==============================
layer22_wv's output 
<N9nntrainer6TensorE at 0x5682df0dc4c0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.7882 1.13721 0.1892090.388468 -0.845765 0.171791 1.62562 0.2951 1.19857]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.17094 0.181875 -0.521885-0.744125 1.06031 1.55124 -0.00522413 0.674167 -1.59911]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a30b9978
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer22_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0debe0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer22_attention_out's output 
<N9nntrainer6TensorE at 0x5682df0deb40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer22_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0dfc60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.36099 0.457464 0.1631260.0157436 1.24821 0.0956826 -0.423355 0.262395 -0.0929469]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.40688 0.629246 0.2189420.021393 1.63368 0.137994 -0.592916 0.354365 -0.121651]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2532834709 1.319361329 -0.9273973703 -0.4799832404 0.8200585246 -0.8766642809 -0.9006481171 -0.1354901046 0.6177851558 -0.2726817131 -0.1768571883 0.3167691529 -0.08762766421 -1.826992393 -0.2613005042 -0.303319037 0.1613652259 -0.4115544558 -0.4437166452 -0.2158848345 0.4222303033 -0.5552941561 -0.6001519561 0.9864567518 -1.051867843 1.273201346 -0.8076007366 0.2752307057 -0.9778748155 -1.147390723 -1.051934958 -1.135565042 0.2705551088 1.186094046 1.150105476 -1.70018971 -0.6541138291 1.126362443 0.4316788912 -0.2468959987 -0.201301679 -0.4365203083 -0.1884734333 -0.1893158555 0.00761179626 -0.7904543877 -1.528731108 -0.3879744112 -0.4193970561 -0.03139106557 -0.8852482438 -0.6177530289 -0.4918429852 -0.6335096955 -0.1996629685 -0.7824709415 0.06522959471 -0.5061064959 0.2007081956 -0.701824069 -0.4186151028 -0.6330970526 -0.7648043036 0.9774491787 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01201654691 0.05791228265 0.006123726256 0.009579112753 0.03515007347 0.006442417856 0.006289742887 0.01351875626 0.02871309593 0.0117856944 0.01297093276 0.02124958299 0.01418153197 0.002490729792 0.01192059647 0.01143008657 0.01819111779 0.01025754679 0.009932890534 0.0124744596 0.0236130245 0.00888419617 0.008494477719 0.04151375964 0.005407032091 0.05529981107 0.006903077476 0.02038499154 0.005822287872 0.004914438352 0.00540666841 0.004972898867 0.02028990164 0.05068663508 0.04889492691 0.002827459015 0.008048246615 0.04774768651 0.02383719198 0.01209354866 0.01265770942 0.01000462845 0.01282113139 0.01281033549 0.01559858117 0.007022461854 0.003356292611 0.01050229464 0.0101774158 0.01500190515 0.006387352478 0.008346273564 0.009466177784 0.00821579434 0.01267846953 0.007078748196 0.01652373374 0.009332114831 0.01892107353 0.007673279382 0.01018537674 0.008219185285 0.007204918656 0.04114149883 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.01739693 27.06329346 27.00959778 27.01352882  27.041008 27.00657845 27.01024055 27.01746941 27.03457069 27.0166893 27.01882935 27.0266304 27.01956177 27.00739479 27.01444054 27.01728821 27.02357101 27.01611519 27.01579094 27.01165581 27.0275631 27.01426506 27.0143528 27.04117203 27.0112648 27.06068039 27.01276016 27.02433586 27.01072693 27.01077271 27.01078796 27.00892258 27.02280998 27.05654335 27.04426193 27.00582314 27.00866127 27.04740715 27.02349663 27.01556778 27.0180378 27.01395416 27.01820183 27.01819038 27.02145576 27.01097298 27.0092144 27.01492882 27.01603508 27.02085876 27.01224518 27.01229668 27.00960159 27.01407242 27.01805878 27.01198196 27.02238083 27.01137543 27.02477837 27.01305389 27.01365852 27.01407623 27.01258469 27.04699898 

-------
======================
selected experts : 1, 23, 25, 33, 34, 37, 
layer22_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df0e2e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.20119 0.0865406 0.000308141-0.259008 0.0523663 0.10195 0.618681 -0.203726 -0.382935]

layer22_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dde69cd0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.56218 0.544004 0.163434-0.243264 1.30058 0.197633 0.195326 0.0586691 -0.475882]

layer23_wq's input 
<N9nntrainer6TensorE at 0x5682de368560>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.41782 0.508503 0.15467-0.214179 1.24597 0.195467 0.178791 0.0511995 -0.435597]
==============================
layer23_wq's output 
<N9nntrainer6TensorE at 0x5682de2bfbc0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.133728 0.267654 -0.951894-0.0687681 0.249725 1.46133 -1.69692 0.833926 -3.59583]
============================
layer23_wk's input 
<N9nntrainer6TensorE at 0x5682de266760>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.41782 0.508503 0.15467-0.214179 1.24597 0.195467 0.178791 0.0511995 -0.435597]
==============================
layer23_wk's output 
<N9nntrainer6TensorE at 0x5682de82d610>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.3357 1.73948 -1.42765-1.32223 -1.52619 1.80991 -0.704212 -0.96132 0.309337]
============================
layer23_wv's input 
<N9nntrainer6TensorE at 0x5682de40ebf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.41782 0.508503 0.15467-0.214179 1.24597 0.195467 0.178791 0.0511995 -0.435597]
==============================
layer23_wv's output 
<N9nntrainer6TensorE at 0x5682de7736d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.476892 -0.116942 0.4939490.247571 -0.288394 0.0916964 -0.745448 -0.0662398 -1.27079]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.133728 0.267654 -0.951894-0.0687681 0.249725 1.46133 -1.69692 0.833926 -3.59583]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a32be988
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer23_attention_out's input 
<N9nntrainer6TensorE at 0x5682ddf81aa0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer23_attention_out's output 
<N9nntrainer6TensorE at 0x5682de55e330>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer23_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0fe910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.56218 0.544004 0.163434-0.243264 1.30058 0.197633 0.195326 0.0586691 -0.475882]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.87831 0.746929 0.221863-0.330232 1.75545 0.283618 0.277278 0.0796437 -0.63863]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.202337876 -0.2507278621 -0.4346319139 -0.8901007771 0.4960963428 -0.7801545858 -0.9137574434 -1.628868103 -1.021232843 -0.7082157731 -1.214393616 -0.8899537325 0.8807164431 0.4514176846 0.3968681395 0.4057284296 0.4395310879 -0.9786946177 1.039314628 -0.6412197948 -0.07255800068 -0.9416559339 -0.1245097294 -0.9044296145 -1.684159875 -0.7635933161 -0.4679452479 0.2921422422 0.4377857447 0.7692565918 -0.6150431633 -0.2185461372 -0.1194713637 1.767685533 0.2449211776 -0.9273558855 0.5535702705 -0.771412611 -0.3419643044 -0.4093151987 -0.4648866653 -1.877330661 -1.243041873 -1.800704241 -0.129768312 -1.068928123 -1.796126008 -0.3178377151 0.2177918851 0.2306961119 0.5995736718 0.4514741004 0.924258709 -0.6328145862 -0.8776138425 -0.7096336484 0.6727351546 0.1207105443 0.3918452859 1.360514045 -0.8354010582 -0.04054627568 -0.700281322 0.918671608 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01802833751 0.01146018971 0.009535055608 0.006046661176 0.02418429591 0.006749392487 0.005905296654 0.002888505114 0.005303537939 0.007252826355 0.004371969029 0.006047550589 0.03552808613 0.02312755398 0.02189974859 0.02209465206 0.02285427414 0.005534008611 0.04163419083 0.007755384315 0.0136952484 0.005742823705 0.01300192345 0.005960638169 0.002733129077 0.006862101145 0.009222644381 0.01972228661 0.02281442098 0.03178084269 0.007961074822 0.01183499489 0.01306759752 0.08625366539 0.0188126266 0.005825537257 0.02561497875 0.006808653008 0.01046088059 0.009779534303 0.009250896052 0.002253030892 0.004248496611 0.002432459034 0.01293373201 0.005056521855 0.002443621168 0.01071633771 0.0183091145 0.01854690909 0.02682088129 0.0231288597 0.03710922971 0.007820843719 0.006122638471 0.007242549676 0.02885669842 0.01661519334 0.02179002762 0.05740440637 0.006386626046 0.01414075121 0.00731060328 0.0369024761 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.93471718 26.9271946 26.92622375 26.92225838 26.93896675 26.92296219 26.92116356 26.91909981 26.92151642 26.92394257 26.92106056 26.91939926 26.95174026 26.93790817 26.93811226 26.9368763 26.93239021 26.9217453 26.95593834 26.9206295 26.92990685 26.92195511 26.92969131 26.92264938 26.91942215 26.92212105 26.92352676 26.9364109 26.93950272 26.94751549 26.92369652 26.92613983 26.9264183 26.99960518 26.93407059 26.92156029 26.94230461 26.92254448 26.92667389 26.9226532 26.92307854 26.91846466 26.92093658 26.91816711 26.92866898 26.92126846 26.91579437 26.92263603 26.93452072 26.93285179 26.94351006 26.93934059 26.95379829 26.92307854 26.91899681 26.92202377 26.94411469 26.92662811 26.93800163 26.97313881 26.92307472 26.92844582 26.92399979 26.95216179 

-------
======================
selected experts : 12, 18, 33, 52, 59, 63, 
layer23_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee1eb60>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0889347 0.0669504 0.19658-0.206055 -0.0550669 0.264187 0.794238 0.763159 0.623039]

layer23_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de7806d0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.65111 0.610955 0.360014-0.449319 1.24551 0.46182 0.989564 0.821828 0.147157]

layer24_wq's input 
<N9nntrainer6TensorE at 0x5682de5e9620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.58603 0.524109 0.318198-0.367929 1.12512 0.399175 0.816744 0.648927 0.125282]
==============================
layer24_wq's output 
<N9nntrainer6TensorE at 0x5682de23a580>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.257745 -0.27048 0.0879703-0.339207 0.619215 -0.240398 0.371746 0.139617 -0.0250534]
============================
layer24_wk's input 
<N9nntrainer6TensorE at 0x5682de680bc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.58603 0.524109 0.318198-0.367929 1.12512 0.399175 0.816744 0.648927 0.125282]
==============================
layer24_wk's output 
<N9nntrainer6TensorE at 0x5682de1e9fa0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.103136 1.12071 0.7960990.584533 -0.180665 0.516244 -0.324663 0.246522 -0.329266]
============================
layer24_wv's input 
<N9nntrainer6TensorE at 0x5682de7cdb70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.58603 0.524109 0.318198-0.367929 1.12512 0.399175 0.816744 0.648927 0.125282]
==============================
layer24_wv's output 
<N9nntrainer6TensorE at 0x5682de067420>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.790441 -0.937528 2.054680.151723 1.26462 -0.454789 -1.62949 2.51697 -2.21844]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.257745 -0.27048 0.0879703-0.339207 0.619215 -0.240398 0.371746 0.139617 -0.0250534]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a36c89a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer24_attention_out's input 
<N9nntrainer6TensorE at 0x5682de40b530>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer24_attention_out's output 
<N9nntrainer6TensorE at 0x5682de646540>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer24_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de7c4940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.65111 0.610955 0.360014-0.449319 1.24551 0.46182 0.989564 0.821828 0.147157]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.87782 0.798075 0.463259-0.584014 1.5865 0.627274 1.34409 1.06819 0.188401]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.04500648007 -0.03446944803 0.3998152316 1.146480918 -0.6997885704 -0.5446648002 -0.6029837132 -0.0106999632 -0.2364248037 -0.8675487638 -0.8802921772 -0.005337756127 -0.07347777486 0.3196677566 -0.1506764293 -0.3248411417 -0.7959033847 -0.1134899706 -0.8929632306 0.8963117599 -0.2197977602 -0.1962273866 0.475338012 -0.2573736012 0.7159689665 -0.1359964907 -1.302157521 -0.8019512296 -1.719242811 -0.3034323454 -1.459727645 0.4444429278 0.3926343322 -0.5303020477 1.277298927 -0.5168495178 -1.04739821 -1.190663815 -0.3970177174 -0.9455783963 -1.48660481 -0.7315213084 -0.3806113899 -1.215191007 0.2894723415 1.387801886 -0.8202996254 -0.6158267856 -0.5182501078 -0.004281651229 -0.7809188366 0.4651793242 -0.6943770051 -1.278454065 -0.1884415895 -0.05068186298 0.8009446859 -0.6050567627 0.09046348929 -0.6251637936 -1.281979561 -1.048711061 -0.8302156925 0.8244877458 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01736026257 0.01603394002 0.02475413121 0.0522300601 0.008243200369 0.009626428597 0.00908108335 0.01641962491 0.01310183667 0.00697009312 0.006881833542 0.01650790684 0.01542052627 0.02284757607 0.01427487098 0.01199315581 0.007487791125 0.01481569745 0.006795183755 0.04066992924 0.01332150307 0.01363922469 0.02669603936 0.01283022389 0.03395873681 0.01448597293 0.004513259511 0.0074426434 0.002974078991 0.01225268282 0.003855303396 0.02588387392 0.02457701415 0.009765689261 0.05952974781 0.009897951037 0.005822786596 0.005045584403 0.01115803141 0.006446897052 0.003753063036 0.007985727862 0.01134260278 0.004923334811 0.02216799557 0.06648518145 0.007307327352 0.008965199813 0.009884096682 0.01652535051 0.007600836921 0.02642621659 0.008287930861 0.004621517844 0.01374583133 0.01577608846 0.03697055951 0.009062277153 0.01816761866 0.008881881833 0.004605253227 0.005815147422 0.007235225756 0.03785128891 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.84807014 28.84578896 28.85546303 28.87674141 28.83847618 28.83890533 28.84026718 28.84760666 28.84381104 28.83767891 28.83473015 28.8476944 28.84660721 28.84974289 28.84403229 28.8431797 28.83772087 28.84123421 28.83416748 28.87185669 28.84450722 28.8391037 28.85454559 28.84401703 28.86514473 28.84567261 28.83379173 28.83862877 28.83415985 28.84296227 28.83504105 28.85611725 28.85576248 28.83999825 28.89071655 28.84108353 28.83748627 28.83623123 28.8361454 28.83763313 28.83112526 28.83917236 28.8425293 28.83372498 28.85144615 28.89719391 28.83849335 28.83872032 28.83820915 28.84580421 28.8378334 28.85761261 28.83852005 28.83390045 28.84493256 28.84505463 28.86815643 28.84024811 28.84983063 28.84006882 28.83579063 28.83414078 28.83842087 28.86856079 

-------
======================
selected experts : 3, 19, 34, 45, 56, 63, 
layer24_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df21d1f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.721025 0.67659 0.7097850.314835 0.189311 0.476098 -0.307011 1.05981 -0.289087]

layer24_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de2b2790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.93009 1.28754 1.0698-0.134484 1.43482 0.937918 0.682553 1.88164 -0.141931]

layer25_wq's input 
<N9nntrainer6TensorE at 0x5682ddf10a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.44713 0.925659 0.849469-0.0937987 1.13931 0.654172 0.501696 1.36287 -0.115745]
==============================
layer25_wq's output 
<N9nntrainer6TensorE at 0x5682de7d58a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.705758 1.16771 -2.280110.641138 -1.05455 4.12197 -2.3234 -0.0613364 -4.23788]
============================
layer25_wk's input 
<N9nntrainer6TensorE at 0x5682de480fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.44713 0.925659 0.849469-0.0937987 1.13931 0.654172 0.501696 1.36287 -0.115745]
==============================
layer25_wk's output 
<N9nntrainer6TensorE at 0x5682de0aef30>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.287747 0.095492 -0.292181-0.105504 -0.951549 0.416063 0.228144 -0.0131705 -0.335498]
============================
layer25_wv's input 
<N9nntrainer6TensorE at 0x5682ddd64050>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.44713 0.925659 0.849469-0.0937987 1.13931 0.654172 0.501696 1.36287 -0.115745]
==============================
layer25_wv's output 
<N9nntrainer6TensorE at 0x5682de58dbd0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.864359 -0.0454634 -4.413810.813989 -1.183 -0.63115 -0.967595 2.7744 -1.79287]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.705758 1.16771 -2.280110.641138 -1.05455 4.12197 -2.3234 -0.0613364 -4.23788]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a38cd9b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer25_attention_out's input 
<N9nntrainer6TensorE at 0x5682df211490>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer25_attention_out's output 
<N9nntrainer6TensorE at 0x5682dddde7f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer25_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0184b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.93009 1.28754 1.0698-0.134484 1.43482 0.937918 0.682553 1.88164 -0.141931]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.948118 1.54737 1.26272-0.160179 1.67818 1.16745 0.834939 2.24116 -0.166003]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3223717511 0.3448728323 -0.7231014371 0.9114750028 -1.451390386 -1.554976225 -0.6127553582 -0.08854304999 -0.6089014411 0.3256269395 -0.4924653471 -1.476640463 -0.6649508476 -0.05943263322 0.152874738 -0.2902230024 -0.2222272456 0.9606100917 -0.3157120645 -0.7300931215 -0.04282486811 -0.1355180442 -0.6595902443 0.1735311747 -0.4253026545 -0.8581945896 0.327870965 -0.3474477232 0.09692040831 -1.057243347 -1.504226565 0.519277513 -1.611870885 -0.2422892898 -0.8235418797 -0.5504502058 -1.608155966 -0.4383630753 -0.114036195 -1.581875205 -1.30670929 0.3548254371 -1.267062902 -0.9437503815 -0.2836904824 -0.08299838006 -0.08046112955 -0.9271339774 1.131254077 -1.187356949 -0.3064573705 -0.4542046785 -1.035317063 -1.474803567 -1.524227977 -1.035863876 -0.9257327318 0.2648697197 0.346263051 -1.22619462 0.4699943662 1.165745616 -0.6364494562 -0.2278395891 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01376916468 0.02683417313 0.009223013185 0.04728903249 0.004452264868 0.004014156759 0.01029901206 0.01739634946 0.01033878047 0.02632266469 0.01161547191 0.004341253079 0.009775238112 0.01791020669 0.02214646898 0.0142190177 0.0152194798 0.0496706143 0.01386116818 0.009158754721 0.01821013913 0.01659805141 0.009827780537 0.02260869555 0.01242239308 0.008057544939 0.02638179995 0.01342818141 0.02094130963 0.00660323631 0.004223131109 0.03194708005 0.003792147618 0.01491718739 0.008341653273 0.01096110512 0.003806261579 0.01226120535 0.0169584658 0.003907619044 0.005145352799 0.02710257843 0.005353446584 0.007396840025 0.01431220863 0.0174930729 0.01753751375 0.007520777173 0.05891274661 0.005797613412 0.01399004459 0.01206849888 0.006749620661 0.004349234514 0.004139501601 0.006745930295 0.007531322073 0.02477098629 0.02687150426 0.005576765165 0.03041079827 0.06098018587 0.01005785447 0.01513430197 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.7019043 28.71783066 28.69783592 28.7387619 28.69544792 28.69501114 28.70129585 28.70648575  28.701334 28.71636581 28.70308876 28.69581413 28.70172501 28.7079525 28.7093277 28.70235443 28.70669174 28.73685265 28.70485687 28.7006321 28.7063446 28.70473289 28.70082474 28.71408081 28.70389557 28.69857597 28.71785545 28.70490074 28.70669174 28.6923542 28.69521904 28.72341919 28.69526482 28.70639038 28.69933701 28.70243454 28.69480324 28.70373344 28.70795441 28.69395065 28.69423485 28.71762276 28.69682693 28.69791603 28.70578575 28.7089653 28.70710373 28.69613266 28.74990845 28.69679451 28.70212555 28.70258713 28.69393158 28.69534492 28.69513512 28.69535828 28.69757462 28.71624374 28.71834373 28.69657326 28.7171154 28.75197601 28.70153046 28.70660782 

-------
======================
selected experts : 3, 17, 31, 48, 60, 61, 
layer25_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df270060>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.581599 1.64585 -0.734405-0.0357525 0.664837 0.579828 0.17837 -0.487916 -0.353176]

layer25_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddfd81b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.51169 2.93339 0.335394-0.170236 2.09966 1.51775 0.860923 1.39373 -0.495106]

layer26_wq's input 
<N9nntrainer6TensorE at 0x5682de245ed0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.95016 2.33495 0.257764-0.121488 1.74815 1.15951 0.618332 1.001 -0.373715]
==============================
layer26_wq's output 
<N9nntrainer6TensorE at 0x5682de21e590>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.53306 0.330565 1.08895-0.540288 -2.87074 4.16208 0.363796 0.421194 -1.28692]
============================
layer26_wk's input 
<N9nntrainer6TensorE at 0x5682de23ab70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.95016 2.33495 0.257764-0.121488 1.74815 1.15951 0.618332 1.001 -0.373715]
==============================
layer26_wk's output 
<N9nntrainer6TensorE at 0x5682de320f60>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.852679 -0.486911 -0.5935740.12614 -1.09829 -0.0154134 -0.692652 0.305636 0.464532]
============================
layer26_wv's input 
<N9nntrainer6TensorE at 0x5682dde7eae0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.95016 2.33495 0.257764-0.121488 1.74815 1.15951 0.618332 1.001 -0.373715]
==============================
layer26_wv's output 
<N9nntrainer6TensorE at 0x5682ddeee690>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.209443 -4.12569 -2.259856.93197 -2.9071 0.853782 1.43478 0.148134 -3.98406]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.53306 0.330565 1.08895-0.540288 -2.87074 4.16208 0.363796 0.421194 -1.28692]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a116c080
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer26_attention_out's input 
<N9nntrainer6TensorE at 0x5682df278ee0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer26_attention_out's output 
<N9nntrainer6TensorE at 0x5682df278e40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer26_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df27a260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.51169 2.93339 0.335394-0.170236 2.09966 1.51775 0.860923 1.39373 -0.495106]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.58364 3.1401 0.359029-0.183011 2.18038 1.68719 0.933406 1.47919 -0.523201]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4275360703 -0.8491968513 0.2424741834 -0.9826481342 -0.7641063333 -0.1889646202 -0.1528485119 1.276336908 -0.09406793118 -0.7470766306 -0.9672474861 -0.04418166727 0.03551728278 -0.2465560436 0.4867364466 -0.9446355104 0.4353444576 0.5211913586 -0.9716127515 0.01324422099 -0.6058094501 1.348570704 -0.2350756526 -0.7946147323 -0.7751601934 -0.02043139748 -0.3985995054 0.3831701577 -0.0418253839 -0.243257612 0.2703409195 -0.6400926113 -0.922337234 -0.8720644116 -0.9357669353 -0.3209537566 -0.4910352528 -1.188711524 -0.8025053144 -1.335775614 -0.8774180412 -0.7746818066 -0.5436838865 -0.4022784531 -0.559966743 -0.7581650019 0.3905887604 -1.021640539 -0.8243860602 -0.4201786518 0.01336613856 0.3987308741 -1.01600194 -0.1985642165 -0.3839970231 -0.02594007552 0.3503150642 0.9357531667 -0.3926474452 -0.6037749648 0.2400371134 -0.4034537375 -1.152715325 -1.179754853 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01181514747 0.007750223391 0.02308984101 0.006781989709 0.008438563906 0.01499855611 0.01555014681 0.06492646784 0.01649159007 0.008583500981 0.006887243595 0.0173351597 0.0187733043 0.01415916998 0.02947831526 0.007044752594 0.02800163813 0.03051168844 0.006857244764 0.01835978776 0.009885895997 0.06978989393 0.01432266086 0.008185004815 0.008345799521 0.01775180362 0.01216203254 0.02657812834 0.01737605594 0.01420595031 0.02374232747 0.009552720003 0.007203603163 0.007575005293 0.007107508369 0.01314399205 0.0110882204 0.005519056693 0.008120673709 0.004764263518 0.00753455935 0.008349793963 0.0105195418 0.01211737189 0.01034964155 0.008488849737 0.02677603625 0.00652263267 0.007944918238 0.0119023975 0.0183620248 0.02699493803 0.006559515372 0.01485526469 0.01234093122 0.01765428483 0.0257190913 0.04618576914 0.01223463845 0.009906029329 0.02303363569 0.01210313942 0.005721340887 0.005568711087 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.07134628 33.0682373 33.08548355 33.06822205 33.06987762 33.07548523 33.07698822 33.11968994 33.07506943 33.06620789 33.06927872 33.07972717 33.08021164 33.07655334 33.09091949 33.06848526 33.08943939 33.09194946 33.06734467 33.07503128 33.07132721 33.1312294 33.07290268 33.06962585 33.0688324 33.07919312 33.07264709 33.08229446 33.07786179 33.07659912 33.08613586 33.07099152 33.06387329 33.0690155 33.06663895 33.07553864 33.07252884 33.06600571 33.07051468 33.0614357 33.06706619 33.06978989 33.07196045 33.07355499 33.07274246 33.07088089 33.08821487 33.06891632 33.0703392 33.0723877 33.0778923 33.0893898 33.06800079 33.07724762 33.07091904 33.08004761 33.0871582 33.10571671 33.07367325 33.07134628 33.08542633 33.0716362 33.06525421 33.0660553 

-------
======================
selected experts : 7, 14, 16, 17, 21, 57, 
layer26_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df27d4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.442383 -2.67264 -0.331042-0.0168688 -1.64033 0.540547 -1.3711 -0.521078 1.8849]

layer26_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddd52130>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.06931 0.260751 0.0043526-0.187105 0.459331 2.05829 -0.510173 0.872648 1.3898]

layer27_wq's input 
<N9nntrainer6TensorE at 0x5682de328070>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.17699 0.207401 0.00360194-0.151078 0.39672 1.72812 -0.40989 0.722148 1.16127]
==============================
layer27_wq's output 
<N9nntrainer6TensorE at 0x5682ddefef30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-2.12358 0.641598 1.223170.247236 0.717713 1.07588 -0.458996 1.48855 -0.360192]
============================
layer27_wk's input 
<N9nntrainer6TensorE at 0x5682de1e5e50>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.17699 0.207401 0.00360194-0.151078 0.39672 1.72812 -0.40989 0.722148 1.16127]
==============================
layer27_wk's output 
<N9nntrainer6TensorE at 0x5682ddfc8350>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.73171 2.23409 1.09523-0.231685 0.662506 0.236294 -0.568655 -0.101359 0.712218]
============================
layer27_wv's input 
<N9nntrainer6TensorE at 0x5682de7969c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.17699 0.207401 0.00360194-0.151078 0.39672 1.72812 -0.40989 0.722148 1.16127]
==============================
layer27_wv's output 
<N9nntrainer6TensorE at 0x5682de46fef0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.685151 3.17763 -0.5630380.972597 2.93775 2.94922 1.45491 -1.28651 1.37587]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-2.12358 0.641598 1.223170.247236 0.717713 1.07588 -0.458996 1.48855 -0.360192]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a054e020
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer27_attention_out's input 
<N9nntrainer6TensorE at 0x5682de426170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer27_attention_out's output 
<N9nntrainer6TensorE at 0x5682de0d2950>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer27_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de6e6390>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.06931 0.260751 0.0043526-0.187105 0.459331 2.05829 -0.510173 0.872648 1.3898]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.09967 0.260823 0.00430134-0.184902 0.470529 2.11674 -0.514412 0.862371 1.36785]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.8975563645 -0.6824918389 0.2976894379 0.09480299056 -0.04825308174 -0.6956527233 0.02409000508 0.3185453713 -0.8159588575 -0.8080035448 0.4366771877 -1.104795933 -0.961515069 0.5640445352 -0.839448452 0.05519466847 -0.9685260057 -0.1311029494 -1.121758461 -0.8895583749 0.5545963049 -1.333006859 -0.7957485914 -2.024419069 -0.3258972764 -0.9597058892 1.294580221 -0.6954064965 -0.6760049462 -1.270164371 0.3766347766 1.421892881 -0.3766465187 -0.3871797025 -0.3016258478 0.9998850822 0.08255623281 0.1375508159 -0.6402568817 -0.239540875 -1.347739577 1.225086927 -0.9895419478  1.1164397 -0.6575826406 -0.7987774014 -0.4796771109 0.1779886186 0.05001206324 -2.220851898 -0.2255286276 0.9075536728 -0.6515741944 -0.5892189145 -0.5610015392 -0.7393690944 0.4110049009 -0.2590482831 0.7353230715 0.6438882351 -0.9080087543 -0.8136808276 -0.07481505722 1.764435649 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03477146104 0.007161709014 0.01908552274 0.01558086462 0.0135040218 0.007068073843 0.01451714989 0.01948774606 0.006266899407 0.006316953339 0.02193136513 0.004694748204 0.005417993292 0.0249103941 0.006121407263 0.01497579366 0.005380141083 0.01243030746 0.004615785088 0.00582222268 0.02467614226 0.00373681495 0.006394843571 0.001871652319 0.01023019105 0.005427803844 0.05171877146 0.007069813088 0.007208317984 0.003979181871 0.02065330371 0.05874073505 0.009723969735 0.009622083977 0.0104815308 0.03851800039 0.01539121475 0.01626135409 0.007470661774 0.01115290169 0.003682165407 0.04824670404 0.005268252455 0.04327955469 0.007342342753 0.006375503726 0.008771988563 0.01693240553 0.01489838306 0.001537855016 0.01131027937 0.03512082621 0.007386591285 0.007861847989 0.008086849004 0.006765739061 0.02137550153 0.0109374458 0.02956418507 0.02698088996 0.005715786479 0.006281192414 0.01315004937 0.08273777366 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
31.52622604 31.49861717 31.51054001 31.50751305 31.50352859 31.49661636 31.50692558 31.51046562 31.49724579 31.49824905 31.51386261 31.49471855 31.49544334 31.51684189 31.49709892 31.50500107 31.49683571 31.50054741 31.4965477 31.4867878 31.51660728 31.49566841 31.49832726 31.48998833 31.50073242 31.49688339 31.54317474 31.49614143 31.49913979 31.49209595 31.51258469 31.54971886 31.50117874 31.50107765 31.50002861 31.52997398 31.5020771 31.50247192 31.49987984 31.50260735 31.49561501 31.5401783 31.4957695 31.53521156 31.49975204 31.49735451 31.48973656 31.50838661 31.50730705 31.49346924 31.50324249 31.52657509 31.49884224 31.49788666 31.49954224 31.49535942 31.51330757 31.50143814 31.52149582 31.51891327 31.49764824 31.49773598 31.50508118 31.57419205 

-------
======================
selected experts : 26, 31, 35, 41, 43, 63, 
layer27_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df2fed10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.20719 -0.760462 0.1858620.353342 -0.96498 -2.79303 -0.0287174 -1.42369 0.764581]

layer27_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de4dbd00>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.2765 -0.49971 0.1902140.166237 -0.505649 -0.734736 -0.53889 -0.551043 2.15438]

(93919)layer0_wq's input 
<N9nntrainer6TensorE at 0x5682dde663b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5682de7965e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.13528 -2.40334 2.68629-0.919085 2.00659 2.0107 -1.72146 -1.10937 2.11685]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5682ddd56d10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5682de0a36b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.89838 -1.3551 1.40273-1.31928 1.80822 0.0189238 -3.15912 0.501596 1.80267]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5682e0a65b00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5682dde490d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0171632 -0.00860554 -0.02487710.023363 0.0279423 0.00942741 0.0125607 0.108111 -0.0271058]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.40894 -2.25384 2.511791.32355 0.342246 2.81997 -0.905078 -1.83711 1.93381]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a259e520
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer0_attention_out's input 
<N9nntrainer6TensorE at 0x5682e0a64030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer0_attention_out's output 
<N9nntrainer6TensorE at 0x5682e0a638e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer0_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dde13420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00261426 -0.0209141 0.0150320.00392139 -0.0209141 -0.00326782 -0.0169927 0.00326782 0.00718921]

layer0_ffn_gate's input 
<N9nntrainer6TensorE at 0x5682ddfb82c0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.016856 -0.133765 0.09458650.0238624 -0.133223 -0.0193776 -0.108684 0.0207315 0.0444924]
==============================
layer0_ffn_gate's output 
<N9nntrainer6TensorE at 0x5682dde852c0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.0745774 -0.045048 -0.104621-0.0199713 -0.0449096 0.327996 0.0860863 0.095988 -0.0662891]
============================
layer0_ffn_up's input 
<N9nntrainer6TensorE at 0x5682de34f990>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.016856 -0.133765 0.09458650.0238624 -0.133223 -0.0193776 -0.108684 0.0207315 0.0444924]
==============================
layer0_ffn_up's output 
<N9nntrainer6TensorE at 0x5682dde690c0>
data addr: 0x7fc0a7fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.107725 -0.084519 -0.0651140.108516 -0.371791 -0.215119 -0.0580026 -0.266965 0.0745787]
============================
layer0_ffn_down's input 
<N9nntrainer6TensorE at 0x5682dc3e1140>
data addr: 0x7fc0aafd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[0.0038672 0.00186083 0.00322812-0.00107278 0.00816106 -0.0410134 -0.00260401 -0.0134272 -0.00238998]
==============================
layer0_ffn_down's output 
<N9nntrainer6TensorE at 0x5682dc3e0770>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.019992 -0.0625515 0.0377594-0.0686288 -0.133513 -0.0569278 -0.00148558 0.141268 0.0288674]
============================
layer0_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3e1bb0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0173777 -0.0834656 0.0527914-0.0647074 -0.154427 -0.0601957 -0.0184783 0.144535 0.0360566]

layer1_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e48b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wq's output 
<N9nntrainer6TensorE at 0x5682dc3e2330>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.796753 0.125337 -0.343608-0.150926 0.507089 0.41414 -0.255773 -0.0929489 0.288512]
============================
layer1_wk's input 
<N9nntrainer6TensorE at 0x5682dc3e6610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wk's output 
<N9nntrainer6TensorE at 0x5682dc3e6380>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.57238 0.950343 0.763138-0.230196 1.08302 0.869608 -0.770607 0.449956 1.26046]
============================
layer1_wv's input 
<N9nntrainer6TensorE at 0x5682dc3e7400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wv's output 
<N9nntrainer6TensorE at 0x5682dc3e7190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.181 0.0291937 0.03531750.0125654 -0.00638554 0.189028 -0.105657 -0.2298 0.067497]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.535955 -0.602725 -0.125973-0.35352 0.144382 0.638596 -0.171468 -0.211325 0.298048]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a34c3d98
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer1_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ea340>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer1_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ea2a0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer1_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3eb440>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0173777 -0.0834656 0.0527914-0.0647074 -0.154427 -0.0601957 -0.0184783 0.144535 0.0360566]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00849878 -0.127214 0.076729-0.116416 -0.229304 -0.113028 -0.033535 0.248681 0.0424914]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.1702160239 -0.2239896655 -0.1769756079 0.04392522946 0.2368980944 0.6970673203 -0.3592808545 0.1850829422 0.05595271289 -0.5391097665 -0.4449483454 -0.1334935427 -0.4149801433 -0.1864147633 -0.1508485675 1.056051373 -0.3195793629 0.2847701907 -0.2090599388 0.2084010988 0.0856358707 -0.2458385676 0.4397518933 -0.2768904567 -0.3535001278 -0.3292910159 -0.614720583 -0.2910648882 -0.5341821313 1.065764666 -0.4363492429 -0.01145206578 -0.3598379493 0.01293567009 -0.4634871483 0.6671438813 0.07331451029 4.606241703 -0.1133288145 -0.4652608633 -0.276211381 -0.27166453 0.3908366859 -0.07471401989 -0.2063711286 -0.08803310245 0.8862541914 0.1459055394 0.1584375054 -0.7652307153 -0.911662221 -0.3270534873 -0.7755787373 -0.1130612567 -0.363222748 -0.1517439485 1.124939442 0.2087254822 -0.1229620501 0.2299077511 -0.002020265907 -0.2369497269 -0.2072182894 0.03846488521 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005106037483 0.004838720895 0.005071639083 0.006325348746 0.0076716966 0.0121545922 0.00422643451 0.007284310181 0.00640188437 0.003530820133 0.003879443277 0.005297030788 0.003997462802 0.005023993552 0.005205893889 0.01740384474 0.004397606011 0.008047888987 0.004911503755 0.007456163876 0.006594760343 0.004734145477 0.009397014044 0.004589401186 0.004250939004 0.004355106037 0.003273693845 0.004524807911 0.003548261477 0.01757371798 0.003912945744 0.005984588526 0.004224081524 0.006132334471 0.003808184993 0.01179627329 0.006514005363 0.6060009599 0.005404926836 0.003801435698 0.004592518788 0.004613446537 0.008948416449 0.005617718678 0.004924725275 0.005543392152 0.01468599215 0.007004447747 0.007092781365 0.002816258464 0.002432641573 0.00436486071 0.002787265228 0.005406372715 0.00420980854 0.005201234482 0.01864502393 0.007458582055 0.005353110842 0.007618254982 0.00604130188 0.004776413552 0.004920556676 0.006290904246 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
62.86117935 62.85995483 62.8611412 62.86048889 62.86183548 62.86727142 62.85934448 62.86240387 62.86151886 62.85865021 62.85899734 62.86041641 62.8591156 62.86014175 62.86032486 62.8706131 62.85951614 62.86316681 62.86003113 62.86257553 62.86171341 62.85985184 62.85974503 62.86066055 62.85936737 62.85947418 62.85839081 62.8605957 62.85675812 62.87173843 62.85998535 62.86110306 62.86029434 62.86125183 62.85987854 62.86691284 62.8616333 63.45921326 62.86052322 62.85892105 62.85971069 62.86068344 62.86215973 62.86073685 62.86004257 62.86066055 62.86789703 62.86212158 62.86125565 62.85793304 62.85755157 62.85948181 62.85790634 62.86052322 62.85932922 62.85936356 62.87281036 62.86257553 62.86046982 62.86273575 62.86116028 62.8598938 62.86003876 62.86140823 

-------
======================
selected experts : 5, 15, 29, 37, 46, 56, 
layer1_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e0a3ef10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00353315 -0.0549329 0.126958-0.123369 0.276545 -0.191098 0.106235 0.309095 -0.178975]

layer1_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3ee080>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0209109 -0.138399 0.179749-0.188076 0.122118 -0.251294 0.0877565 0.45363 -0.142918]

layer2_wq's input 
<N9nntrainer6TensorE at 0x5682dc3ee2c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wq's output 
<N9nntrainer6TensorE at 0x5682dc3ee260>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.311247 0.115223 -0.416898-0.165847 -0.237754 -0.201397 0.366615 0.127884 -0.336297]
============================
layer2_wk's input 
<N9nntrainer6TensorE at 0x5682dc3edf00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wk's output 
<N9nntrainer6TensorE at 0x5682dc3ede70>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0170464 -0.00491821 -0.00816116-0.0380695 0.0298006 -0.00619471 0.0300897 0.0291104 -0.00756178]
============================
layer2_wv's input 
<N9nntrainer6TensorE at 0x5682dc3ee380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wv's output 
<N9nntrainer6TensorE at 0x5682dc3ee3b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0488053 0.00885962 0.00802386-0.00675694 -0.00410349 -0.01637 0.00385213 -0.0244586 -0.011974]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.265124 -0.19965 -0.165406-0.417073 -0.0632453 -0.305103 0.248525 0.298322 -0.365071]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0855c38
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer2_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ee500>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer2_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ee620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer2_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3fefb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0209109 -0.138399 0.179749-0.188076 0.122118 -0.251294 0.0877565 0.45363 -0.142918]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00114894 -0.0176881 0.0220069-0.0260591 0.0151698 -0.0354185 0.0120544 0.0614986 -0.0157906]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2300609797 -0.0573739633 -0.0792670846 -0.07990511507 -0.02465081401 0.3291009963 -0.0433845073 0.0155646475 -0.0844059214 0.0009286757559 0.03862661868 -0.08860354871 -0.003646862693 -0.01065728627 0.02001750097 0.02708270214 0.04012955353 0.008215387352 -0.02356889471 -0.008847231045 -0.1422992498 2.097109318 -0.2351353914 0.4799684286 -0.5973323584 0.03877436742 0.04228200763 0.03647579625 -0.1728328317 0.0651492998 0.9051232338 0.01538673695 -0.1603259444 -0.3426310718 0.1016679481 0.5145780444 -0.05423829705 -0.0345232375 -0.1464090049 0.08176235855 -0.0002122647129 -0.1026671231 0.08935724944 0.1386951506 0.009488531388 0.03291593865 -0.3518608809 -0.01619542576 0.1929396689 -0.04016084224 0.006257107947 0.08056685328 -0.2241435498 -0.1660892814 0.1276066601 0.09963126481 -0.1244759187 0.005371605046 -0.127043888 -0.3551532924 -0.3419806063 -0.0312563628 -0.01512844954 -0.1615694612 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01110433694 0.01319743972 0.01291164756 0.0129034128 0.01363644563 0.01942377351 0.01338336244 0.01419601869 0.01284546684 0.01398975775 0.01452721003 0.01279165968 0.01392589416 0.01382860821 0.01425937004 0.01436047349 0.01454906166 0.01409207098 0.01365120709 0.01385366265 0.01212291792 0.1138072386 0.01104813442 0.02258679084 0.007691104431 0.0145293558 0.01458041091 0.01449599955 0.01175835636 0.01491766516 0.03455388919 0.01419349387 0.01190633792 0.009922111407 0.01547250804 0.02338219807 0.0132388873 0.01350248232 0.01207319647 0.01516756415 0.01397380698 0.01261302177 0.01528319623 0.0160561502 0.01411002409 0.01444448438 0.009830952622 0.01375223417 0.01695116423 0.01342657488 0.01406450011 0.01514944155 0.01117024291 0.01183791552 0.01587909646 0.0154410284 0.01234092377 0.01405205205 0.01230927277 0.009798639454 0.009928567335 0.0135466652 0.01376691833 0.01189154293 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
53.42486572 53.42695999 53.42667389 53.42666626 53.42739868 53.43127823 53.4271431 53.42795563 53.42660522 53.42774963 53.42828751 53.4236908 53.4276886 53.42758942 53.42802048 53.42812347 53.42735672 53.42785263 53.42741394 53.42666245 53.42588425 53.52566147 53.4248085 53.43539429 53.42145157 53.42829132 53.42738724 53.42825699 53.42551804 53.42868042 53.44831467 53.42795563 53.42566681 53.42368317 53.42923355 53.43714523 53.42699814 53.42631149 53.42583466 53.42892838 53.42773438 53.42637253 53.42904282 53.4298172 53.4278717 53.4282074 53.42359161 53.42751312 53.42785263 53.42718887 53.42782593 53.42700195 53.42493057 53.42559814 53.42868805 53.42920303 53.42610168 53.42781448 53.42511749 53.4235611 53.42273712 53.42635345 53.42752838 53.42565155 

-------
======================
selected experts : 5, 21, 23, 30, 35, 48, 
layer2_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e09f8dd0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00287643 0.0675208 -0.00951222-0.0402701 -0.0273482 0.0245452 0.04068 0.00865384 -0.00745776]

layer2_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc401970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0180344 -0.0708777 0.170237-0.228346 0.0947696 -0.226748 0.128437 0.462284 -0.150376]

layer3_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e86c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wq's output 
<N9nntrainer6TensorE at 0x5682dc409160>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.367673 -0.164716 0.417190.0188933 -0.448419 0.281779 -0.241015 -0.0599261 0.228738]
============================
layer3_wk's input 
<N9nntrainer6TensorE at 0x5682dc41f6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wk's output 
<N9nntrainer6TensorE at 0x5682dc41f440>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0494961 -0.00890612 -0.00339991-0.0380567 -0.012209 -0.0539861 0.0167038 0.0355852 0.0534441]
============================
layer3_wv's input 
<N9nntrainer6TensorE at 0x5682dc4204c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wv's output 
<N9nntrainer6TensorE at 0x5682dc420250>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00987394 -0.0372493 0.01608040.0108743 -0.00258411 -0.0155564 0.00276103 0.00223089 -0.00269894]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.337258 0.22039 0.2725090.316454 -0.526819 -0.054228 -0.175809 -0.175416 0.0953542]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1678ca8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer3_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc422910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer3_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc422870>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer3_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc423990>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0180344 -0.0708777 0.170237-0.228346 0.0947696 -0.226748 0.128437 0.462284 -0.150376]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00117001 -0.00973031 0.0224832-0.0335967 0.012626 -0.0336243 0.0186737 0.0650705 -0.0180309]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.7030926943 0.730641067 0.9185103774 1.089624643 0.6388058662 0.8775565028 0.3533841074 0.9655683041 0.9445055723 0.9198542237 0.6780980229 1.313909769 1.142851233 1.079918623 0.7256379724 0.9863049984 0.9989354014 0.95402354 0.8960082531 0.8800563216 0.8590018153 0.3948054016 1.023362279 0.8607522845 1.028882027 1.132201791 0.9340718389 1.035694122 1.269880891 1.17101717 1.161755562 0.8632258773 7.094688416 0.9837840796 1.429793835 0.3792514503 1.048365355 0.4638099968 1.291579366 0.9866654277 1.075057983 0.7833786011 0.8463903069 0.3343887925 1.796683669 1.537041783 0.5512750745 1.040719032 0.6032510996 0.8395021558 0.1258548796 0.3762799203 0.7514244914 1.113770843 0.7281199098 1.025203586 0.4975908697 0.7822400331 1.484714389 1.298515081 0.8620041013 0.9687132239 0.9522148371 0.9354790449 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001474627294 0.0015158155 0.001829098328 0.002170455642 0.001382811344 0.001755702426 0.001039455179 0.001917229616 0.001877269591 0.001831557835 0.001438226667 0.002716168528 0.002289112192 0.002149492037 0.001508250833 0.001957401866 0.001982280519 0.001895222114 0.001788399648 0.001760097337 0.001723426278 0.001083415002 0.002031297656 0.001726445742 0.00204254128 0.002264863113 0.001857784577 0.002056502737 0.002599173458 0.002354503609 0.00233279774 0.001730722026 0.8800697327 0.001952473191 0.003049893072 0.001066694036 0.002082727384 0.001160815358 0.002656187862 0.001958106412 0.00213906914 0.00159790169 0.001701827976 0.001019896823 0.004401725251 0.003395171836 0.00126691896 0.002066862537 0.001334509347 0.001690146164 0.0008279253379 0.001063528936 0.001547649037 0.002223502612 0.00151199894 0.002035042038 0.001200698782 0.001596083166 0.00322208018 0.002674675314 0.001728608971 0.001923268428 0.001891797525 0.001860400545 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
42.53669739 42.53292084 42.53704834 42.53739166 42.53564835 42.53697586  42.532444 42.53809357 42.53709793 42.53800583 42.53570557 42.53793716 42.5346489 42.53736877 42.53672791 42.53717804 42.53720474 42.53616333 42.53796387 42.53507233 42.53694534 42.53725815 42.53820419 42.53694916 42.53726196 42.53748703 42.53707886 42.53727722 42.53781891 42.53757477 42.53755569 42.53695297 43.41242981 42.53717422 42.53827286 42.53628922 42.53730392 42.53638077 42.53787613 42.53717804 42.53736115 42.53681946 42.53787613 42.53623962 42.53771591 42.53861618 42.53648758 42.53728867 42.53750992 42.53691101 42.53700256 42.5362854 42.53581619 42.53744507 42.53673172 42.53630066 42.53642273 42.53776932 42.53749084 42.53408051 42.53694916 42.53714371 42.53711319 42.53708267 

-------
======================
selected experts : 11, 32, 34, 44, 45, 58, 
layer3_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc426710>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.40804 -0.163766 -0.0283651-0.0258024 0.375191 -0.636849 0.150238 0.480676 -0.0173886]

layer3_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc426050>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.426075 -0.234644 0.141872-0.254149 0.469961 -0.863597 0.278674 0.942961 -0.167765]

layer4_wq's input 
<N9nntrainer6TensorE at 0x5682dc44b9a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wq's output 
<N9nntrainer6TensorE at 0x5682dc492890>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0362699 0.0761985 -0.162530.0108048 0.133773 0.0730457 0.019711 0.0756074 0.0487248]
============================
layer4_wk's input 
<N9nntrainer6TensorE at 0x5682dc44d700>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wk's output 
<N9nntrainer6TensorE at 0x5682dc44d470>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00265456 0.0108227 0.006283270.0177541 -0.0206112 0.00339958 -0.00927054 0.0110561 -0.0341779]
============================
layer4_wv's input 
<N9nntrainer6TensorE at 0x5682dc44e4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wv's output 
<N9nntrainer6TensorE at 0x5682dc44e280>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00723192 0.0269832 0.01238150.00259692 -0.0625021 0.0233134 -0.0178625 -0.0133778 -0.0104791]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0837155 0.0106502 -0.11938-0.110821 0.0603908 0.139943 -0.0220098 0.0749704 0.00906887]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1e8cce8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer4_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc450940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer4_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4508a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer4_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4519c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.426075 -0.234644 0.141872-0.254149 0.469961 -0.863597 0.278674 0.942961 -0.167765]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0182407 -0.0208817 0.0120996-0.0239882 0.0418232 -0.0826764 0.0268667 0.0864598 -0.0135161]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4858219922 -0.6959101558 -1.212872982 -0.5218012333 -0.3581064343 -0.6095018983 -0.9364464879 -0.09696792811 0.1423784941 -0.6651900411 -0.3415829241 -0.6328966618 -0.448492974 0.1721494049 -0.6025950313 -0.3689320683 0.2208227664 -0.4570725858 -0.2653499246 -0.5709964633 -0.5247528553 -0.8439400792 -0.7144295573 -0.4792812765 -0.2926749885 -0.719201386 5.035842419 -0.5945936441 -0.8254883885 -0.2731153667 -0.396169126 -0.2761000395 -0.4569109082 -0.4405405819 -0.4258541465 -0.9477441907 -0.5268508196 -0.8339192271 -0.6794077754 -0.0201159101 -0.3519995511 -0.3451288044 -0.7215133309 -0.1839890182 -0.3048131168 -0.4804430902 -0.3798335195 -0.1730620563 -0.3575777709 -0.1691406071 -0.5078726411 -0.7150136232 -0.4467060566 -0.5603669286 -0.3437692225 -0.2371052802 -0.9603158832 -0.3850839734 -0.2239291668 -0.5798804164 -0.4820096195 -0.009696807712 -0.3213909268 -0.4072785378 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003149774857 0.002552933758 0.001522388076 0.003038462717 0.003578868229 0.002783339238 0.002007131465 0.004646830726 0.005903418176 0.002632576274 0.003638495924 0.002718978561 0.003269575769 0.006081810221 0.002802630188 0.00354033336 0.006385156885 0.003241643542 0.003926715348 0.002892603399 0.003029507585 0.002201662865 0.002506090095 0.003170444164 0.003820870072 0.002494159155 0.7876041532 0.002825144911 0.002242664341 0.003896341659 0.003445207141 0.003884728299 0.003242167644 0.003295679577 0.003344439203 0.001984582981 0.003023159457 0.002223837189 0.002595413011 0.005018029362 0.003600790864 0.003625615733 0.002488400089 0.004259552807 0.003774773097 0.00316676381 0.003501948435 0.004306353163 0.003580761142 0.004323271569 0.003081081435 0.002504626755 0.003275422612 0.002923513297 0.00363054988 0.004039204679 0.001959790243 0.003483609762 0.004092779011 0.002867019502 0.003161807079 0.005070585292 0.003712710226 0.003407144919 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.82080841 40.8202095 40.81822586 40.82165146 40.82218933 40.82139587 40.82061768 40.8213501 40.81974792 40.82124329 40.82129669 40.82133102 40.82188034 40.8237381 40.82141495 40.82215118 40.8230896 40.81994629 40.82253647 40.82150269 40.82068634 40.82081223 40.81825638 40.81987381 40.8214798 40.82110596 41.60335541 40.81953049 40.82085419 40.82250595 40.82205582 40.82249451 40.82185364 40.82190704 40.82195663 40.81868744 40.81877518 40.81797409 40.82120514 40.82172012 40.82125854 40.82223511 40.82109833 40.82191849 40.8223877 40.81796265 40.82211304 40.82196426 40.82123947 40.8153038 40.82073975 40.81825638 40.82188797 40.82057953 40.82128906 40.82265091 40.8205719 40.82209396 40.81984329 40.8214798 40.82177353 40.82368088 40.82232285 40.82201767 

-------
======================
selected experts : 8, 13, 16, 26, 39, 61, 
layer4_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc454a40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0859682 -0.410187 -0.0549648-0.0186526 0.0215153 0.136957 0.138183 0.141585 -0.052018]

layer4_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc454380>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.512043 -0.644831 0.0869074-0.272801 0.491476 -0.72664 0.416858 1.08455 -0.219783]

layer5_wq's input 
<N9nntrainer6TensorE at 0x5682dc4a0910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wq's output 
<N9nntrainer6TensorE at 0x5682dc454560>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.275413 -0.275119 -0.4205730.130582 -0.153064 -0.171391 0.250294 0.344814 -0.237526]
============================
layer5_wk's input 
<N9nntrainer6TensorE at 0x5682dc4a2670>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wk's output 
<N9nntrainer6TensorE at 0x5682dc4a23e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0251711 0.00994586 -0.00368810.0447051 -0.0208935 -0.0184831 -0.00454087 0.00173929 -5.86053e-05]
============================
layer5_wv's input 
<N9nntrainer6TensorE at 0x5682dc4a3460>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wv's output 
<N9nntrainer6TensorE at 0x5682dc4a31f0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00785 0.000318006 -0.00348613-0.00889498 -0.0160193 0.010875 -0.0116615 -0.00481091 -0.00860701]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.380311 0.0831049 -0.383568-0.216353 -0.0150112 -0.229299 0.0371511 0.424457 -0.297463]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1c87cd8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer5_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc4a58b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer5_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4a5810>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer5_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a6930>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.512043 -0.644831 0.0869074-0.272801 0.491476 -0.72664 0.416858 1.08455 -0.219783]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0104662 -0.0263608 0.00340267-0.011859 0.0191012 -0.0313787 0.0180013 0.0458975 -0.00822548]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.07918033749 -0.2179847509 -0.1854854673 -0.02147212252 -0.2435834855 -0.04457190633 -0.05281364918 0.02368463762 -0.7193178535 -0.03581977263 1.976906419 -0.0489499718 -0.1354791224 0.1448095441 -0.05553285405 -0.09898391366 -0.3166708648 -0.1941818893 -0.1947810501 -0.2095515877 -0.3199042678 -0.01641224325 -0.1026784554 -0.07198929787 -0.6075111628 -0.3197972476 -0.03667161986 -0.07751637697 0.02160535939 -0.2651851773 -0.04437225312 -0.3091673255 -0.003033100627 -0.08875891566 -0.05681180954 0.985704422 -0.1130490974 -0.03929310292 -0.3192313612 0.09553340077 -0.003807086032 -0.145200029 -0.2841767073 -0.1278078854 2.390167236 -0.05618714541 -0.1036904231 -0.02516179718 0.9318757057 -0.4884956181 -0.7425076962 -1.161397815 -0.01418332662 0.03714296594 1.100428462 -0.02066170983 -0.01740192436 -0.5280942917 -0.0759184286 -1.118462682 -0.1128986701 -0.281962961 -0.1339662522 0.06412689388 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01403941866 0.01043018512 0.01077472791 0.01269510575 0.0101665752 0.0124052139 0.0123033952 0.01328151859 0.006317798514 0.01251426246 0.09365288168 0.0123510221 0.01132723037 0.01499172207 0.01226998307 0.01174825523 0.009450029582 0.01068143174 0.01067503355 0.01051851641 0.00941952318 0.01275950484 0.01170493197 0.01206971519 0.00706517417 0.009420530871 0.01250360627 0.01200318988 0.01325392816 0.009949313477 0.01240768936 0.009521204047 0.01293136273 0.01186899748 0.01225430053 0.03475742415 0.01158417203 0.01247087214 0.009425864555 0.01427089516 0.01292135939 0.01121765375 0.009762142785 0.01141445898 0.1415787339 0.01226195786 0.01169309299 0.01264835335 0.03293593973 0.007958122529 0.006172975991 0.004060437903 0.01278797723 0.0134614734 0.03898267075 0.01270540152 0.01274688449 0.007649149746 0.01202238444 0.00423857104 0.01158591546 0.009783779271 0.01134438068 0.01382966246 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.25190735 33.25020599 33.25246048 33.25437927 33.24994278 33.25027466 33.25398636 33.24829102 33.24704742 33.25419998 33.33438492 33.25308228 33.2530098 33.2538147 33.25395584 33.25343323 33.25113297 33.24378204 33.25235748 33.25220108 33.2415657 33.25444412 33.25338745 33.25375366 33.24398041 33.25110626 33.25418854 33.25368881 33.25493622 33.25067902 33.25409317 33.2492981 33.24889374 33.25355148 33.25393677 33.27548599 33.2532692 33.25415421 33.24729538 33.25309372 33.25460434 33.25290298 33.2504921 33.25309753 33.38135529 33.2539444 33.25337601 33.25337982 33.27366638 33.24964142 33.24594879 33.2457428 33.25065613 33.25419235 33.27780533 33.25057602 33.25443268 33.24456406 33.25370789 33.24592209 33.2532692 33.24670029 33.25112152 33.24883652 

-------
======================
selected experts : 10, 13, 35, 44, 48, 54, 
layer5_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc4a9a10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.230467 0.147142 0.06459260.0019409 -0.181316 0.0733079 0.0421877 0.0761149 -0.146847]

layer5_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a9350>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.74251 -0.497689 0.1515-0.27086 0.310161 -0.653332 0.459045 1.16066 -0.36663]

layer6_wq's input 
<N9nntrainer6TensorE at 0x5682dc4e8620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wq's output 
<N9nntrainer6TensorE at 0x5682dc4a9530>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.695634 -0.228144 -0.5810460.323757 -0.197663 -0.540155 0.504746 0.847593 -0.763714]
============================
layer6_wk's input 
<N9nntrainer6TensorE at 0x5682dc4ea380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wk's output 
<N9nntrainer6TensorE at 0x5682dc4ea0f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0214494 -0.00297009 0.00338558-0.00782245 0.00143022 0.00439973 0.00877311 -0.0147463 -0.046852]
============================
layer6_wv's input 
<N9nntrainer6TensorE at 0x5682dc4eb170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wv's output 
<N9nntrainer6TensorE at 0x5682dc4eaf00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0156485 0.0104525 0.01945610.00157869 0.0098697 0.000841773 -0.0121287 0.00979754 -0.00119108]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.567829 0.462089 -0.634204-0.200544 0.176998 -0.547274 -0.00342649 0.986494 -0.884955]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1a82cc8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer6_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc41beb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer6_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc41be10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer6_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc41cf30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.74251 -0.497689 0.1515-0.27086 0.310161 -0.653332 0.459045 1.16066 -0.36663]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0147305 -0.0212876 0.00626695-0.0120428 0.0127428 -0.0295996 0.0207973 0.051278 -0.014547]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.04598842189 0.871989727 0.1590040326 -0.8808486462 -0.7566508055 -0.0392893441 0.2642817199 0.3292520642 0.2644926012 0.08304589987 0.0166921448 -0.2166069597 1.023880839 -0.08878401667 -0.2583498955 0.2684820294 0.1323997676 -0.9021778703 0.135657087 0.2334127873 0.1226155683 0.1617766619 0.007764321752 1.611345887 0.2760307789 -0.5341758728 -0.6800649762 0.1462279111 0.2474199682 -0.1545801759 -0.6242238879 -0.3659591973 0.0122226933 -0.2061981857 -0.1350325495 -0.7296162844 1.269290686 -0.002525131684 0.3083646595 -0.1382303983 0.2969625592 0.06327658892 0.1928350031 0.676184237 0.2964215279 0.01302839536 0.08529359847 0.2071783841 -0.05202829838 -0.6404911876 -0.05744434148 0.4427712262 0.3092009425 0.38174209 -0.3089568913 0.2807747126 0.3261196911 0.22609815 -0.1027657315 0.3057509661 0.296938926 0.3073717356 0.02158760652 -0.1024745256 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01360130031 0.03106763959 0.01522868965 0.005383443553 0.006095350254 0.01248949207 0.01691936329 0.01805511862 0.01692293212 0.01411478501 0.01320861373 0.01046012156 0.03616377339 0.01188637782 0.01003247313 0.01699057966 0.01482888218 0.005269835237 0.01487726346 0.01640505902 0.01468450017 0.01527097076 0.013091214 0.06507385522 0.01711932197 0.007614096161 0.006580508314 0.01503536291 0.01663646474 0.0111294724 0.006958425511 0.009008944035 0.01314970851 0.01056956686 0.01134916861 0.006262382492 0.04622254521 0.01295720413 0.01768190227 0.01131293271 0.01748143882 0.01383848768 0.01575270295 0.02554294653 0.01747198217 0.01316030882 0.0141465487 0.01598027907 0.0123313982 0.006846146192 0.01226479094 0.02022558078 0.01769669354 0.01902814396 0.009537393227 0.01720072888 0.01799864694 0.01628550142 0.01172134187 0.01763574779 0.01748102345 0.01766435429 0.01327343471 0.01172475517 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.13698196 40.15444946 40.13098145 40.12876511 40.12947845 40.13587189 40.14125443 40.14143753 40.14030457 40.13749695 40.13659286 40.13098145 40.1595459 40.13431549 40.13341522 40.14037323 40.1382103 40.12865067 40.13825989 40.13978577 40.13806534 40.1386528 40.13647461 40.18845749 40.14050293 40.1309967 40.1309166 40.13841629 40.14001846 40.13451385 40.12747955 40.13143921 40.13653183 40.13395309 40.13473129 40.1296463 40.16960526 40.13634109 40.14106369 40.13469696 40.14086533 40.13722229 40.13817978 40.14892578 40.14085388 40.13749695 40.13657379 40.13936234 40.13476181 40.13022995 40.13564682 40.14360809 40.14107895 40.14241028 40.13005829 40.14058304 40.14042664 40.13966751 40.13319778 40.14101791 40.14086533 40.13818741 40.13665771 40.13510895 

-------
======================
selected experts : 1, 12, 23, 36, 43, 51, 
layer6_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc47b4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0510724 -0.0072978 0.002230830.066627 0.0371369 -0.00985265 -0.0324661 0.0408974 0.107894]

layer6_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc47ae20>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.793582 -0.504987 0.153731-0.204233 0.347298 -0.663184 0.426579 1.20156 -0.258736]

layer7_wq's input 
<N9nntrainer6TensorE at 0x5682dc5555c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wq's output 
<N9nntrainer6TensorE at 0x5682dc47b000>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.657963 0.508159 0.759416-0.493352 0.0679253 0.91612 0.356312 0.745763 0.297703]
============================
layer7_wk's input 
<N9nntrainer6TensorE at 0x5682dc557b30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wk's output 
<N9nntrainer6TensorE at 0x5682dc5578a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00883845 -0.00656046 -0.02105710.0099999 0.028946 0.0126508 0.00832559 -0.0132098 -0.0295955]
============================
layer7_wv's input 
<N9nntrainer6TensorE at 0x5682dc558920>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wv's output 
<N9nntrainer6TensorE at 0x5682dc5586b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0188292 0.010387 -0.0138226-0.0142297 0.00276319 0.00587439 0.00344935 -0.0125941 0.00343755]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0721018 0.828216 0.8799660.213935 -0.510781 0.763539 -0.0782901 0.822795 0.523187]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a187dcb8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer7_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc55ad70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer7_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc55acd0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer7_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55bdf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.793582 -0.504987 0.153731-0.204233 0.347298 -0.663184 0.426579 1.20156 -0.258736]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0163221 -0.0230185 0.00675105-0.00965002 0.0152515 -0.0313355 0.0206301 0.0554378 -0.0110747]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.168024302 0.6618694067 -0.4694300592 -0.07413705438 0.7391534448 -0.06975306571 0.1814451218 0.4088294804 0.2756572068 -0.01008156221 0.5435899496 0.4069769084 -0.6550350189 0.07319442928 -0.56976825 0.3659587801 0.6475477815 0.04731979966 0.2641719878 0.295361042 0.4828495979 0.6668714285 -0.2184385061 -0.2693095505 -0.4303425848 0.4009917974 0.5435461998 -0.2240395248 0.3005890548 0.2294455171 0.1688566357 1.472923517 0.4575823247 0.5258388519 0.4786459804 -0.03981018811 0.3397579789 -0.005647979677 0.05844898149 0.6566990614 -0.944694221 0.03326295689 1.298671484 1.307865739 0.6658383608 0.252460748 0.4188720584 0.521461308 0.061222516 0.3877601027 0.6422598958 0.1709300727 0.5699272752 -0.7041506171 -0.5168834329 -0.1764284968 -0.09934764355 0.5614067316 0.6186754107 0.6668535471 0.02402624302 1.682482243 0.5926005244 -0.3600988984 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03339649364 0.02013170719 0.006494766567 0.009643552825 0.02174926735 0.009685923345 0.01245188154 0.01563099958 0.01368203759 0.01028148923 0.01788596809 0.01560206991 0.005394563079 0.01117435098 0.005874720402 0.01497504953 0.01984544285 0.01088892762 0.01352579426 0.0139542995 0.01683190651 0.02023265883 0.008347717114 0.007933680899 0.006753655616 0.01550896745 0.01788518578 0.00830109138 0.01402744371 0.01306415349 0.01229611319 0.04530195147 0.01641193777 0.01757127605 0.01676130109 0.009980333038 0.01458778512 0.0103271734 0.01101079024 0.02002788708 0.00403793063 0.01073693391 0.03805749863 0.03840902448 0.02021176741 0.01336831506 0.01578876749 0.0174945239 0.01104137115 0.01530511118 0.01974077895 0.01232163515 0.01836329512 0.005136006977 0.006193765905 0.008705874905 0.009403472766 0.01820749603 0.01928065158 0.02023229748 0.01063821744 0.05586336926 0.01878440939 0.007245117333 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
35.95775986 35.94926071 35.93467331 35.93495941 35.94897079 35.93881607 35.92441559 35.94285583 35.9418602 35.93845749 35.94701767 35.94473267 35.93452454 35.93839645 35.93500519 35.94315338 35.94897461 35.9400177 35.94075012 35.94213104 35.94500732 35.94841003 35.93461609 35.93515778 35.92539215 35.94273376 35.94701385 35.93647766 35.93075943 35.94219589 35.94047165 35.97348022 35.94458771 35.94670105 35.94589233 35.93434143 35.94276428 35.93754959 35.9391861 35.94820404 35.9303093 35.93796158 35.96528244 35.96754074 35.94934082 35.93868256 35.94396591 35.94662476 35.93921661 35.93966675 35.94791794 35.93668365 35.94749451 35.93331146 35.93532562 35.93592834 35.93758011 35.9473381 35.94841003 35.94936371 35.9378624 35.98499298 35.94791412 35.93542099 

-------
======================
selected experts : 0, 4, 31, 42, 43, 61, 
layer7_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5969b0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0358682 0.0494057 -0.02676070.00325278 -0.0567075 -0.0131402 0.0472899 0.0318014 0.108935]

layer7_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55e510>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.757714 -0.455581 0.12697-0.20098 0.29059 -0.676324 0.473869 1.23336 -0.149801]

layer8_wq's input 
<N9nntrainer6TensorE at 0x5682dc59a250>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wq's output 
<N9nntrainer6TensorE at 0x5682dc5d3620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.17101 -0.653928 0.222739-0.618268 0.202001 -0.518507 -0.352742 -0.371231 0.40923]
============================
layer8_wk's input 
<N9nntrainer6TensorE at 0x5682dc59bfb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wk's output 
<N9nntrainer6TensorE at 0x5682dc59bd20>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0122512 -0.0240249 0.0049726-0.00696511 -0.00671129 0.0076463 -0.00612936 0.00283497 -0.00945466]
============================
layer8_wv's input 
<N9nntrainer6TensorE at 0x5682dc59cda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wv's output 
<N9nntrainer6TensorE at 0x5682dc59cb30>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0125965 -0.00244861 0.007529460.00303611 0.0145719 0.00140784 -0.0154647 -0.0179054 0.00261313]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.457864 -0.497218 0.602599-0.262188 0.478511 -0.284045 -0.111396 -0.49983 0.377893]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1473c98
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer8_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc59f1f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer8_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc59f150>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer8_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a0270>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.757714 -0.455581 0.12697-0.20098 0.29059 -0.676324 0.473869 1.23336 -0.149801]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0170022 -0.0222015 0.005803-0.0102922 0.013441 -0.0348208 0.0242669 0.0607834 -0.0068052]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.04677072912 0.0153601896 0.2453148216 0.3004711866 -0.3885725439 0.05983536318 -0.01540975925 0.05687586218 0.2940652668  0.1836714 -0.01984599419 0.4423549771 0.2803600132 0.05182646215 0.1945592016 0.2888280451 0.1189836785 0.1493378282 -0.5161525607 0.266795069 -0.8293113112 0.2661831379 0.08042082191 0.07239897549 0.05997288972 0.3686698079 -1.536476731 -0.3078627288 -0.7882967591 0.24841474 0.2563607693 -0.04476862773 0.5374804139 -0.3126162291 4.726294041 0.2904126942 -0.4587142169 0.1429113746 0.2790945172 -0.3088897169 0.3767482638 0.1019092426 0.2512847781 0.5570003986 0.134382531 -0.3317438364 0.1961397231 -0.2455921173 -0.03754698113 0.2989471853 0.1975146532 0.2983741462 0.5875585675 0.003402953502 0.7836763859 -0.401131928 0.07859761268 0.2543839812 0.2182640433 0.1351471692 0.2176695615 0.1511563063 0.435500294 0.8533852696 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005646863021 0.005472250748 0.006887059659 0.007277598605 0.003653760534 0.005721122492 0.005306432024 0.005704214796 0.007231128402 0.006475340109 0.005282944534 0.008387016132 0.007132700179 0.005675485358 0.00654622633 0.007193353958 0.006069725845 0.006256790832 0.003216125071 0.007036597934 0.002351417439 0.007032294292 0.005840115249 0.005793454591 0.005721908063 0.007791236974 0.001159342472 0.003960882314 0.002449864987 0.006908441894 0.006963555235 0.005152905826 0.009224010631 0.003942098934 0.6082729101 0.007204764523 0.003406262491 0.00621671183 0.007123679388 0.003956816625 0.007854430005 0.005966967437 0.006928298157 0.009405835532 0.006163916085 0.003867413383 0.006556582171 0.004215370398 0.005190253723 0.007266516332 0.006565601565 0.007262352388 0.009697696194 0.005407207645 0.01179889683 0.003608158557 0.005829476751 0.006949805655 0.006703258492 0.006168629508 0.006699273828 0.006268180441 0.008329719305 0.01265072823 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.07797623 34.07875824  34.079216 34.08056259 34.07598495 34.0790062 34.07859039 34.07898712 34.07956314 34.07880402 34.0785675 34.07595062 34.07660294 34.07896042 34.07983017 34.07857132 34.07839966 34.07954025 34.04884338 34.07269287 34.07468033 34.07936096 34.07912445  34.078125 34.07805252 34.08012009 34.07444382 34.07629013 34.07573318 34.07923889 34.08024597 34.07843781 34.08155441 34.07627487 34.67488098 34.07858276 34.07669067 34.07854843 34.07945251 34.07533264 34.08018494 34.07925034 34.07925797 34.07983017 34.0794487 34.07715225 34.07984161 34.07654572 34.07752228 34.08055115 34.07984924 34.07959366 34.08107376 34.07868958 34.08031464 34.07689285 34.07911301 34.07928085 34.0790329 34.07945251 34.07998276 34.07859802 34.0758934 34.07258224 

-------
======================
selected experts : 32, 34, 43, 52, 54, 63, 
layer8_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5a3350>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0681935 -0.0987799 -0.1255480.266272 -0.427989 -0.0341151 -0.182963 0.2666 0.19531]

layer8_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a2c90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.68952 -0.554361 0.00142260.0652915 -0.137399 -0.71044 0.290906 1.49996 0.0455094]

layer9_wq's input 
<N9nntrainer6TensorE at 0x5682dc5e1750>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wq's output 
<N9nntrainer6TensorE at 0x5682dc5a2e70>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141972 0.0167292 -0.2640250.310849 -0.154788 0.0734234 -0.210784 -0.00362809 -0.189374]
============================
layer9_wk's input 
<N9nntrainer6TensorE at 0x5682dc5e3c80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wk's output 
<N9nntrainer6TensorE at 0x5682dc5e39f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00161957 -0.00211483 -0.01375779.81252e-05 -0.00883225 0.00970442 -0.0232949 -0.00734125 -0.0170646]
============================
layer9_wv's input 
<N9nntrainer6TensorE at 0x5682dc5e4a70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wv's output 
<N9nntrainer6TensorE at 0x5682dc5e4800>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.011892 -0.000943265 -0.006786920.0114438 -0.0217582 0.0152061 -0.00763955 -0.0135636 0.0142479]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0626306 0.128504 -0.4072920.0212196 -0.167165 -0.0375017 -0.178861 -0.111587 -0.216107]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a126ec88
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer9_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc5e6ec0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer9_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc5e6e20>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer9_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5e7f40>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.68952 -0.554361 0.00142260.0652915 -0.137399 -0.71044 0.290906 1.49996 0.0455094]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0163705 -0.0284533 6.91121e-050.00351246 -0.00667504 -0.0384142 0.0157296 0.0773991 0.00218593]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3258353472 0.183533296 -0.09342952073 -1.036007285 2.088111162 0.008346061222 -0.7364020944 -1.349478364 0.3679609299 0.1264469326 1.101921201 0.259608686 0.4678474665 -1.35572803 0.4126421809 -0.07927054912 0.1937977076 0.3577730358 -0.3610570133 -0.1297360808 0.3895307481 1.095702529 0.1365136802 0.2798104882 0.4129787385 0.1292768866 0.1402641833 -0.1215476245 -0.04986479506 -0.7106806636 0.4740997851 0.4535753131 -0.2847249806 1.092014313 -1.758917809 -0.2847560942 -0.2298212647 -0.6525506973 -0.1235622168 0.4583579898 -0.7284759879 0.4226437807 1.040506482 0.5733621716 0.317548275 -0.7666806579 -0.6158863902 -0.1706359237 -0.3159227073 0.4458977878 -0.1455331892 -0.06074886769 0.1500902325 -0.07550656796 -0.2112460881 -0.4560808241 -0.04254198447 -0.6656578779 -0.3927685916 -0.1671101898 -0.002543612383 0.1304136366 0.551289022 -0.1643009335 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009224582464 0.01535192225 0.01163802482 0.004534433596 0.1031122804 0.01288486551 0.006118428428 0.003314241767 0.01846114546 0.01450008154 0.0384603776 0.01656539738 0.02040040493 0.003293594345 0.01930471882 0.01180397905 0.01551031135 0.0182740204 0.008905332536 0.01122306567 0.01886367425 0.03822194785 0.0146467872 0.01690345071 0.01931121573 0.01454117335 0.01470182277 0.0113153439 0.01215623971 0.00627784431 0.02052835561 0.02011131682 0.009611711837 0.03808123246 0.002200730843 0.009611411951 0.01015418675 0.006653590593 0.01129257306 0.02020773478 0.006167116109 0.01949876361 0.03616941348 0.02267061174 0.01755353995 0.005935947411 0.006902066525 0.01077330578 0.009316476993 0.01995750144 0.01104716957 0.01202464849 0.01484699547 0.01184849534 0.01034456585 0.008098075166 0.01224558335 0.006566950586 0.008627361618 0.01081135683 0.01274531428 0.01455771364 0.02217568457 0.01084177103 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.46111679 34.46724319 34.45780945 34.45547485 34.55405045 34.4647789 34.43607712 34.45520782 34.47035217 34.46543884 34.49035263 34.46846008 34.47229385 34.45518494 34.47119904 34.46369553 34.46644974 34.47016525 34.45984268 34.46311569 34.46503448 34.49011612 34.46558762 34.46688843 34.47120285 34.46643448 34.4665947 34.46320724 34.45355988 34.45817184 34.47241974 34.47200394 34.46055222 34.4890213 34.45409393 34.45292282 34.45632553 34.45759201 34.46318436 34.4720993 34.43421936 34.47138977 34.48329544 34.47360992 34.46944809 34.45782852 34.45879364 34.45789719 34.45930099 34.47185135 34.45817184 34.46391678 34.46673965 34.4637413 34.45937729 34.45808411 34.46127701 34.45750427 34.45861435 34.46175003 34.46273041 34.46644974 34.47406769 34.46082687 

-------
======================
selected experts : 4, 10, 21, 33, 42, 43, 
layer9_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5eb020>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.104579 -0.000398263 -0.07572780.115588 0.014312 0.0643511 0.122948 -0.0377023 0.091618]

layer9_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5ea960>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.584942 -0.554759 -0.07430520.18088 -0.123087 -0.646088 0.413854 1.46226 0.137127]

layer10_wq's input 
<N9nntrainer6TensorE at 0x5682ded33210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wq's output 
<N9nntrainer6TensorE at 0x5682dc5eab40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37707 -0.407332 -0.004689360.264799 -0.450686 0.237675 0.354465 0.042499 -0.208016]
============================
layer10_wk's input 
<N9nntrainer6TensorE at 0x5682ded34f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wk's output 
<N9nntrainer6TensorE at 0x5682ded34ce0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0208244 0.0187902 -0.0183501-5.44079e-05 0.00482989 0.0189981 -0.00186447 -0.0230889 0.00503917]
============================
layer10_wv's input 
<N9nntrainer6TensorE at 0x5682ded35d60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wv's output 
<N9nntrainer6TensorE at 0x5682ded35af0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0224915 0.00636522 0.0154213-0.00975636 0.0199064 0.0167431 -0.0279089 -0.0151201 0.023924]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.54649 0.0972113 -0.1958490.17828 -0.501439 -0.0903686 0.28205 0.218859 -0.153279]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1069c78
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer10_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded38210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer10_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded38170>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer10_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded39290>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.584942 -0.554759 -0.07430520.18088 -0.123087 -0.646088 0.413854 1.46226 0.137127]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.01385 -0.0297634 -0.003742470.0101995 -0.00619941 -0.0366087 0.0237897 0.0788518 0.00683152]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.2405900508 0.2403998226 0.002393446397 0.09837586433 1.045801878 -0.8216309547 -1.209175825 0.3056552112 -0.2752718031 0.3853158951 -1.040553689 -0.4904887974 0.2650624514 -0.7685959339 -0.8298601508 -1.237736106 0.03745195642 -0.165141806 -0.4367792606 -0.7191370726 -0.961849153 0.3766517937 -0.4394464791 0.6722314358 -0.05634330213 0.07336346805 0.2354294658 -0.00606180029 -1.113972902 0.9323561192 -0.3637063205 0.3454566598 0.2466523647 0.2701610923 0.3343005478 -0.5620473027 -1.098581672 0.1022080481 -0.1563752741 0.02149196714 0.1330704093 -1.023319602 -0.3335804641 -0.1875314862 0.009166814387 -0.7846198082 0.1157286912 -0.9036570191 -0.8283277154 1.769645333 -0.7296331525 -0.4721302688 -0.02899205871 0.1692908704 0.2316015065 1.04218781 -0.1277344823 0.7623437047 -0.3691411912 0.1704837829 -0.1390079856 0.9013450146 0.08754011244 0.1399177164 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01815791614 0.01815446094 0.01430930384 0.01575081982 0.0406223461 0.006276959088 0.004260303918 0.01937864535 0.01084001828 0.02098551393 0.005042806268 0.008741025813 0.01860776357 0.006618842017 0.006225516088 0.004140350502 0.01481986418 0.01210204791 0.009223339148 0.006954433862 0.00545573514 0.02080447786 0.00919877179 0.02795924433 0.01349302847 0.01536173839 0.01806444861 0.01418882515 0.004685831722 0.03626570851 0.009922552854 0.0201654993 0.01826832816 0.01870287955 0.01994178072 0.008137387224 0.004758510739 0.01581129432 0.01220860705 0.01458521653 0.01630687527 0.005130467936 0.01022602711 0.01183409803 0.01440655533 0.006513629574 0.01602652669 0.005782634486 0.006235063076 0.08377727866 0.006881820504 0.008902981877 0.01386717334 0.01690834761 0.01799543202 0.04047580063 0.0125633264 0.03059572168 0.009868769906 0.01692852937 0.01242249086 0.03515832499 0.01558106858 0.0164189171 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.12060547 33.12155533 33.11771011 33.11915207 33.1440239 33.10013962 33.1076622 33.12277985 33.11233521 33.12438583 33.10844421 33.11118698 33.12200928 33.10429764 33.10581207 33.10754013 33.11822128 33.11454773 33.1059494 33.10749435 33.10790253 33.12420654 33.11259842 33.12563705 33.11403275 33.1139946 33.1205101 33.11759186 33.10713196 33.13966751 33.11236954 33.12356567 33.12166977 33.12210464 33.12334442 33.10963058 33.10625076 33.1192131 33.11560822 33.11798477 33.1015892 33.08945847 33.11362839 33.11523438 33.1178093 33.10800934 33.11847305 33.10918427 33.10486603 33.18717957 33.1064682 33.11230469 33.11726761 33.11840057 33.12139511 33.14387512 33.11405563 33.12922668 33.11136246 33.11937714 33.11582184 33.1366539 33.11898041 33.11981964 

-------
======================
selected experts : 4, 29, 49, 55, 57, 61, 
layer10_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded3c110>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00871513 -0.0179093 -0.129039-0.00419578 -0.0721665 -0.0473022 0.0376891 -0.0830591 0.0259834]

layer10_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded3bb90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.576227 -0.572668 -0.2033450.176684 -0.195253 -0.693391 0.451544 1.3792 0.163111]

layer11_wq's input 
<N9nntrainer6TensorE at 0x5682ded7c3b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wq's output 
<N9nntrainer6TensorE at 0x5682ded3ba40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.574647 -0.344996 -0.3160790.0666121 0.327954 0.336796 -0.180087 0.539557 0.764458]
============================
layer11_wk's input 
<N9nntrainer6TensorE at 0x5682ded7e110>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wk's output 
<N9nntrainer6TensorE at 0x5682ded7de80>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0108217 0.0526808 0.006898240.0209765 0.0171261 0.0374855 -0.0384892 0.0369667 0.0138322]
============================
layer11_wv's input 
<N9nntrainer6TensorE at 0x5682ded7ef00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wv's output 
<N9nntrainer6TensorE at 0x5682ded7ec90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00918804 0.00942161 0.0280262-0.0530578 0.0101649 0.00276343 0.00300308 0.0247157 0.0975801]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.600787 0.297146 -0.265334-0.18423 0.0509033 0.467326 -0.432083 0.369942 0.909601]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0e64c68
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer11_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded813b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer11_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded81310>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer11_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded82430>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.576227 -0.572668 -0.2033450.176684 -0.195253 -0.693391 0.451544 1.3792 0.163111]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0134085 -0.0321063 -0.01051490.0103385 -0.0102559 -0.0415165 0.027036 0.0765732 0.00839005]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8536322117 -0.350666672 -0.2271159291 -0.814027369 -0.24312675 -0.4555317461 -0.1419058442 2.084069014 -0.5543870926 0.160293147 -0.3175723851 -1.9721241 -0.2567070723 -1.214590073 -0.7125858068 0.09249140322 -0.09203302115 -0.7283654809 1.177680373 -0.4151083827 -0.1389609128 0.09961105138 -1.649830222 -0.6365466118 -0.4705213308 -0.9583889842 -0.7093999982 -1.075470805 -0.6670421362 -0.1231312156 -0.5486690998 -0.05667171255 0.2446939349 -0.4024503827 -0.2572669983 -0.4099058807 -0.1073041111 -1.158459306 -0.703230381 -0.5467608571 -0.07921869308 -0.1965308785 -2.247526884 -0.1062458828 -0.2751447856 -1.356668234 -0.3595725298 -0.07924947888 -1.645887733 -0.6230176091 -1.833443165 -0.3092767894 -0.6894958615 -0.2229477465 -0.4004736543 0.674198091 -0.08846428245 -0.1153771728 -0.8708809018 -1.661915421 -0.03361873329 0.5712429285 -1.02976048 -0.3162067533 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007948376238 0.01314357575 0.0148720555 0.00826948788 0.01463583857 0.01183508057 0.01619486138 0.1500050426 0.01072108932 0.02190889977 0.01358583197 0.002597307786 0.0144384224 0.005540084559 0.009152381681 0.02047267929 0.01702302694 0.009009093046 0.06059911102 0.0123232957 0.01624262705 0.0206189584 0.003585040569 0.009875463322 0.01165900286 0.007157857995 0.009181586094 0.006367004942 0.009578852914 0.01650178619 0.01078256872 0.01763575152 0.02383830771 0.01248027664 0.01443033852 0.01238757465 0.01676503941 0.005859945901 0.009238407016 0.01080316398 0.01724256761 0.01533394586 0.001972048776 0.01678278856 0.01417464856 0.004806319252 0.01302704029 0.01724203676 0.00359920226 0.01000997704 0.002983677667 0.0136990035 0.009366167709 0.01493417192 0.01250497065 0.0366274491 0.01708388515 0.01663023792 0.007812452968 0.003541974584 0.01804703102 0.03304409236 0.006664795801 0.01360439882 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.54969406 28.55584335 28.55804825 28.53952599 28.55208969 28.54166031 28.55126572 28.69365883 28.55199051 28.5617485 28.55723953 28.5462513 28.55284691 28.5487175 28.55232811 28.55649757 28.56019974 28.55218506 28.59614563 28.5512085 28.55989647 28.5614109 28.54676247  28.543993 28.55197525 28.54699707 28.54806709 28.53809929 28.54703331 28.55967903 28.5501442 28.55985832 28.56701469 28.55565643 28.55713081 28.54984283 28.55994225  28.546175 28.55098534 28.55397987 28.56041908 28.55707932 28.54514885 28.55280685 28.55544472 28.54607582 28.55334282 28.56041908 28.54725266 28.54794121 28.54568291 28.55401421 28.5520668 28.55811119 28.55568123 28.57932663 28.55978394 28.55980682 28.54622078 28.5467186 28.56074715 28.57574463 28.54936409 28.55630493 

-------
======================
selected experts : 7, 9, 18, 32, 55, 61, 
layer11_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded85530>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.333239 -0.0966277 0.0164065-0.155013 -0.154962 0.0912206 0.0206473 0.0287376 0.173099]

layer11_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded84d30>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.242987 -0.669296 -0.1869380.0216705 -0.350215 -0.60217 0.472191 1.40794 0.336209]

layer12_wq's input 
<N9nntrainer6TensorE at 0x5682dedc4470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wq's output 
<N9nntrainer6TensorE at 0x5682ded84be0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.242823 0.417797 0.07170260.586705 0.501475 0.360597 0.460942 0.30801 0.72607]
============================
layer12_wk's input 
<N9nntrainer6TensorE at 0x5682dedc61d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wk's output 
<N9nntrainer6TensorE at 0x5682dedc5f40>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0059719 0.0473741 0.01258060.0277794 0.0201364 0.0578011 0.0204722 0.00987752 -0.0366265]
============================
layer12_wv's input 
<N9nntrainer6TensorE at 0x5682dedc6fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wv's output 
<N9nntrainer6TensorE at 0x5682dedc6d50>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00766343 -0.0528842 0.0304772-0.00113746 -0.0263957 0.00103918 0.00807294 -0.021785 0.00503729]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.220366 0.430065 -0.3776080.454727 0.172939 0.592959 0.236704 0.501307 0.629851]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0c5fc58
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer12_attention_out's input 
<N9nntrainer6TensorE at 0x5682dedc9470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer12_attention_out's output 
<N9nntrainer6TensorE at 0x5682dedc93d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer12_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dedca4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.242987 -0.669296 -0.1869380.0216705 -0.350215 -0.60217 0.472191 1.40794 0.336209]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00532087 -0.0374544 -0.009399940.00127128 -0.0179888 -0.0363026 0.0284667 0.0772668 0.0171785]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.515114903 0.1988955289 -0.9148083925 0.4729863703 0.09639342874 -0.6808546782 0.1147310883 -0.4401502907 -0.1680116206 -0.3849343359 0.007665990852 0.2398532033 -0.804179132 -1.055164337 -0.8419640064 0.1758016348 -0.00687226234 -0.1439996511 -1.990939736 0.1290771216 0.2109279782 -1.326081753 0.06457764655 -1.200477242 -0.4049041867 -0.09832254797 -0.5622937083 -0.5176398158 -0.5233002305 -1.259488463 -1.66703105 -1.807760835 -1.113789678 -1.614046335 0.0009765264113 1.904020071 -0.4413326979 -0.8838368654 -0.04244723171 0.2512405515 -0.04221006855 -0.5307527184 -0.7680432796 -1.219922185 -0.0778702423 -1.0996387 -0.5135358572 -0.5197799802 -0.987991631 -0.5169560909 0.6045063138 -0.9295527935 -0.9713642001 -0.537006259 0.2595245838 0.04104918987 -0.4304583073 -1.368692636 0.4785416722 -0.1011550277 -0.1014918387 2.315051079 -0.7431070209 -0.141637668 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003567925189 0.01980618946 0.00650317641 0.02605176158 0.01787659712 0.008217320777 0.01820743643 0.01045362372 0.01372319274 0.0110470634 0.01635878161 0.02063424699 0.007263921667 0.005651577841 0.006994576193 0.01935403235 0.01612267829 0.01405670401 0.002217009896 0.01847052574 0.02004594728 0.004310342018 0.01731679216 0.004887211602 0.01082864497 0.01471366175 0.009251681156 0.009674167261 0.009619562887 0.004607154522 0.003065062687 0.002662693616 0.005329777021 0.003231843235 0.01624971814 0.1089750677 0.01044126973 0.006707741413 0.01555919368 0.02087055892 0.01556288544 0.009548139758 0.007531210314 0.004793098196 0.01501769014 0.005405734293 0.009713950567 0.009653486311 0.006044249982 0.009680784307 0.02971361391 0.006407993846 0.006145589985 0.009488614276 0.02104417048 0.01691411063 0.01055543404 0.004130532965 0.02619688772 0.0146720456 0.01466710307 0.1643749475 0.007721371017 0.0140899457 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
30.80790329 30.82461739 30.8108387 30.82991028 30.82125664 30.81064415 30.82301903 30.81478882 30.81472015 30.81585884 30.82117081 30.82115364 30.81207466 30.8085556 30.80989838 30.82368851 30.8209343 30.81791496 30.80702782 30.82232857 30.82104301 30.80912209 30.8221283 30.80922127 30.8156395 30.81952477 30.81311035 30.81448555 30.81252289 30.80798721 30.80739975 30.80747414 30.80918694 30.80327415 30.82058525 30.90997124 30.81477547 30.81056595 30.81989288 30.82520485 30.8198967 30.81435966 30.80948257 30.80912781 30.8193531 30.80974007 30.81309509 30.8058815 30.80894852 30.81449318 30.83404922 30.80835915 30.81048012 30.81143951 30.82585526 30.82172585 30.81488991 30.80703545 30.83053207 30.81900597 30.81947899 30.96918678 30.80108833 30.81747055 

-------
======================
selected experts : 3, 35, 50, 54, 58, 61, 
layer12_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dedcd730>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.261759 0.0260365 0.00151380.0209557 -0.246369 0.0859744 -0.00723364 -0.109461 0.183084]

layer12_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dedccdf0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0187714 -0.64326 -0.1854240.0426262 -0.596584 -0.516196 0.464957 1.29847 0.519293]

layer13_wq's input 
<N9nntrainer6TensorE at 0x5682dee397f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wq's output 
<N9nntrainer6TensorE at 0x5682dedccca0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.544315 0.211178 0.4857970.142756 0.287921 -0.0756668 -0.190495 0.334301 0.515609]
============================
layer13_wk's input 
<N9nntrainer6TensorE at 0x5682dc471a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wk's output 
<N9nntrainer6TensorE at 0x5682dc4717a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00536536 0.0270588 0.0105784-0.0175378 -0.0381201 -0.00524855 -0.0441706 0.0075387 0.00437258]
============================
layer13_wv's input 
<N9nntrainer6TensorE at 0x5682dc472820>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wv's output 
<N9nntrainer6TensorE at 0x5682dc4725b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0538234 0.00921317 -0.00105804-0.0519059 -0.0114752 0.000672776 0.0390768 0.0122256 -0.005239]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.116394 0.572125 0.2294780.451351 0.273426 0.117739 -0.335375 0.188598 0.619426]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0a5ac48
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer13_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc474cd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer13_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc474c30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer13_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc475da0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0187714 -0.64326 -0.1854240.0426262 -0.596584 -0.516196 0.464957 1.29847 0.519293]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.000411249 -0.0366582 -0.009470430.00255523 -0.0306305 -0.0320535 0.0282469 0.0722525 0.0266621]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8210696578 0.01764702797 0.1705377102 -1.32864821 -0.6457030773 0.2107856125 -0.5317567587 0.4186590016 0.1665709466 -0.09206339717 -0.7631891966 0.5217927694 -0.4000129104 -0.0318245478 -0.6582522988 -0.6459796429 -0.1373912543 -0.6905651093 -0.9183356166 -0.1151067689 -1.146143317 -1.225360155 -0.8136463761 -1.787121296 -0.08054890484 0.2638849914 0.1978272647 -1.86265564 -0.3499395549 -1.720562339 -0.5657072663 -1.050999761 -0.5782107711 0.1856319308 -0.4710305333 0.3538194895 -0.02123886347 0.2299393564 -0.5446910262 -0.2708410919 0.1396059841 -0.009761870839 -0.4558828175 -0.8684517741 -1.109177709 -1.336254835 -0.4432338178 -0.7737660408 0.2498282343 3.344063044 0.06941227615 0.2823231816 -0.2373957634 -0.1085118875 0.5851342678 -0.1705833822 -0.638215065 -0.5434451699 0.4397984147 -0.7761206031 -0.911747992 -1.731405616 -0.6584652066 -1.277460694 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.00578087708 0.01337345783 0.01558271982 0.003479806008 0.00688897213 0.01622268371 0.007720416412 0.01997105218 0.01552102901 0.01198386867 0.006125349551 0.02214070037 0.008807573467 0.01272794977 0.006803059019 0.006887066178 0.01145279221 0.006586750038 0.005245073233 0.0117108766 0.004176533781 0.003858446609 0.005823947955 0.002200101269 0.01212265249 0.01710737869 0.01601382345 0.002040040214 0.009259826504 0.002351521747 0.007462702692 0.004593420774 0.007369973231 0.01581971347 0.008203774691 0.01871722937 0.01286340132 0.01653640531 0.007621199358 0.01002201065 0.01510809734 0.01301188301 0.008328989148 0.005513353739 0.004333809949 0.003453437472 0.008435011841 0.006060902029 0.01686858758 0.3722955287 0.01408396848 0.01742573269 0.01036286913 0.0117883645 0.02358849533 0.01107888855 0.00694074994 0.007630701177 0.02039772272 0.00604665 0.005279738922 0.002326161368 0.006801612675 0.003662566189 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.72777176 28.73631859 28.73805046 28.72642326 28.72840309 28.73821259 28.73018837 28.74196243 28.73894119 28.73540497 28.72525406 28.73697853 28.72984505 28.73471832 28.72784042 28.73030853 28.73439789 28.7252388 28.72866631 28.73513222 28.72664452 28.72489548 28.72781372 28.72514343 28.73602104 28.74005127 28.73609734 28.72450829 28.73220444 28.72434235 28.72993088 28.72753716 28.73031425 28.73876381 28.72637939 28.74023056 28.73580742 28.73709679 28.73104286 28.73296547 28.73852921 28.73595619 28.72841263 28.7284584 28.72489357 28.72592163 28.73137856 28.7237606 28.73933601 29.09571648 28.73750496 28.7403698 28.73330688 28.73473167 28.74653244 28.73450089 28.72940826 28.72914505 28.74286461 28.72756004 28.7282238 28.72479439 28.7302227 28.72708321 

-------
======================
selected experts : 7, 11, 35, 49, 54, 58, 
layer13_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee45420>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.337035 -0.127108 -0.2176710.144968 -0.150565 0.148819 0.00124518 -0.257126 0.256935]

layer13_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc478790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.355807 -0.770368 -0.4030950.187594 -0.747149 -0.367376 0.466202 1.04135 0.776228]

layer14_wq's input 
<N9nntrainer6TensorE at 0x5682dee98c10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wq's output 
<N9nntrainer6TensorE at 0x5682dc478730>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.310121 0.128975 0.07752420.61004 -0.194837 0.0533598 0.711713 0.43598 -0.135811]
============================
layer14_wk's input 
<N9nntrainer6TensorE at 0x5682dee9aab0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wk's output 
<N9nntrainer6TensorE at 0x5682dee9a7d0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00563616 -0.0128344 0.0348296-0.0478778 0.0302346 0.0681164 0.063781 -0.00346803 -0.0459049]
============================
layer14_wv's input 
<N9nntrainer6TensorE at 0x5682dee9b8a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wv's output 
<N9nntrainer6TensorE at 0x5682dee9b630>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0533198 0.0518202 0.0305033-0.0279568 0.0927579 0.00337922 0.0188315 0.0349787 0.00499831]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0590304 0.330644 -0.3905890.474973 -0.186356 -0.0779759 0.38586 0.740086 -0.0578709]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2eb4d68
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer14_attention_out's input 
<N9nntrainer6TensorE at 0x5682dee9dda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer14_attention_out's output 
<N9nntrainer6TensorE at 0x5682dee9dd00>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer14_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dee9ee70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.355807 -0.770368 -0.4030950.187594 -0.747149 -0.367376 0.466202 1.04135 0.776228]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.00819254 -0.0462011 -0.02115290.0116523 -0.0396076 -0.0239998 0.0294573 0.0596645 0.0411491]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3146974742 -0.7524214983 -0.5073871613 1.047515512 -1.900506973 -0.5483075976 -0.8108694553 -1.170781374 -0.3059524596 -2.787629366 -0.9951738119 -0.8819032907 -0.03284237161 -1.08283782 -1.844440937 -0.9865199924 -0.8003217578 -1.080387592 0.4031157792 -1.560947061 -0.3382537067 -0.08784183115 0.1755543947 -0.5047937036 -1.889325738 -0.3198569417 -0.09724221379 -0.5367322564 -0.489025116 -0.007524366491 -2.364694357 -2.770090342 -0.593550086 -1.921137214 -0.9594412446 -0.5471981168 -0.2572587132 -1.150555253 -0.003611662425 -0.3223264217 -0.2941896915 0.8458377719 0.2309077829 -1.740465164 -0.182038337 0.1403097957 -0.5310169458 -2.140178204 -1.20871079 0.02241208963 -1.441024542 -1.899502873 -1.541872621 0.405549556 -0.9199211597 1.239122152 -0.1296442747 -0.2416889817 -0.3628253043 -0.6105259061 -1.894799471 2.003627777 -1.867062569 -0.0566174984 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01456574071 0.00940224342 0.01201291662 0.05687666684 0.002982800826 0.01153126452 0.00886845123 0.006187853869 0.01469367556 0.001228434499 0.007375736721 0.008260346018 0.01930814981 0.006756681949 0.003154811682 0.007439842448 0.008962488733 0.006773257162 0.02985897474 0.004188835621 0.01422663592 0.01827489026 0.02378188446 0.01204411406 0.003016339615 0.01449078415 0.01810390316 0.01166552026 0.01223553717 0.01980323717 0.001875124522 0.001250170055 0.0110211866 0.002921894891 0.007644057274 0.01154406741 0.01542687323 0.006314285565 0.01988087222 0.01445504278 0.01486753579 0.04648862034 0.02513540722 0.003500495572 0.01663204841 0.02295829915 0.01173238363 0.002347125672 0.005957548507 0.02040503547 0.004722532351 0.00298579759 0.004269502126 0.02993173338 0.007952199318 0.06888867915 0.01752669737 0.01566894539 0.01388132386 0.01083567459 0.002999873599 0.1479682177 0.003084245836 0.01885451004 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.17491913 27.17023087 27.17188835 27.21484566 27.16142845 27.17188454 27.16969872 27.16510963 27.17552376 27.16205788 27.16677475 27.16718292 27.18061447 27.16186333 27.15873909 27.1668396 27.1688385 27.16664886 27.19116592 27.16168022 27.17457962 27.17910385 27.18461227 27.16762924 27.16384506 27.17484283 27.1789341 27.17249489 27.17306519 27.18111038 27.16175079 27.16112518 27.1718502 27.16279793 27.16799736 27.17094231 27.17387199 27.1661911 27.18070984 27.1748085 27.17569733 27.20684052 27.1835804 27.16289902 27.17746162 27.18331146 27.17256165 27.15888596 27.16535568 27.18123436 27.16412163 27.16238403 27.16462135 27.19076157 27.16878128 27.22876549 27.17835617 27.17602158 27.16898918 27.17071152 27.16335297 27.30927467 27.15390015 27.17968369 

-------
======================
selected experts : 3, 18, 41, 53, 55, 61, 
layer14_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deea2ef0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.415789 0.0136436 -0.07160960.00549867 -0.0739112 0.0502533 -0.0109407 -0.342321 0.111997]

layer14_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deea2970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.771596 -0.756724 -0.4747040.193093 -0.82106 -0.317123 0.455262 0.699027 0.888225]

layer15_wq's input 
<N9nntrainer6TensorE at 0x5682deedb770>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wq's output 
<N9nntrainer6TensorE at 0x5682deea2820>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.246993 -0.0980489 0.2560660.161456 0.156527 -0.0754717 0.249379 -0.286325 0.0365459]
============================
layer15_wk's input 
<N9nntrainer6TensorE at 0x5682deedd610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wk's output 
<N9nntrainer6TensorE at 0x5682deedd330>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0280981 0.0160434 -0.020244-0.0687225 -0.0147608 0.0326301 -0.00132725 -0.034869 -0.0117971]
============================
layer15_wv's input 
<N9nntrainer6TensorE at 0x5682deede400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wv's output 
<N9nntrainer6TensorE at 0x5682deede190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.027509 -0.0128741 -0.01039650.00837937 0.0063715 0.011103 0.00334155 -0.0227479 -0.0511434]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0509459 -0.260814 0.05824590.297061 0.169796 0.0369588 0.361172 -0.117159 0.130596]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2bad550
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer15_attention_out's input 
<N9nntrainer6TensorE at 0x5682deee0900>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer15_attention_out's output 
<N9nntrainer6TensorE at 0x5682deee0860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer15_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682deee19d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.771596 -0.756724 -0.4747040.193093 -0.82106 -0.317123 0.455262 0.699027 0.888225]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0191901 -0.0468997 -0.0252540.0122755 -0.0443351 -0.0211728 0.0291847 0.0401629 0.0477256]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-2.068495512 0.06064449251 -0.2854043543 -2.37253499 -0.5997478962 -1.363569617 -0.4294730723 0.3454683125 -2.21794486 -0.3285040855 -1.38233602 -0.9914281368 -1.088238001 -0.1005136892 0.2885901928 -0.3372989893 0.335038662 0.4939994216 -0.1296791434 -1.760103464 -1.571818233 -0.3351227045 0.3463970125 -1.455619454 4.249740124 -1.797733426 -0.3779758513 0.04171392322 -2.804435015 -1.001756907 -0.419159323 -0.5463706255 -1.305555463 -0.07715242356 0.08199023455 -0.2658957541 -1.742617965 -0.8322230577 0.1008040458 0.6929460168 0.6067660451 -1.113214135 -0.4716964066 0.1628283262 -0.9055261016 -3.344549894 -1.85081017 -1.61446631 -0.8867996931 -0.2743210196 -1.716823936 0.4269520342 -1.464987159 -0.145443514 -2.872466326 -0.7048119903 0.2177646607 -0.8569467664 -1.120281219 -0.7068556547 0.1902229339 -0.1809620261 -2.570884466 -1.580011606 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001140439766 0.009588398971 0.006783580873 0.0008414522745 0.004953830503 0.002307903487 0.005873415619 0.01274804026 0.0009821263375 0.006497419905 0.002264996292 0.003348395927 0.003039433155 0.008161237463 0.01204319112 0.006440527271 0.01261577383 0.01478937082 0.00792664662 0.001552405418 0.001874029636 0.006454559043 0.01275988482 0.002104946179 0.6324805021 0.001495074364 0.00618380215 0.009408589453 0.00054633338 0.003313987516 0.005934304558 0.005225438625 0.002445755294 0.008354138583 0.009795268998 0.006917216349 0.001579788863 0.003926256206 0.009981297888 0.01804475859 0.01655478589 0.002964461222 0.005630582571 0.0106199868 0.00364874443 0.0003183383669 0.001417789841 0.001795786549 0.003717715852 0.00685918238 0.00162106799 0.01383029483 0.002085319255 0.007802668959 0.0005104016745 0.004459770396 0.01121973339 0.00383037352 0.002943584695 0.004450664856 0.0109149348 0.007530393079 0.0006900612498 0.001858737436 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.89215469 25.90060234 25.88921547 25.89090157 25.89453697 25.88950729 25.89736366 25.90423965 25.89295006 25.89560509 25.8942337 25.89007187 25.89405441 25.89917564 25.90401077 25.89697838 25.90458298 25.90675735 25.90037155 25.89256668 25.89336586 25.89556122 25.90186691 25.89359665 26.52111053 25.89346313 25.89767456 25.90137672 25.89060593 25.89289665 25.8974247 25.8957634 25.89393616 25.89936829 25.90176392 25.89697838 25.89163971 25.8958931 25.90194893 25.89475441 25.90852165 25.88968658 25.89712143 25.90354156 25.89561653 25.89180946 25.89195442 25.88518143 25.89520836 25.8988266 25.89263535 25.90055275 25.89262199 25.89977074 25.89104843 25.89642715 25.9031868 25.89293671 25.89204979 25.89307976 25.90288353 25.89902115 25.88979721 25.88381386 

-------
======================
selected experts : 17, 22, 24, 39, 40, 51, 
layer15_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deee4f80>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.420765 0.217941 0.222422-0.14563 -0.174842 -0.00262449 -0.196889 0.0361661 0.230033]

layer15_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deee44b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.19236 -0.538783 -0.2522820.0474629 -0.995903 -0.319747 0.258373 0.735193 1.11826]

layer16_wq's input 
<N9nntrainer6TensorE at 0x5682def24710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wq's output 
<N9nntrainer6TensorE at 0x5682deee4360>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.355268 0.197313 -0.389867-0.372069 -0.160161 -0.638674 0.37698 0.298585 0.319134]
============================
layer16_wk's input 
<N9nntrainer6TensorE at 0x5682def26470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wk's output 
<N9nntrainer6TensorE at 0x5682def261e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0315604 -0.0124703 -0.07055450.0248561 0.0810568 -0.00435547 0.0442637 0.0670922 -0.00547626]
============================
layer16_wv's input 
<N9nntrainer6TensorE at 0x5682def27260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wv's output 
<N9nntrainer6TensorE at 0x5682def26ff0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.037477 0.0743753 0.0621462-0.163479 0.00509745 -0.0277609 -0.0101428 -0.0310047 -0.0741977]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.357985 -0.19234 0.00316063-0.538908 0.267225 -0.601786 0.169565 0.450016 0.36978]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2091cf8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer16_attention_out's input 
<N9nntrainer6TensorE at 0x5682def29710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer16_attention_out's output 
<N9nntrainer6TensorE at 0x5682def29670>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer16_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def2a790>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.19236 -0.538783 -0.2522820.0474629 -0.995903 -0.319747 0.258373 0.735193 1.11826]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0341949 -0.0347478 -0.01433670.00316139 -0.0565951 -0.0224808 0.0170047 0.0437227 0.0635483]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.05211476982 -0.6416469216 -2.025191069 -0.1436697394 -0.6531259418 -0.6036865711 0.08149973303 0.3208004832 -3.047298193 -1.111545444 -1.02949369 -3.965992212 -1.467410803 -1.43652916 -1.315266013 -1.292850018 -1.682392359 -2.04670763 -1.666963696 0.1243281886 -0.3349597156 0.08837586641 -1.756295681 -0.1972560436 -0.1667171866 -0.7029651999 -1.273959517 -0.3595299125 -1.542718649 -0.3003361225 -0.304392606 -0.9442470074 -1.322111726 -0.8383237123 -1.063028097 -0.2437692136 0.8430628181 -0.2073403895 -1.313209176 -0.1361294836 2.023962736 -1.132570505 0.9384945631 -2.073050261 -0.5370718837 -2.903338671 -0.1327673644 -1.958109021 -3.113909483 -1.157161355 -1.999120355 -0.06422943622 -0.9717085361 -1.779744625 -0.4174019694 0.0480931066 -1.076514125 -2.244340897 -0.8149682879 -0.7359886765 -0.1602908522 -0.7065141797 0.3943091333 2.630728483 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01854330115 0.009265955538 0.002322868444 0.01524610445 0.009160199203 0.009624456055 0.01909628138 0.02425916307 0.0008358515333 0.005791831296 0.006287102588 0.0003335380461 0.004057565238 0.004184823018 0.004724340513 0.004831436556 0.003272654954 0.002273422666 0.003323538462 0.01993191056 0.0125916535 0.01922804117 0.003039516509 0.01445062645 0.01489873882 0.008714850992 0.004923572764 0.01228604373 0.003763220971 0.01303525735 0.01298248675 0.006846563891 0.00469210837 0.007611574605 0.006079763174 0.01379387639 0.04089700431 0.01430563349 0.004734066781 0.01536150184 0.1332139671 0.005671328399 0.0449921675 0.002214316046 0.01028742176 0.0009652726003 0.01541323401 0.002484036377 0.0007819882012 0.005533565767 0.002384223277 0.01650666818 0.00666110497 0.0029690722 0.01159520727 0.01846887544 0.005998322275 0.001865730737 0.007791439071 0.0084317578 0.01499479171 0.00868397858 0.02610959671 0.2443795055 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
23.54921722 23.53088188 23.53299713 23.54591942 23.52934647 23.5407753 23.55024719 23.54730606 23.52578926 23.53694344 23.53505516 23.53053093 23.53473091 23.53247643 23.52490997 23.5264473 23.53299332 23.53056526 23.53304291 23.55012894 23.53706932 23.5503788 23.53371429 23.54464722 23.54557228 23.53223801 23.53464317 23.54343605 23.53443718 23.54180336 23.5436573 23.53704453 23.53393745 23.53780937 23.53580093 23.54446793 23.5682354 23.54593277 23.53588486 23.54508209 23.66341019 23.53300858 23.57518959 23.53241158 23.53905678 23.53021049 23.54608727 23.53268051 23.53145599 23.53477859 23.52924538 23.54765701 23.53399849 23.5255394 23.54274559 23.55009651 23.53667259 23.5277729 23.53751183 23.53862953 23.54566956 23.53840446 23.55726051 23.7760067 

-------
======================
selected experts : 7, 36, 40, 42, 62, 63, 
layer16_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def2d9d0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.431278 -0.0191207 -0.0520095-0.191345 -0.0821877 0.0657345 0.0929842 -0.17835 0.119429]

layer16_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def2d090>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.62364 -0.557904 -0.304292-0.143882 -1.07809 -0.254013 0.351357 0.556844 1.23769]

layer17_wq's input 
<N9nntrainer6TensorE at 0x5682def6d870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wq's output 
<N9nntrainer6TensorE at 0x5682def2cf40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0986049 0.941314 -0.409761-0.228745 -0.439152 -0.517336 0.20517 0.411878 0.786435]
============================
layer17_wk's input 
<N9nntrainer6TensorE at 0x5682def6f5d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wk's output 
<N9nntrainer6TensorE at 0x5682def6f340>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0270154 -0.012093 0.0181588-0.0148033 -0.0128511 0.0329365 -0.048675 0.0630503 0.0434794]
============================
layer17_wv's input 
<N9nntrainer6TensorE at 0x5682def703c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wv's output 
<N9nntrainer6TensorE at 0x5682def70150>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.274216 -0.0489666 0.0310645-0.0363662 -0.0251874 -0.0699952 -0.236286 -0.151216 0.111659]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.738812 0.591568 -0.114753-0.455039 -0.0272975 -0.678046 -0.0360514 0.458736 1.08923]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2296d08
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer17_attention_out's input 
<N9nntrainer6TensorE at 0x5682def72870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer17_attention_out's output 
<N9nntrainer6TensorE at 0x5682def727d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer17_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def738f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.62364 -0.557904 -0.304292-0.143882 -1.07809 -0.254013 0.351357 0.556844 1.23769]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0535453 -0.0381172 -0.018551-0.00990592 -0.0660084 -0.0185562 0.0241901 0.0358498 0.0748043]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.447009921 -1.251222968 0.4436779618 1.208736181 0.4357713461 -1.42989099 0.6122367978 0.2530575395 0.4667769969 0.4646663964 -2.264201641 -0.3218255341 -1.396860361 -0.2306746393 -0.1178826988 0.7724598646 0.2812962234 0.5701763034 -0.05667025223 -0.4016815722 0.5942981243 -0.2179611325 -1.151953578 1.020982146 0.1786067039 -0.5935477614 0.4067239463 0.5758956671 -0.2033901215 -1.378864169 0.6396024823 -0.2597191632 0.6028248668 -0.01780005358 -0.4718881547 -1.254062057 -0.4256217182 0.6643728614 -0.9968361259 0.7363439798 0.7514398098 0.1557527333 0.05587822571 -0.2031203806 0.02681217901 0.5725940466 1.238481522 0.2346255332 -0.7182914615 -0.5017694831 0.2432640791 -0.7048752308 5.43648386 -0.1543168426 -0.4374468923 0.8873459697 -0.7013961077 -0.7799318433 -0.2013331503 0.02283242717 -2.182951212 -0.4535562098 0.4822836518 -1.40295589 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01393856574 0.00093840505 0.005110653583 0.01098340377 0.005070406478 0.0007848665118 0.006048960611 0.004223680589 0.005230078474 0.00521905208 0.000340768398 0.00237696385 0.0008112239884 0.002603807254 0.002914699493 0.007100104354 0.004344652407 0.00579981273 0.003098689485 0.002194530331 0.005941415206 0.002637122059 0.001036340487 0.009103251621 0.003920644056 0.001811402966 0.00492524216 0.005833080504 0.002675829455 0.000825955125 0.006216780283 0.002529268386 0.005992292892 0.003221508116 0.002045743633 0.0009357446106 0.002142617013 0.006372694392 0.001210233429 0.006848250981 0.006952414755 0.003832058283 0.003467825241 0.002676551463 0.003368479898 0.005813853815 0.01131501887 0.0041465424 0.001598967589 0.001985518262 0.004182518926 0.001620563678 0.753051281 0.002810416045 0.002117428463 0.007964508608 0.00162621215 0.001503382344 0.002681339392 0.003355100984 0.0003696118365 0.002083592117 0.005311812274 0.000806294207 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
22.11791992 22.11302567 22.11862755 22.11687088 22.11572647 22.1081028 22.11956596 22.11774063 22.11827087 22.11873627 22.11195183 22.11541748 22.10622215 22.11516762 22.11595535 22.12109375 22.1178627 22.11979485 22.10278893 22.11523628 22.11564445 22.11138725 22.11216927 22.11976051 22.11696243 22.11103821 22.11891937 22.11935043 22.1076107 22.11291313 22.11925697 22.11557007 22.11855698 22.11673927 22.11556435 22.1058712 22.11518288 22.11941338 22.11139107 22.11988831 22.12047005 22.10972023 22.11698532 22.11237907 22.10877991 22.1198082 22.12149429 22.11766434 22.11034775 22.11550331 22.11770058 22.11466217 22.84749603 22.10822105 22.10991287 22.11814499 22.11562157 22.11120605 22.11429214 22.11210442 22.11341095 22.11512375 22.11930656 22.11194038 

-------
======================
selected experts : 0, 3, 23, 46, 52, 55, 
layer17_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def76b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.34535 0.153269 -0.0514444-0.155825 0.00398532 -0.280045 -0.110691 -0.0676852 -0.0705817]

layer17_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def761f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.96899 -0.404635 -0.355736-0.299706 -1.07411 -0.534058 0.240666 0.489158 1.16711]

layer18_wq's input 
<N9nntrainer6TensorE at 0x5682defb6420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wq's output 
<N9nntrainer6TensorE at 0x5682def760a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.892632 0.785006 0.2843590.732417 0.502672 0.0353727 -0.273241 0.803194 -0.858658]
============================
layer18_wk's input 
<N9nntrainer6TensorE at 0x5682defb8180>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wk's output 
<N9nntrainer6TensorE at 0x5682defb7ef0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0625939 0.0209839 -0.02201980.140951 0.13563 0.073881 -0.0576498 0.0120187 -0.0372709]
============================
layer18_wv's input 
<N9nntrainer6TensorE at 0x5682defb8f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wv's output 
<N9nntrainer6TensorE at 0x5682defb8d00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0673743 0.132851 -0.8126420.0689228 0.0105354 -0.0484212 -0.0431445 0.0169316 0.0487522]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.178269 1.17526 -0.3376940.709406 0.374206 0.33749 -0.647631 0.548047 -0.945128]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a249bd18
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer18_attention_out's input 
<N9nntrainer6TensorE at 0x5682defbb420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer18_attention_out's output 
<N9nntrainer6TensorE at 0x5682defbb380>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer18_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682defbc4a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.96899 -0.404635 -0.355736-0.299706 -1.07411 -0.534058 0.240666 0.489158 1.16711]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0721664 -0.027966 -0.0225376-0.0210278 -0.0680496 -0.039148 0.0168854 0.032015 0.073025]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7184080482 -1.151590586 -1.859447241 -0.977907002 -1.203753948 0.2016505301 0.3415195346 0.1751564294 -0.9603215456 0.07764619589 -0.7337498069 0.7458074093 -0.4427110255 -2.942986965 -1.691908717 -1.262107611 -1.842625141 3.898965359 -0.4046615362 0.1811235845 0.07861576974 0.7561917901 -2.544876337 -0.3593176007 -1.128900528 -0.5133380294 -0.7166668773 -1.134882569 -0.3825878203 -0.8983453512 -1.73834765 0.4515714049 -2.509013414 0.3447127342 -1.726599813 -1.201112628 0.3410312831 -1.635834694 -0.9594169855 -1.42271924 -0.5482043624 -0.2436633706 -0.3327748179 -0.1896322966 -0.08608092368 -0.4912527204 0.02922016196 0.4147014618 0.102746658 -1.13919425 -0.06142451242 -0.05008335412 0.8983634114 -0.6112719774 0.4918267131 -0.466303587 -0.5821825266 0.1258903295 -0.5778212547 0.5221877098 -2.873530388 -0.7968274951 -1.698697209 0.7144367695 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005024361424 0.003258007113 0.001605217811 0.003875982948 0.003092415631 0.01260832138 0.01450112276 0.0122786602 0.003944747616 0.01113788877 0.004947867244 0.02172609232 0.006619339809 0.00054319849 0.001897994196 0.00291712652 0.001632448984 0.508605063 0.006876053289 0.01235214714 0.01114869118 0.02195287496 0.0008088270552 0.007195016835 0.003332777182 0.006167961285 0.005033118185 0.003312900197 0.007029520813 0.004196962342 0.001811869093 0.01618812606 0.0008383603999 0.01454750076 0.001833280083 0.00310059404 0.01449404284 0.002007463016 0.003948317841 0.002484290162 0.005956612993 0.008077182807 0.007388552651 0.008525605313 0.009455773048 0.006305697374 0.01061137579 0.01560213789 0.01142099407 0.003298647236 0.009691816755 0.009802358225 0.0253067147 0.00559254596 0.01685307547 0.006465000566 0.005757619161 0.01168839727 0.005782783963 0.01737259701 0.000582268287 0.004645407666 0.001885153819 0.0210551098 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
24.21805191 24.20770264 24.21368027 24.21356583 24.21611977 24.22611237 24.22752953 24.2257843 24.21601868 24.2246418 24.21416092 24.23427773 24.21773911 24.21214104 24.2154026 24.21594429 24.20703125 24.7202034 24.21895027 24.22490311 24.21797752 24.22830582 24.21383667 24.21974564 24.21588326 24.21776581 24.21710777 24.20918846 24.20432091 24.21722412 24.21340942 24.22969246 24.21243668 24.21946907 24.21486092 24.21565247 24.22799873 24.20072937 24.21602249 24.21455765 24.21850777 24.22110558 24.21946335 24.22107697 24.22296143 24.21504211 24.22077751 24.22719955 24.22444916 24.21537209 24.22271919 24.22330666 24.22927475 24.2186203 24.23035812 24.21615601 24.21878624 24.22471619 24.21881104 24.23040009 24.21074867 24.21672058 24.21443558 24.23408318 

-------
======================
selected experts : 11, 17, 21, 52, 59, 63, 
layer18_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682defbf6e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.57986 0.0943264 -0.0378901-0.0561241 -0.00075978 -0.0367193 -0.33725 -0.0977015 -0.0766937]

layer18_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682defbeda0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.54885 -0.310308 -0.393626-0.35583 -1.07486 -0.570777 -0.0965837 0.391457 1.09041]

layer19_wq's input 
<N9nntrainer6TensorE at 0x5682deffefd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wq's output 
<N9nntrainer6TensorE at 0x5682defbec50>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.361323 -0.227422 0.290729-0.417 -0.367518 -0.121355 0.565305 -0.199414 0.142538]
============================
layer19_wk's input 
<N9nntrainer6TensorE at 0x5682df001130>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wk's output 
<N9nntrainer6TensorE at 0x5682df001100>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00226154 -0.0396273 0.06855920.0128666 0.0418959 -0.0108973 0.0969948 -0.022773 -0.0303774]
============================
layer19_wv's input 
<N9nntrainer6TensorE at 0x5682df002000>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wv's output 
<N9nntrainer6TensorE at 0x5682df001d90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0179469 0.0446899 0.0160040.00136719 0.031549 0.0285391 -0.0551306 0.0632468 -0.0651789]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00385499 -0.42692 0.502835-0.0746283 -0.214774 -0.321977 0.587323 0.119946 0.0537725]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a28a5d38
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer19_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0044b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer19_attention_out's output 
<N9nntrainer6TensorE at 0x5682df004410>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer19_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df005580>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.54885 -0.310308 -0.393626-0.35583 -1.07486 -0.570777 -0.0965837 0.391457 1.09041]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.104808 -0.0219663 -0.0262252-0.0255591 -0.0707731 -0.0427812 -0.00708838 0.0262844 0.0717968]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.870427072 -0.4297446311 0.3893831074 -2.882740974 -1.749268174 -1.140577197 -1.86351347 -2.083424807 -0.1198053062 -1.283785939 -3.595624924 -1.68920207 -0.931278646 1.751794577 -0.9549500942 -2.474923849 -0.3612092137 -2.245876074 0.4594415128 -1.703000188 -0.006122693419 -0.2473336458 -0.1874592602 -1.355520844 -1.34108603 -4.318873405 -0.1267712563 -3.603009701 0.3241306543 -2.305549383 -0.7661187053 -1.171770692 -0.2226484567 -1.774108052 -3.001091003 -2.214206457 -0.9160502553 -1.340917349 -0.1638941765 0.6700047255 -0.1463842988 -0.7276086211 -0.6233993769 -0.04615239799 -1.428402066 -0.2105231136 -1.808840513 -0.7044687271 -3.060681105 -1.606765389 -5.207351685 -3.351971865 -2.702824354 -1.067015171 -1.12849617 -0.5040866733 -2.808013678 -1.055145264 -0.2338203192 -3.263477802 -0.8612078428 0.8286098838 -0.3876197636 -1.732399702 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01169053651 0.01816437021 0.0412062481 0.001562778838 0.004854657222 0.008922977373 0.004330544267 0.003475651378 0.02476425841 0.00773241045 0.0007661184645 0.005155193619 0.01100036036 0.1609351188 0.01074302476 0.002349688904 0.01945292763 0.002954503521 0.04419661686 0.005084549543 0.02774578705 0.02179919556 0.02314427681 0.007197155152 0.007301797625 0.000371700502 0.02459235303 0.0007604820421 0.03860328719 0.002783356002 0.01297582407 0.008648932911 0.02234400995 0.004735553171 0.001388349221 0.003049568972 0.01116916165 0.00730303023 0.02369614877 0.05455511436 0.02411472239 0.01348527148 0.01496639382 0.0266570691 0.00669127563 0.02261658758 0.004573899787 0.01380095724 0.001308034523 0.005598178133 0.0001528733992 0.0009774920763 0.001870830311 0.009604114108 0.009031428955 0.01686296798 0.001684035524 0.009718793444 0.02209577523 0.001067937468 0.01179881394 0.06393178552 0.01894588955 0.004937242717 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.25842476 26.25917625 26.28078842 26.2478199 26.25206566 26.24659729 26.24963379 26.25020981 26.27149963 26.25446701 26.24177933 26.25093651 26.25630379 26.40766907 26.25747681 26.24956131 26.26618767 26.24682808 26.29045486 26.25134277 26.27495766 26.26805687 26.26463318 26.25250053 26.25451279 26.24710655 26.27132607 26.24701881 26.28486061 26.24713326 26.26018715 26.25586128 26.26955605 26.2519474 26.24621582 26.2488308 26.2559967 26.25165367 26.27043152 26.29318428 26.27084923 26.26021957 26.26170158 26.2705307 26.24722672 26.26935196 26.25130844 26.26053619 26.24708939 26.24804115 26.24641037 26.24675751 26.24812889 26.25252342 26.24241447 26.26407433 26.24794197 26.2569294 26.26930809 26.24303436 26.25901031 26.30828285 26.26568031 26.25071907 

-------
======================
selected experts : 2, 13, 18, 28, 39, 61, 
layer19_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df008b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.291141 -0.0548041 0.1960420.0124939 0.0760055 -0.388228 -0.0445634 -0.0385717 0.00012557]

layer19_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df008060>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.83999 -0.365113 -0.197585-0.343336 -0.998859 -0.959005 -0.141147 0.352885 1.09054]

layer20_wq's input 
<N9nntrainer6TensorE at 0x5682df047b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wq's output 
<N9nntrainer6TensorE at 0x5682df007f10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.443588 -0.365536 0.0309314-0.373895 1.03147 -0.199066 0.619521 -0.0463079 0.570942]
============================
layer20_wk's input 
<N9nntrainer6TensorE at 0x5682df0498e0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wk's output 
<N9nntrainer6TensorE at 0x5682df049650>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.061873 -0.0443794 0.0643148-0.0113864 0.0207143 0.00327355 0.052702 0.0385123 0.0354851]
============================
layer20_wv's input 
<N9nntrainer6TensorE at 0x5682df04a6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wv's output 
<N9nntrainer6TensorE at 0x5682df04a460>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00685912 -0.00390602 -0.02020850.0231271 -0.0199988 0.0483193 -0.0235687 0.0313001 0.0278894]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0679166 -0.570766 0.293218-0.234045 0.935183 0.47852 0.555015 0.279122 0.675518]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2cafd58
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer20_attention_out's input 
<N9nntrainer6TensorE at 0x5682df04cb80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer20_attention_out's output 
<N9nntrainer6TensorE at 0x5682df04cae0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer20_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df04dc00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.83999 -0.365113 -0.197585-0.343336 -0.998859 -0.959005 -0.141147 0.352885 1.09054]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.134808 -0.0267069 -0.0138377-0.0252921 -0.0684 -0.0736309 -0.0106906 0.0247141 0.0752436]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.07704258 -2.381285906 -0.1274219602 0.474237591 -1.869292617 0.430000782 -0.9043648243 -0.4669285119 0.2660955489 -1.392124534 -0.8622024655  0.1724381 0.3264771998 0.9078991413 0.1739273667 -0.3697404861 -0.88002038 0.2017908543 0.6609428525 -2.082634687 0.03842191026 -1.76477313 -0.5597907901 -2.003566265 -0.2413147092 -0.1986148357 0.2799862325 -0.3508349657 -0.9200164676 0.4224737883 0.5498284101 0.2064149082 1.088294625 -1.623036504 -0.8739697933 -0.8394398689 0.6316232085 5.037063122 -0.5610482693 -2.034821033 -0.7283396125 -0.5939122438 -4.271018505 0.4074138105 0.9174279571 -0.8665634394 -1.88837862 -2.123327732 0.770165205 -1.222227216 0.05432872102 -0.7720525861 -1.608665943 -0.2474517077 0.5766109824 -1.176881194 -1.034535289 -0.09248919785 -1.464740157 -2.865098953 -1.450525284 -0.5726585388 0.5862969756 -0.6457912326 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001647277153 0.0004470343119 0.004257765133 0.007771037985 0.0007459277986 0.007434765808 0.001957760425 0.00303204637 0.006310796365 0.001202065847 0.002042069333 0.005746577401 0.006703590509 0.01198991202 0.005755141377 0.003341520205 0.002006005961 0.00591775449 0.009366217069 0.0006026201881 0.005025818478 0.0008281121845 0.002763161901 0.0006522025797 0.003799431259 0.003965181299 0.006399069447 0.003405294614 0.001927357749 0.007379014976 0.008381230757 0.005945181008 0.01436020341 0.0009542113403 0.002018181141 0.002089085523 0.009095588699 0.7448846698 0.002759689698 0.0006321334513 0.002334567253 0.002670469228 6.755236245e-05 0.007268719841 0.01210470591 0.002033183817 0.0007318261196 0.0005785898538 0.01044717059 0.001424668473 0.005106402561 0.002234714571 0.0009680227959 0.003776186146 0.008608734235 0.001490758266 0.001718807616 0.004409128334 0.001117871027 0.0002755647292 0.00113387499 0.002727833577 0.008692523465 0.002535460284 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.39579964 25.39555168 25.40126991 25.40526009 25.39680481 25.40492439 25.39420128 25.40004539 25.40332413 25.39201546 25.39857864 25.39989853 25.40371704 25.40852547 25.40276718 25.39892387 25.3932972 25.39720917 25.40447235 25.39666176 25.40203857 25.3978405 25.39453125 25.39623451 25.39747429 25.40097809 25.39864349 25.39994049 25.39321709 25.40439224 25.4053936 25.40343475 25.41041946 25.39701271 25.39903069 25.39862442 25.40610886 26.1328373 25.39548111 25.39573669 25.39934731 25.39825249 25.39517212 25.40475845 25.40768623 25.39952278 25.39774513 25.39759064 25.40698242 25.39796066 25.3997345 25.39924812 25.38367653 25.40078926 25.4046669 25.39755058 25.39920807 25.39808464 25.39574623 25.39394951 25.39671516 25.39830971 25.40093613 25.39477921 

-------
======================
selected experts : 13, 18, 32, 37, 44, 48, 
layer20_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df050e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0120884 -0.209664 0.05369820.136559 0.0140424 -0.212215 -0.0268751 0.245811 -0.552276]

layer20_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df050500>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8279 -0.574777 -0.143887-0.206777 -0.984817 -1.17122 -0.168022 0.598696 0.538261]

layer21_wq's input 
<N9nntrainer6TensorE at 0x5682df091030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wq's output 
<N9nntrainer6TensorE at 0x5682df0503b0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.332466 -0.309924 0.2384420.07408 0.479344 -0.182912 -0.21657 -0.208468 -0.599435]
============================
layer21_wk's input 
<N9nntrainer6TensorE at 0x5682df092d90>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wk's output 
<N9nntrainer6TensorE at 0x5682df092b00>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0128925 -0.14536 -0.03713740.107526 -0.0377128 0.0351184 0.0651516 -0.0369747 -0.00649811]
============================
layer21_wv's input 
<N9nntrainer6TensorE at 0x5682df093b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wv's output 
<N9nntrainer6TensorE at 0x5682df093910>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0628524 0.476884 -0.03043020.0533559 0.0167144 -0.0309751 -0.0983312 -0.00852327 0.00372253]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0811601 -0.447213 0.1097160.224288 0.490283 0.151161 -0.0784048 -0.290197 -1.06673]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1f8f4f0
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer21_attention_out's input 
<N9nntrainer6TensorE at 0x5682df096030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer21_attention_out's output 
<N9nntrainer6TensorE at 0x5682df095f90>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer21_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0970b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8279 -0.574777 -0.143887-0.206777 -0.984817 -1.17122 -0.168022 0.598696 0.538261]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.144591 -0.045282 -0.0109603-0.0163982 -0.073989 -0.0977705 -0.0138507 0.0459169 0.0404394]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.06304276 -0.6021475196 -2.169597626 -1.313102484 -2.742123365 -0.4679281712 0.3970277607 -2.853251934 -0.06517066061 -1.92474246 -4.035582066 0.06261336058 -2.236532211 -2.247601271 -0.04237207025 -1.586821675 -1.129099131 -0.2283283621 -2.213349104 -0.2064970732 -3.909958363 -0.2399390191 -1.702290535 -2.80487442 -1.139941931 -2.144385815 0.2781732678 -0.2992320657 -0.5869427323 -0.1516870111 -1.931723356 -3.424999952 -0.7316350341 -2.441805601 -2.182060957 -1.475407958 0.5334613919 -1.330709934 -1.049032211 3.90513134 0.4757867754 0.219257772 -2.52214694 -0.5174241662 0.6447601318 -0.966193676 0.1037304252 -1.640603065 -1.418705821 -1.239153266 -0.990398109 -3.344450474 -2.827080965 -0.2736230493 -0.09573896229 -0.2715366781 -0.3317405581 -0.1800187677 -1.254295468 0.3095138967 -0.3546442688 -3.898478985 -2.363801718 -1.45413053 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.004216297995 0.006684909109 0.001394314109 0.003283458995 0.0007865307853 0.007645156235 0.01815648749 0.0007038065814 0.01143672224 0.001781146857 0.0002157614508 0.0129956333 0.001304041129 0.001289685839 0.01170045976 0.00249722111 0.003946784884 0.009715008549 0.001334625646 0.009929428808 0.0002446422877 0.009602860548 0.002224894706 0.0007386920042 0.00390421995 0.001429914031 0.01612181589 0.009050031193 0.006787329447 0.01048885286 0.001768756192 0.0003973252606 0.005872997455 0.001062042895 0.00137704378 0.002791536273 0.02081057988 0.003226152388 0.004275786225 0.6061524749 0.01964429393 0.01519943215 0.0009800546104 0.007275962271 0.02326058596 0.004645070527 0.01354111452 0.002366464585 0.002954395954 0.003535471857 0.004533989821 0.0004306539777 0.0007224691217 0.009284785949 0.01109241135 0.009304176085 0.008760559373 0.01019585505 0.003482341068 0.01663508452 0.008562188596 0.0002474668145 0.001148203155 0.002851569559 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.64250755 25.64497566 25.63920784 25.64109612 25.63716888 25.64545822 25.65644646 25.63661003 25.64925003 25.63911819 25.62753868 25.64222527 25.63578033 25.63719559 25.64999008 25.64031029 25.64223671 25.64800453 25.63676453 25.64822006 25.63805771 25.64789391 25.64003754 25.63759804 25.64219475 25.63876724 25.65393448 25.64591026 25.64507866 25.64877892 25.64005852 25.63725662 25.64320946 25.63887596  25.638237 25.64012909 25.65910149 25.64103889 25.6401825 26.24348831 25.65793419 25.65349007 25.63784027 25.6450901 25.65725899 25.64245796 25.65183067 25.64018059 25.63599968 25.63896561 25.64282417 25.63490677 25.63090706 25.64757538 25.64938354 25.6456871 25.64180565 25.64801025 25.63366699 25.65444946 25.64542198 25.63806152 25.63753128 25.64018822 

-------
======================
selected experts : 6, 36, 39, 40, 44, 59, 
layer21_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df09a2f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.215912 0.0337436 -0.14080.25848 -0.380119 0.226237 0.102527 -0.408488 0.198852]

layer21_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df0999b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04381 -0.541033 -0.2846860.0517024 -1.36494 -0.944982 -0.0654953 0.190208 0.737113]

layer22_wq's input 
<N9nntrainer6TensorE at 0x5682df0d9be0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wq's output 
<N9nntrainer6TensorE at 0x5682df099860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0645966 2.94181 1.97864-1.35017 -2.31954 0.353108 -0.301218 -1.04382 -2.49729]
============================
layer22_wk's input 
<N9nntrainer6TensorE at 0x5682df0db940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wk's output 
<N9nntrainer6TensorE at 0x5682df0db6b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0181593 0.194621 0.1058130.081483 -0.104169 -0.00915633 0.00530279 0.0582135 -0.174956]
============================
layer22_wv's input 
<N9nntrainer6TensorE at 0x5682df0dc730>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wv's output 
<N9nntrainer6TensorE at 0x5682df0dc4c0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.305374 -0.118744 0.1250070.0234811 0.348752 0.0440496 -0.268004 -0.125917 0.012953]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-2.51035 1.53511 2.339830.512973 -2.04478 -1.15057 0.27892 -1.05 -2.2433]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a30b9d78
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer22_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0debe0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer22_attention_out's output 
<N9nntrainer6TensorE at 0x5682df0deb40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer22_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0dfc60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04381 -0.541033 -0.2846860.0517024 -1.36494 -0.944982 -0.0654953 0.190208 0.737113]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.197024 -0.0466002 -0.02392610.00439924 -0.111864 -0.0853393 -0.0057438 0.0160851 0.0604106]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.199773863 -1.673453927 -1.750790596 -1.891195297 -0.7850407362 -0.5988141298 0.3508761823 0.4396923184 -0.5164562464 -0.1288634688 -0.439224124 -0.1732848287 -0.6426890492 0.3127274215 -1.910321116 -0.2244655788 0.03051177971 -1.879820585 0.03443358094 0.8580367565 -1.790165305 0.5585227013 -0.4073811471 -1.642910004 0.4139422178 -0.3693930805 -0.7692814469 -0.3295662105 -2.578949928 -0.6650422812 -2.566251755 -2.248004675 -0.9758638144 0.04356760532 0.9725430608 -2.060469627 -0.793438375 0.1285246015 0.4450246394 -1.208471537 -0.1679882407 0.3906342387 -1.493481159 -0.03915252537 -0.4554958344 -0.8757504225 0.291896075 -2.210798025 -0.09234327823 -0.6468251944 0.1034733579 -1.954865456 4.743592262 -3.236852884 -0.3848002851 -3.316403866 -0.5754801035 -1.129412532 0.2965017557 -0.4800824225 0.2253926992 -1.031445861 -1.540406108 -0.7616586685 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007627194747 0.001171743148 0.001084539806 0.0009424721356 0.002848821692 0.00343196257 0.008871312253 0.009695276618 0.003726577386 0.005490849726 0.004025793634 0.00525227515 0.003284640145 0.008539254777 0.0009246177506 0.004990224726 0.006439546589 0.0009532533586 0.006464849226 0.01473142672 0.00104266603 0.01091861352 0.004156050738 0.001208084868 0.009448808618 0.004316968843 0.002894073259 0.00449236948 0.00047378405 0.003212032374 0.0004798386362 0.0006596416351 0.002353920834 0.00652417168 0.01651863754 0.0007957077469 0.002824998694 0.007102672476 0.009747110307 0.00186539907 0.005280168727 0.009231120348 0.00140279287 0.006006208714 0.003960817587 0.002601779765 0.008363208733 0.0006846469478 0.005695081782 0.003271082649 0.006926949136 0.000884335197 0.7173318863 0.0002453900233 0.004250964615 0.0002266253578 0.003512985772 0.00201886124 0.008401816711 0.003864621744 0.007825120352 0.002226654906 0.001338487375 0.002916218247 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.01300812 27.00655174 27.00455856 27.00489235 27.00870705 27.00356674 27.0128212 27.01364517 27.00958443 27.01039505 27.00988388 27.01063347 27.00866508 27.01344299 27.00344467 27.01084709 27.01181984 27.00681114 27.01232147 27.01391411 27.00499344 27.01629829 27.01001358 27.00086594 27.01530647 27.00969696 27.00875092 27.00844193 27.00537682 27.00906944 27.00586128 27.00461006 27.00487328 27.01238251 27.0118866 27.00379181 27.00343704 27.00676155 27.00940514 27.00533867 27.01066017 27.01318169 27.00678253 27.01138687 27.00981903 27.00655174 27.01422119 27.00511169 27.01155281 27.00912857 27.01278496 27.00483513 27.71746826 27.00610352 27.00963211 27.00513077 27.0093708 27.00406075 27.01425934 27.00924492 27.01129913 27.00808334 27.00671959 27.0087738 

-------
======================
selected experts : 7, 19, 21, 34, 38, 52, 
layer22_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df0e2e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0903192 0.42473 0.3125610.306603 0.951165 1.31895 0.790386 1.13406 0.257965]

layer22_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dde69cd0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.9535 -0.116303 0.02787510.358305 -0.413771 0.373971 0.724891 1.32427 0.995078]

layer23_wq's input 
<N9nntrainer6TensorE at 0x5682de368560>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wq's output 
<N9nntrainer6TensorE at 0x5682de2bfbc0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88475 1.19701 -2.95799-0.774949 -0.550968 3.72149 -2.80755 0.835098 0.0767813]
============================
layer23_wk's input 
<N9nntrainer6TensorE at 0x5682de266760>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wk's output 
<N9nntrainer6TensorE at 0x5682de82d610>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.16132 0.101492 -0.1736-0.0632329 0.00180998 0.100202 -0.12567 -0.0723858 0.0486436]
============================
layer23_wv's input 
<N9nntrainer6TensorE at 0x5682de40ebf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wv's output 
<N9nntrainer6TensorE at 0x5682de7736d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.133239 0.0820239 -0.446299-0.364692 0.117455 0.266068 0.109828 0.368292 0.705527]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.551392 3.07418 -1.46587-2.68356 -2.72632 2.59234 -2.83699 -0.728841 1.4284]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a32bed88
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer23_attention_out's input 
<N9nntrainer6TensorE at 0x5682ddf81aa0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer23_attention_out's output 
<N9nntrainer6TensorE at 0x5682de55e330>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer23_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0fe910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.9535 -0.116303 0.02787510.358305 -0.413771 0.373971 0.724891 1.32427 0.995078]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.248394 -0.0111696 0.002646840.0340224 -0.0390645 0.037539 0.0719775 0.125744 0.0934063]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4227033556 -0.08820123225 -1.093985319 -1.440326333 0.1767097861 -0.6456956863 -1.188692927 -2.515872002 -0.1630707234 0.6196206212 0.6059263349 -1.085564375 -0.3715315461 0.8512659073 0.2090708166 0.6669648886 1.468102455 -1.003164649 4.688289642 -1.688715458 -1.784513116 -0.9512995481 0.2725952566 -1.258306623 0.1121827066 -1.115008235 -1.628750801 -2.018517733 0.472153604 -0.4246005118 -0.5433605313 -0.1163094714 0.03554884717 -1.526789784 -1.247554541 -1.311082482 0.3014304638 -2.34950757 0.6530562043 -0.4077222347 -0.4513951242 -0.467533648 -1.078356385 0.04713717103 0.2013515085 -1.248224258 -0.7126752138 -1.343229294 -2.383528709 -0.6903945208 0.5946252346 -0.4792165756 0.7827592492 -0.3523043096 -1.912632704 -0.1119556129 -0.1083869934 0.8989235163 -1.450334668 0.4656749964 0.7065121531 -0.6281039715 0.8132551908 0.9489036798 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009099072777 0.005459014326 0.001996675739 0.001412191894 0.007114813197 0.003126060357 0.001816254109 0.0004817149311 0.005065225065 0.01107942872 0.010928737 0.002013560617 0.004112116061 0.01396752708 0.007348821498 0.01161659043 0.02588262036 0.002186505357 0.6479145885 0.001101589063 0.001000956749 0.002302900888 0.007830799557 0.001694118953 0.00667021377 0.001955138287 0.001169666299 0.0007921153447 0.009560336359 0.003899579169 0.003462907393 0.005307705607 0.006178144366 0.00129521871 0.001712431898 0.001607028535 0.008059890009 0.0005689071259 0.01145613473 0.003965955228 0.003796479665 0.003735701554 0.002028127434 0.006250156555 0.007292313501 0.001711285789 0.002923537046 0.001556189149 0.0005498776445 0.002989406232 0.01080592722 0.003692311235 0.01304269768 0.004191944841 0.0008805895341 0.005330865271 0.005349923857 0.01464930177 0.00139812869 0.009498597123 0.01208519842 0.00318153901 0.01344657689 0.01540008187 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.92578888 26.92119408 26.91868591 26.91762352 26.92189598 26.91933823 26.9170742 26.91669464  26.921278 26.92776871 26.92761803 26.91536522 26.92032433 26.92874908 26.9235611 26.92639732 26.93541908 26.9183979 27.56221962 26.91397667 26.91721344 26.91851425 26.92452049 26.91838264 26.92335892 26.91721344 26.91547394 26.91748047 26.92624855 26.91963577 26.91919899 26.91961288 26.91952896 26.91464615 26.91697121 26.91734314 26.92474937 26.91630363 26.92766762 26.9168396 26.91762352 26.91994858 26.91871643 26.92198563 26.92302704 26.91792297 26.91627502 26.91347694 26.9167614 26.91729355 26.92749405 26.91990471 26.92973137 26.91945076 26.91375542 26.92011261 26.92060852 26.92466164 26.91761017 26.92523384 26.92877388 26.91748619 26.93013573 26.93065834 

-------
======================
selected experts : 13, 16, 18, 57, 62, 63, 
layer23_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee1eb60>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0869226 -0.195127 -0.00683361-0.561033 0.658098 0.719169 0.109476 -0.258927 -0.228366]

layer23_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de7806d0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.86657 -0.31143 0.0210415-0.202728 0.244327 1.09314 0.834367 1.06534 0.766711]

layer24_wq's input 
<N9nntrainer6TensorE at 0x5682de5e9620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wq's output 
<N9nntrainer6TensorE at 0x5682de23a580>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.336158 -0.169375 -0.425678-0.648299 -0.123858 -0.259336 0.708369 -0.032059 -0.618515]
============================
layer24_wk's input 
<N9nntrainer6TensorE at 0x5682de680bc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wk's output 
<N9nntrainer6TensorE at 0x5682de1e9fa0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0118696 -0.0472703 0.113450.103728 0.0296149 -0.0224001 -0.0348054 0.0611872 -0.0188398]
============================
layer24_wv's input 
<N9nntrainer6TensorE at 0x5682de7cdb70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wv's output 
<N9nntrainer6TensorE at 0x5682de067420>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0733123 0.0836663 -0.00333526-0.468789 0.0173092 0.0456101 -0.047658 0.045135 -0.0803263]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.324151 0.191353 0.179536-0.754493 0.0621674 -0.280591 0.623861 0.337063 -0.870887]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a36c8da8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer24_attention_out's input 
<N9nntrainer6TensorE at 0x5682de40b530>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer24_attention_out's output 
<N9nntrainer6TensorE at 0x5682de646540>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer24_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de7c4940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.86657 -0.31143 0.0210415-0.202728 0.244327 1.09314 0.834367 1.06534 0.766711]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.272563 -0.0340113 0.00226365-0.0220298 0.0260193 0.124133 0.094748 0.115767 0.0820663]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.929450631 -1.128785849 -0.6543552279 -0.8471324444 -1.39042747 -0.55434829 -0.02498121932 -0.4676400721 -2.470920801 -1.70237565 -0.9748182893 -1.800919175 -0.2439994067 -1.728101611 -1.238625407 -0.255404681 -0.2346673757 -1.047284842 -2.222267866 -0.4669069946 -0.6821814775 0.1248121113 -1.806736708 -0.9977571964 -0.1882074773 -1.306464791 -1.56954062 -1.755864024 -0.8727980852 -1.033334374 -1.979539037 5.464857101 -1.646643162 -0.4878594875 0.3052386045 -0.8554965258 -0.3183939159 -0.9714736342 1.016834497 -2.717564344 -1.23928678 -0.06641087681 0.3262445629 -1.273775458 -1.078132153 0.4311248064 0.4545654655 -2.53660512 -1.765888453 -1.713524938 -1.485613465 -1.774708033 -1.024132609 -1.954378843 0.06704782695 -0.327961266 0.04493098333 -2.279580355 0.0472863242 -0.5062567592 -1.145820975 -1.043580055 -1.944802403 -2.451274872 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0005397897912 0.001202122658 0.001931931009 0.001593196415 0.0009253784083 0.002135128016 0.003625144018 0.002328525297 0.0003140994813 0.0006773952045 0.001402220107 0.0006138258614 0.002912103198 0.0006601905916 0.001077075489 0.002879079431 0.002939406782 0.001304200152 0.0004027686082 0.002330232412 0.001878913492 0.004210945219 0.0006102650659 0.001370421145 0.003079192713 0.001006430946 0.0007736269617 0.0006421142025 0.001552826958 0.001322522294 0.0005134185776 0.8780751228 0.0007162198308 0.002281915629 0.00504356809 0.001579926931 0.002703321865 0.001406917698 0.01027495414 0.0002454432251 0.001076363376 0.003478022991 0.005150632001 0.001039873925 0.001264583552 0.005720176734 0.005855846219 0.0002941310522 0.00063570973 0.0006698846119 0.0008413577452 0.0006301276735 0.001334747649 0.0005264999345 0.003974594176 0.002677580575 0.003887654282 0.0003803341533 0.003896822687 0.002240319503 0.001181818079 0.001309041283 0.0005315663293 0.0003203311935 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.83124924 28.83095741 28.8326416 28.82610321 28.83115768 28.83141327 28.83481216 28.83351517 28.83102417 28.83138657 28.82925034 28.83180046 28.83409882 28.8275547 28.83083534 28.83406448 28.83317184 28.82772255 28.82777405 28.83351707 28.83306503 28.82967567 28.82846069 28.83255577 28.83426476 28.83219337 28.83005333 28.83182907 28.83273888 28.83203125 28.83169937 29.70830727 28.83190346 28.83251381 28.83622932 28.83276558 28.83436584 28.83259392 28.8352623 28.83143234 28.82844734 28.83466339 28.83633614 28.82984161 28.83054352 28.8364296 28.83704185 28.83004951 28.82896042 28.82994843 28.83107376 28.83181572 28.83156776 28.82980537 28.83516121 28.83195686 28.83507347 28.83156586 28.83555984 28.83342743 28.83236885 28.82963371 28.83171844 28.83102989 

-------
======================
selected experts : 31, 34, 38, 42, 45, 46, 
layer24_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df21d1f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.833895 -0.802753 -0.3862-2.35492 0.648108 1.42702 0.936258 -1.31322 -0.598527]

layer24_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de2b2790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.70047 -1.11418 -0.365158-2.55765 0.892435 2.52016 1.77062 -0.247877 0.168184]

layer25_wq's input 
<N9nntrainer6TensorE at 0x5682ddf10a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wq's output 
<N9nntrainer6TensorE at 0x5682de7d58a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.64346 4.6151 -3.59633-1.6699 -4.39449 -0.0783202 -2.1087 -2.86507 -0.238884]
============================
layer25_wk's input 
<N9nntrainer6TensorE at 0x5682de480fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wk's output 
<N9nntrainer6TensorE at 0x5682de0aef30>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0538789 0.0193812 -0.0043537-0.242867 0.037277 -0.198658 0.0676407 -0.0872147 0.0887407]
============================
layer25_wv's input 
<N9nntrainer6TensorE at 0x5682ddd64050>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wv's output 
<N9nntrainer6TensorE at 0x5682de58dbd0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.241149 -0.135526 -0.009660890.227738 -0.432866 0.166314 -0.223882 0.00738034 -0.38231]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-2.4552 4.71794 -1.25282-3.76199 -3.41365 -2.76852 -0.333553 -3.54175 1.22088]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a38cddb8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer25_attention_out's input 
<N9nntrainer6TensorE at 0x5682df211490>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer25_attention_out's output 
<N9nntrainer6TensorE at 0x5682dddde7f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer25_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0184b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.70047 -1.11418 -0.365158-2.55765 0.892435 2.52016 1.77062 -0.247877 0.168184]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.566076 -0.200941 -0.0646798-0.457149 0.156638 0.47074 0.325032 -0.0443051 0.0295192]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-2.033876419 -0.6662036777 -2.519889355 -1.634744644 -1.620467186 -1.470805049 -1.356907725 -0.6036100984 -2.662803173 -3.570815802 -0.7119606137 -2.638509989 -2.228242636 -2.593982458 -1.716693759 -1.688163757 -3.056198359 -2.286839008 -2.550026178 -0.5139263868 -0.06882531941 -1.386721492 -2.962647438 -2.006780863 -2.144985676 -2.108816862 -1.044886827 0.2158241868 1.383966804  -0.539756 -2.881628513 -1.352892756 -1.068458796 -0.9172226787 -1.361247182 -0.08626000583 -2.900213718 -2.272035122 -0.9135314226 -1.731878757 -2.158599854 -2.207988501 -1.664811611 -0.8823071718 -3.022545099 -0.1656448096 -2.413261414 -1.190886617 -0.6852507591 -0.8799331188 -2.690348148 -2.977132082 -2.799127102 -2.899184465 -2.980380535 -1.859682441 -1.973814964 -1.156326056 -1.944438696 -1.011434793 -0.5033848286 -1.838603735 -1.536196589 2.701905012 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003711364232 0.01457157079 0.002282764297 0.005531900097 0.005611447617 0.006517372094 0.007303609047 0.01551281009 0.001978765707 0.0007980854134 0.01391984802 0.002027424518 0.003055776004 0.002119740704 0.00509664556 0.00524414517 0.001335195615 0.002881864319 0.002214994747 0.01696835272 0.0264816191 0.007089074235 0.001466133283 0.003813301679 0.003321082564 0.003443400143 0.00997806713 0.03520191088 0.1132098287 0.01653567515 0.001589863212 0.007332991809 0.009745614603 0.01133679319 0.007271982264 0.02602392063 0.001560588018 0.00292484439 0.01137871668 0.00501983799 0.003276173491 0.003118299181 0.005368050653 0.01173961349 0.001380893984 0.02403789014 0.002539620269 0.008622624911 0.01429665275 0.01176751871 0.00192500453 0.001445050235 0.00172659161 0.001562194782 0.001440364053 0.004417588003 0.003941104282 0.008925837465 0.004058597609 0.01031749882 0.01714816876 0.004511693027 0.006104826927 0.4229192436 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.69184685 28.70556831 28.69089508 28.69700432 28.69660759 28.69751358 28.69829941 28.70460129 28.69297409 28.69083977 28.70539284 28.69350052 28.69500542 28.69216156 28.69227791 28.69337845 28.69280815 28.69006348 28.6932106 28.70844078 28.71461678 28.69522476 28.69246292 28.6952858 28.6947937 28.6939621 28.70145035 28.72667503 28.79896164 28.70228577 28.6925869 28.69880676 28.70121956 28.70281029 28.69826889 28.71749687 28.69255638 28.69439697 28.70237541 28.69506264 28.69236565 28.69363785 28.69684029 28.70225906 28.69285393 28.71551132 28.69210434 28.69723511 28.70529366 28.70276451 28.69005966 28.6919651 28.68890762 28.69255829 28.69243622 28.6930294 28.69398308 28.7003994 28.69553185 28.70131302 28.70385361 28.69550705 28.69757843 29.11439133 

-------
======================
selected experts : 20, 27, 28, 35, 45, 63, 
layer25_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df270060>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.44193 3.30931 -0.1478391.66089 -1.97504 -0.568949 3.54565 0.684309 -1.95359]

layer25_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddfd81b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.1424 2.19513 -0.512997-0.896758 -1.0826 1.95121 5.31627 0.436431 -1.78541]

layer26_wq's input 
<N9nntrainer6TensorE at 0x5682de245ed0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wq's output 
<N9nntrainer6TensorE at 0x5682de21e590>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-7.19763 4.21139 1.345270.336204 -5.75587 3.75966 4.87192 1.62306 1.39669]
============================
layer26_wk's input 
<N9nntrainer6TensorE at 0x5682de23ab70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wk's output 
<N9nntrainer6TensorE at 0x5682de320f60>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.146106 -0.197982 -0.1023530.20076 -0.00982388 -0.0815199 -0.115575 0.150995 -0.0874328]
============================
layer26_wv's input 
<N9nntrainer6TensorE at 0x5682dde7eae0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wv's output 
<N9nntrainer6TensorE at 0x5682ddeee690>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.787365 1.20748 2.441630.378884 -1.00658 -1.26723 0.465748 0.381196 -1.92399]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-7.43266 -3.78117 0.6784771.20932 -6.85015 -0.583587 3.34195 3.89888 1.70999]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a116c480
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer26_attention_out's input 
<N9nntrainer6TensorE at 0x5682df278ee0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer26_attention_out's output 
<N9nntrainer6TensorE at 0x5682df278e40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer26_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df27a260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.1424 2.19513 -0.512997-0.896758 -1.0826 1.95121 5.31627 0.436431 -1.78541]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.23653 0.539361 -0.126048-0.221282 -0.258047 0.497869 1.323 0.106318 -0.433065]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.229813457 -0.05995209515 -2.346139908 -1.001055837 -0.8235158324 -0.05465627834 -0.1190630272 0.5707327127 0.606651783 0.7820273638 0.002560531255 -0.5726556778 -0.5510423183 -1.395941615 -0.6992129683 -0.1102071032 -0.01739729755 -1.311926961 -0.3690626919 0.4405331016 -0.3804124296 0.1966792345 -0.3727973402 -0.2154888511 0.1727482677 -0.1869333088 0.1713048369 1.859833717 -1.653277993 -1.194599271 -0.2070242614 -2.092623711 0.7438879013 -0.4336843491 -0.8664966226 -0.5564077497 -0.4844253659 -1.836260319 0.4542253315 4.332145214 0.1508646607 0.1188326254 -0.7216179967 -0.6991884112 0.1267536134 0.3779300153 -1.579019308 -0.1242448017 0.3456149697 -0.2343725562 -2.290715456 -0.7030614018 0.944742322 0.4067699015 0.230991438 -1.112182736 -0.7881058455 -1.062981129 -1.485591888 -0.741122663 -1.58641994 0.2200573087 0.5616708994 0.5927568078 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.002155417111 0.006943775341 0.000705857412 0.002709440188 0.003235818585 0.006980645005 0.006545219105 0.01304663718 0.01352377981 0.01611620188 0.007391705178 0.004158448894 0.004249306396 0.001825504005 0.003664107528 0.00660344027 0.007245643996 0.001985500567 0.005097421817 0.01145390794 0.005039894953 0.008975305595 0.005078420509 0.005943563767 0.008763066493 0.006115731318 0.008750427514 0.0473530665 0.00141131226 0.00223267125 0.005994088482 0.0009095313144 0.0155131137 0.004778436851 0.003099687397 0.004226566292 0.004542022478 0.001175316633 0.01161181554 0.5611246228 0.008573383093 0.00830311235 0.003582925536 0.003664198564 0.008369144984 0.01075883955 0.001520104008 0.006511391141 0.01041672565 0.005832380615 0.0007460833876 0.003650033148 0.01896395534 0.01107364334 0.009288612753 0.002424475737 0.003352451371 0.002546746517 0.00166896882 0.003513719188 0.001508895191 0.009187606163 0.01292894501 0.01333716605 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.06168747 33.06742859 33.06309891 33.06414795 33.06467438 33.06746674 33.06798553 33.06781006 33.07210159 33.07374191 33.06978607 33.06655121 33.06568909 33.06422043 33.06510544 33.06804276 33.06868362 33.06342316 33.06558228 33.06812668 33.06647873 33.0704155 33.06365585 33.06738281 33.0692482 33.06755447 33.06923676 33.10306931 33.06189728 33.06462479 33.06838608 33.06234741 33.07218552 33.06621933 33.06263351 33.06661987 33.06598282 33.06166077 33.07400513 33.61779404 33.06810379 33.06974411 33.06502151 33.06510544 33.07076263 33.07315063 33.06295776 33.06890488 33.07281113 33.06631851 33.06027985 33.06604385 33.08040237 33.07346725 33.06786728 33.06481934 33.06479263 33.06208038 33.06311035 33.06495285 33.06390381 33.06871796 33.07246017 33.07382202 

-------
======================
selected experts : 8, 9, 27, 32, 39, 52, 
layer26_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df27d4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.09747 -1.72508 -0.102068-3.96982 0.264923 0.310013 0.223394 0.572912 -0.468745]

layer26_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddd52130>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[8.23987 0.470053 -0.615066-4.86658 -0.817679 2.26123 5.53967 1.00934 -2.25415]

layer27_wq's input 
<N9nntrainer6TensorE at 0x5682de328070>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wq's output 
<N9nntrainer6TensorE at 0x5682ddefef30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-3.71408 1.9354 2.356543.03328 2.67895 4.20827 -1.76141 2.67573 -0.578456]
============================
layer27_wk's input 
<N9nntrainer6TensorE at 0x5682de1e5e50>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wk's output 
<N9nntrainer6TensorE at 0x5682ddfc8350>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.400105 -0.24232 0.401053-0.150454 0.0979789 0.371003 -0.358186 -0.0571382 0.698908]
============================
layer27_wv's input 
<N9nntrainer6TensorE at 0x5682de7969c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wv's output 
<N9nntrainer6TensorE at 0x5682de46fef0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.420768 -0.0722796 -0.2112940.196022 -0.195416 0.81495 0.146881 0.813715 -0.146626]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-3.6353 -2.07959 -0.5896663.79557 -0.481701 4.96531 -2.88728 1.38771 -2.44499]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a054e420
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer27_attention_out's input 
<N9nntrainer6TensorE at 0x5682de426170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer27_attention_out's output 
<N9nntrainer6TensorE at 0x5682de0d2950>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer27_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de6e6390>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[8.23987 0.470053 -0.615066-4.86658 -0.817679 2.26123 5.53967 1.00934 -2.25415]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.05855 0.114221 -0.147658-1.16832 -0.203481 0.564918 1.35693 0.242312 -0.538953]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.987653255 -0.7842393517 -2.230341911 -0.758665204 -1.053579092 -1.312015295 1.44309485 -0.69209975 -1.784579635 -1.067586184 -0.6883801222 -1.15128839 -0.1300299764 -0.478109628 -0.1315491945 -0.6079538465 -0.1765194386 1.365325212 -1.465485215 -1.203162909 -0.4411250651 -0.5796673298 -0.9326632023 -0.09328451753 -2.341962814 -0.3186990917 -1.199958563 2.033224821 -0.1808017492 -1.539794326 1.491401196 -1.677116752 -0.9739207029 -0.5623084307 -0.4002993405 -1.290343404 -0.2136254013 2.042429447 0.2812911868 -0.07124047726 -0.1099433899 -0.68425107 -0.9261820316 -1.498537898 -1.244819045 -0.7785608768 0.3858971894 -1.06656611 -0.2841586769 -1.134593248 -2.137027025 -0.7241751552 -2.135964632 -1.843329668 -0.5121998787 -1.465894222 -2.073708057 -0.02629480883 -0.6666491628 -2.23829031 -0.3608047664 -1.097417712 -1.685164094 -0.1254190207 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.002409837907 0.008028305136 0.001890555723 0.008236270398 0.006132691167 0.004736021161 0.07446338981 0.008803178556 0.00295244297 0.006047389004 0.008835984394 0.005561813246 0.01544341724 0.0109037105 0.01541997306 0.009575990029 0.01474189386 0.06889185309 0.004062212072 0.00528065348 0.01131452806 0.009850728326 0.006920925807 0.01602144539 0.001690881327 0.01278808154 0.005297601689 0.1343485564 0.0146788964 0.003771294607 0.078148745 0.003287396161 0.00664119469 0.01002322044 0.01178601291 0.004839781206 0.01420490444 0.1355908811 0.02330117859 0.01637854613 0.01575675793 0.008872545324 0.006965926848 0.00393013889 0.005065199919 0.00807402283 0.02587066963 0.006053561345 0.01323750429 0.005655448884 0.002075465396 0.00852529332 0.002077671699 0.002783984412 0.01053826418 0.004060550593 0.002211132087 0.01713148504 0.009030101821 0.001875588438 0.01226080861 0.005869649351 0.003261048347 0.01551478729 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
31.49386406 31.49948311 31.49334526 31.50016785 31.49615669 31.49428368 31.56687164 31.49978065 31.49393082 31.49798012 31.50076866 31.4955864 31.50546837 31.50283623 31.50639915 31.49960136 31.50619698 31.55700874 31.49599457 31.48624611 31.50324631 31.50178337 31.49885368 31.50413895 31.49219322 31.50424385 31.49675179 31.62341881 31.50661087 31.49188805 31.5700798 31.49426651 31.49809647 31.5014782 31.50133324 31.49629402 31.50089073 31.62180138 31.51571083 31.50783348 31.50768852 31.5008049 31.49746704 31.49586296 31.49747467 31.49905205 31.50683594  31.497509 31.50564575 31.4975872 31.49400711 31.49998093 31.49353218 31.4928093 31.50199318 31.4926548 31.49414253 31.50763321 31.5009613 31.49380684 31.50419235 31.49732399 31.49519348 31.50696945 

-------
======================
selected experts : 6, 17, 27, 30, 37, 46, 
layer27_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df2fed10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-2.73092 -1.75519 1.56366.56381 4.80255 3.19545 -10.1483 2.09887 -0.0882844]

layer27_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de4dbd00>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.50894 -1.28514 0.9485321.69723 3.98487 5.45668 -4.60863 3.10822 -2.34244]

(93958)Ilayer0_wq's input 
<N9nntrainer6TensorE at 0x5682dde663b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00470756 -0.0465267 -0.01080840.0123846 0.0280342 -0.012272 -0.0514805 -0.00136512 0.0315807]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5682de7965e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.166964 -1.09071 1.079920.0058572 0.676155 0.796471 -0.433137 -0.820415 0.66633]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5682ddd56d10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00470756 -0.0465267 -0.01080840.0123846 0.0280342 -0.012272 -0.0514805 -0.00136512 0.0315807]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5682de0a36b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.86394 -0.0748888 0.168426-0.845703 0.365969 -0.525742 -1.64801 0.556798 0.671278]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5682e0a65b00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00470756 -0.0465267 -0.01080840.0123846 0.0280342 -0.012272 -0.0514805 -0.00136512 0.0315807]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5682dde490d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0143575 0.0228836 0.003861170.00985081 0.0516625 0.0180623 0.0077625 -0.0177031 0.00990551]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.06126 0.302075 -0.06891981.07773 -0.609874 0.848295 0.520314 -0.76809 0.286139]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a259e920
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer0_attention_out's input 
<N9nntrainer6TensorE at 0x5682e0a64030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer0_attention_out's output 
<N9nntrainer6TensorE at 0x5682e0a638e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer0_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dde13420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00302124 -0.0292053 -0.008056640.00805664 0.0161133 -0.00805664 -0.0312195 -0.00100708 0.0241699]

layer0_ffn_gate's input 
<N9nntrainer6TensorE at 0x5682ddfb82c0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0210257 -0.201616 -0.05471740.052916 0.110786 -0.051565 -0.21552 -0.00689597 0.16145]
==============================
layer0_ffn_gate's output 
<N9nntrainer6TensorE at 0x5682dde852c0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[0.0710219 -0.0243796 -0.08894840.12087 0.0489584 -0.104624 0.0413304 0.0387468 -0.0774261]
============================
layer0_ffn_up's input 
<N9nntrainer6TensorE at 0x5682de34f990>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0210257 -0.201616 -0.05471740.052916 0.110786 -0.051565 -0.21552 -0.00689597 0.16145]
==============================
layer0_ffn_up's output 
<N9nntrainer6TensorE at 0x5682dde690c0>
data addr: 0x7fc0a7fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.129525 -0.047763 -0.2889950.0299654 -0.331167 -0.346303 -0.0853519 -0.0627946 -0.10754]
============================
layer0_ffn_down's input 
<N9nntrainer6TensorE at 0x5682dc3e1140>
data addr: 0x7fc0aafd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.00476281 0.000575125 0.01228160.00192028 -0.0083051 0.017169 -0.00180026 -0.00124011 0.00400212]
==============================
layer0_ffn_down's output 
<N9nntrainer6TensorE at 0x5682dc3e0770>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.000936617 0.0861878 0.002459120.0408338 -0.0465336 -0.0519033 -0.00198296 0.0126573 0.0261818]
============================
layer0_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3e1bb0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00208462 0.0569825 -0.005597520.0488904 -0.0304203 -0.0599599 -0.0332024 0.0116502 0.0503517]

layer1_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e48b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.003422 0.090049 -0.007508580.0856461 -0.0376385 -0.0657403 -0.0496224 0.0147001 0.09129]
==============================
layer1_wq's output 
<N9nntrainer6TensorE at 0x5682dc3e2330>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-2.2137 1.49018 1.76725-0.873064 2.77531 0.719708 -1.12149 1.2827 1.41735]
============================
layer1_wk's input 
<N9nntrainer6TensorE at 0x5682dc3e6610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.003422 0.090049 -0.007508580.0856461 -0.0376385 -0.0657403 -0.0496224 0.0147001 0.09129]
==============================
layer1_wk's output 
<N9nntrainer6TensorE at 0x5682dc3e6380>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.00567 1.59998 1.3431.87863 0.238808 1.73569 -2.11491 -0.212269 1.81347]
============================
layer1_wv's input 
<N9nntrainer6TensorE at 0x5682dc3e7400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.003422 0.090049 -0.007508580.0856461 -0.0376385 -0.0657403 -0.0496224 0.0147001 0.09129]
==============================
layer1_wv's output 
<N9nntrainer6TensorE at 0x5682dc3e7190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0673909 0.0620003 0.109753-0.102173 0.0435433 0.0182136 -0.0732091 -0.0083449 0.147085]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.433795 -2.63304 0.7683581.81523 -0.0290779 2.86697 -1.65943 -0.386462 2.67485]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a34c4198
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer1_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ea340>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer1_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ea2a0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer1_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3eb440>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00208462 0.0569825 -0.005597520.0488904 -0.0304203 -0.0599599 -0.0332024 0.0116502 0.0503517]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0031794 0.270845 -0.02537140.274307 -0.140865 -0.351105 -0.187914 0.062511 0.185047]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4307895005 -0.1841507256 0.135800615 0.04447042197 -0.0499409847 -0.4950153232 -0.5512891412 1.30370307 1.275840998 0.5842041373 -0.3279032111 -1.648462653 -0.02648603171 -0.0264756158 -0.2227101475 2.397724152 -0.6761419773 -0.2701722682 0.5824278593 0.1082199812 0.001042265445 -0.4016340971 1.609354734 -0.5031391382 -0.5605567694 -0.6605211496 -0.1350102723 -1.336895704 -0.5455344915 2.85885191 -0.6387345195 -0.1259180605 -0.6464231014 -0.07153322548 -0.07752400637 0.3379843533 -0.1304998696 -0.5933691859 0.4696699679 -1.348541856 -0.9087414145 -1.581966996 1.002173305 1.892059326 -0.8242944479 0.5786972046 -0.6346139908 0.05505080894 -0.4305692911 -0.01128564775 -1.803298354 -0.3296391964 -0.5814422369 -0.3645513356 -0.6953773499 -0.8920446634 0.763395071 0.3901729286 -0.1331802905 -0.1245460138 1.428204656 -1.546777725 -0.6999182105 -0.2506659031 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01537049562 0.008310415782 0.01144394744 0.01044507604 0.009504062124 0.00608998118 0.005756739527 0.03679505363 0.03578401729 0.01791905425 0.00719766831 0.001921675866 0.009729616344 0.009729715995 0.007996070199 0.109879531 0.005081052426 0.007625424769 0.01788725331 0.01113263052 0.01000117604 0.006686069537 0.04994963109 0.006040709093 0.005703633651 0.005161046516 0.008728994057 0.002624170622 0.005789962132 0.1742537022 0.005274720956 0.008808720857 0.005234321579 0.009301048703 0.009245495312 0.01400822587 0.008768454194 0.005519520957 0.01597988047 0.002593786223 0.00402658619 0.002053803531 0.02721678093 0.06626883894 0.004381389357 0.01782064326 0.005296500865 0.01055617724 0.006495380308 0.009878640063 0.001646022662 0.007185184397 0.005585746374 0.006938662846 0.004984250292 0.004094382282 0.02143565007 0.01475870889 0.00874498114 0.008820815012 0.04167348519 0.00212736195 0.004961668514 0.007775629871 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
62.87144089 62.86343002 62.86751556 62.86460876 62.86366653 62.86120605 62.86087418 62.89191437 62.89090347 62.87303543 62.86231613 62.85704041 62.86484909 62.86484909 62.8631134 62.96308899 62.86019897 62.86274338 62.87300491 62.86624908 62.86511993 62.86180496 62.90029907 62.86211395 62.86082077 62.86027908 62.86384583 62.85869598 62.85900116 63.02841949 62.8613472 62.86392593 62.86130524 62.86441803 62.8653183 62.86912537 62.86388779 62.85873032 62.87109756 62.85771179 62.85914612 62.85812378 62.88042831 62.92138672 62.85950089 62.87294006 62.85850525 62.86567307 62.86066055 62.86499786 62.85676193 62.86230469 62.86070251 62.86205673 62.86010361 62.85825729 62.87559891 62.86987686 62.86386108 62.86393738 62.89678955 62.8572464 62.86008072 62.86289215 

-------
======================
selected experts : 7, 15, 22, 29, 43, 60, 
layer1_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e0a3ef10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0245953 -0.0391809 -0.02191010.0561746 -0.0766892 -0.0429587 -0.0702658 0.0359129 -0.109381]

layer1_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3ee080>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.02668 0.0178016 -0.02750760.105065 -0.10711 -0.102919 -0.103468 0.0475631 -0.0590292]

layer2_wq's input 
<N9nntrainer6TensorE at 0x5682dc3ee2c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.105586 0.0526663 -0.07292650.347169 -0.253097 -0.340076 -0.320027 0.139803 -0.165567]
==============================
layer2_wq's output 
<N9nntrainer6TensorE at 0x5682dc3ee260>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.728063 0.116087 -0.7897090.168591 -0.62339 -0.0035476 0.975437 0.2551 -0.481121]
============================
layer2_wk's input 
<N9nntrainer6TensorE at 0x5682dc3edf00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.105586 0.0526663 -0.07292650.347169 -0.253097 -0.340076 -0.320027 0.139803 -0.165567]
==============================
layer2_wk's output 
<N9nntrainer6TensorE at 0x5682dc3ede70>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.49132 0.0543507 -0.20134-2.59986 0.763209 -1.86359 -0.642021 1.05378 -0.949512]
============================
layer2_wv's input 
<N9nntrainer6TensorE at 0x5682dc3ee380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.105586 0.0526663 -0.07292650.347169 -0.253097 -0.340076 -0.320027 0.139803 -0.165567]
==============================
layer2_wv's output 
<N9nntrainer6TensorE at 0x5682dc3ee3b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.725264 -0.00604983 -0.4373230.0222086 -0.0746775 -0.442288 0.476208 0.433268 0.273971]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.197423 -0.710335 -0.12218-0.798207 -0.146914 -0.605842 0.233624 0.980802 -1.27041]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0856038
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer2_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ee500>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer2_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ee620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer2_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3fefb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.02668 0.0178016 -0.02750760.105065 -0.10711 -0.102919 -0.103468 0.0475631 -0.0590292]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0471549 0.0731857 -0.1083330.468274 -0.428001 -0.466616 -0.457182 0.20742 -0.209794]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.0934920162 0.5232843757 -0.8450167775 -0.3234837353 -0.0336504057 2.137332201 -0.5679025054 0.006714668591 -0.3903882802 0.1523206532 0.2629042566 -0.2128079832 0.240971595 0.1091089919 -0.5416561365 -0.6098800302 1.601985097 -0.7315782309 -0.3482190669 1.016847491 -0.2046647668 0.06216091663 0.1674819887 -0.1112588271 -0.535158813 -0.2945003808 -0.5575503707 0.02658708766 -1.601998091 0.1779913604 -0.6792650819 -0.06728672981 -0.1698344648 -0.322052598 -0.0734956935 -0.309035331 -0.6906391978 -0.7844748497 0.08373695612 0.03448255733 0.4836958349 -0.1885450035 -0.5079341531 1.050334334 0.06574561447 0.2271577567 0.693333745 -0.1737065762 -0.3850834966 0.2595508099 1.380516768 0.5898442268 -0.4565664828 -0.9783053398 0.5971566439 -0.1786491424 0.2759366035 -0.8576596379 -1.095670342 0.5211244226 -0.1892276555 -0.1837007254 0.04368966445 0.7588869333 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0116348099 0.0215586666 0.005487521645 0.009244323708 0.01235231012 0.1082913876 0.007239780389 0.01286111027 0.00864607282 0.01487696543 0.01661652513 0.01032621227 0.01625604741 0.01424779743 0.007432313636 0.006942163687 0.06340093166 0.006146699656 0.009018465877 0.03531616926 0.01041064411 0.01359435264 0.01510423888 0.01142992266 0.007480761502 0.009516175836 0.007315116934 0.01311924774 0.002574088285 0.01526381262 0.006476812065 0.01194373332 0.01077963877 0.009257561527 0.01186980586 0.009378859773 0.00640356075 0.005830009468 0.01389084943 0.01322324108 0.02072186209 0.01057982072 0.007687221281 0.03651881963 0.01364316978 0.01603303291 0.0255548507 0.01073797885 0.008692059666 0.01656089723 0.05080578476 0.02304243855 0.008092412725 0.004802747164 0.02321155183 0.01068503596 0.01683449559 0.005418580491 0.004270893056 0.02151214704 0.01057260111 0.01063119527 0.01334555261 0.02728618123 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
53.42539597 53.43531799 53.41925049 53.42300415 53.42611313 53.52014542 53.42100143 53.42662048 53.42240906 53.42863846 53.43037796 53.4212265 53.43001556 53.42800903 53.42119217 53.42070389 53.47620773 53.41990662 53.42277908 53.44812393 53.42417145 53.42544937 53.42886353 53.4242363 53.42124176 53.42327881 53.42012405 53.42687988 53.41633606 53.42902374 53.42023849 53.42570496 53.42454147 53.42301941 53.42563248 53.42314148 53.42016602 53.41863632 53.42765045 53.42698288 53.43448257 53.42433929 53.42144775 53.45027924 53.4274025 53.42979431 53.4393158 53.42449951 53.41959381 53.43032074 53.46456528 53.43489456 53.42185211 53.41856384 53.4360199 53.42444611 53.4305954 53.41917801 53.41707993 53.43527222 53.42338181 53.42343903 53.42710495 53.44104767 

-------
======================
selected experts : 5, 16, 19, 43, 50, 63, 
layer2_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e09f8dd0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0519867 0.00856681 -0.0284037-0.0400309 0.0270178 0.0200372 0.0438958 -0.00988634 -0.0751584]

layer2_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc401970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0786666 0.0263684 -0.05591130.0650342 -0.0800917 -0.0828815 -0.0595725 0.0376768 -0.134188]

layer3_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e86c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.371832 0.0749493 -0.1526720.168237 -0.191842 -0.199847 -0.150303 0.0950594 -0.426412]
==============================
layer3_wq's output 
<N9nntrainer6TensorE at 0x5682dc409160>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.0692 -0.458864 1.38395-1.07684 -0.394386 1.17786 -0.148935 -0.389548 0.619026]
============================
layer3_wk's input 
<N9nntrainer6TensorE at 0x5682dc41f6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.371832 0.0749493 -0.1526720.168237 -0.191842 -0.199847 -0.150303 0.0950594 -0.426412]
==============================
layer3_wk's output 
<N9nntrainer6TensorE at 0x5682dc41f440>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[3.77456 0.805306 0.5845431.64642 -2.70246 1.18473 0.379973 0.740736 -1.26943]
============================
layer3_wv's input 
<N9nntrainer6TensorE at 0x5682dc4204c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.371832 0.0749493 -0.1526720.168237 -0.191842 -0.199847 -0.150303 0.0950594 -0.426412]
==============================
layer3_wv's output 
<N9nntrainer6TensorE at 0x5682dc420250>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.181916 -0.197801 -0.242114-0.0812725 0.0323169 -0.359375 0.0569709 0.188467 -0.595215]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0277019 1.16318 0.9941771.44448 -1.23821 -0.0986525 0.273733 -0.314642 -0.735535]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a16790a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer3_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc422910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer3_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc422870>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer3_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc423990>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0786666 0.0263684 -0.05591130.0650342 -0.0800917 -0.0828815 -0.0595725 0.0376768 -0.134188]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.140693 0.0997921 -0.2035630.263778 -0.294157 -0.338814 -0.238772 0.146199 -0.443554]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7289729714 -0.5335597396 -0.1839262992 -0.5233195424 0.3554777801 0.2119001746 1.552555442 -0.6535074711 -0.00459009409 -0.07510069758 0.5618703961 0.1054131314 0.253040731 -0.1304226369 -1.080092669 -0.1675660461 -1.218974829 -0.8078290224 -0.05679995567 -0.01361918356 0.1924585104 -0.1846369505 -0.4339244068 -0.5550991893 -0.09112460911 -0.4543816149 -0.3196879923 -0.5018143058 -0.2495882511 0.2730513811 -0.9791836739 0.1265223324 -0.4175069928 -0.1767056584 1.010258198 0.4161131382 -0.3894725144 0.1850838661 -0.7227553725 -0.01342593506 0.02664080262 -0.4128195047 -1.153370023 -0.5147992373 -0.3168607652 -0.4345905781 -0.4674172699 -0.5376713276 1.158827305 -1.018765807 1.621137977 -0.1733201444 0.3592012525 0.07649448514 0.09867663682 -0.5094680786 -0.08239448071 0.6137117743 -0.8467483521 1.075052023 1.401985168 -0.4103972316 -0.1727882624 -1.128186226 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006799882744 0.008267388679 0.01172768231 0.008352482691 0.02011279576 0.01742278039 0.06658197194 0.007332900073 0.01403126772 0.0130759906 0.02472336777 0.01566284709 0.01815451123 0.01237224694 0.004786435049 0.01192112826 0.004165780731 0.006284268107 0.01331749279 0.01390514988 0.01708732359 0.01171935163 0.009133546613 0.008091217838 0.01286813058 0.008948598057 0.01023886167 0.008534051478 0.0109823579 0.01852145605 0.00529463822 0.01599699259 0.009284732863 0.01181267016 0.0387114957 0.02137007378 0.009548707865 0.01696177572 0.006842294708 0.01390783675 0.01447639242 0.009328356944 0.004448239692 0.008423952386 0.01026785001 0.009127464145 0.008832703345 0.008233467117 0.04491203278 0.005089159124 0.07130856067 0.01185273007 0.02018782683 0.01521638595 0.01555769052 0.008468980901 0.0129809631 0.02603886276 0.00604438642 0.0413028039 0.05727496371 0.009350981563 0.01185903698 0.004561685026 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
42.54202271 42.53967285 42.54694748 42.54357529 42.55437851 42.55264282 42.59798813 42.54350662 42.54925156 42.54925156 42.55899048 42.55088425 42.55051422 42.54759216 42.54000854 42.54714203 42.53938675 42.54055023 42.54949188 42.54721832 42.55230713 42.54789352 42.54530716 42.54331207 42.54808807 42.54417038 42.54545975 42.54375458 42.54620361 42.55374146 42.5405159 42.55121994 42.54164505 42.54703522 42.57393265 42.55659103 42.54476929 42.55218124 42.54206467 42.54912949 42.54969788 42.54454803 42.54062271 42.54364395 42.54358292 42.54434967 42.54405212 42.54345322 42.58108521 42.54030991 42.60748291 42.54707336 42.5544548 42.55043793 42.55077744 42.54273605 42.54820251 42.5622139 42.54030991 42.57270813 42.59249496 42.54457092 42.54708099 42.53978348 

-------
======================
selected experts : 6, 34, 48, 50, 59, 60, 
layer3_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc426710>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.060015 -0.0205406 0.0372005-0.0560069 0.0877867 -0.00908835 -0.0705842 0.0198905 0.0873397]

layer3_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc426050>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.138682 0.00582782 -0.01871080.00902725 0.007695 -0.0919698 -0.130157 0.0575673 -0.0468479]

layer4_wq's input 
<N9nntrainer6TensorE at 0x5682dc44b9a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.350666 0.016757 -0.05298880.0273912 0.0195685 -0.28172 -0.383648 0.175507 -0.140796]
==============================
layer4_wq's output 
<N9nntrainer6TensorE at 0x5682dc492890>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.969563 0.721811 -1.201660.176894 1.05716 -0.291057 0.800175 0.638609 0.780764]
============================
layer4_wk's input 
<N9nntrainer6TensorE at 0x5682dc44d700>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.350666 0.016757 -0.05298880.0273912 0.0195685 -0.28172 -0.383648 0.175507 -0.140796]
==============================
layer4_wk's output 
<N9nntrainer6TensorE at 0x5682dc44d470>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.985035 -1.19871 1.55621-0.124086 -1.33027 0.445463 -1.51528 -0.496529 -0.296997]
============================
layer4_wv's input 
<N9nntrainer6TensorE at 0x5682dc44e4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.350666 0.016757 -0.05298880.0273912 0.0195685 -0.28172 -0.383648 0.175507 -0.140796]
==============================
layer4_wv's output 
<N9nntrainer6TensorE at 0x5682dc44e280>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.232352 0.0497875 0.2972450.215731 1.04167 0.073453 -0.145023 0.023658 -0.0093237]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.05982 0.581241 -0.106409-1.20994 0.537443 0.955752 -0.18725 1.0065 -0.170702]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1e8d0e8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer4_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc450940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer4_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4508a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer4_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4519c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.138682 0.00582782 -0.01871080.00902725 0.007695 -0.0919698 -0.130157 0.0575673 -0.0468479]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.254483 0.0222303 -0.06839880.0365216 0.0293528 -0.377398 -0.53786 0.226246 -0.16178]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4233067334 -0.8003293872 0.6444360018 -0.4378878772 -1.36439085 -0.1103366837 -0.7561166883 0.1250419915 0.3909090459 0.02027952112 -0.2909910083 0.1024083048 -0.9229542017 -0.448563695 -1.051607847 -0.5025811195 -0.5787528753 0.1923734844 -0.9440920353 -0.5193585753 -0.08674078435 -1.059256077 -0.4905348122 -0.6434621215 -0.8703958392 1.485964775 -0.1829965711 -0.744075954 -0.7400940061 -1.118461967 -0.506603539 -0.1404953897 0.03317378461 -0.8824873567 -0.2091689259 0.6334250569 0.6675570011 -1.059693217 0.1148692369 -0.3503339589 -0.3829305768 -0.5799865723 0.864215374 -0.6390654445 -0.493824482 0.3954688013 1.241177559 -0.1369689256 0.2495298237 2.187966347 2.07179904 1.488792062 -0.8710832596 -0.5833969712 0.1309114397 0.8206555247 -0.95511657 0.3027754426 -1.015067458 -0.1963151693 0.06178678945 0.2862616777 -1.829807281 -0.1472508758 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01924641244 0.005661497824 0.02400960401 0.008134627715 0.003220791463 0.01128733344 0.005917424336 0.01428285614 0.01863286458 0.01286225859 0.009421806782 0.01396321505 0.005008136388 0.008048247546 0.004403545521 0.007625034545 0.007065791171 0.01527765673 0.004903385881 0.007498172577 0.01155683771 0.004369994625 0.007717443164 0.006623048335 0.005278395023 0.05570014566 0.01049628574 0.005989104975 0.006013001315 0.004118775483 0.007594425697 0.01095200609 0.01302918326 0.005214955658 0.01022513676 0.02374668419 0.02457119711 0.004368084949 0.01413829438 0.008878955618 0.008594199084 0.007057080045 0.0299112089 0.00665223226 0.007692097686 0.01871802099 0.04360603169 0.01099069603 0.01617630944 0.1123910472 0.1000647023 0.05585784465 0.005274767522 0.007033053786 0.01436693408 0.02863625437 0.004849625286 0.01706096902 0.004567428492 0.0103574153 0.0134073738 0.01678154245 0.002022249857 0.01087826863 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.83690262 40.82331848 40.8407135 40.82674408 40.82183075 40.82989883 40.82452774 40.83098602 40.83247375 40.8314743 40.82707977 40.83257294 40.82361984 40.82570648 40.82301331 40.82623672 40.82376862 40.83198166 40.82351303 40.82611084  40.829216 40.82298279 40.82346725 40.82332611 40.82293701 40.87430954 40.82624817 40.82269287 40.82462311 40.82273102 40.82620621 40.82956314 40.83164215 40.82382584 40.82883453 40.84045029 40.84032059 40.82011795 40.83274841 40.82558441 40.82625198 40.82566833 40.84852219 40.8243103 40.82630157 40.83351517 40.86221695 40.82864761 40.8338356 40.92337418 40.91772079 40.87160873 40.82388687 40.82469177 40.83202362 40.84724808 40.82345963 40.83567047 40.82031631 40.82896805 40.83201981  40.835392 40.82063293 40.82949066 

-------
======================
selected experts : 25, 42, 46, 49, 50, 51, 
layer4_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc454a40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0478261 -0.0202937 0.1414030.138244 0.0105741 0.0660352 -0.078456 -0.0414171 -0.0757324]

layer4_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc454380>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.186508 -0.0144659 0.1226920.147271 0.0182691 -0.0259347 -0.208613 0.0161502 -0.12258]

layer5_wq's input 
<N9nntrainer6TensorE at 0x5682dc4a0910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37183 -0.0395841 0.2973610.381879 0.0397548 -0.0713048 -0.551814 0.0452452 -0.319453]
==============================
layer5_wq's output 
<N9nntrainer6TensorE at 0x5682dc454560>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.27904 -1.01169 -0.9215611.36454 -0.72238 -0.498745 1.54375 0.659523 -1.45093]
============================
layer5_wk's input 
<N9nntrainer6TensorE at 0x5682dc4a2670>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37183 -0.0395841 0.2973610.381879 0.0397548 -0.0713048 -0.551814 0.0452452 -0.319453]
==============================
layer5_wk's output 
<N9nntrainer6TensorE at 0x5682dc4a23e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[3.24098 0.412286 -2.08267-1.41415 0.314497 -1.61792 -1.16653 0.709432 -1.39033]
============================
layer5_wv's input 
<N9nntrainer6TensorE at 0x5682dc4a3460>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37183 -0.0395841 0.2973610.381879 0.0397548 -0.0713048 -0.551814 0.0452452 -0.319453]
==============================
layer5_wv's output 
<N9nntrainer6TensorE at 0x5682dc4a31f0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.139015 0.095336 -0.0847325-0.0599647 0.125625 -0.379508 -0.338026 -0.0653292 0.0863798]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.803805 0.674742 -1.30839-0.999683 0.309789 -0.821347 0.143997 1.67254 -1.20914]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1c880d8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer5_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc4a58b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer5_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4a5810>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer5_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a6930>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.186508 -0.0144659 0.1226920.147271 0.0182691 -0.0259347 -0.208613 0.0161502 -0.12258]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.345097 -0.0535328 0.4348510.579535 0.0642743 -0.101381 -0.815489 0.0618702 -0.415289]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.6644698381 0.3958806396 -0.8431923985 0.2933754027 -0.9926815033 0.3259683251 0.4573433399 -1.295527816 -0.8638315797 -0.5962546468 1.083653688 -0.5674967766 -0.2397421151 -0.5430603027 -1.03829217 -0.1272376031 -0.290961802 1.88923049 -0.6655781865 -0.4766088128 1.197840452 -0.892660141 -1.295008659 0.4723694921 -0.5369101167 -0.04444982111 -0.7701082826 -0.6128735542 -0.4972300231 -0.9362294674 0.0592253916 -0.4229903519 0.525193572 -0.3231920004 -0.5599902868 -0.8925861716 0.3094721735 -0.1731057167 0.5254550576 0.6374439001 0.4803516567 -1.244556785 -1.547644854 -0.3532342017 0.2070346922 -0.2350983173 -0.2090717554 -1.477300048 0.4622754753 -0.6229419112 0.3936619759 -1.05861032 -0.765895009 -1.137443542 -0.4172428548 0.1035719812 0.1171668693 -0.9444702864 -0.2407902479 -0.0649222061 -1.223350048 -0.465829283 -0.371851325 -0.9839936495 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03131745011 0.02394085377 0.006934529636 0.02160837501 0.005971654784 0.0223242566 0.02545848116 0.004411337432 0.006792874075 0.008876888081 0.04762506858 0.009135873988 0.012679209 0.00936187245 0.005705402233 0.01418901514 0.01204613503 0.1065842882 0.008282355964 0.01000511926 0.05338586867 0.006599840242 0.004413628019 0.02584391087 0.009419627488 0.0154136857 0.007460313383 0.008730582893 0.009800913744 0.006318463944 0.01709747873 0.01055622008 0.02724579349 0.01166407671 0.009204710834 0.006600328255 0.0219590161 0.01355289109 0.02725291811 0.03048240207 0.02605102956 0.00464201672 0.003428286873 0.01131887082 0.01982096769 0.01273822412 0.01307410747 0.003678134643 0.02558435686 0.008643120527 0.0238877926 0.005590649322 0.007491810247 0.005166843999 0.01061706711 0.01787275821 0.0181173943 0.0062666093 0.01266592741 0.01510133874 0.004741509445 0.01011355128 0.01111009717 0.006023761351 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.26918793 33.26371765 33.24861908 33.26329422 33.24574661 33.26019287 33.26714325 33.23941803 33.24752426 33.25056076 33.28835678 33.24986649 33.25436401 33.2481842 33.24739075 33.25587463 33.25373077 33.33968353 33.24996567 33.25168991 33.28553391 33.24828339 33.24609756 33.26752853 33.24633408 33.25709915 33.24914551 33.2504158 33.25148392 33.24704742 33.25878143 33.25033188 33.26320648 33.2533493 33.25088882 33.24732971 33.26364136 33.25523758 33.26512146 33.26930618 33.26773453 33.24632645 33.2441597 33.25300217 33.25959778 33.25442123 33.25475693 33.24440765 33.26631546 33.25032806 33.26366425 33.24727631 33.24536133 33.24589539 33.24943924 33.25574112 33.25979996 33.24318314 33.25434875 33.25678635 33.24642563 33.24702835 33.25088501 33.24103165 

-------
======================
selected experts : 0, 10, 17, 20, 38, 39, 
layer5_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc4a9a10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0342631 0.0553379 -0.039758-0.0504181 0.0299267 0.0941602 0.0995771 -0.124148 0.0256439]

layer5_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a9350>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.152245 0.040872 0.08293390.0968529 0.0481958 0.0682255 -0.109036 -0.107998 -0.0969364]

layer6_wq's input 
<N9nntrainer6TensorE at 0x5682dc4e8620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.481221 0.135603 0.2714360.327848 0.136133 0.21565 -0.334867 -0.321996 -0.291189]
==============================
layer6_wq's output 
<N9nntrainer6TensorE at 0x5682dc4a9530>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.08021 0.134619 -1.689510.372374 -0.432704 -1.72997 0.560465 1.13711 -2.68552]
============================
layer6_wk's input 
<N9nntrainer6TensorE at 0x5682dc4ea380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.481221 0.135603 0.2714360.327848 0.136133 0.21565 -0.334867 -0.321996 -0.291189]
==============================
layer6_wk's output 
<N9nntrainer6TensorE at 0x5682dc4ea0f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.24336 0.122814 -0.1984340.556906 0.592433 -1.41524 -0.579507 0.669371 0.388004]
============================
layer6_wv's input 
<N9nntrainer6TensorE at 0x5682dc4eb170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.481221 0.135603 0.2714360.327848 0.136133 0.21565 -0.334867 -0.321996 -0.291189]
==============================
layer6_wv's output 
<N9nntrainer6TensorE at 0x5682dc4eaf00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.270678 -0.163141 -0.07282670.287713 0.071787 -0.199607 0.473052 -0.0426461 0.254859]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.571935 0.926213 -0.273062-1.70837 1.57454 -0.837185 -0.739918 1.0294 -2.23288]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1a830c8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer6_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc41beb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer6_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc41be10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer6_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc41cf30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.152245 0.040872 0.08293390.0968529 0.0481958 0.0682255 -0.109036 -0.107998 -0.0969364]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.24061 0.139268 0.2732950.343046 0.157741 0.246238 -0.393529 -0.380101 -0.3064]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4410547912 -1.218328714 -0.749876678 -0.9559231997 -0.1196647584 0.1754807979 -0.5955162048 -1.395718694 -1.214615464 2.168490887 0.1459833086 0.8688387871 -0.7450354695 0.1884209365 0.9173011184 0.175174281 -0.9830300212 -1.049170732 -0.6121963263 -0.0005945349112 -0.5670848489 0.2899364531 0.5462858081 -0.2541283667 0.09138106555 0.06696138531 -1.341629744 -1.249254823 -0.4981438816 -1.828889728 0.9308676124 0.9007117152 0.7550630569 0.6048219204 0.6557562947 0.1265725344 0.4342204928 -0.3482604623 -1.431741595 0.3023626208 2.698046684 -1.048008323 -0.1608816832 -0.9697629213 -0.1068262458 -0.6657227874 -0.5831062198 0.0226062946 -1.022549629 -0.3982205987 -0.1861209869 -0.4678562284 0.5408172607 -0.1379685253 -0.3198312521 -0.4305019677 -0.6436776519 -0.3965961635 -0.2285197973 -0.2880137563 -0.3232179582 0.3415495753 0.3171806037 -0.8836710453 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01893318258 0.00360215595 0.005754514132 0.004682996776 0.01080702711 0.01451731566 0.006715008989 0.003016637405 0.003615557216 0.1065220684 0.01409534365 0.02904075198 0.005782441236 0.01470639277 0.03048279695 0.0145128658 0.004557759501 0.004266059492 0.00660392968 0.01217356324 0.006908665877 0.0162777286 0.02103414759 0.009447337128 0.0133463433 0.01302437484 0.003184296191 0.003492460819 0.007401756942 0.001956136664 0.03089915961 0.02998127788 0.02591765299 0.02230215259 0.02346752398 0.0138243828 0.0188042298 0.008598613553 0.002909902483 0.0164812617 0.1808934212 0.004271020647 0.01037064847 0.004618631676 0.01094666682 0.006259738468 0.006798860617 0.01245930512 0.00438115187 0.008179579861 0.01011217758 0.00762936892 0.02091943286 0.0106110163 0.008846570738 0.007919748314 0.006399268284 0.008192877285 0.009692393243 0.009132574312 0.008816663176 0.01713993214 0.01672729664 0.005033876281 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.14231491 40.12698364 40.12150955 40.12806702 40.13418961 40.13790131 40.13105011 40.12639999 40.1269989 40.22990417 40.13747787 40.14956284 40.12916565 40.13713455 40.15386581 40.13789368 40.12794113 40.1276474 40.12998581 40.13555527 40.13029099 40.13965988 40.14441681 40.13283157 40.13673019 40.13640594 40.12752151 40.12687683 40.13078308 40.12533951 40.15142059 40.1524086 40.14929962 40.14568329 40.14685059 40.13720703 40.14218521 40.1319809 40.12629318 40.13986206 40.30427551 40.12765503 40.13280106 40.12800217 40.13433075 40.13059616 40.12922668 40.13584137 40.12680817 40.13156128 40.13349533 40.13101196 40.14430237 40.13399506 40.12936783 40.13130188 40.12882996 40.13157654 40.13116837 40.13251495 40.13219833 40.13766098 40.14011002 40.12841797 

-------
======================
selected experts : 9, 11, 14, 30, 31, 40, 
layer6_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc47b4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.116619 0.06211 0.0381594-0.153191 0.0637205 -0.0967168 0.0778489 0.131376 0.107361]

layer6_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc47ae20>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.268863 0.102982 0.121093-0.0563378 0.111916 -0.0284913 -0.0311867 0.0233776 0.010425]

layer7_wq's input 
<N9nntrainer6TensorE at 0x5682dc5555c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.644431 0.295358 0.332417-0.150038 0.27742 -0.073543 -0.0830561 0.0581881 0.029045]
==============================
layer7_wq's output 
<N9nntrainer6TensorE at 0x5682dc47b000>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.732738 0.628422 1.19-0.581977 -0.188778 0.047805 -0.324582 0.481942 0.357657]
============================
layer7_wk's input 
<N9nntrainer6TensorE at 0x5682dc557b30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.644431 0.295358 0.332417-0.150038 0.27742 -0.073543 -0.0830561 0.0581881 0.029045]
==============================
layer7_wk's output 
<N9nntrainer6TensorE at 0x5682dc5578a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.62036 0.00124264 1.4656-1.44503 -0.546472 0.551392 -0.13881 0.625616 -0.065592]
============================
layer7_wv's input 
<N9nntrainer6TensorE at 0x5682dc558920>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.644431 0.295358 0.332417-0.150038 0.27742 -0.073543 -0.0830561 0.0581881 0.029045]
==============================
layer7_wv's output 
<N9nntrainer6TensorE at 0x5682dc5586b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.152496 -0.0865679 0.2932710.462981 -0.2989 0.268249 0.458184 0.729476 0.53018]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.876349 0.40476 0.5114821.22196 -0.0919254 -0.171675 -0.577968 -0.0597867 0.986627]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a187e0b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer7_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc55ad70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer7_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc55acd0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer7_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55bdf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.268863 0.102982 0.121093-0.0563378 0.111916 -0.0284913 -0.0311867 0.0233776 0.010425]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.407589 0.34599 0.391955-0.196204 0.362251 -0.0992247 -0.111167 0.0794998 0.0328892]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.098373771 0.2836256325 -0.2417769879 -0.3635024428 -0.606269002 0.2527832985 1.537901521 0.4816333354 0.09163210541 -1.234294653 -1.267491341 0.1218170673 -1.077616811 -0.6664997339 -1.141363263 -1.204203129 0.3488199711 -0.7398209572 -0.5408400297 -0.4675128162 0.485101819 0.2313048244 -0.05166152492 0.2560469806 1.058061838 -0.336117357 -0.6226214767 -0.9360643625 0.6463159323 -1.137920022 -0.1322301924 -0.1359293163 -0.3121391535 -0.7324919105 -0.521625936 0.09431058168 -0.3835838437 -0.3052536845 -0.400924474 -0.5267472863 0.1987118423 -1.661210179 -0.8067662716 -0.8190937042 -0.7711262703 0.4742020965 -0.4262674153 -0.8152752519 -0.8452249765 -0.2902589738 -0.3541771472 -0.3275723457 -0.3245003223 -0.08514315635 -1.52711904 -0.1305801272 -0.6654924154 -0.6012252569 -0.7324240804 -0.9401038289 1.551528454 -0.654296875 1.070305347 0.1213589758 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005570847541 0.02218789048 0.01312008314 0.01161640882 0.009112547152 0.02151401155 0.07777520269 0.02704641409 0.01831193827 0.004862858914 0.004704077728 0.01887311041 0.005687691271 0.008579893969 0.005336435977 0.005011413712 0.02368261106 0.007973313332 0.009728706442 0.01046889275 0.0271403864 0.02105685323 0.01586728729 0.02158434317 0.04813371971 0.01193892118 0.008964744397 0.006552566774 0.03188823164 0.005354842171 0.01463902555 0.01458497252 0.0122286547 0.008031964302 0.009917442687 0.01836105064 0.01138546225 0.01231314428 0.0111897327 0.009866783395 0.02038160898 0.003173106583 0.007457012311 0.007365650497 0.00772757316 0.02684617229 0.01090971567 0.007393830456 0.007175670471 0.01249916758 0.01172524225 0.0120413769 0.01207842398 0.01534481905 0.003628436942 0.01466319896 0.008588538505 0.009158621542 0.008032510057 0.006526151206 0.07884228975 0.008685233071 0.04872666672 0.01886446774 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
35.92993164 35.95131683 35.94129562 35.93693161 35.93633652 35.95064545 35.98973846 35.95426941 35.94648743 35.93304062 35.93383408 35.94800186 35.93481827 35.93580246 35.93446732 35.93318939 35.95281219 35.93710327 35.93695068 35.93864441 35.95531845 35.94923401 35.94213867 35.94880676 35.96677399 35.93916321 35.93809509 35.93473053 35.94861984 35.93448639 35.94281769 35.94276047 35.9404068 35.93716431 35.93904877 35.94272232 35.93956375 35.93953705 35.93936539 35.9380455 35.94665146 35.93039703 35.93468094 35.93649673 35.93685913 35.9521637 35.93908691 35.93652344 35.93535233 35.93686295 35.93990326 35.93640518 35.94120789 35.94352341 35.93275833 35.9418869 35.93676376 35.93828964 35.93716431 35.9356575 36.00606537 35.93781662 35.97785568 35.94704056 

-------
======================
selected experts : 6, 20, 24, 28, 60, 62, 
layer7_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5969b0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0117731 -0.00431516 0.09412550.0485652 -0.0529214 -0.069048 -0.0954666 0.055075 0.0510467]

layer7_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55e510>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.25709 0.0986668 0.215219-0.00777257 0.0589949 -0.0975393 -0.126653 0.0784525 0.0614716]

layer8_wq's input 
<N9nntrainer6TensorE at 0x5682dc59a250>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.541513 0.253167 0.515135-0.0193481 0.134994 -0.235332 -0.30315 0.184024 0.151843]
==============================
layer8_wq's output 
<N9nntrainer6TensorE at 0x5682dc5d3620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0237115 0.0685095 -0.414937-0.247035 -0.467361 0.0607781 -0.238849 0.292587 -0.135862]
============================
layer8_wk's input 
<N9nntrainer6TensorE at 0x5682dc59bfb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.541513 0.253167 0.515135-0.0193481 0.134994 -0.235332 -0.30315 0.184024 0.151843]
==============================
layer8_wk's output 
<N9nntrainer6TensorE at 0x5682dc59bd20>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.896541 -1.61613 1.186980.590892 0.540082 -0.798445 -0.046022 -2.45929 -0.234835]
============================
layer8_wv's input 
<N9nntrainer6TensorE at 0x5682dc59cda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.541513 0.253167 0.515135-0.0193481 0.134994 -0.235332 -0.30315 0.184024 0.151843]
==============================
layer8_wv's output 
<N9nntrainer6TensorE at 0x5682dc59cb30>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.15903 -0.87771 0.1879420.172852 0.341283 -0.0373287 0.476336 0.355474 0.699468]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0524281 -0.0500709 0.270847-0.3998 -0.171708 -0.438905 -0.370541 -0.0731805 0.38978]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1474098
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer8_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc59f1f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer8_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc59f150>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer8_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a0270>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.25709 0.0986668 0.215219-0.00777257 0.0589949 -0.0975393 -0.126653 0.0784525 0.0614716]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.401212 0.334407 0.684099-0.0276827 0.189782 -0.349262 -0.451087 0.2689 0.194218]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5820931196 -0.2350897938 -0.4585057497 -0.3865448833 0.7096521854 0.06612271816 -0.6608039141 -0.3367446661 -0.8939000368 -0.4477111101 -1.01867187 -0.6945809126 -0.962595582 1.454297066 0.001071602106 0.02070719749 -0.7310253978 -1.269895792 0.4321978688 0.4479066133 -0.2188422233 -0.8506630659 -1.137848377 -0.3327110112 0.3433792889 0.1516014189 0.6872583628 -1.29946208 -0.8785806894 -0.856221199 -0.2928788364 -1.726149082 -0.4915761352 -0.9426625967 1.706531644 -0.5457578897 -1.037370682 -1.509035707 -0.5542669296 0.1647266001 -0.8272060752 -0.7226264477 0.09949754179 1.002302289 -0.6495707631 -0.2562497854 -0.1520896554 -0.1404538006 0.3654158711 -1.098366261 -0.5634807944 -0.00612174347 0.2465134561 -0.5623323917 -0.5518009067 -1.863395095 -0.1223517507 -0.4435008764 0.2245500088 -1.699274421 0.5346589684 -0.5374289751 0.04647413269 1.446173787 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009014371783 0.01275372691 0.01020020247 0.01096127369 0.03280449286 0.01723661833 0.008332048543 0.01152096875 0.006599627901 0.01031090599 0.005825479981 0.008055317216 0.006161484402 0.06907621026 0.01615104638 0.0164713189 0.007767030969 0.004531338345 0.02485630102 0.02524984069 0.01296263654 0.006891234312 0.005170994438 0.01156753115 0.02274380066 0.0187747851 0.03207804263 0.004399325233 0.006701508537 0.006853039376 0.01203759294 0.002871298464 0.009868394583 0.006285533309 0.08889402449 0.009347935207 0.005717563909 0.003567544976 0.00926873181 0.01902283169 0.007054793648 0.007832539268 0.01782159321 0.04395716265 0.008426170796 0.01248669345 0.01385745872 0.01401964389 0.02325055934 0.005379240494 0.009183721617 0.01603528298 0.0206440445 0.009194273502 0.009291616268 0.002503070515 0.01427573897 0.01035440993 0.02019557171 0.00294950977 0.02753815055 0.009426117875 0.0169012472 0.06851735711 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.0813446 34.08603668 34.08253098 34.08424377 34.10513687 34.09051895 34.08161545 34.08480453 34.0789299 34.0826416 34.07910919 34.07561874 34.07563019 34.14236069 34.08943558 34.08784866 34.0800972 34.07781601 34.07048416 34.09090424 34.08529282 34.07921982 34.07845688 34.08389664 34.0950737 34.09110641 34.10536194 34.07672882 34.07998657 34.07918167 34.08532333 34.07615662 34.0821991 34.07862091 34.15550232 34.08072662 34.07900238 34.07589722 34.08160019 34.0904007 34.07938385 34.08111572 34.09015274 34.11437988 34.08171082 34.08576965 34.08714294 34.08634949 34.09558105 34.07866287 34.08246613 34.08836746 34.09202194 34.08247757 34.07780838 34.07578659 34.08755875 34.08268356 34.09252548 34.07623291 34.10082245 34.08175659 34.08446503 34.12844849 

-------
======================
selected experts : 4, 13, 26, 34, 43, 63, 
layer8_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5a3350>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0659566 0.0530296 0.1635850.0778446 -0.0195666 0.0881568 0.183909 0.170824 0.0908925]

layer8_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a2c90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.191133 0.151696 0.3788040.0700721 0.0394283 -0.00938249 0.0572556 0.249276 0.152364]

layer9_wq's input 
<N9nntrainer6TensorE at 0x5682dc5e1750>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628368 0.419554 0.9949620.203553 0.100819 -0.02546 0.153375 0.659083 0.445254]
==============================
layer9_wq's output 
<N9nntrainer6TensorE at 0x5682dc5a2e70>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.990122 -0.0779878 1.01044-0.451464 -0.0806437 1.01568 0.814009 0.598821 0.507806]
============================
layer9_wk's input 
<N9nntrainer6TensorE at 0x5682dc5e3c80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628368 0.419554 0.9949620.203553 0.100819 -0.02546 0.153375 0.659083 0.445254]
==============================
layer9_wk's output 
<N9nntrainer6TensorE at 0x5682dc5e39f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.93641 -0.107036 -0.8609020.46931 0.199984 -0.895828 -0.831834 -0.632928 -0.362626]
============================
layer9_wv's input 
<N9nntrainer6TensorE at 0x5682dc5e4a70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628368 0.419554 0.9949620.203553 0.100819 -0.02546 0.153375 0.659083 0.445254]
==============================
layer9_wv's output 
<N9nntrainer6TensorE at 0x5682dc5e4800>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.249564 -0.310188 -0.025437-0.134065 -1.11543 0.202387 0.0279106 0.0432688 0.980205]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.341122 0.93277 0.3916791.03509 -1.00514 0.16671 -0.145631 0.999994 -0.0692124]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a126f088
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer9_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc5e6ec0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer9_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc5e6e20>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer9_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5e7f40>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.191133 0.151696 0.3788040.0700721 0.0394283 -0.00938249 0.0572556 0.249276 0.152364]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.287586 0.493438 1.166280.2389 0.121394 -0.0321514 0.1962 0.815181 0.463806]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5784392953 -2.692181826 -0.5327215791 -1.096446872 0.06641447544 -0.5960524678 0.4831649363 -0.9647579789 0.7627049088 -0.09703366458 -2.138244867 -1.655194521 -0.7575159669 -0.2602666914 -1.185462832 -1.286947131 -1.109573603 -0.4413939416 -0.1912102252 0.1474581361 2.318176985 -1.217723966 1.076936603 -1.016357303 -1.984680414 -0.8027300239 -0.8972060084 -0.9883889556 -0.08658076823 -0.681370914 -1.071043372 -0.9319506288 -0.4055244625 -1.134295821 0.2941918075 0.5751672387 -0.2030042708 0.5597757101 -1.342829466 -1.232607245 0.2436300069 1.034404755 0.596901238 2.314760923 -0.914604485 -1.468491554 -1.077005982 -0.7855711579 -1.070604563 -1.898351192 0.5030686259 -0.6025437117 -1.22859478 -0.6789172292 -1.126736045 -0.4787145555 0.06532867253 0.009236903861 0.5657193065 -0.2974469364 -0.4449689388 -1.005197048 0.08275671303 -0.4499510229 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.008367558941 0.001010676147 0.008758983575 0.004984606989 0.01594612747 0.00822146982 0.02419065125 0.005686207209 0.03199265152 0.0135416165 0.00175866764 0.002850820543 0.006995628588 0.01150215697 0.004560073372 0.004120005295 0.004919602536 0.009596587159 0.01232452411 0.01729226671 0.1515595168 0.004415306728 0.04380455986 0.005400244147 0.002050576499 0.006686371285 0.006083591841 0.005553410854 0.01368390862 0.007549115457 0.005112856161 0.005875850562 0.009947058745 0.004799470771 0.02002523467 0.02652184106 0.01218002196 0.02611675672 0.003896083683 0.004350080155 0.01903789304 0.04198053479 0.02710457519 0.1510426551 0.005978662521 0.00343600614 0.005082459655 0.006802092306 0.005115099251 0.002235467779 0.02467696182 0.008168275468 0.004367568996 0.00756766228 0.004835891072 0.009245037101 0.01592881791 0.01505993959 0.02627244778 0.01108235773 0.009562339634 0.005460849497 0.01620886102 0.009514818899 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.4602623 34.45290375 34.45492935 34.45592499 34.46688461 34.46011353 34.45414734 34.45758057 34.48388672 34.46448135 34.45365143 34.45474243 34.45888901 34.46339417 34.45645142 34.45601273 34.45586014 34.46149063 34.46326447 34.46918488 34.59772873 34.45630646 34.49474335 34.45538712 34.45394516 34.45858002 34.45797729 34.45744705 34.45508575 34.45944214 34.45700455 34.45776749 34.46088791 34.45573807 34.4719162 34.46983337 34.45835114 34.4770546 34.45578766 34.45624161 34.44709015 34.4938736 34.47422791 34.60198212 34.45787048 34.4553299 34.45697403 34.45392609 34.45510101 34.45412827 34.47180176 34.46006012 34.45626068 34.45946121 34.45386887 34.45923233 34.46496201 34.4659996 34.47625732 34.46202087 34.45954895 34.4573555 34.4681015 34.45949936 

-------
======================
selected experts : 8, 20, 22, 41, 42, 43, 
layer9_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5eb020>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0292678 -0.0956209 -0.113527-0.268267 0.0155715 -0.0378454 0.0868689 0.020848 -0.0885791]

layer9_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5ea960>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.220401 0.0560755 0.265277-0.198195 0.0549998 -0.0472279 0.144125 0.270124 0.063785]

layer10_wq's input 
<N9nntrainer6TensorE at 0x5682ded33210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.39589 0.154817 0.723569-0.566966 0.133552 -0.132746 0.397908 0.673894 0.163371]
==============================
layer10_wq's output 
<N9nntrainer6TensorE at 0x5682dc5eab40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.181234 -0.342398 1.430770.0895295 -0.553066 0.257564 0.0833396 -1.49051 -1.00958]
============================
layer10_wk's input 
<N9nntrainer6TensorE at 0x5682ded34f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.39589 0.154817 0.723569-0.566966 0.133552 -0.132746 0.397908 0.673894 0.163371]
==============================
layer10_wk's output 
<N9nntrainer6TensorE at 0x5682ded34ce0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.53692 -0.0485435 -0.1724740.715683 0.119405 -0.883975 1.76163 -0.277954 0.280245]
============================
layer10_wv's input 
<N9nntrainer6TensorE at 0x5682ded35d60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.39589 0.154817 0.723569-0.566966 0.133552 -0.132746 0.397908 0.673894 0.163371]
==============================
layer10_wv's output 
<N9nntrainer6TensorE at 0x5682ded35af0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.559905 -0.0366422 0.3549090.866707 -0.239438 -0.0393911 0.553588 0.34391 1.07834]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.386761 -0.0223075 -0.1729411.4231 -0.383355 -0.474616 1.35458 -0.627445 -0.513315]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a106a078
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer10_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded38210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer10_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded38170>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer10_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded39290>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.220401 0.0560755 0.265277-0.198195 0.0549998 -0.0472279 0.144125 0.270124 0.063785]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.317078 0.182795 0.81181-0.679041 0.168312 -0.162594 0.503378 0.885047 0.193075]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.06926098466 -1.889656901 -2.135423183 -1.227051497 -0.4244788289 -0.7646638155 -0.2025152743 -0.2169721425 1.188247561 -0.662728548 -1.118843555 0.2492176294 0.9456104636 -1.251841784 -0.3659493923 -0.8920525908 -0.1320210993 -0.5265669227 0.1242789775 -1.218567133 -0.7645328045 -0.8224347234 -1.494637251 1.817089558 -0.5894706845 -0.3520736098 -0.3152672648 0.9674650431 0.737018168 0.09049356729 -0.4484396577 -1.74812007 -0.8611502647 0.1298037916 0.4455396831 0.7185868621 1.352536917 -0.9928257465 -0.9874344468 0.2044235319 0.3249462843 -0.4133012295 -1.023074627 -0.9486420751 -0.08636790514 0.4954489172 -1.477710724 -0.9838752151 -0.9046508074 -0.6560556293 -0.6540198922 -0.6196044087 -1.701559186 -0.4007335007 -1.854149699 0.3188380301 -1.211869359 0.8672431707 -1.061550379 -1.684293866 -1.357903361 -1.057067871 -0.7432658076 -1.377599716 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01834772527 0.002587229479 0.002023485489 0.005018811673 0.01119834371 0.007969174534 0.01398141962 0.01378074847 0.05617614463 0.008824360557 0.005592358299 0.02196526341 0.04407334328 0.004895923194 0.01187333651 0.00701599149 0.01500260178 0.01011154335 0.01938546821 0.005061573815 0.007970217615 0.007521834224 0.00384051865 0.105354853 0.009495083243 0.01203923579 0.01249061152 0.04504714906 0.03577548265 0.01874146052 0.01093321107 0.002980599878 0.007236186881 0.01949286275 0.02672994137 0.03512213379 0.06620669365 0.006343425252 0.00637771748 0.02100306191 0.02369326726 0.01132421568 0.00615441706 0.006629985757 0.01570339315 0.0280978661 0.003906078404 0.006400457118 0.006928157993 0.008883440867 0.008901544847 0.00921322871 0.003122661263 0.01146743447 0.002680745209 0.0235489849 0.00509558944 0.04075130448 0.005922118668 0.003177043051 0.004403242376 0.005948724225 0.008141535334 0.004317363258 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.1207962 33.10598755 33.10542297 33.10842133 33.11460114 33.10183334 33.11738205 33.11718369 33.15766907 33.11222458 33.10899353 33.12441254 33.1474762 33.10257339 33.11146164 33.11041641 33.11840439 33.11256027 33.11611176 33.10560226 33.11041641 33.11092377 33.10724258 33.20303345 33.11003494  33.110672 33.11493683 33.14844894 33.13822174 33.12214279 33.11338043 33.10638046 33.11063766 33.12289429 33.13013077 33.13661575 33.16770172 33.10974503 33.10977936 33.12440491 33.10897446 33.09565353 33.10955429 33.11003113 33.11910629 33.1295929 33.10635376 33.10980225 33.1055603 33.11228561 33.10848618 33.11261368 33.10652542 33.11296082 33.10608292 33.12694931 33.10659027 33.13938522 33.10741425 33.10562515 33.10780334 33.10744095 33.11154175 33.10771942 

-------
======================
selected experts : 8, 12, 23, 27, 36, 57, 
layer10_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded3c110>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.161962 -0.0780533 0.1249870.0509749 0.26931 0.0336457 -0.056708 0.0038211 0.0792823]

layer10_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded3bb90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.382363 -0.0219779 0.390264-0.14722 0.32431 -0.0135822 0.0874166 0.273945 0.143067]

layer11_wq's input 
<N9nntrainer6TensorE at 0x5682ded7c3b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.633897 -0.0508481 0.85691-0.364473 0.688197 -0.032825 0.202248 0.573248 0.326785]
==============================
layer11_wq's output 
<N9nntrainer6TensorE at 0x5682ded3ba40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.657842 0.365413 0.2754280.0422222 -0.275213 -0.197291 0.727014 -0.487024 -0.91165]
============================
layer11_wk's input 
<N9nntrainer6TensorE at 0x5682ded7e110>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.633897 -0.0508481 0.85691-0.364473 0.688197 -0.032825 0.202248 0.573248 0.326785]
==============================
layer11_wk's output 
<N9nntrainer6TensorE at 0x5682ded7de80>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.47571 0.339769 -0.600838-1.8889 -1.66195 2.8416 -0.0334167 -0.885505 2.48664]
============================
layer11_wv's input 
<N9nntrainer6TensorE at 0x5682ded7ef00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.633897 -0.0508481 0.85691-0.364473 0.688197 -0.032825 0.202248 0.573248 0.326785]
==============================
layer11_wv's output 
<N9nntrainer6TensorE at 0x5682ded7ec90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.427054 0.818584 0.0928597-0.0225618 0.314247 -0.0656768 -0.627374 -0.441628 -0.612546]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0585101 -0.750239 -0.05823650.272492 0.125088 -0.314673 0.771718 0.412545 -0.513196]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0e65068
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer11_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded813b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer11_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded81310>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer11_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded82430>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.382363 -0.0219779 0.390264-0.14722 0.32431 -0.0135822 0.0874166 0.273945 0.143067]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.481761 -0.0667179 1.0927-0.466439 0.922375 -0.0440336 0.283404 0.823539 0.398467]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1634536982 0.2338491082 1.390282989 -0.3676809072 -0.5225353837 0.1594894528 1.739082575 -2.323273182 -1.632861614 -0.00858733058 -1.730676174 -1.526996255 0.113975741 -0.1351315677 -2.58881259 0.814460218 -0.05961622298 -0.1475380659 0.4953226447 -0.9851433039 -1.164471626 0.004394590855 0.316722542 -0.2453278005 1.028160095 -0.268912673 -1.446122289 -0.4320624769 0.7278697491 -0.5316099524 -1.532606602 -1.846465111 -1.457428217 -0.6088111997 -0.6791196465 -0.2312903404 -1.189405918 -0.5066782236 -1.544893384 -0.2530484796 -0.3886814713 -0.8982741237 -2.302025318 2.996816397 -1.963040948 -0.8953847885 1.07270515 -2.094770432 -1.289910674 -1.249869108 -0.7210344076 -0.9068789482 -0.1988134235 -0.3278206587 -0.8654219508 -0.7071698308 1.135054111 -1.895164251 -0.7949581146 -1.250328422 -0.9984998107 -0.09211537242 0.314479351 0.6850012541 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01535347197 0.01647323184 0.05236145854 0.009026882239 0.007731883321 0.01529272459 0.07421530038 0.001277129399 0.00254728063 0.01292677131 0.002309917705 0.002831740072 0.01461229846 0.01139023341 0.0009792926721 0.02943981625 0.0122836791 0.01124979462 0.02139613964 0.004868297838 0.00406907592 0.01309567876 0.01789659448 0.01020175777 0.03645388037 0.009963966906 0.003070269711 0.00846402999 0.02699785866 0.007662036456 0.002815898741 0.002057357691 0.003035753267 0.007092775311 0.006611220073 0.01034597401 0.003968872596 0.007855464704 0.002781510819 0.01012329664 0.008839287795 0.00531011587 0.001304555917 0.2610479593 0.001830971567 0.00532548083 0.03811443225 0.001604989404 0.003589371918 0.003736011917 0.00633983966 0.005264619365 0.01068749465 0.009393963031 0.005487461574 0.00642835116 0.04056647047 0.001959566958 0.005888078362 0.003734296653 0.004803707357 0.01189088821 0.01785649173 0.02586495504 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.5571003 28.55917358 28.59553719 28.5402832  28.545187 28.54511833 28.60928535 28.54493141 28.54381752 28.55276489 28.54596329 28.5464859 28.55302048 28.55456734 28.54415512 28.56546402 28.55545998 28.55442619 28.55694389 28.54375267 28.54772186 28.55388832 28.5610733 28.54431915 28.57676888 28.54980278 28.54195595 28.54019737 28.56445312 28.55083847 28.5421772 28.54428101 28.54621315 28.55027008 28.54931068 28.54780006 28.54714584  28.548172 28.54452705 28.55330086 28.5520153 28.5470562 28.54448128 28.79707146 28.54310036 28.54659462 28.57843018 28.54478073 28.54724312 28.54166794 28.54903984 28.54557991 28.55338669 28.55257034 28.54866409 28.54912758 28.58326721 28.5451355 28.54429626 28.54691124 28.54750443 28.55459023 28.56055641 28.56856537 

-------
======================
selected experts : 2, 6, 24, 43, 46, 56, 
layer11_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded85530>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.110667 -0.0970047 -0.1928990.0703382 -0.0718385 -0.0774949 0.0410839 -0.230315 -0.184965]

layer11_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded84d30>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.271696 -0.118983 0.197365-0.0768817 0.252471 -0.0910772 0.1285 0.0436299 -0.0418973]

layer12_wq's input 
<N9nntrainer6TensorE at 0x5682dedc4470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.587024 -0.265787 0.436063-0.182064 0.520833 -0.210122 0.302734 0.0916035 -0.090523]
==============================
layer12_wq's output 
<N9nntrainer6TensorE at 0x5682ded84be0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.195443 0.0918374 -0.399431-0.0701363 -0.641462 -1.13066 0.0613714 -0.661867 -0.174475]
============================
layer12_wk's input 
<N9nntrainer6TensorE at 0x5682dedc61d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.587024 -0.265787 0.436063-0.182064 0.520833 -0.210122 0.302734 0.0916035 -0.090523]
==============================
layer12_wk's output 
<N9nntrainer6TensorE at 0x5682dedc5f40>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.81585 4.64406 -2.971531.07527 0.725059 -2.12363 0.344063 3.10269 -0.357611]
============================
layer12_wv's input 
<N9nntrainer6TensorE at 0x5682dedc6fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.587024 -0.265787 0.436063-0.182064 0.520833 -0.210122 0.302734 0.0916035 -0.090523]
==============================
layer12_wv's output 
<N9nntrainer6TensorE at 0x5682dedc6d50>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.606237 -0.376929 -0.2368030.537972 -0.0929719 0.621698 -0.115335 -0.129155 -0.282883]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.164841 0.139498 0.0933453-0.394653 0.942562 -0.89523 0.612964 -0.257118 -0.530829]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0c60058
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer12_attention_out's input 
<N9nntrainer6TensorE at 0x5682dedc9470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer12_attention_out's output 
<N9nntrainer6TensorE at 0x5682dedc93d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer12_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dedca4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.271696 -0.118983 0.197365-0.0768817 0.252471 -0.0910772 0.1285 0.0436299 -0.0418973]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.268638 -0.300644 0.448109-0.203649 0.585551 -0.247921 0.349791 0.108113 -0.0966601]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5848432779 -0.06417887658 -1.037602186 -1.280631304 -1.952714562 -0.7851061225 0.4353520572 -0.9345266223 -1.532158494 -1.828743815 0.4825015366 2.507848501 0.07632251829 -0.888548851 -0.5898402929 -0.4689797163 -1.602545977 -0.6417217255 -1.735739827 -0.5481534004 1.384607673 -1.051821113 -1.005732775 1.02190423 -1.972499847 3.210705757 -0.7393202186 -0.4116578698 1.16415596 -1.84118855 -2.054331779 -1.744372249 1.187615275 -0.9100969434 -1.870270967 0.6191681623 -0.4727206528 -0.5952572227 0.1113234684 0.4223324656 -1.865560293 1.320002913 -0.8549823761 0.6602346301 -0.7330172658 -1.084182143 0.5193742514 0.9488451481 -0.7109173536 -1.60622704 -1.243872404 -1.451077938 -0.1899505407 -0.8899843097 0.0192386359 0.5107498169 -0.5357310176 0.801186204 -1.535245895 -0.2447298169 -0.4390060008 0.4783777595 -0.001597560942 -1.822441101 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005956804845 0.01002616808 0.003787760623 0.002970547648 0.001516891061 0.004875736777 0.01652260497 0.004199019168 0.002309934236 0.001717094216 0.01732029393 0.1312660128 0.01153862383 0.004396587145 0.005927111488 0.006688552909 0.002152934205 0.005627445411 0.001884453231 0.006179417484 0.04269086942 0.003734284313 0.003910419997 0.02970399708 0.001487173839 0.2650936544 0.00510416599 0.007083156146 0.03424475342 0.001695858315 0.001370321726 0.001868255436 0.03505761549 0.004302861635 0.001647249097 0.01985678263 0.006663579494 0.005895091686 0.01194963511 0.01630888321 0.001655026223 0.04002003744 0.004546669312 0.02068920434 0.005136439577 0.00361537328 0.01797086187 0.02761122957 0.005251217168 0.002145023551 0.003081772011 0.002505026758 0.008841237985 0.004390281159 0.01089840103 0.01781653985 0.006256658584 0.02382090315 0.002302813111 0.008369946852 0.006892068777 0.01724901795 0.01067366824 0.001727950992 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
30.81029129 30.81483841 30.80812263 30.80682755 30.80489731 30.80730247 30.82133484 30.80853271 30.80330658 30.80652809 30.82213211 30.93178558 30.81635094 30.80730057 30.80883217 30.81102371 30.80696487 30.80948448 30.80669594 30.81003761 30.84368706 30.80854607 30.80872154 30.83403778 30.80629921 31.06990433 30.80896187 30.81189537 30.83714867 30.8050766 30.80570412 30.80668068 30.83891487 30.80434608 30.80598259 30.82085419 30.81099892 30.80975342 30.81628418 30.82064438 30.80599022 30.84483147 30.80649757 30.82502365 30.80947113 30.80794907 30.82135201 30.82383919 30.80815506 30.80695724 30.80741882 30.8044548 30.8131752 30.80634117 30.81571007 30.82262802 30.81059074 30.82672501 30.80663681 30.81270409 30.81170273 30.82205963 30.80404091 30.80510902 

-------
======================
selected experts : 11, 20, 25, 28, 32, 41, 
layer12_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dedcd730>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0773612 -0.0899024 -0.0828959-0.0931412 -0.197045 0.172348 -0.07765 0.0527294 0.366331]

layer12_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dedccdf0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349057 -0.208885 0.11447-0.170023 0.0554258 0.0812705 0.0508505 0.0963593 0.324434]

layer13_wq's input 
<N9nntrainer6TensorE at 0x5682dee397f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.461882 -0.434706 0.234089-0.398826 0.100677 0.199437 0.115611 0.181985 0.636145]
==============================
layer13_wq's output 
<N9nntrainer6TensorE at 0x5682dedccca0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.638957 -0.286022 -0.2500940.205265 0.251586 -0.456803 0.130424 0.103303 0.140089]
============================
layer13_wk's input 
<N9nntrainer6TensorE at 0x5682dc471a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.461882 -0.434706 0.234089-0.398826 0.100677 0.199437 0.115611 0.181985 0.636145]
==============================
layer13_wk's output 
<N9nntrainer6TensorE at 0x5682dc4717a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.526126 2.17734 1.116081.92351 -0.739024 1.67844 -2.07329 0.114944 0.717841]
============================
layer13_wv's input 
<N9nntrainer6TensorE at 0x5682dc472820>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.461882 -0.434706 0.234089-0.398826 0.100677 0.199437 0.115611 0.181985 0.636145]
==============================
layer13_wv's output 
<N9nntrainer6TensorE at 0x5682dc4725b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.260204 -0.896868 0.430393-0.162672 0.192095 -0.0549694 -0.108279 0.371327 -0.0893489]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.525979 -0.461975 -0.190307-0.261656 0.503997 0.133982 -0.0298267 0.163683 0.0426333]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0a5b048
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer13_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc474cd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer13_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc474c30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer13_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc475da0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349057 -0.208885 0.11447-0.170023 0.0554258 0.0812705 0.0508505 0.0963593 0.324434]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.342213 -0.532703 0.261629-0.456094 0.127347 0.225833 0.138244 0.239942 0.745421]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8907374144 -0.2349317372 0.4580129087 -0.9498534799 0.8698978424 -0.1809544414 -0.4279190898 -1.527326465 0.4683110118 -1.227486372 -0.1315159798 2.054972887 -0.3449802697 -0.4493123293 -0.4004764557 -1.177681446 -0.4874285161 -1.356473684 3.522906542 -0.8342306614 -0.8314092755 -0.8831923008 -0.8793950677 -0.8831965923 -1.476154804 -1.014450431 -1.720691442 -1.865071416 -0.9642260075 -1.74390769 -0.981577754 -0.2707402706 -1.329746127 -1.580141306 -1.104965568 -0.227812171 -0.3364129663 1.441262126 -2.311327696 -0.09721283615 -0.556394577 -2.072245598 -0.4464695454 -0.6179936528 -0.519634068 -0.9891636968 -0.3636598587 0.2545301914 1.943602204 -0.0002803578973 0.4254202247 -0.4662814438 -1.054075718 0.08678603917 -0.05748613551 -0.07400264591 -1.778453827 0.4547889531 -1.29742372 -1.191100597 0.5785340071 -0.7324755192 0.7080338001 -0.008419480175 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.004408756271 0.008494324982 0.01698520593 0.004155681003 0.02564190328 0.008965425193 0.007003505249 0.002332646865 0.01716102846 0.00314824027 0.009419801645 0.08387292176 0.007609136403 0.006855268497 0.00719836168 0.003309007501 0.006598890759 0.002767256228 0.364030093 0.00466505345 0.004678234458 0.004442146514 0.004459045362 0.004442127421 0.002455118345 0.003895724425 0.001922523137 0.001664056676 0.004096380901 0.001878403593 0.004025915638 0.008195537142 0.002842215821 0.00221264502 0.003558590543 0.008555017412 0.007674606517 0.04540362582 0.001065029297 0.009748536162 0.00615913095 0.001352675608 0.006874785293 0.005791181233 0.006389754824 0.00399549026 0.007468319964 0.01385796536 0.07503330708 0.01074079983 0.01644054055 0.006739923265 0.003744372167 0.01171788108 0.01014360972 0.009977446869 0.001814620453 0.01693053544 0.002935583936 0.003264899831 0.01916074939 0.005164738279 0.02180989459 0.01065373421 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.72639847 28.73143768 28.73945236 28.72710037 28.74715614 28.73095512 28.72947121 28.72432327 28.74058151 28.72657013 28.72854996 28.79871178 28.72864532 28.7288456 28.72823524 28.72673035 28.72954369 28.72142029 29.08745193 28.72808647 28.72714615 28.72547913 28.72644997 28.72738647 28.72635269 28.72683907 28.72200584 28.72413063 28.72704124 28.72386932 28.72649384 28.73114014 28.72578621 28.72515678  28.721735 28.73006821 28.73061943 28.76596451 28.7244854 28.73269272 28.72957993 28.72429657 28.72695732 28.72873497 28.72694969 28.72646332 28.73041344 28.73155785 28.79750061 28.73416138 28.73986244 28.72968483 28.72668839 28.73466301 28.73308754 28.73339844 28.72428131 28.73844337 28.72540283 28.72477913 28.74210548 28.72763252 28.74523163 28.73407555 

-------
======================
selected experts : 4, 11, 18, 37, 48, 62, 
layer13_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee45420>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0729003 -0.406801 -0.0252013-0.0780241 0.037404 -0.3087 0.00187028 0.0189472 0.107898]

layer13_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc478790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.276157 -0.615686 0.0892683-0.248047 0.0928298 -0.22743 0.0527207 0.115307 0.432332]

layer14_wq's input 
<N9nntrainer6TensorE at 0x5682dee98c10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.36022 -1.20466 0.166346-0.540219 0.176226 -0.537696 0.113592 0.205466 0.840868]
==============================
layer14_wq's output 
<N9nntrainer6TensorE at 0x5682dc478730>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.12488 -0.544552 -0.317194-0.0739089 -0.0644269 -0.186063 -0.590938 -2.86144 -0.181958]
============================
layer14_wk's input 
<N9nntrainer6TensorE at 0x5682dee9aab0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.36022 -1.20466 0.166346-0.540219 0.176226 -0.537696 0.113592 0.205466 0.840868]
==============================
layer14_wk's output 
<N9nntrainer6TensorE at 0x5682dee9a7d0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.98509 -0.163158 2.52324-0.284793 0.998914 1.36633 0.93989 1.91786 0.308451]
============================
layer14_wv's input 
<N9nntrainer6TensorE at 0x5682dee9b8a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.36022 -1.20466 0.166346-0.540219 0.176226 -0.537696 0.113592 0.205466 0.840868]
==============================
layer14_wv's output 
<N9nntrainer6TensorE at 0x5682dee9b630>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.182041 -0.249189 -0.7183710.144929 0.19251 0.802127 -0.24679 0.0621993 0.0480825]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.389102 2.15876 0.0923084-0.312336 0.16503 -0.107402 2.24732 -1.86725 -0.146016]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2eb5168
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer14_attention_out's input 
<N9nntrainer6TensorE at 0x5682dee9dda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer14_attention_out's output 
<N9nntrainer6TensorE at 0x5682dee9dd00>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer14_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dee9ee70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.276157 -0.615686 0.0892683-0.248047 0.0928298 -0.22743 0.0527207 0.115307 0.432332]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.276598 -1.60621 0.203773-0.670218 0.214065 -0.646295 0.144906 0.287383 0.996957]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
2.169183016 -0.1604429483 -0.9380071163 1.747939944 -0.8642760515 0.1506029963 -1.677625179 -0.8631830812 0.1483230442 -0.08318985999 -1.837387323 -1.404093146 -1.562247038 0.2200235873 -0.9583565593 -1.2070961 -0.4648033679 0.3947082162 -1.420911908 -1.946756005 -1.052036047 -0.1699156612 -0.2060705721 -0.6792519093 -1.332456946 -0.8604491353 -0.2004051059 0.3646580279 -0.4279718995 0.6756101847 -1.140719056 -1.863321185 -0.36134848 -0.4934558272 -1.52702415 -1.021582603 -1.233463764 -0.6591947675 -0.408067733 0.9524257183 1.252907276 0.1095041335 -1.392297745 -0.7397685647 -0.05964815244 -1.079560161 -0.3602063656 1.245722413 0.01374107972 0.6682664156 -1.669662714 -1.121862054 -2.291163206 -1.056569099 -0.3179639578 0.9675385952 -0.3354649842 0.9148709178 -0.1700505018 0.08554217219 -1.779774308 -0.8672316074 -0.3966808021 -1.210223794 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1360198706 0.01323910523 0.006083686836 0.08926039934 0.006549192593 0.01806942001 0.002903720364 0.006556356326 0.01802826859 0.01430241019 0.002474976005 0.003817229765 0.003258838784 0.01936837658 0.005961137824 0.004648394883 0.00976509694 0.02306522615 0.003753564786 0.002218567999 0.005428060889 0.01311428845 0.0126486104 0.007880301215 0.004100714345 0.00657430524 0.01272047404 0.02238242328 0.01013146713 0.03054583073 0.004967411514 0.002411615569 0.01082945429 0.009489273652 0.003375670407 0.005595907103 0.004527429119 0.008039953187 0.01033514552 0.04028759897 0.05440876633 0.01734184287 0.003862521611 0.007417555433 0.01464311127 0.005280696321 0.01084182784 0.05401924998 0.01575817168 0.03032233194 0.002926933579 0.005061970092 0.001572166802 0.005403510761 0.01130962465 0.0409010835 0.0111134164 0.03880266473 0.01311252173 0.01693123579 0.002621754073 0.006529865786 0.01045350265 0.004633877892 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.29637337 27.17406845 27.16596031 27.24722862 27.16499519 27.17842293 27.16373253 27.16547775 27.1788578 27.17513275 27.16187477 27.1627388 27.16456604 27.17447662 27.1615448 27.16404724 27.16964149 27.18294144 27.16506004 27.15970993 27.16578102 27.17394447 27.17347908 27.1634655 27.16493034 27.16692734 27.17354965 27.18321228 27.17096138 27.19185257 27.16484261 27.16228676 27.17165947 27.16936493 27.16372871 27.16499519 27.1629734 27.16791534 27.17116547 27.20063972 27.21523857 27.17769432 27.16230774 27.16681671 27.17547226 27.16563416 27.17167091 27.21055794 27.17515755 27.19115257 27.16232681 27.16446114 27.16192436 27.16623306 27.17214012 27.20077705 27.17194366 27.19915581 27.16822052 27.1768074 27.16297531 27.16783714 27.16127014 27.16546249 

-------
======================
selected experts : 0, 3, 39, 40, 47, 55, 
layer14_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deea2ef0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.279306 0.135505 -0.261712-0.00655481 0.0436773 0.142907 0.18215 0.0979225 -0.15622]

layer14_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deea2970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.555463 -0.480181 -0.172444-0.254602 0.136507 -0.0845226 0.234871 0.213229 0.276112]

layer15_wq's input 
<N9nntrainer6TensorE at 0x5682deedb770>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.634636 -0.924824 -0.287091-0.537457 0.227262 -0.199578 0.483027 0.359632 0.49273]
==============================
layer15_wq's output 
<N9nntrainer6TensorE at 0x5682deea2820>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.233871 0.664037 0.2406980.172847 0.303741 0.385071 0.666595 -0.662647 0.309314]
============================
layer15_wk's input 
<N9nntrainer6TensorE at 0x5682deedd610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.634636 -0.924824 -0.287091-0.537457 0.227262 -0.199578 0.483027 0.359632 0.49273]
==============================
layer15_wk's output 
<N9nntrainer6TensorE at 0x5682deedd330>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.92189 -2.39179 0.02301212.86165 -1.21816 1.07583 1.87755 0.562447 1.75388]
============================
layer15_wv's input 
<N9nntrainer6TensorE at 0x5682deede400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.634636 -0.924824 -0.287091-0.537457 0.227262 -0.199578 0.483027 0.359632 0.49273]
==============================
layer15_wv's output 
<N9nntrainer6TensorE at 0x5682deede190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.453229 -0.0764084 0.201708-0.115856 0.961992 -0.409499 -0.061211 -0.629738 -0.174694]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.506482 -0.488995 -0.186610.230192 -0.300442 0.38765 0.898291 0.276629 0.776017]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2bad950
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer15_attention_out's input 
<N9nntrainer6TensorE at 0x5682deee0900>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer15_attention_out's output 
<N9nntrainer6TensorE at 0x5682deee0860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer15_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682deee19d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.555463 -0.480181 -0.172444-0.254602 0.136507 -0.0845226 0.234871 0.213229 0.276112]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.565129 -1.21742 -0.375283-0.662125 0.301531 -0.230849 0.615923 0.501165 0.606899]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.9196115136 -0.7669365406 -0.1744032204 -0.2425152659 -0.2824247777 -1.25149405 -1.074480534 -1.513965726 -1.402485013 -1.540763378 -0.1442510784 -0.7152411938 -1.841566443 -0.6420508027 0.04125054926 1.053928852 0.3776424229 -0.5294575691 -1.38181293 -0.04154314101 -1.268128037 -0.3668287992  1.1564219 -0.6394540071 -0.5798906684 -1.367501974 -0.1567556113 -1.181677222 -0.6673570871 0.073171556 0.06182174385 -0.3293156624 -1.589536548 -0.4025172889 0.5978791714 -0.7584404349 -0.4674280584 -0.4243714213 0.5434920788 -0.5038707256 -0.7242248058 -0.7007819414 0.5043699741 -2.407653093 -1.076235056 -0.1618063748 -0.6935269237 -1.068996668 1.034954309 0.138767764 0.5236951113 -1.64547205 0.9407889843 -1.954601169 -0.7338450551 -1.331152916 -0.2034887075 -1.151724339 2.390234232 -1.969763517 -0.3684638143 1.214165568 -1.248273849 -0.7750394344 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006471737288 0.007539226674 0.01363517623 0.01273737662 0.01223904733 0.004643934313 0.005543219857 0.003571873531 0.003993112594 0.00347742741 0.01405256521 0.007939218543 0.002574073849 0.008542086929 0.01691678911 0.04657132179 0.02368160337 0.009560103528 0.004076518584 0.01557259727 0.004567326047 0.0112484172 0.05159774423 0.008564296179 0.009089913219 0.004135276191 0.0138779385 0.004979746882 0.008328628726 0.01746550389 0.01726839133 0.011678393 0.00331189204 0.01085405517 0.02951608226 0.007603552658 0.01017189119 0.01061942242 0.02795366012 0.009807872586 0.007868215442 0.008054846898 0.02688117139 0.001461411826 0.005533502903 0.01380802132 0.008113497868 0.005573702045 0.04569597915 0.01864958368 0.0274057053 0.003131724428 0.04158939049 0.002298955806 0.00779288495 0.004288354889 0.01324430294 0.005131159909 0.1772020012 0.002264360897 0.01123004034 0.05466489494 0.00465891324 0.007478383835 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.89748573 25.89855385 25.89606667 25.9027977 25.90182304 25.8918438 25.89703369 25.8950634 25.89596176 25.89258385 25.90602112 25.89466095 25.89358902 25.89955711 25.90888405 25.93710899 25.91564941 25.9015274 25.89652061 25.9065876 25.89605904 25.90035439 25.94070435 25.90005493 25.89772034 25.89610291 25.9053688 25.89694786 25.89838982 25.90704918 25.90876007 25.90221596 25.89480209 25.90186882 25.92148399 25.89766312 25.90023232 25.90258789 25.91992188 25.88651657 25.89983559 25.8947773 25.9183712 25.89438248 25.89750099 25.90529823 25.89865112 25.88895798 25.93718719 25.91061783 25.91841888 25.88985443  25.932127 25.89426613 25.89833069 25.89625549 25.9052124 25.89423752 26.06630898 25.89089394 25.90319824 25.94615555 25.8937664 25.88943291 

-------
======================
selected experts : 15, 22, 48, 52, 58, 61, 
layer15_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deee4f80>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0327959 0.187632 -0.1807630.204037 0.164419 -0.0681101 0.291705 0.0602662 -0.180333]

layer15_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deee44b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.588259 -0.292549 -0.353207-0.0505649 0.300926 -0.152633 0.526576 0.273495 0.0957787]

layer16_wq's input 
<N9nntrainer6TensorE at 0x5682def24710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.24158 -0.706571 -0.695522-0.125426 0.586026 -0.428421 1.23742 0.538557 0.20215]
==============================
layer16_wq's output 
<N9nntrainer6TensorE at 0x5682deee4360>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.102363 0.226864 0.0246720.308009 -0.648733 0.0484672 0.830685 0.0413778 -0.381088]
============================
layer16_wk's input 
<N9nntrainer6TensorE at 0x5682def26470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.24158 -0.706571 -0.695522-0.125426 0.586026 -0.428421 1.23742 0.538557 0.20215]
==============================
layer16_wk's output 
<N9nntrainer6TensorE at 0x5682def261e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.9102 -0.102631 -0.171847-0.533853 2.44988 0.0296557 -1.81455 -0.814734 0.755135]
============================
layer16_wv's input 
<N9nntrainer6TensorE at 0x5682def27260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.24158 -0.706571 -0.695522-0.125426 0.586026 -0.428421 1.23742 0.538557 0.20215]
==============================
layer16_wv's output 
<N9nntrainer6TensorE at 0x5682def26ff0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0874291 -1.24879 -0.3393321.28179 0.497896 0.352713 -0.0204428 0.3092 -1.14995]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.163688 -0.187487 -0.3089240.00664063 -0.203505 -0.617891 0.354158 0.752544 0.364862]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a20920f8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer16_attention_out's input 
<N9nntrainer6TensorE at 0x5682def29710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer16_attention_out's output 
<N9nntrainer6TensorE at 0x5682def29670>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer16_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def2a790>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.588259 -0.292549 -0.353207-0.0505649 0.300926 -0.152633 0.526576 0.273495 0.0957787]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.694387 -0.776591 -0.826173-0.138629 0.703886 -0.441706 1.42648 0.669477 0.224033]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2243914902 -1.273052216 -0.3731522858 0.7100962996 -1.470478892 -1.412188768 -0.6100212336 0.3334301412 -1.558926463 3.685372591 -1.342689157 2.300887823 -1.008253455 -1.188391924 -0.5533849001 -0.7647204995 -1.543614745 -1.685294986 -0.8623319864 -1.274074912 -0.7444522977 -0.1626450568 -0.0900862366 1.783777118 -1.973642945 -1.383884192 -0.04768214375 0.01108001545 -1.786719918 -1.643375397 -1.694744349 0.89670223 0.2155798376 -0.7740887403 -0.7881854773 -2.029365301 -0.8679792285 -1.80484283 -1.472986341 0.3872671127 0.8609884977 -1.821317554 -3.562850237 -0.8730406761 -0.6067320704 -2.005383253 0.7215870023 0.3278435469 -1.254088759 0.5948729515 -0.8321160078 0.3374435306 2.182619333 -1.570125222 -0.9135497212 -2.348448277 -1.675305605 -0.09843407571 0.3884909153 -0.2105440795 -0.694961071 -1.161129594 -0.6163506508 -1.226319551 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007750793826 0.002715930808 0.006679440383 0.01973281801 0.002229345264 0.002363155829 0.005270711146 0.01353957411 0.002040633699 0.386665225 0.002533235587 0.0968413949 0.003539315425 0.002955875359 0.005577840377 0.004515274428 0.002072119853 0.001798390062 0.004095360171 0.002713154303 0.004607725888 0.00824446138 0.008864907548 0.05774079263 0.001347894431 0.002430999419 0.009248900227 0.009808670729 0.001624933095 0.00187538052 0.001781476196 0.02378105 0.01203436684 0.004473173525 0.00441055838 0.001274840906 0.00407229783 0.001595750335 0.002223761752 0.01428848319 0.02294672094 0.00156967598 0.0002750881831 0.004051737487 0.005288076587 0.00130578375 0.01996086724 0.0134641435 0.002767925384 0.01758523658 0.004220994655 0.01359402388 0.0860394612 0.002017908031 0.00389088667 0.000926573528 0.001816444681 0.008791213855 0.01430597994 0.007858868688 0.004841504153 0.00303756725 0.00523745548 0.002845865209 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
23.53842545 23.52433205 23.53735352 23.55040741 23.52241516 23.53351402 23.53642082 23.53658676 23.52699471 23.91781616 23.5313015 23.62703896 23.53421402 23.53124809 23.52576256 23.52613068 23.53179169 23.53009033 23.53381538 23.53290939 23.52908516 23.53939438 23.53953934 23.58793831 23.53202248 23.5259552 23.53896904 23.54096031 23.53229904 23.53064346 23.53245544 23.55397797 23.54127884 23.53466988 23.5341301 23.53194809 23.53141022 23.53322411 23.53337479 23.54400826 23.55314445 23.52890778 23.5304718 23.53424835 23.53405571 23.53055191 23.55063438 23.54366112 23.53344154 23.54683113 23.53108215 23.54474449 23.61337662 23.52458763 23.53504181 23.53255463 23.53248978 23.53469849 23.54402542 23.53805542 23.53551483 23.53275871 23.5363884 23.53447342 

-------
======================
selected experts : 9, 11, 23, 31, 40, 52, 
layer16_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def2d9d0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.275041 -0.0150698 0.1121280.106804 0.0153342 0.117826 -0.297133 -0.0696298 -0.113063]

layer16_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def2d090>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.863299 -0.307619 -0.2410780.0562393 0.31626 -0.0348067 0.229443 0.203865 -0.0172845]

layer17_wq's input 
<N9nntrainer6TensorE at 0x5682def6d870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.955608 -0.647937 -0.3954220.118961 0.484722 -0.0861039 0.495614 0.321594 -0.0298995]
==============================
layer17_wq's output 
<N9nntrainer6TensorE at 0x5682def2cf40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0768425 0.187951 -0.32892-0.0927655 -0.281091 0.0565282 0.16259 0.139941 -0.147259]
============================
layer17_wk's input 
<N9nntrainer6TensorE at 0x5682def6f5d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.955608 -0.647937 -0.3954220.118961 0.484722 -0.0861039 0.495614 0.321594 -0.0298995]
==============================
layer17_wk's output 
<N9nntrainer6TensorE at 0x5682def6f340>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.58195 0.714871 2.247810.698659 0.00432331 0.300537 -2.55857 -0.410296 0.803148]
============================
layer17_wv's input 
<N9nntrainer6TensorE at 0x5682def703c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.955608 -0.647937 -0.3954220.118961 0.484722 -0.0861039 0.495614 0.321594 -0.0298995]
==============================
layer17_wv's output 
<N9nntrainer6TensorE at 0x5682def70150>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.346848 -1.11488 0.153260.0998686 0.317869 -0.707371 0.349783 -0.456701 -0.521514]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.202881 -0.00834242 0.111818-0.322941 -0.122656 -0.259159 -0.0470322 0.209301 0.237559]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2297108
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer17_attention_out's input 
<N9nntrainer6TensorE at 0x5682def72870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer17_attention_out's output 
<N9nntrainer6TensorE at 0x5682def727d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer17_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def738f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.863299 -0.307619 -0.2410780.0562393 0.31626 -0.0348067 0.229443 0.203865 -0.0172845]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.971084 -0.716866 -0.50130.132066 0.660469 -0.0867279 0.5388 0.447673 -0.0356316]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5649166703 -1.567571998 0.3276652992 2.513124704 -0.1520899236 -0.8303835988 -3.270487309 -1.296907067 -0.04425581917 -0.9040798545 -2.194829941 -0.8708052635 -0.01627292112 -1.334774017 -1.348267436 -0.3647217751 0.8149148822 -1.805742145 -0.7421472073 -1.794073939 0.04781312495 -0.8486894369 -2.223347902 -0.2245208025 -1.042313933 -1.049682975 -0.2846728563 -0.4662835598 0.1692023426 -1.313108087 -2.433745384 -0.4951153398 -0.1207370013 -1.148418069 -1.066797137 0.3209392726 1.22931695 -2.256134033 -1.501471758 -2.023600817 -2.457115412 -0.7980403304 -0.4143774509 -0.1150985137 -0.3079393506 -0.4383943379 2.676130772 -0.9510215521 -0.9202147722 -1.216504931 -1.759028435 -2.573677063 0.2100169212 -1.125802994 2.914211035 1.666934848 -2.273659468 -0.2277843654 -1.183776975 -0.9288334846 -0.7405062914 -0.147444278 -0.6151849627 -0.9241185188 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006672522053 0.002448174171 0.01629046351 0.1448993236 0.01008273568 0.005116808694 0.0004459392221 0.003209153889 0.0112307854 0.004753278103 0.001307457336 0.00491410261 0.01154949237 0.003089904552 0.003048492363 0.008151424117 0.02651815116 0.001929329243 0.005588814616 0.001951972954 0.01231388748 0.005023993552 0.001270698267 0.009378253482 0.004139606375 0.004109213129 0.0088307634 0.007364203688 0.01390316896 0.003157581203 0.00102959841 0.007154912688 0.01040386595 0.003722875379 0.004039485939 0.01618126035 0.04013430327 0.001229712274 0.00261546718 0.00155164185 0.001005815924 0.005285007879 0.007756545208 0.0104626948 0.008627676405 0.007572476752 0.1705528498 0.004535308108 0.004677199759 0.003477833932 0.002021593042 0.0008951509953 0.01448236126 0.003808027133 0.2163993418 0.0621685572 0.001208349015 0.00934769772 0.003593538655 0.004637062084 0.005597992335 0.01012968458 0.00634539593 0.004658977035 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
22.11065292 22.11453629 22.12980843 22.25078773 22.12073898 22.11243629 22.11396408 22.11672783 22.12427139 22.11827087 22.11291695 22.11795425 22.11696053 22.11565399 22.11608887 22.12214661 22.14003563 22.11592484 22.10527802 22.11499214 22.12201691 22.11377335 22.11240387 22.12003517 22.11717987 22.11333466 22.12282562 22.12088203 22.11883736 22.11524391 22.11407089 22.12019539 22.12296867 22.11724091 22.11755753 22.12111664 22.15317535 22.11427116 22.11279488 22.11459351 22.11452293 22.11117363 22.12127495 22.12016487 22.11403847 22.12156677 22.28073311 22.11805344 22.11342621 22.11699486 22.11553955 22.11393547 22.10892677 22.1092205 22.32419586 22.17234802 22.11520386 22.11905098 22.11520386 22.11338615 22.11863899 22.12317085 22.12034035 22.11579323 

-------
======================
selected experts : 3, 16, 36, 46, 54, 55, 
layer17_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def76b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.119878 0.0427516 0.0836584-0.082742 -0.192372 -0.123712 -0.352863 0.0408223 0.0129357]

layer17_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def761f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.743421 -0.264867 -0.15742-0.0265027 0.123888 -0.158519 -0.12342 0.244688 -0.00434877]

layer18_wq's input 
<N9nntrainer6TensorE at 0x5682defb6420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.2624 -0.541026 -0.275062-0.0539179 0.198178 -0.361506 -0.252102 0.383386 -0.00774135]
==============================
layer18_wq's output 
<N9nntrainer6TensorE at 0x5682def760a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.5232 0.418725 1.278382.72879 1.82538 -3.37991 2.63293 1.65801 -2.0232]
============================
layer18_wk's input 
<N9nntrainer6TensorE at 0x5682defb8180>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.2624 -0.541026 -0.275062-0.0539179 0.198178 -0.361506 -0.252102 0.383386 -0.00774135]
==============================
layer18_wk's output 
<N9nntrainer6TensorE at 0x5682defb7ef0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.25415 1.13258 -0.5479561.12094 1.30056 1.08249 0.19233 2.1954 -1.79507]
============================
layer18_wv's input 
<N9nntrainer6TensorE at 0x5682defb8f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.2624 -0.541026 -0.275062-0.0539179 0.198178 -0.361506 -0.252102 0.383386 -0.00774135]
==============================
layer18_wv's output 
<N9nntrainer6TensorE at 0x5682defb8d00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0587756 -2.15294 1.13441-0.139991 1.24529 -1.41666 1.10897 -0.340765 -0.298185]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.43077 2.12009 -2.798791.11682 3.72039 0.956283 -0.224925 3.10334 -3.13896]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a249c118
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer18_attention_out's input 
<N9nntrainer6TensorE at 0x5682defbb420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer18_attention_out's output 
<N9nntrainer6TensorE at 0x5682defbb380>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer18_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682defbc4a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.743421 -0.264867 -0.15742-0.0265027 0.123888 -0.158519 -0.12342 0.244688 -0.00434877]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.853795 -0.573618 -0.312511-0.0582662 0.245943 -0.364107 -0.271338 0.501814 -0.00852619]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.6273706555 -0.3092482686 -0.5520982742 0.7557987571 -0.8661976457 -1.701852083 -0.7072938085 -0.8364729881 2.185483932 -1.531793118 0.2034626007 -1.502796769 -2.203984737 -1.11043334 -3.4694345 -1.465497494 0.04039787501 -0.8558729887 -0.8649594784 -0.1077571064 -1.545637369 -0.1326479465 -1.634534836 0.9015256166 -0.9431143999 0.08800459653 0.1092985123 0.880182445 -1.240120649 1.658906698 -0.6974722147 0.2955052853 -0.584644258 -0.2497467101 -0.6149420738 -0.1882206351 -1.878281355 0.670244813 -1.747626901 -0.8226674795 -0.1309736073 -0.2170142829 -0.9305517077 -0.02207532339 -2.079432011 -0.9483323097 -0.7753231525 -1.186023712 -0.00827340968 0.1153657958 -0.4481774271 -1.542468667 -0.3585171103 0.4268810451 -0.4900393784 -1.062475324 0.4979901612 -0.4232053757 -0.2158964276 0.3050209582 -0.2451109588 -1.548001289 -0.1942561567 0.5499870181 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03072108515 0.01204115618 0.00944495108 0.03493109718 0.00689903181 0.002991355257 0.008087218739 0.007107180543 0.1459205896 0.003545877058 0.02010646276 0.003650200088 0.001810483402 0.005404031835 0.0005107596517 0.003788920352 0.01708116755 0.006970629096 0.006907578558 0.01472904719 0.003497125115 0.0143669527 0.003199657658 0.04041108862 0.006388275418 0.01791401207 0.01829956099 0.03955772892 0.004746739287 0.08618406951 0.008167039603 0.02204495855 0.009142503142 0.01277936529 0.008869660087 0.01359032094 0.002507527126 0.03206687048 0.00285751326 0.007205978502 0.01439102925 0.01320458762 0.006469034124 0.01604669914 0.002050629118 0.006355028134 0.007555346936 0.005010596476 0.01626971178 0.01841092855 0.01047929376 0.003508224618 0.01146227773 0.02513998747 0.01004966535 0.005669514183 0.02699276246 0.01074427739 0.0132193584 0.02225573175 0.01283874549 0.003488867776 0.01350854617 0.0284334328 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
24.24374962 24.21648598 24.22151947 24.24462128 24.21992683 24.21649551 24.22111511 24.22061157 24.35799408 24.21705055 24.22932053 24.21620178 24.21293068 24.21700096 24.21401596 24.21681595 24.22247887 24.2185688 24.2189827 24.22727966 24.21032715 24.22071838 24.21622849 24.25296211 24.21893883 24.22951126 24.23037338 24.24543381 24.20203972 24.2992115 24.21976471 24.23554993 24.22073936 24.21770096 24.22189713 24.22614098 24.21601295 24.23078918 24.21493149 24.21928024 24.22694206 24.22623253 24.21854401 24.22859764 24.21555519 24.21509171 24.21772194 24.21660805 24.22929764 24.23048592 24.22350693 24.21701241 24.21543121 24.23816872 24.22355461 24.21535873 24.24002075 24.22377205 24.22624779 24.2352829 24.22300529 24.21556282 24.22605896 24.2414608 

-------
======================
selected experts : 3, 8, 23, 27, 29, 37, 
layer18_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682defbf6e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0224344 0.0454053 -0.0709348-0.187937 0.124586 0.226347 -0.290267 -0.267766 -0.0996515]

layer18_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682defbeda0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.765856 -0.219462 -0.228355-0.214439 0.248474 0.0678284 -0.413687 -0.0230783 -0.104]

layer19_wq's input 
<N9nntrainer6TensorE at 0x5682deffefd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1351 -0.389111 -0.347942-0.37575 0.359667 0.135294 -0.727746 -0.0334059 -0.170709]
==============================
layer19_wq's output 
<N9nntrainer6TensorE at 0x5682defbec50>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.673518 0.446467 0.06407090.0890631 -0.215499 -0.0496878 -0.193079 -0.477774 -0.15175]
============================
layer19_wk's input 
<N9nntrainer6TensorE at 0x5682df001130>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1351 -0.389111 -0.347942-0.37575 0.359667 0.135294 -0.727746 -0.0334059 -0.170709]
==============================
layer19_wk's output 
<N9nntrainer6TensorE at 0x5682df001100>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.884585 -1.93369 1.787090.760586 0.241383 -0.515798 1.96247 1.30788 -1.42562]
============================
layer19_wv's input 
<N9nntrainer6TensorE at 0x5682df002000>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1351 -0.389111 -0.347942-0.37575 0.359667 0.135294 -0.727746 -0.0334059 -0.170709]
==============================
layer19_wv's output 
<N9nntrainer6TensorE at 0x5682df001d90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.888076 -0.00238157 -0.1487370.265708 -0.512243 0.150262 0.424696 -0.238823 -1.16209]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.686254 0.426633 -0.09265310.0587598 -0.00375583 -0.221122 0.330832 -0.395092 -0.165893]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a28a6138
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer19_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0044b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer19_attention_out's output 
<N9nntrainer6TensorE at 0x5682df004410>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer19_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df005580>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.765856 -0.219462 -0.228355-0.214439 0.248474 0.0678284 -0.413687 -0.0230783 -0.104]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.838065 -0.41343 -0.404878-0.409909 0.435386 0.135294 -0.80797 -0.0412379 -0.182234]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.6672039032 1.011161685 0.3233934939 -0.5856403112 0.2339823842 -1.09533155 -0.2589462996 -1.10770607 -0.5928098559 -1.665809155 0.1330215782 1.439721942 -0.8517971039 -0.3086450398 -0.06121952832 -2.85298562 -1.539274931 0.7510276437 -1.042135715 -0.7157807946 0.00371193327 -0.07794098556 -0.5857000351 -0.1359512359 0.2269063443 -1.96133101 -0.1968873888 -0.7613671422 -0.9728127718 0.08115919679 0.6174609065 0.7811871767 -0.2542393506 -0.6601142883 -0.5794465542 -0.4633648992 -1.890489697 -0.8679003119 -1.077695847 -0.3713322282 -1.334422827 0.2955068052 -1.211002588 -0.4735624194 -2.129509211 1.023646951 -0.8193566203 -1.493514538 0.2843222618 -1.879455209 0.4954262972 1.167628288 -0.9052318335 -0.4109098315 -1.314629674 -2.20801115 0.2125170231 -0.6533298492 0.8769615293 -0.951233983 -2.019967318 1.744927764 -0.07661728561 -0.1612648964 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.008408664726 0.0450434871 0.02264321409 0.009123252705 0.02070653066 0.005480164662 0.01264826953 0.005412767641 0.00905807782 0.003097692272 0.01871804893 0.06914381683 0.00699132029 0.01203502994 0.01541355159 0.0009450486978 0.0035155355 0.03472619876 0.005779579282 0.008009960875 0.01644758508 0.01515795942 0.00912270695 0.01430366002 0.02056052536 0.002305126982 0.01345807593 0.007653013803 0.006194451358 0.01777203195 0.03038434684 0.03578947484 0.01270794496 0.008468491025 0.009179935791 0.01030987035 0.002474348294 0.006879640743 0.005577668082 0.01130374894 0.004314769991 0.02202049457 0.004881557077 0.01020527072 0.001948300865 0.04560939223 0.00722184265 0.003680144902 0.02177557722 0.002501802519 0.02689372748 0.05267257988 0.00662754802 0.01086511184 0.004401023034 0.001801204169 0.02026679181 0.008526139893 0.03938670084 0.006329572294 0.002173849382 0.09382154047 0.01517803781 0.01394612622 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.25514412 26.28605652 26.2622261 26.25538063 26.26791763 26.24315453 26.25795174 26.25214767 26.25579262 26.24983215 26.25973129 26.31492424 26.25229454 26.25876999 26.2621479 26.24815559 26.25024986 26.27860069 26.25203705 26.25426865 26.26365852 26.26141548 26.25061226 26.25960732 26.26777267 26.2490406 26.26019287 26.25391006 26.25245285 26.26212311 26.27759552 26.28300095 26.25992012 26.25568008 26.25400734 26.25609016 26.2473011 26.25123024 26.25231171 26.24993134 26.25104904 26.26875496 26.25161552 26.25407982 26.24248314 26.29234314 26.25395584 26.25041389 26.26755714 26.24494553 26.2731514 26.29845428 26.25288582 26.25378418 26.23778343 26.24901199 26.26652527 26.2557373 26.28659821 26.24829674 26.24938583 26.33817291 26.2619133 26.25972748 

-------
======================
selected experts : 1, 11, 45, 51, 58, 61, 
layer19_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df008b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.215267 -0.39338 -0.000695813-0.0864399 -0.112795 -0.0509957 0.289701 0.168486 -0.00108794]

layer19_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df008060>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.981122 -0.612842 -0.229051-0.300879 0.135679 0.0168326 -0.123986 0.145408 -0.105088]

layer20_wq's input 
<N9nntrainer6TensorE at 0x5682df047b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.958103 -0.910237 -0.334845-0.431053 0.180098 0.0257885 -0.183428 0.183659 -0.144409]
==============================
layer20_wq's output 
<N9nntrainer6TensorE at 0x5682df007f10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.876517 0.0806131 -1.10045-0.950074 1.5474 -0.0318424 1.07022 0.0833046 1.55108]
============================
layer20_wk's input 
<N9nntrainer6TensorE at 0x5682df0498e0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.958103 -0.910237 -0.334845-0.431053 0.180098 0.0257885 -0.183428 0.183659 -0.144409]
==============================
layer20_wk's output 
<N9nntrainer6TensorE at 0x5682df049650>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.846784 -2.53762 1.45796-1.87529 0.273083 1.54017 1.20665 1.44815 1.83976]
============================
layer20_wv's input 
<N9nntrainer6TensorE at 0x5682df04a6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.958103 -0.910237 -0.334845-0.431053 0.180098 0.0257885 -0.183428 0.183659 -0.144409]
==============================
layer20_wv's output 
<N9nntrainer6TensorE at 0x5682df04a460>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.58004 -0.259193 0.555010.26039 0.126245 -0.290294 -0.940173 -0.403823 -0.0109447]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.291458 -0.830561 1.01272-1.04308 0.404122 1.49403 0.429811 0.983652 2.29577]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2cb0158
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer20_attention_out's input 
<N9nntrainer6TensorE at 0x5682df04cb80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer20_attention_out's output 
<N9nntrainer6TensorE at 0x5682df04cae0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer20_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df04dc00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.981122 -0.612842 -0.229051-0.300879 0.135679 0.0168326 -0.123986 0.145408 -0.105088]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.0499 -1.01058 -0.361632-0.49967 0.209454 0.0291351 -0.211703 0.229574 -0.163459]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8655126095 -0.70669806 -1.061430693 -2.783363581 -0.2065856159 -1.022460699 0.2129929066 -1.197860122 -1.765060186 -0.4202759564 -1.40267086 0.1384142488 -0.4667899311 0.519497931 -0.8139014244 -0.7501202226 -0.5346457958 -0.2915263474 0.2705768645 -1.274973035 -0.9905731678 -1.995363832 0.3463840187 0.3722329736 -0.7950048447 0.1706930399 -0.4584597349 -0.921906352 -0.128356114 -1.033184409 -1.007602215 0.4361215532 2.485273838 -0.09640012681 -0.3592478633 -0.608148098 -0.2030857652 0.9808261991 -0.533608377 -1.060790062 -0.230525136 -0.3972931206 -0.6110050678 -0.6829974651 -0.7350553274 0.05229857937 -0.8097520471 0.1194356456 -0.5318554044 -1.408503294 -1.412146211 -0.8701547384 -0.1973832399 0.2585422397 0.1805107296 0.8161994219 -1.081575871 -1.17308712 0.1499855518 -0.9741865396 -1.142312765 0.02617833763 -0.6642144322 -1.035818815 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007350394502 0.008615549654 0.006042608991 0.001079937094 0.0142062353 0.006282737944 0.02161223255 0.005271981936 0.002989800414 0.01147293393 0.004295619205 0.02005905658 0.01095150225 0.02936385572 0.007739717606 0.008249448612 0.01023303065 0.01304937527 0.02289328352 0.004880724475 0.00648630783 0.002374775475 0.02469623089 0.02534292266 0.007887362503 0.02071710117 0.01104311086 0.006947348826 0.01536220685 0.006215723231 0.006376787089 0.02701488696 0.2096711695 0.01586105116 0.01219491009 0.009507857263 0.01425604336 0.04657634348 0.01024365239 0.006046481431 0.01387018524 0.01173966751 0.009480731562 0.008822181262 0.008374665864 0.01840394735 0.007771899924 0.01968195476 0.01026162598 0.004270638339 0.004255109467 0.007316350937 0.01433757041 0.02261942253 0.0209215004 0.03950653225 0.005922097713 0.005404216703 0.0202925168 0.006593472324 0.005573113449 0.01792945713 0.008989455178 0.006199370604 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.40150261 25.40372086 25.40305519 25.39856911 25.41026497 25.40377235 25.41385651 25.40228462 25.40000343 25.40228653 25.40083122 25.41421127 25.40796471 25.42589951 25.40475273 25.40383148 25.40152359 25.40434074 25.41799927 25.40093994 25.4034996 25.39938736 25.41646385 25.42092514 25.40156174 25.41773033 25.40328789 25.40348244 25.40665245 25.40322876 25.40338898 25.42450523 25.60573006 25.41192055 25.4092083 25.40604401 25.41126823 25.43452835 25.40296555 25.40115166 25.41088295 25.40732193 25.40458679 25.40631104 25.40395737 25.41589355 25.40478516 25.41669464 25.40679741 25.40080643 25.39888382 25.4043293 25.39704514 25.41963196 25.41698074 25.43556595 25.40341187 25.39907837 25.41492081 25.40026855 25.40115547 25.41351128 25.40123367 25.39844322 

-------
======================
selected experts : 13, 23, 31, 32, 37, 55, 
layer20_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df050e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.885376 -0.319169 0.5262190.70381 -0.196865 -0.350957 0.573935 -0.108444 0.136571]

layer20_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df050500>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.8665 -0.932011 0.2971680.402931 -0.061186 -0.334124 0.449949 0.0369634 0.0314824]

layer21_wq's input 
<N9nntrainer6TensorE at 0x5682df091030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.34343 -1.12902 0.3250060.462413 -0.0660174 -0.435887 0.5252 0.0393383 0.0359756]
==============================
layer21_wq's output 
<N9nntrainer6TensorE at 0x5682df0503b0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.438507 -0.128789 0.342350.258348 0.64409 -0.20004 -0.185343 -0.0576341 -0.281783]
============================
layer21_wk's input 
<N9nntrainer6TensorE at 0x5682df092d90>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.34343 -1.12902 0.3250060.462413 -0.0660174 -0.435887 0.5252 0.0393383 0.0359756]
==============================
layer21_wk's output 
<N9nntrainer6TensorE at 0x5682df092b00>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.141955 -1.32763 -0.06101911.14812 1.04022 0.493206 2.01475 -0.189959 -0.493183]
============================
layer21_wv's input 
<N9nntrainer6TensorE at 0x5682df093b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.34343 -1.12902 0.3250060.462413 -0.0660174 -0.435887 0.5252 0.0393383 0.0359756]
==============================
layer21_wv's output 
<N9nntrainer6TensorE at 0x5682df093910>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.848235 -1.16323 -0.1315370.66145 -1.24199 0.601555 0.0756982 -0.25 0.0249144]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.299591 -0.345138 -0.2779020.326677 0.349483 0.576827 -0.0363051 -0.190672 -1.20087]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1f8f8f0
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer21_attention_out's input 
<N9nntrainer6TensorE at 0x5682df096030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer21_attention_out's output 
<N9nntrainer6TensorE at 0x5682df095f90>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer21_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0970b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.8665 -0.932011 0.2971680.402931 -0.061186 -0.334124 0.449949 0.0369634 0.0314824]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.79419 -1.38042 0.4255680.600742 -0.0864228 -0.524375 0.697324 0.0532971 0.0444677]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.338927716 -0.8085083365 -0.3935043216 -0.2765239775 -1.24435389 -0.5573443174 -1.160563588 -1.030288935 0.6692617536 -1.052990317 -0.06676454842 -0.3132822514 -0.6337903738 -0.5771283507 -1.292338848 -0.7287265062 0.2857293487 -0.967897892 -0.9411482811 -1.694105983 -0.8988958001 0.2688181698 0.01038398501 -1.540452242 -1.435884714 0.8472945094 0.6545837522 -1.271214008 0.688174367 0.7262431979 1.963293791 -1.16886127 -2.187511683 -0.9855898023 -1.560562253 -1.163798332 -1.570108056 0.5532386899 0.03886730224 -1.896592736 -1.347119093 -1.031612039 -0.1494785547 0.2236829996 0.130858317 -1.156510353 1.787328124 -1.326728463 -0.7687029839 -0.6601318717 -0.3301847577 -0.3158607781 0.6373904347 2.850577593 0.06893432885 0.979413867 -0.1041699052 0.04358827695 0.4303562045 0.220823437 0.630808413 -0.0217722021 -0.3897924423 -0.5688437819 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01735400409 0.005509022158 0.008342735469 0.009378045797 0.003562781261 0.007081964053 0.003874171525 0.004413228948 0.02414692938 0.004314171616 0.01156670786 0.009039585479 0.006560752634 0.006943230517 0.003395857988 0.005966550205 0.01645492762 0.004697345663 0.00482469378 0.00227229367 0.005032917485 0.01617899351 0.01249438897 0.002649691654 0.002941768151 0.02885231189 0.02379508875 0.003468357958 0.02460796013 0.02556281723 0.08807505667 0.003842158942 0.001387333847 0.004614972044 0.002596938284 0.003861661302 0.002572266385 0.02150174603 0.01285538543 0.001855775598 0.003214836353 0.00440739328 0.01064847689 0.01546498947 0.01409406774 0.00388990785 0.07386386395 0.003281061538 0.005732734222 0.006390187424 0.008888077922 0.009016307071 0.02338946983 0.2138924152 0.0132477805 0.0329275392 0.0111420434 0.01291621756 0.01901545003 0.01542082801 0.02323602512 0.01209900714 0.00837376155 0.007000990678 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.65564346 25.64379883 25.64615631  25.647192 25.63994598 25.64489555 25.64216423 25.64031982 25.6619606 25.64165115 25.63888931 25.63826942 25.64103699 25.64284897 25.64168549 25.64377975 25.6547451 25.6429882 25.64025497 25.64056206 25.64284706 25.65446854 25.65030861 25.6395092 25.64123154 25.66618919 25.66160774 25.64032745 25.66289902 25.66385269 25.72636604 25.64070129 25.63872337 25.64242935 25.6394577 25.64119911 25.64086342 25.65931511 25.64876175 25.63919258 25.6415062 25.64269829 25.64750862 25.65327835 25.64809227 25.64170265 25.71215439 25.64109421 25.63877869  25.641819 25.64717865 25.64349174 25.65357399 25.85218239 25.65153885 25.66931152 25.64418793 25.65073013 25.64920044 25.65323448 25.66009521 25.64991188 25.64475632 25.64433861 

-------
======================
selected experts : 25, 29, 30, 46, 53, 55, 
layer21_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df09a2f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.203484 0.325646 -0.08617490.263837 -0.197649 -0.211468 -0.165355 0.027559 -0.218294]

layer21_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df0999b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.06998 -0.606365 0.2109930.666768 -0.258835 -0.545592 0.284594 0.0645224 -0.186811]

layer22_wq's input 
<N9nntrainer6TensorE at 0x5682df0d9be0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52088 -0.661526 0.2176970.727424 -0.272531 -0.641366 0.290025 0.065481 -0.206965]
==============================
layer22_wq's output 
<N9nntrainer6TensorE at 0x5682df099860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.437703 1.93202 -0.130586-1.09558 -0.350645 2.35805 0.589283 0.483181 -1.41336]
============================
layer22_wk's input 
<N9nntrainer6TensorE at 0x5682df0db940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52088 -0.661526 0.2176970.727424 -0.272531 -0.641366 0.290025 0.065481 -0.206965]
==============================
layer22_wk's output 
<N9nntrainer6TensorE at 0x5682df0db6b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.46632 2.72871 1.06410.640243 -2.17135 -0.228131 0.0903081 -0.916295 0.0818679]
============================
layer22_wv's input 
<N9nntrainer6TensorE at 0x5682df0dc730>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52088 -0.661526 0.2176970.727424 -0.272531 -0.641366 0.290025 0.065481 -0.206965]
==============================
layer22_wv's output 
<N9nntrainer6TensorE at 0x5682df0dc4c0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.220364 1.69392 0.3736711.04747 0.378844 0.398043 -0.296168 -0.251376 -0.942125]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.93893 -0.406 1.10133-0.0663767 -2.37301 0.228449 -0.149268 0.747287 0.253667]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a30ba178
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer22_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0debe0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer22_attention_out's output 
<N9nntrainer6TensorE at 0x5682df0deb40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer22_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0dfc60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.06998 -0.606365 0.2109930.666768 -0.258835 -0.545592 0.284594 0.0645224 -0.186811]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.17076 -0.846138 0.2872880.919148 -0.343673 -0.798248 0.404351 0.0883993 -0.248042]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8047953844 -0.01834646985 -0.3145961165 -0.1551435143 -0.1897218674 -0.6782951951 -0.001238539815 -0.1476960182 0.8379756808 -0.3640313745 0.08346153051 -0.7165501118 -0.9255920649 0.1504372358 -0.8932706118 -0.4338618517 0.1948764473 0.2700033784 -1.274457693 -0.1353416145 0.4278050363 -0.8345499039 -0.1699510664 0.9164355397 -1.557055831 0.668407321 -0.7479814291 -0.5342580676 -1.330482841 -0.1022242233 -1.963770986 -1.084569573 -1.34240365 -0.1084434316 -0.565561533 -0.5060130954 -1.144616723 1.264299154 -0.1902586669 0.02174477838 -1.254423261 -0.9504104853 -0.8645780683 -0.1366228163 -0.144697085 -0.5823468566 -1.647065759 -0.5357928872 -0.8950794339 0.5012350082 -1.256810546 1.121241927 -0.6218414307 -0.2271721363 -0.5474994183 -0.4918791652 0.3645601869 -0.9830704927 2.122302771 -0.6177154779 -0.6622462273 -0.9478222728 -0.01968348585 1.327158451 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007012990303 0.01539762318 0.01144970022 0.01342899539 0.01297258027 0.007958691567 0.01566331089 0.01352938171 0.0362534821 0.01089744549 0.01704780012 0.007659981493 0.006215011235 0.01822869293 0.006419171114 0.01016243175 0.01905703172 0.0205438789 0.004384615924 0.0136975646 0.02405552752 0.00680739712 0.01323161181 0.03921248391 0.003305223072 0.03059899248 0.007422963623 0.009191705845 0.004145721905 0.01415878907 0.002200728748 0.005301501136 0.004096594639 0.01407100353 0.008908431046 0.009455027059 0.004992530216 0.05552641675 0.01296561677 0.01602747478 0.004473344889 0.006062662695 0.006606022362 0.01368002594 0.01357001439 0.008760148659 0.0030207159 0.009177611209 0.006407571491 0.02588839456 0.004462679382 0.04812499508 0.00842091348 0.01249573752 0.009070798755 0.009589612484 0.02258124948 0.005867854692 0.1309561431 0.008455728181 0.008087449707 0.006078375038 0.01537704933 0.05912880227 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.01239395 27.02077866 27.0149231 27.01737976 27.01882935 27.00809479 27.01961327 27.01747894 27.04211044 27.01580048 27.02290535 27.01304054 27.01159477 27.02313232 27.00893784 27.01601982 27.02443695 27.02640152 27.01024246 27.01287842 27.0280056 27.01218796 27.01908875 27.03887177 27.0091629 27.03598022 27.01328087 27.01314163 27.00905037 27.02001572 27.00758171 27.00925255 27.00661659 27.01992798 27.00427628 27.01245117 27.0056057 27.05518532 27.01262474 27.01950073 27.00985336 27.01001358 27.01198578 27.01906013 27.01942825 27.01271057 27.00887871 27.01360512 27.01226425 27.03174591 27.01032066 27.05207443 27.00855637 27.01835251 27.01445198 27.01449394 27.02843857 27.00790977 27.13681412 27.01383591 27.01156044 27.01193619 27.02075768 27.06498718 

-------
======================
selected experts : 8, 23, 37, 51, 58, 63, 
layer22_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df0e2e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.459906 -0.801032 -0.4119380.196134 -0.324941 0.14068 0.0877142 0.237325 -0.955242]

layer22_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dde69cd0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52989 -1.4074 -0.2009450.862902 -0.583776 -0.404912 0.372308 0.301847 -1.14205]

layer23_wq's input 
<N9nntrainer6TensorE at 0x5682de368560>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.32152 -1.33011 -0.1922740.768143 -0.565455 -0.404908 0.344564 0.266333 -1.05695]
==============================
layer23_wq's output 
<N9nntrainer6TensorE at 0x5682de2bfbc0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60922 2.58156 -3.89571.96592 1.101 3.35278 -1.33262 2.75291 -3.83909]
============================
layer23_wk's input 
<N9nntrainer6TensorE at 0x5682de266760>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.32152 -1.33011 -0.1922740.768143 -0.565455 -0.404908 0.344564 0.266333 -1.05695]
==============================
layer23_wk's output 
<N9nntrainer6TensorE at 0x5682de82d610>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.06271 3.21187 -2.23235-2.24058 -2.63303 2.30116 -0.501631 -1.88495 2.02967]
============================
layer23_wv's input 
<N9nntrainer6TensorE at 0x5682de40ebf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.32152 -1.33011 -0.1922740.768143 -0.565455 -0.404908 0.344564 0.266333 -1.05695]
==============================
layer23_wv's output 
<N9nntrainer6TensorE at 0x5682de7736d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.178801 -0.967032 0.719379-1.08272 -0.607393 -0.18185 -0.818278 -0.941207 -0.217915]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-3.84937 2.20754 -1.73504-4.00387 -2.98824 1.87716 -3.0562 0.118659 -1.18352]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a32bf188
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer23_attention_out's input 
<N9nntrainer6TensorE at 0x5682ddf81aa0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer23_attention_out's output 
<N9nntrainer6TensorE at 0x5682de55e330>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer23_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0fe910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52989 -1.4074 -0.2009450.862902 -0.583776 -0.404912 0.372308 0.301847 -1.14205]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.07552 -1.95378 -0.2758031.18436 -0.796674 -0.587513 0.534366 0.414296 -1.54959]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4839372635 -0.9653638005 -0.2139574289 -0.4169965982 -0.9937536716 -2.169672012 -0.2422578484 -1.502996802 -0.8820543885 -1.586862683 -2.791267872 0.3879947662 0.2185072303 0.8950022459 -0.311399132 0.2695389986 -0.6820523143 -0.01871247217 0.1456014663 -0.4945863783 0.7300466895 -0.5971394777 -0.5344864726 -0.5229815245 -1.184855461 -1.106283307 -0.7813099623 -0.5901976228 0.5363240242 0.7315717936 -1.264652252 -0.4504970312 0.6880748272 0.6829567552 -0.008895480074 -1.164098144 0.3065220416 -0.6324129105 -1.468803048 0.1183366179 -1.34001267 -0.1585486531 -1.519421697 -1.86741221 0.5924387574 -0.7581304312 -1.252984047 -0.6759970188 -1.148257971 0.4346925616 0.1837275922 2.585729837 0.6428440213 -0.5275315046 -0.9693915844 -0.2661961317 -0.9315228462 0.7165947556 0.05729415268 0.2847727537 -0.4847031832 -0.06007727981 -0.8921365738 0.2510969937 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009283553809 0.00573632028 0.01216087956 0.009926272556 0.005575756542 0.001720319386 0.01182154752 0.003350752639 0.006234680768 0.003081199247 0.0009239601204 0.02220186964 0.01874053851 0.03686210141 0.01103180554 0.01972172596 0.007615071256 0.01478287205 0.01742286049 0.00918521639 0.03125653416 0.008289935067 0.008825941011 0.008928070776 0.004605845548 0.004982333165 0.006895519327 0.008347684518 0.02575183101 0.03130424023 0.004252595361 0.009599248879 0.02997178771 0.02981878258 0.01492871158 0.004702450242 0.02046475001 0.008002618328 0.003467308125 0.01695424691 0.003943895455 0.01285371929 0.003296165727 0.002327441005 0.02723819949 0.007057221606 0.004302506335 0.007661323529 0.004777530674 0.02326323837 0.01809995063 0.1999188513 0.02864634059 0.008887539618 0.00571326213 0.01154192071 0.005933764856 0.03083888628 0.01595027186 0.02002445795 0.009276445955 0.01418385748 0.006172136869 0.01936134696 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.92597198 26.92147064 26.92885017 26.92613792 26.92035675 26.91793251 26.92708015 26.91956329 26.9224472 26.91976929 26.91761208 26.9355526 26.93495178 26.95164299 26.92724419 26.93450356 26.9171505 26.93099403 26.93172836 26.92206001 26.9474678 26.92450142 26.92551422 26.92561722 26.92129517 26.9202404 26.9211998 26.92503738 26.94244003 26.94703865 26.91998863 26.92390442 26.94332314 26.94317055 26.93018723 26.92043686 26.93715286 26.92373848 26.91967964 26.92982864 26.91777229 26.9290657 26.91998482 26.91806221 26.94297409 26.92326927 26.91765404 26.91958237 26.92098999 26.93756866 26.93478966 27.11613083 26.94533539 26.92414665 26.91858673 26.92632294 26.92119217 26.94085121 26.93216324 26.9357605 26.92596626 26.92848778 26.9228611 26.9346199 

-------
======================
selected experts : 13, 20, 29, 32, 51, 57, 
layer23_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee1eb60>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.906188 -0.93121 -0.0112482-0.0990461 0.00702408 -1.02714 -0.165144 0.382759 0.00785814]

layer23_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de7806d0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.6237 -2.33861 -0.2121930.763855 -0.576752 -1.43206 0.207164 0.684606 -1.1342]

layer24_wq's input 
<N9nntrainer6TensorE at 0x5682de5e9620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.23194 -1.76072 -0.16460.548961 -0.457261 -1.08635 0.150064 0.474435 -0.847459]
==============================
layer24_wq's output 
<N9nntrainer6TensorE at 0x5682de23a580>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00566128 0.0150758 0.4445990.272002 0.00526445 0.243909 0.0761507 0.0756884 0.0855249]
============================
layer24_wk's input 
<N9nntrainer6TensorE at 0x5682de680bc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.23194 -1.76072 -0.16460.548961 -0.457261 -1.08635 0.150064 0.474435 -0.847459]
==============================
layer24_wk's output 
<N9nntrainer6TensorE at 0x5682de1e9fa0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.20187 1.80715 1.48120.76211 -0.307243 1.50088 -0.724443 0.979726 -0.9136]
============================
layer24_wv's input 
<N9nntrainer6TensorE at 0x5682de7cdb70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.23194 -1.76072 -0.16460.548961 -0.457261 -1.08635 0.150064 0.474435 -0.847459]
==============================
layer24_wv's output 
<N9nntrainer6TensorE at 0x5682de067420>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.0577 -0.642175 2.07097-2.49102 -1.41601 2.35112 -0.627438 2.78031 -2.84199]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0160643 -0.00112594 -0.2975050.427954 -0.235438 0.0639378 -0.0309815 0.1028 -0.30922]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a36c91a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer24_attention_out's input 
<N9nntrainer6TensorE at 0x5682de40b530>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer24_attention_out's output 
<N9nntrainer6TensorE at 0x5682de646540>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer24_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de7c4940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.6237 -2.33861 -0.2121930.763855 -0.576752 -1.43206 0.207164 0.684606 -1.1342]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.6207 -2.6811 -0.2396380.871366 -0.64477 -1.70713 0.246956 0.780963 -1.27442]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.074664474 -0.8922616839 -0.102407448 0.07062817365 -0.1484004259 -0.2287002653 0.5861350894 0.1625005603 -0.2460435629 -0.3501291871 -1.06761992 -0.003797911108 1.444381356 -0.2615830898 -0.7064641118 -0.7513090372 -0.7412349582 -0.6171593666 -0.3239291012 0.02110742219 -0.7781904936 0.538713336 -0.255209446 -1.102991581 1.804532766 0.3891856074 -0.1016360149 -0.2039393783 -1.245521784 -0.1747154146 -1.308147907 1.133462429 -0.7939858437 -1.383263707 0.3777789772 -0.802591145 -1.066303134 0.01695022546 0.304941386 -1.007137418 -0.5375985503 -0.9835063219 -0.8290171027 -0.7907453775 0.5081122518 -0.939088285 -0.6026405692 -0.6043896675 -1.491520166 -0.5610138774 -0.09709006548 -0.3465279341 0.1509504467 -0.8219507337 -0.6634860635 -0.9424288273 -0.1440306008 -0.1431129873 -0.3499019742 -0.9935693741 -0.1177032068 -0.7337630987 -0.95454216 -0.2616923749 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005998932756 0.007199303247 0.01586060785 0.01885681041 0.01514765248 0.01397885382 0.03157548606 0.02067130618 0.01373850647 0.01238042768 0.00604134053 0.01750432514 0.07448720187 0.01352666412 0.008669246919 0.008289061487 0.008372988552 0.009479073808 0.0127090821 0.01794575155 0.008069209754 0.03011306934 0.01361315325 0.0058313841 0.1067808643 0.02593080327 0.01587284729 0.01432930212 0.005056750961 0.01475424133 0.004749778658 0.05458222702 0.007942754775 0.00440606568 0.02563670091 0.007874698378 0.006049302407 0.01787130348 0.02383576892 0.006418012083 0.01026404835 0.006571482867 0.007669326849 0.007968532853 0.02920553274 0.006869955454 0.009617701173 0.009600894526 0.003953992389 0.01002650429 0.01594517007 0.01242509391 0.02043392323 0.007723713294 0.009049955755 0.006847044453 0.01521398965 0.0152279567 0.01238324121 0.006505685858 0.01561985258 0.008435786702 0.006764604244 0.01352518704 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.83670807 28.83695602 28.84657097 28.84336662 28.84538078 28.8432579 28.86276245 28.85185814 28.84444809 28.84309006 28.83388901 28.84869003 28.90567398 28.84042168 28.83842659 28.83947563 28.83860588 28.83589745 28.84008026 28.84913254 28.83925629 28.85557747 28.84146309 28.83701706 28.9379673 28.8571167 28.8451519 28.8455162 28.83624268 28.8454628 28.83593559 28.88481522 28.83912849 28.8346386 28.85682297 28.83906174 28.83771324 28.84905815 28.84882355 28.83760452 28.83763504 28.83775711 28.83885574 28.83677101 28.85848427 28.83757973 28.84080315 28.83935738 28.83227921 28.83930588 28.84617805 28.84361076 28.85066605 28.8370018 28.84023666 28.83612633 28.84640121 28.84641457 28.84404564 28.83769226 28.84680557 28.83676147 28.83795166 28.84423447 

-------
======================
selected experts : 6, 12, 21, 24, 31, 44, 
layer24_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df21d1f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628785 0.184833 -0.112852-0.955649 0.0126883 -0.311257 -0.82243 -0.778489 0.780474]

layer24_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de2b2790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25249 -2.15377 -0.325045-0.191793 -0.564064 -1.74331 -0.615266 -0.0938824 -0.353721]

layer25_wq's input 
<N9nntrainer6TensorE at 0x5682ddf10a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.871 -1.26846 -0.211436-0.109585 -0.366913 -0.996073 -0.370473 -0.0557046 -0.236307]
==============================
layer25_wq's output 
<N9nntrainer6TensorE at 0x5682de7d58a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.72197 4.42588 -4.597341.49702 -2.261 4.52404 -2.91168 -0.674019 -2.79383]
============================
layer25_wk's input 
<N9nntrainer6TensorE at 0x5682de480fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.871 -1.26846 -0.211436-0.109585 -0.366913 -0.996073 -0.370473 -0.0557046 -0.236307]
==============================
layer25_wk's output 
<N9nntrainer6TensorE at 0x5682de0aef30>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.34389 1.4774 -0.535676-0.850426 -0.684613 -0.76615 0.418316 -1.17355 0.647725]
============================
layer25_wv's input 
<N9nntrainer6TensorE at 0x5682ddd64050>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.871 -1.26846 -0.211436-0.109585 -0.366913 -0.996073 -0.370473 -0.0557046 -0.236307]
==============================
layer25_wv's output 
<N9nntrainer6TensorE at 0x5682de58dbd0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.854036 0.851605 -3.935430.344204 -0.228041 -2.01824 -1.358 0.834995 -4.27294]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-5.98948 2.45186 -1.22596-4.67693 -4.93582 -1.10308 -0.774547 -2.88656 0.696418]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a38ce1b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer25_attention_out's input 
<N9nntrainer6TensorE at 0x5682df211490>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer25_attention_out's output 
<N9nntrainer6TensorE at 0x5682dddde7f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer25_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0184b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25249 -2.15377 -0.325045-0.191793 -0.564064 -1.74331 -0.615266 -0.0938824 -0.353721]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.881 -2.12042 -0.314296-0.187137 -0.540453 -1.77761 -0.616553 -0.0916031 -0.338914]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4517963231 -0.09050495923 -0.8284288645 -0.4897360504 -0.2275577635 -1.753577471 -1.147008538 1.391741633 -0.6251775622 -0.3415489197 0.6419427395 -0.5139391422 -1.198913932 -0.6744518876 -0.06356103718 0.0596325025 -0.9952005744 0.1956784427 0.7104929686 -1.46526897 -0.3979146183 -0.3888883293 -1.125691056 -0.0878001377 -1.128727078 -0.6170650721 -0.02985788137 -0.358745873 0.193454355 -1.149133563 -1.199773073 -0.5610435009 -1.269292355 1.229914904 -0.7043933868 -0.6024431586 -1.094941974 1.197730541 0.2244047076 -0.9261249304 -1.127594829 0.5340222716 -0.5747808814 -0.4632236958 -1.321432948 0.2379128188 -0.06032478064 -0.4061294496 0.6326365471 -0.4532514513 -0.1660106778 -0.599544704 -0.3058767021 -0.8097100258 -0.871348083 0.2680715322 -0.2872420549 0.7725386024 -0.3412109613 1.382186532 -0.1154797748 1.190463305 -0.2778798938 -0.3134531379 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01020949334 0.01465247478 0.007005429361 0.009829403833 0.01277584769 0.002777460264 0.00509421574 0.06451230496 0.008584315889 0.01139945351 0.03047958203 0.009594357572 0.004836543929 0.008171580732 0.01505263709 0.01702608913 0.005929345265 0.01950737834 0.03264224529 0.003705600509 0.01077468786 0.0108723836 0.005203977693 0.01469216216 0.00518820202 0.008654238656 0.01556860562 0.01120509207 0.01946404018 0.005083402153 0.004832390696 0.009152900428 0.004507856909 0.05487342551 0.007930537686 0.00878171064 0.005366480444 0.05313547701 0.02007587813 0.006353395525 0.005194080062 0.0273614917 0.009028023109 0.01009348966 0.004278837703 0.02034890465 0.01510143094 0.01068653818 0.03019724973 0.01019464806 0.01358686574 0.008807200938 0.01181343663 0.007137796842 0.006711123046 0.02097195014 0.01203564089 0.03473170474 0.01140330639 0.0638988167 0.01429106481 0.05275073275 0.01214884967 0.01172427181 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.69834518 28.70564842 28.69561768 28.70130157 28.70377159 28.69377327 28.6960907 28.75360107 28.69958115 28.70144272 28.72195244 28.70106697 28.69678688 28.69821358 28.70223427 28.70516205 28.69740295 28.70668793 28.72363853 28.69517899 28.69890976 28.69900703 28.69619942 28.70616531  28.696661 28.69917297 28.70704079 28.70267868 28.70521545 28.69083405 28.69582939 28.70062637 28.69598007 28.74634552 28.69892693 28.70025444 28.69636345 28.74460793 28.71107292 28.69639587 28.69428253 28.71788025 28.70050049 28.70061302 28.69575119 28.71182251 28.70466614 28.69929886 28.72119331 28.70119095 28.70172119 28.69932747 28.69899559 28.69813347 28.69770813 28.70958328 28.70207787 28.72620392 28.70287704 28.75489426 28.7009964 28.74374771 28.70362091 28.70319748 

-------
======================
selected experts : 7, 33, 37, 57, 59, 61, 
layer25_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df270060>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.181181 1.97758 1.990520.33743 0.29224 -0.657881 0.751527 -0.182415 1.26058]

layer25_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddfd81b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.43367 -0.176199 1.665470.145637 -0.271824 -2.40119 0.136262 -0.276298 0.906856]

layer26_wq's input 
<N9nntrainer6TensorE at 0x5682de245ed0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.6407 -0.117968 1.076610.0874191 -0.190357 -1.54295 0.0823158 -0.166911 0.575747]
==============================
layer26_wq's output 
<N9nntrainer6TensorE at 0x5682de21e590>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-5.11612 4.31771 1.10957-0.466114 -5.50468 5.45947 2.49852 1.2956 -1.05644]
============================
layer26_wk's input 
<N9nntrainer6TensorE at 0x5682de23ab70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.6407 -0.117968 1.076610.0874191 -0.190357 -1.54295 0.0823158 -0.166911 0.575747]
==============================
layer26_wk's output 
<N9nntrainer6TensorE at 0x5682de320f60>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.00795 -1.36418 0.3074020.544895 -1.04127 -0.565749 -0.416073 0.374108 0.161235]
============================
layer26_wv's input 
<N9nntrainer6TensorE at 0x5682dde7eae0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.6407 -0.117968 1.076610.0874191 -0.190357 -1.54295 0.0823158 -0.166911 0.575747]
==============================
layer26_wv's output 
<N9nntrainer6TensorE at 0x5682ddeee690>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.85801 -1.24985 -3.019780.374335 -0.668769 1.9824 -2.17322 1.1992 -4.69897]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.79703 -6.44887 0.4005141.1349 -6.62598 -4.02539 0.0316895 2.81428 0.137886]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a116c880
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer26_attention_out's input 
<N9nntrainer6TensorE at 0x5682df278ee0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer26_attention_out's output 
<N9nntrainer6TensorE at 0x5682df278e40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer26_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df27a260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.43367 -0.176199 1.665470.145637 -0.271824 -2.40119 0.136262 -0.276298 0.906856]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.1444 -0.158646 1.499560.131689 -0.237423 -2.24514 0.12426 -0.246646 0.806046]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7976108193 -1.237690926 0.3693436384 -1.320588946 0.4601677656 -1.316403985 0.3657962978 1.585767984 0.7315429449 -0.1187434494 -0.7654778361 -2.125173807 0.1955475211 -1.207199097 2.000904083 -0.7493480444 1.018078804 -0.07063479722 -0.3333452046 -0.7209935188 -0.02316588908 0.04870539159 0.1151986048 -0.7828495502 0.01025529951 1.13081646 -0.690267086 0.3549180925 -0.9964004755 -0.4106429815 -1.097838998 -1.076774597 -0.07724364102 -1.294981956 -0.7529384494 -0.9240140319 0.2047221065 -0.4458819628 -0.08619339764 -0.601223588 -0.3765991032 -0.6582266092 -0.8708590269 -0.2210022956 -1.058641672 -0.8108075857 0.9971785545 -1.19317472 -0.669097662 0.03125523776 -0.10601601 -0.1617669761 -0.7126160264 -0.3440948129 -0.2707051635 0.7163293362 0.3726058006 -0.2156991065 -0.7929415107 0.1992799789 0.1424860656 -1.363229513 -0.7534536123 -0.4182652831 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006906083319 0.004447412677 0.02218368277 0.004093598109 0.02429282852 0.004110766575 0.02210512944 0.07487210631 0.03186653554 0.01361633185 0.007131599355 0.001830958994 0.01864468306 0.004585111048 0.1133995578 0.00724756252 0.04244003817 0.01428740844 0.0109865116 0.007456006017 0.01498196926 0.01609838195 0.01720520668 0.007008781657 0.01549114659 0.04750476032 0.007688658312 0.02186596952 0.005661070812 0.01016926859 0.005114985164 0.005223871674 0.01419329736 0.004199777264 0.007221587934 0.006086050533 0.01881652698 0.009817156941 0.01406683773 0.008404689841 0.01052143238 0.007938996889 0.006418306381 0.01229276787 0.005319459364 0.006815542933 0.04156223312 0.004649866838 0.007853157818 0.01581989974 0.01379074156 0.01304293238 0.007518731523 0.01086904295 0.01169671677 0.0313853994 0.02225616761 0.01235813089 0.006938404404 0.01871440373 0.01768115722 0.003922714386 0.007217868231 0.01009205077 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.06643677 33.06493378 33.08457565 33.06553268 33.08573151 33.06459808 33.08354568 33.12963486 33.09044647 33.07123947 33.06952667 33.06422424 33.08008575 33.06697845 33.17483902 33.06868744 33.10387802 33.07572556 33.07147217 33.06412888 33.07641983 33.07753754 33.07578278 33.06844711 33.07597733 33.10894394 33.06817627 33.07758331 33.06614685 33.07256317 33.0675087 33.06666183 33.07086563 33.0656395 33.06675339 33.06847763 33.08025742 33.07030487 33.07646179 33.06507492 33.0700531 33.0693779 33.06785965 33.07373047 33.06771088 33.06921005 33.10300064 33.0670433 33.07024765 33.07630539 33.0733223 33.07543564 33.06895828 33.07326126 33.07027435 33.0937767 33.08369446 33.07189178 33.06837845 33.08015442 33.08007431 33.06345367 33.06674957 33.07057953 

-------
======================
selected experts : 7, 8, 14, 16, 25, 46, 
layer26_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df27d4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-2.04064 -0.314795 -1.400310.827417 1.52577 -2.1098 -1.85683 1.97067 0.542728]

layer26_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddd52130>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.393023 -0.490994 0.2651620.973054 1.25395 -4.51099 -1.72057 1.69437 1.44958]

layer27_wq's input 
<N9nntrainer6TensorE at 0x5682de328070>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349417 -0.31544 0.1772360.634612 0.874767 -3.0591 -1.11655 1.13253 0.978322]
==============================
layer27_wq's output 
<N9nntrainer6TensorE at 0x5682ddefef30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.47915 2.14073 0.8226340.55384 1.33991 0.998374 -1.32992 1.91716 -1.1047]
============================
layer27_wk's input 
<N9nntrainer6TensorE at 0x5682de1e5e50>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349417 -0.31544 0.1772360.634612 0.874767 -3.0591 -1.11655 1.13253 0.978322]
==============================
layer27_wk's output 
<N9nntrainer6TensorE at 0x5682ddfc8350>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.56288 2.69319 1.58043-0.311879 0.972928 0.535231 -0.916197 0.858185 0.225043]
============================
layer27_wv's input 
<N9nntrainer6TensorE at 0x5682de7969c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349417 -0.31544 0.1772360.634612 0.874767 -3.0591 -1.11655 1.13253 0.978322]
==============================
layer27_wv's output 
<N9nntrainer6TensorE at 0x5682de46fef0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.39497 -3.06129 2.057072.83891 -0.841989 -0.0350844 -3.97103 0.705508 2.87695]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.33102 -2.23584 -0.6009410.788883 -0.645723 1.54115 -2.31736 -0.272012 -1.69287]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a054e820
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer27_attention_out's input 
<N9nntrainer6TensorE at 0x5682de426170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer27_attention_out's output 
<N9nntrainer6TensorE at 0x5682de0d2950>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer27_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de6e6390>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.393023 -0.490994 0.2651620.973054 1.25395 -4.51099 -1.72057 1.69437 1.44958]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.326462 -0.396689 0.2116510.776689 1.03751 -3.74703 -1.40127 1.35244 1.15235]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4075613916 -1.537694812 -1.079890847 -1.658623457 -0.7141698599 -0.2288180739 -0.1915958375 -0.421092689 -0.3735206723 -1.561541319 -1.216026425 -0.9826565981 -0.783592999 0.02853864431 0.3969347179 -0.001903982367 1.232006073 -0.5751284957 -2.305074215 -1.735985398 1.168386698 -1.215337038 -1.044820428 -1.323595166 -1.625537992 -1.10840559 1.333244324 -0.7492160201 -0.4535664916 -1.268533945 -0.9302008152 1.042670369 -0.133242324 -0.2272001654 -0.9168794751 2.142210484 0.3906172514 0.3940891325 -0.1735385656 -0.6589808464 -1.141647696 -1.435662866 -0.8268273473 0.4714540839 -1.632031679 -0.6181524992 -0.7313773632 -0.7323353291 -0.3073841035 -1.545512915 0.5358894467 0.81878829 1.656416535 -0.4525648057 -0.9500568509 -0.5141102672 -0.7638406754 -0.1650416851 0.7898381948 -0.04235753417 0.6157683134 -1.09482491 -0.0324466154 0.3313139081 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.02213611454 0.003164370079 0.005001602229 0.00280393986 0.007210072596 0.01171453949 0.01215879992 0.009665436111 0.01013635378 0.003089804202 0.0043650195 0.005512358155 0.006726507097 0.01515283622 0.02190212719 0.01469849329 0.05048392713 0.008285610937 0.001468989532 0.002595200436 0.04737220705 0.004368029069 0.005180122331 0.003919851966 0.00289826165 0.004860996269 0.05586250126 0.006961764302 0.009356603958 0.004141735844 0.00580923073 0.04177588969 0.01288941782 0.01173350867 0.005887135863 0.125443995 0.02176419646 0.02183989063 0.01238034666 0.007619175594 0.004702062346 0.003504283959 0.006441887934 0.02359661087 0.002879502019 0.007936690003 0.007087067235 0.007080281153 0.010829404 0.003139727516 0.02516711876 0.03339603916 0.07717422396 0.009365982376 0.005695020314 0.00880692713 0.006860691588 0.0124859903 0.0324430801 0.01411575451 0.0272599142 0.004927462433 0.01425634976 0.02051103115 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
31.51359177 31.49461937 31.49645615 31.49473572 31.49723434 31.50126266 31.5045681 31.50064278 31.50111389 31.49502182 31.49629784 31.4955368 31.49675179 31.50708389 31.51288033 31.5047226 31.54193878 31.49640274 31.49340057 31.48356056 31.53930473 31.49629974 31.49711227 31.49203682 31.49340057 31.49631691 31.5473175 31.49603271 31.50128937 31.49225807 31.4977417 31.5327549 31.50434494 31.50318909 31.49543571 31.61689949 31.50845146 31.50804901 31.50478935 31.49907494 31.49663353 31.49543571 31.49694252 31.51552773 31.49528885 31.49891472 31.48805237 31.49853516 31.50323868 31.49507141 31.51709938 31.52485085 31.56863022 31.49938965 31.49715042 31.49740028 31.49879265 31.50298691 31.52437592 31.5060482 31.51919174 31.49638176 31.50618744 31.51196671 

-------
======================
selected experts : 16, 20, 26, 31, 35, 52, 
layer27_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df2fed10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-4.31966 -0.122392 6.770020.867754 -0.695816 2.88133 1.86454 -0.848765 -0.0286945]

layer27_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de4dbd00>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-3.92664 -0.613386 7.035181.84081 0.55813 -1.62966 0.143973 0.845604 1.42089]

(269) layer0_wq's input 
<N9nntrainer6TensorE at 0x5682dde663b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00533584 -0.00181849 0.03675270.05615 -0.0456777 -0.00173874 -0.0301168 -0.0278517 0.0253552]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5682de7965e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.340285 -1.96606 1.93697-0.305517 1.33136 1.26645 -0.936659 -1.37615 1.32085]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5682ddd56d10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00533584 -0.00181849 0.03675270.05615 -0.0456777 -0.00173874 -0.0301168 -0.0278517 0.0253552]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5682de0a36b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.36719 -0.829909 0.716176-1.44964 1.40511 -0.75517 -2.5288 0.252318 1.2568]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5682e0a65b00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00533584 -0.00181849 0.03675270.05615 -0.0456777 -0.00173874 -0.0301168 -0.0278517 0.0253552]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5682dde490d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.077627 -0.0288866 -0.01865970.0186231 -0.0536395 0.0625538 0.0203159 -0.044671 0.0258807]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.61433 1.89837 -1.2881.47859 -1.69926 0.699231 1.42207 -0.865364 0.467347]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a259ed20
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer0_attention_out's input 
<N9nntrainer6TensorE at 0x5682e0a64030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer0_attention_out's output 
<N9nntrainer6TensorE at 0x5682e0a638e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer0_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dde13420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0038867 -0.00129557 0.03109360.0414581 -0.029798 -0.00129557 -0.0207291 -0.0233202 0.0220246]

layer0_ffn_gate's input 
<N9nntrainer6TensorE at 0x5682ddfb82c0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0238318 -0.00788014 0.1860610.239914 -0.180509 -0.00730588 -0.126082 -0.140694 0.129624]
==============================
layer0_ffn_gate's output 
<N9nntrainer6TensorE at 0x5682dde852c0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.0094283 -0.0215598 -0.05527670.0783745 -0.00284603 0.0299465 0.149653 0.102264 0.0322584]
============================
layer0_ffn_up's input 
<N9nntrainer6TensorE at 0x5682de34f990>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0238318 -0.00788014 0.1860610.239914 -0.180509 -0.00730588 -0.126082 -0.140694 0.129624]
==============================
layer0_ffn_up's output 
<N9nntrainer6TensorE at 0x5682dde690c0>
data addr: 0x7fc0a7fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.0954491 0.0131496 -0.09047790.163799 -0.131224 -0.0671627 -0.091035 -0.367695 0.0737123]
============================
layer0_ffn_down's input 
<N9nntrainer6TensorE at 0x5682dc3e1140>
data addr: 0x7fc0aafd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[0.00044784 -0.000140224 0.002431570.00667022 0.000186468 -0.0010207 -0.00732061 -0.0197615 0.00120809]
==============================
layer0_ffn_down's output 
<N9nntrainer6TensorE at 0x5682dc3e0770>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.530313 -0.039013 0.00509636-0.0215666 0.0196059 -0.013654 -0.0333485 0.135026 -0.0696264]
============================
layer0_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3e1bb0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.5342 -0.0403086 0.036190.0198915 -0.0101922 -0.0149496 -0.0540776 0.111705 -0.0476018]

layer1_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e48b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.770854 -0.0559952 0.04267420.0306314 -0.0110854 -0.0144084 -0.0710461 0.123901 -0.0758662]
==============================
layer1_wq's output 
<N9nntrainer6TensorE at 0x5682dc3e2330>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.05036 0.665655 0.332401-0.370155 1.02647 0.764256 -1.18285 2.57484 0.0606972]
============================
layer1_wk's input 
<N9nntrainer6TensorE at 0x5682dc3e6610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.770854 -0.0559952 0.04267420.0306314 -0.0110854 -0.0144084 -0.0710461 0.123901 -0.0758662]
==============================
layer1_wk's output 
<N9nntrainer6TensorE at 0x5682dc3e6380>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.24526 1.03814 0.9174490.701469 1.23946 1.46682 -2.86744 -0.60461 1.33113]
============================
layer1_wv's input 
<N9nntrainer6TensorE at 0x5682dc3e7400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.770854 -0.0559952 0.04267420.0306314 -0.0110854 -0.0144084 -0.0710461 0.123901 -0.0758662]
==============================
layer1_wv's output 
<N9nntrainer6TensorE at 0x5682dc3e7190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.204227 0.0149028 0.0230723-0.0187487 0.161088 0.184685 0.0454985 -0.0533836 0.0407351]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.945909 -0.80722 -0.01689720.497212 -1.11639 0.625614 -2.51126 -1.31244 1.18183]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a34c4598
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer1_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ea340>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer1_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ea2a0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer1_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3eb440>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.5342 -0.0403086 0.036190.0198915 -0.0101922 -0.0149496 -0.0540776 0.111705 -0.0476018]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.716204 -0.16842 0.1441960.0981063 -0.041488 -0.076952 -0.269044 0.52688 -0.153783]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4938856959 0.2744270563 -0.8380575776 2.652425766 0.3581895828 -0.3603386879 3.49582696 1.066620708 -0.07572924346 -1.366705418 -0.1647537351 -0.2697153091 -0.2739833891 -0.2273011953 -0.28377226 0.4387896359 0.1971707344 -0.6836133599 0.8687351942 -0.1118115112 -0.08855776489 -0.276751399 0.3082902133 0.1831746846 -0.3872572482 0.157389462 -0.6663765907 1.623328567 -0.928239882 0.9732655883 -0.4263276458 0.08605601639 -0.7634534836 -0.237398982 -0.7045798898 0.2429447472 0.01626846194 -0.9829031825 -0.3773329854 -0.6508309245 -0.7802859545 -0.2845839858 -0.4929048717 -0.319824338 0.4986183345 0.105902642 1.925558448 -0.3053503633 -0.413780421 -0.5639892817 -0.4926785231 -0.9096289873 -0.9575096369 0.2258247584 -0.4971837699 0.3114612699 0.9630727768 -0.1422177702 -0.2463431656 0.2854246497 -0.7421780825 -0.7862241864 -0.3267106712 -0.7311197519 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005316769239 0.01146362349 0.003768563503 0.1236156747 0.01246520597 0.006076402962 0.2873148322 0.02531437017 0.0080770161 0.002221196424 0.007389040664 0.006652789656 0.006624455098 0.00694103213 0.006559926085 0.01351150032 0.01061133016 0.004397948273 0.02076952346 0.007790774107 0.007974061184 0.006606145296 0.01185846422 0.01046384685 0.005915016402 0.01019748393 0.004474411253 0.04417151585 0.003443579888 0.0230581034 0.005688371137 0.009495400824 0.004060468171 0.006871296093 0.004306698218 0.01110834163 0.008855334483 0.003260395024 0.005974011496 0.0045445133 0.00399269117 0.006554603111 0.005321986508 0.006327638868 0.01434454881 0.00968573615 0.05975841358 0.006419891957 0.005760194268 0.004956808873 0.00532319257 0.003508268157 0.003344248049 0.01091978699 0.005299263634 0.01189612597 0.02282426693 0.007557449397 0.006810111459 0.01159039047 0.004147780593 0.003969052806 0.006284215022 0.004193902947 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
62.86138916 62.86658096 62.85984039 62.97777939 62.86663055 62.86119461 63.14243317 62.88043213 62.86319351 62.85733795 62.86250687 62.86177063 62.86174393 62.86206055 62.86167908 62.86672211 62.86573029 62.85951614 62.87588882 62.86290741 62.86309052 62.86172485 62.86220932 62.86653519 62.86103439 62.86531448 62.85959244 62.90024185 62.85665512 62.87722397 62.86175919 62.86461258 62.86013031 62.86198807 62.86037827 62.8662262 62.86397171 62.85647202 62.86109161 62.8596611 62.85911179 62.86262512 62.85853195 62.86144638 62.86946106 62.86480331 62.91296768 62.86153793 62.85992432 62.86007309 62.8604393 62.85862732 62.85846329 62.86603928 62.86041641 62.86605835 62.87698746 62.86267471 62.86192703 62.86670685 62.85926437 62.85908508 62.8614006 62.85931015 

-------
======================
selected experts : 3, 6, 7, 27, 29, 46, 
layer1_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e0a3ef10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.121317 -0.0599546 0.0436244-0.0415144 -0.0689801 -0.0147215 0.0202303 0.024195 -0.0197212]

layer1_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3ee080>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.655517 -0.100263 0.0798143-0.0216228 -0.0791723 -0.0296711 -0.0338473 0.1359 -0.067323]

layer2_wq's input 
<N9nntrainer6TensorE at 0x5682dc3ee2c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.50176 -0.286059 0.204058-0.0689026 -0.180415 -0.0945488 -0.100959 0.385217 -0.1821]
==============================
layer2_wq's output 
<N9nntrainer6TensorE at 0x5682dc3ee260>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0462497 0.124748 -0.389427-0.181901 0.158622 0.0341469 -0.150277 0.784759 -0.579801]
============================
layer2_wk's input 
<N9nntrainer6TensorE at 0x5682dc3edf00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.50176 -0.286059 0.204058-0.0689026 -0.180415 -0.0945488 -0.100959 0.385217 -0.1821]
==============================
layer2_wk's output 
<N9nntrainer6TensorE at 0x5682dc3ede70>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.66199 -0.380247 1.43585-1.95493 -2.02044 -0.628309 -0.453666 1.36711 -1.76648]
============================
layer2_wv's input 
<N9nntrainer6TensorE at 0x5682dc3ee380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.50176 -0.286059 0.204058-0.0689026 -0.180415 -0.0945488 -0.100959 0.385217 -0.1821]
==============================
layer2_wv's output 
<N9nntrainer6TensorE at 0x5682dc3ee3b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.16022 -0.046587 -0.08186970.00729331 -0.0579034 -0.106257 0.0585689 0.194708 -0.107775]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0281824 -0.130026 0.415285-0.110812 -0.0958599 0.130911 -0.776088 -0.190045 -0.550987]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0856438
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer2_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ee500>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer2_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ee620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer2_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3fefb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.655517 -0.100263 0.0798143-0.0216228 -0.0791723 -0.0296711 -0.0338473 0.1359 -0.067323]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.11729 -0.397511 0.30313-0.0929383 -0.305092 -0.12973 -0.144227 0.571532 -0.230743]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.0007239356637 0.3967224956 0.7473183274 -0.3814888 0.7392625213 2.840141058 -0.4369773269 -0.6523282528 -0.7334950566 -0.2333211303 -0.191916123 -0.6012032032 0.9653558731 -0.3224940598 -0.4581566751 0.1935741156 -0.4096742272 -0.1640245169 -0.3989120722 -0.2542994618 -0.9824817777 -0.9129154682 0.01834851131 -0.004838172346 0.2320720404 0.01329177432 2.106049538 0.08493182063 -1.030921578 -0.05433372408 -0.05983022228 0.237671569 -0.1196894795 -0.01123329997 -0.4972101152 -0.2299947292 -0.4662125707 -0.7897862792 0.09493773431 -0.4111535251 -0.7961652279 -0.4509711862 -0.003034375608 0.7694603801 0.5840034485 0.7430487871 -0.3115803897 -0.389572531 -0.2015502304 0.1198345572 -0.7311477661 -0.4564379752 0.1348663867 1.469751716 0.6477128863 0.1367376447 0.4490277767 -0.4847815335 0.4408440888 -0.5562569499 -1.426332355 -0.4745022058 -0.273398757 -0.3905330002 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01132527925 0.01685224101 0.02392871864 0.007738999091 0.02373673022 0.1940085441 0.007321269251 0.005902835634 0.005442650523 0.008974973112 0.009354382753 0.006212466396 0.02975856699 0.008209295571 0.007167841308 0.01375407632 0.007523918059 0.009618964046 0.007605327293 0.008788655512 0.004243037663 0.004548719153 0.01154335123 0.01127877831 0.01429390535 0.01148512773 0.09311270714 0.01233811118 0.004042403307 0.01073411945 0.01067528129 0.01437416859 0.01005501579 0.01120687928 0.006893307902 0.009004876949 0.007110329345 0.005144739989 0.01246218476 0.007512794808 0.005112026352 0.007219531108 0.01129914168 0.02446446382 0.02032322995 0.02382677607 0.008299378678 0.007676690351 0.009264694527 0.01277634967 0.005455440376 0.00718016969 0.01296985243 0.04927973077 0.0216601491 0.01299414318 0.01775716059 0.006979516242 0.01761243492 0.006498062517 0.002722168807 0.007051630411 0.008622392081 0.007669321261 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
53.42508698 53.43061447 53.43769073 53.42150116 53.43749619 53.60586166 53.42108154 53.41966248 53.41920471 53.42273712 53.42311478 53.41711426 53.44351959 53.42197037 53.42092896 53.42751694 53.42033005 53.42338181 53.42136765 53.42159653 53.41800308 53.41640091 53.42530441 53.42408752 53.42805481 53.42524719 53.50592041 53.42609787 53.41780472 53.4244957 53.42443466 53.42813492 53.42381668 53.42496872 53.4206543 53.42276764 53.42087173 53.41795349 53.42622375 53.42127228 53.41887283 53.42098236 53.42506027 53.43822479 53.43408585 53.43758774 53.42206192 53.42143631 53.42016602 53.42653656 53.41921616 53.41903305 53.42673111 53.4630394 53.43446732  53.426754 53.43151855 53.42074203 53.43041992 53.42025757 53.41553116 53.41986084 53.42238235 53.42142868 

-------
======================
selected experts : 2, 5, 12, 26, 43, 53, 
layer2_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e09f8dd0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.108269 0.067201 0.00380213-0.0592974 -0.0135828 0.000535565 -0.0324741 0.0812852 -0.0584557]

layer2_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc401970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.763786 -0.0330622 0.0836164-0.0809202 -0.0927551 -0.0291355 -0.0663213 0.217186 -0.125779]

layer3_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e86c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.46605 -0.0902244 0.21921-0.200976 -0.213305 -0.0674484 -0.160651 0.52609 -0.383736]
==============================
layer3_wq's output 
<N9nntrainer6TensorE at 0x5682dc409160>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.707984 0.0854658 1.18397-0.202544 -0.690064 0.887325 -0.748177 -0.459255 0.0479311]
============================
layer3_wk's input 
<N9nntrainer6TensorE at 0x5682dc41f6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.46605 -0.0902244 0.21921-0.200976 -0.213305 -0.0674484 -0.160651 0.52609 -0.383736]
==============================
layer3_wk's output 
<N9nntrainer6TensorE at 0x5682dc41f440>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.97 -0.264283 1.824420.813446 -1.20373 0.686917 -0.606336 1.37327 0.799509]
============================
layer3_wv's input 
<N9nntrainer6TensorE at 0x5682dc4204c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.46605 -0.0902244 0.21921-0.200976 -0.213305 -0.0674484 -0.160651 0.52609 -0.383736]
==============================
layer3_wv's output 
<N9nntrainer6TensorE at 0x5682dc420250>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.081883 -0.2498 -0.0316294-0.00160729 0.140572 -0.270699 -0.00854238 0.0444744 -0.062748]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.71296 0.0153002 -0.7771370.915894 -0.528818 -0.99191 0.49676 -0.723819 -1.1872]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a16794a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer3_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc422910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer3_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc422870>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer3_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc423990>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.763786 -0.0330622 0.0836164-0.0809202 -0.0927551 -0.0291355 -0.0663213 0.217186 -0.125779]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.31148 -0.12013 0.29228-0.31511 -0.327068 -0.11435 -0.255211 0.809113 -0.399162]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.1962377876 -0.103987515 0.4357120097 -0.2954514623 0.2231798172 -0.8020195365 -0.6774917245 1.119437695 -0.9338757396 -0.6962167621 1.503954053 0.1658852398 0.7134883404 -0.01098105684 -0.6858609319 -0.7453010082 -0.1625581384 -0.6343906522 -1.371559501 0.3677153885 -0.8660032153 -0.2938483655 1.433504224 -0.2337851226 -0.5885555148 -0.6060359478 -0.2926838398 0.1693664789 -0.3851058781 -0.1493725628 1.251326323 -0.4069331884 -0.1012405455 -0.1888886988 1.836473346 -0.4836421609 0.4375371933 -0.6476139426 0.1758795381 0.1851105392 -0.6089960337 -0.9272542596 0.03914502636 -0.680539012 0.02375158295 -0.6262216568 0.02406140417 0.4593750536 -0.180501461 -0.2702381611 -0.5046441555 -0.7031311989 -1.169670343 -0.161546275 -0.02932170779 -0.1969992369 -0.2860062122 -0.623481214 -0.6204127073 0.712192893 1.42602241 -0.7648400664 -0.6141082644 -0.7594501376 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01130137499 0.01239352953 0.02126099169 0.01023394894 0.01719024219 0.006166568957 0.00698433863 0.04212324694 0.005404794123 0.006854773965 0.06187498942 0.01623301767 0.02806856856 0.01360151265 0.006926128641 0.006526436657 0.01168848109 0.007291952148 0.003488956019 0.01986337081 0.005784366746 0.01025036909 0.05766591802 0.01088490617 0.007633958943 0.00750167435 0.01026231423 0.01628962718 0.009356358089 0.01184362173 0.04806183279 0.009154347703 0.01242762152 0.01138473488 0.08628324419 0.008478383534 0.02129983343 0.007196164224 0.0163960699 0.01654812135 0.007479500491 0.005440699868 0.01430067979 0.006963088177 0.0140822297 0.007351764012 0.01408659294 0.02177009173 0.01148062106 0.01049526315 0.008302179165 0.006807539612 0.004269479308 0.01170031633 0.0133543266 0.01129277237 0.01033107098 0.007371940184 0.007394595072 0.02803223021 0.05723607913 0.006400153972 0.007441361435 0.006434743758 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
42.54652405 42.54380035 42.55648041 42.54545593 42.55145645 42.54138947 42.53839111 42.57829666 42.54062653 42.54302979 42.59614182 42.55145264 42.56042862 42.54882431 42.54214859 42.54174805 42.54690933 42.54156113 42.53966522 42.55317688 42.54100418 42.54642487 42.59384155 42.54610443 42.54285431 42.54272461 42.54548264 42.55150986 42.54457855 42.54706573 42.58328247 42.54437637 42.54478836 42.54660416 42.62150574 42.54370117 42.55652237 42.54241562 42.55161667 42.55176926 42.54270172 42.54066086 42.55047607 42.54218292 42.54739761 42.54257202 42.54930878 42.55699158 42.54765701 42.54571533 42.54447556 42.54203033 42.53853607 42.54692078 42.54857635 42.54555893 42.5455513 42.54354858 42.54166031 42.5594368 42.59245682 42.54162216 42.54266357 42.54165649 

-------
======================
selected experts : 7, 10, 22, 30, 34, 60, 
layer3_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc426710>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141647 -0.00445617 0.00815817-0.0470299 0.0815447 -0.00950901 -0.0401189 -0.0316625 0.0468293]

layer3_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc426050>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.905433 -0.0375184 0.0917746-0.12795 -0.0112103 -0.0386445 -0.10644 0.185523 -0.0789494]

layer4_wq's input 
<N9nntrainer6TensorE at 0x5682dc44b9a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25242 -0.106134 0.255702-0.381958 -0.028047 -0.116461 -0.308668 0.556463 -0.233436]
==============================
layer4_wq's output 
<N9nntrainer6TensorE at 0x5682dc492890>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.030635 1.00211 -0.774273-0.0781808 0.867989 0.037558 0.177326 0.147243 -0.0249077]
============================
layer4_wk's input 
<N9nntrainer6TensorE at 0x5682dc44d700>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25242 -0.106134 0.255702-0.381958 -0.028047 -0.116461 -0.308668 0.556463 -0.233436]
==============================
layer4_wk's output 
<N9nntrainer6TensorE at 0x5682dc44d470>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.249979 -0.474866 0.5057910.318708 -0.907339 -0.236762 -0.611483 -0.579829 0.15471]
============================
layer4_wv's input 
<N9nntrainer6TensorE at 0x5682dc44e4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25242 -0.106134 0.255702-0.381958 -0.028047 -0.116461 -0.308668 0.556463 -0.233436]
==============================
layer4_wv's output 
<N9nntrainer6TensorE at 0x5682dc44e280>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.39199 -0.576836 -0.292241-0.205637 0.461115 -0.0912468 -0.0864808 0.0981705 -0.163482]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.171747 -0.987762 0.643552-0.437551 -0.388231 0.777234 -0.156082 0.169597 -0.55296]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1e8d4e8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer4_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc450940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer4_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4508a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer4_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4519c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.905433 -0.0375184 0.0917746-0.12795 -0.0112103 -0.0386445 -0.10644 0.185523 -0.0789494]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.63462 -0.1408 0.330064-0.509277 -0.0420705 -0.156013 -0.432741 0.717336 -0.268227]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.9344680309 -0.1224616915 0.7122747302 -0.879663825 -1.050984979 -0.7712023854 -0.3001823127 0.3099183738 0.6146305799 -0.2456123233 0.09972074628 -0.1390371174 -1.008883476 0.470620662 -1.563606739 -0.5021421313 1.683896899 -0.5823207498 -0.7483549118 -0.7811715007 -0.09415169805 -0.3758384883 -0.3066797853 -0.7935734987 -0.3613235056 -0.182633847 0.3211717308 -0.1839020997 -1.400904298 -0.5521258712 -0.7814593315 -0.6820674539 0.07244253904 -0.554870069 0.3046645224 0.4763628244 -0.2898865044 -0.5237286091 -0.3867425323 -1.036280394 -0.3734202087 -0.272709161 -0.9219664931 -0.1225607991 -0.6516411304 0.2383146882 -0.6645326018 -0.1037149951 -0.7804605365 0.3365232646 -0.5520038009 0.4484129548 3.885401487 0.1329425722 -0.8620144725 -0.3145994842 1.132389545 -0.4294472635 -0.005604511127 -0.1885679513 0.178714633 -0.5649235845 -1.028280616 -0.8051867485 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003731110599 0.008404039778 0.01936464198 0.003941298928 0.003320744028 0.004392821342 0.00703566242 0.01294995565 0.01756317541 0.007430265658 0.01049495582 0.008265887387 0.003463536967 0.01520758867 0.001988871722 0.005749033764 0.05116577074 0.005306078587 0.004494340159 0.00434924569 0.008645355701 0.006523007061 0.006990094204 0.004295639228 0.006618378684 0.007913264446 0.0130965095 0.007903233171 0.002340277657 0.005468740594 0.004347995389 0.004802354611 0.01021254156 0.005453753751 0.01288209856 0.01529516745 0.007108471822 0.005626262631 0.00645226799 0.003369935555 0.006538802292 0.007231632713 0.003778048558 0.008403205313 0.004950718954 0.01205511019 0.004887307528 0.008563072421 0.004352339078 0.01329911221 0.005469407886 0.0148735866 0.462467134 0.01084947493 0.004011476878 0.006934956182 0.02947562188 0.00618252391 0.009445792995 0.007866444066 0.0113576157 0.005399198271 0.003397002816 0.004246043041 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.82138824 40.82606125 40.8360672 40.82255173 40.82193375 40.82300568 40.82564545 40.82965469 40.83140564 40.82604218 40.8281517 40.82687759 40.82207489 40.83286667 40.8205986 40.82435989 40.86787033 40.82201004 40.82310486 40.8229599 40.82630157 40.82513428 40.82273865 40.82099915 40.82427597 40.82652283 40.82884598 40.82460785 40.82094955 40.82408142 40.8229599 40.82341385 40.82882309 40.82406616 40.83149338 40.83200073 40.8228569 40.8213768 40.8250618 40.82007217 40.82419586 40.82584381 40.8223877 40.82606125 40.82356262 40.82685089 40.82349777 40.82622147 40.82201004 40.82427979 40.82312775 40.83062363 41.28107834 40.82850647 40.82167053 40.82554626 40.84808731 40.82479477 40.82519531 40.82647705 40.8299675 40.82400894 40.82201004 40.8228569 

-------
======================
selected experts : 2, 8, 16, 35, 52, 56, 
layer4_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc454a40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.120465 -0.0358364 -0.05859290.166895 0.0969606 0.00967123 -0.031883 -0.0466452 0.0645548]

layer4_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc454380>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.0259 -0.0733548 0.03318170.0389447 0.0857503 -0.0289733 -0.138323 0.138878 -0.0143946]

layer5_wq's input 
<N9nntrainer6TensorE at 0x5682dc4a0910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.91652 -0.18809 0.0753580.0946279 0.174852 -0.0746445 -0.342854 0.364577 -0.0351518]
==============================
layer5_wq's output 
<N9nntrainer6TensorE at 0x5682dc454560>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.663014 -1.19488 -0.8537191.46899 -1.12072 -0.569173 1.06715 0.145476 -1.55287]
============================
layer5_wk's input 
<N9nntrainer6TensorE at 0x5682dc4a2670>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.91652 -0.18809 0.0753580.0946279 0.174852 -0.0746445 -0.342854 0.364577 -0.0351518]
==============================
layer5_wk's output 
<N9nntrainer6TensorE at 0x5682dc4a23e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.19873 0.192916 -1.6543-0.510519 0.482255 -1.19605 0.612818 0.82119 -1.07766]
============================
layer5_wv's input 
<N9nntrainer6TensorE at 0x5682dc4a3460>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.91652 -0.18809 0.0753580.0946279 0.174852 -0.0746445 -0.342854 0.364577 -0.0351518]
==============================
layer5_wv's output 
<N9nntrainer6TensorE at 0x5682dc4a31f0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.155008 0.274099 0.359369-0.512762 -0.0739251 -0.105005 0.0591907 0.0220726 0.146967]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.487757 1.27649 -0.289608-1.67418 0.976699 -0.791228 -0.199632 1.05836 -1.1682]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1c884d8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer5_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc4a58b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer5_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4a5810>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer5_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a6930>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.0259 -0.0733548 0.03318170.0389447 0.0857503 -0.0289733 -0.138323 0.138878 -0.0143946]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.77873 -0.254369 0.1102010.143606 0.282694 -0.10613 -0.506681 0.498538 -0.0456973]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3291094005 -1.067005634 -0.2928633988 -0.1757128835 -1.373118639 0.4114755392 0.2584048212 -0.2752860188 -1.167376161 -1.057608366 -0.8374167085 0.9554618001 -0.2741447389 0.1757035106 -0.9989030957 -0.576164782 -0.8192147017 2.311264992 -1.016098022 -1.270412564 1.849908113 -1.933212638 -2.491990566 -0.2602374554 -0.3482982516 -0.05025612563 -0.3480886519 -0.7141461372 -1.404352665 -1.230741978 -0.6166434288 -0.3129088879 0.2098553181 -1.20407033 -0.556591928 -0.04374771565 -1.015693903 -0.8262186646 -0.04862868041 0.3627088964 -0.01372391731 -0.4134725928 -0.2538684905 -0.03223772347 0.5227943659 -0.1476397663 -0.6841863394 -1.285633087 -1.073455691 -0.1691674292 -1.354353428 -1.352234244 0.2500188053 -0.3856589496 0.6190481186 1.555152297 -1.104683876 -1.076963305 -0.0127296634 -0.9971109629 -0.788003087 -0.2736488283 -0.186482653 -0.8268713355 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01124760229 0.005377688911 0.01166276168 0.01311231125 0.003959611058 0.02358804271 0.02024016716 0.01186957583 0.004864132497 0.005428462755 0.006765577942 0.04063891247 0.01188312937 0.01863362826 0.005756682716 0.008785473183 0.006889851298 0.1576739699 0.005658542272 0.004387905356 0.09940202534 0.002261552727 0.001293399138 0.01204954553 0.01103383023 0.01486498397 0.01103614364 0.007653156761 0.003837847617 0.004565474112 0.008436950855 0.01143130288 0.01928099059 0.004688881338 0.008959123865 0.01496204641 0.0056608296 0.006841765717 0.01488919556 0.02246533148 0.01541807503 0.01033764146 0.01212653238 0.01513525192 0.02636556327 0.01348562911 0.007885912433 0.004321624059 0.005343114026 0.01319841668 0.004034615587 0.004043173976 0.02007114515 0.01062920503 0.02902949974 0.07402602583 0.00517883664 0.005324405152 0.01543341111 0.005767008755 0.007108287886 0.01188902464 0.01297185197 0.006837300025 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.24911499 33.24515533 33.25334549 33.25479507 33.24373627 33.26145554 33.26192474 33.24687958 33.24559402 33.24711227 33.24749756 33.28136826 33.25356674 33.25745773 33.24744034 33.25046921 33.2485733 33.39077377 33.24734116 33.24607086 33.3315506 33.24394608 33.24297714 33.25373459 33.24794769 33.25654984 33.25271988 33.24933624 33.24552155 33.24529648 33.25012207 33.25120926 33.25524139 33.24637222 33.25064468 33.25569153 33.24734497 33.24852753 33.25275803 33.26128769 33.25710297 33.25202179 33.25285721 33.25682068 33.2661438 33.25516891 33.24956894 33.24505234 33.24607468 33.25488281 33.24381256 33.24572754 33.2579422 33.25135803 33.26785278 33.31189346 33.24686432 33.24224091 33.25711823 33.24745178 33.24879074  33.248806 33.25274658 33.24184418 

-------
======================
selected experts : 11, 17, 20, 44, 54, 55, 
layer5_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc4a9a10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.147336 -0.141224 0.01327730.0567547 0.0745959 0.013839 0.0319384 -0.0718612 -0.0475456]

layer5_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a9350>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.17323 -0.214579 0.0464590.0956994 0.160346 -0.0151342 -0.106385 0.0670166 -0.0619403]

layer6_wq's input 
<N9nntrainer6TensorE at 0x5682dc4e8620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.77169 -0.724071 0.1546520.329472 0.46064 -0.0486533 -0.332302 0.20322 -0.189239]
==============================
layer6_wq's output 
<N9nntrainer6TensorE at 0x5682dc4a9530>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0864339 -0.612978 -0.835630.900747 -0.667181 -0.993839 0.76025 0.722293 -1.56412]
============================
layer6_wk's input 
<N9nntrainer6TensorE at 0x5682dc4ea380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.77169 -0.724071 0.1546520.329472 0.46064 -0.0486533 -0.332302 0.20322 -0.189239]
==============================
layer6_wk's output 
<N9nntrainer6TensorE at 0x5682dc4ea0f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.11929 -0.10324 -0.009236750.557981 0.238305 -1.40537 0.128687 -0.405944 0.023759]
============================
layer6_wv's input 
<N9nntrainer6TensorE at 0x5682dc4eb170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.77169 -0.724071 0.1546520.329472 0.46064 -0.0486533 -0.332302 0.20322 -0.189239]
==============================
layer6_wv's output 
<N9nntrainer6TensorE at 0x5682dc4eaf00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.271435 -0.148165 0.352868-0.367987 0.232461 -0.637829 -0.47838 -0.252549 0.428962]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.000934435 0.619041 0.0616198-1.22712 1.17952 -0.203938 -0.760072 0.722481 -0.650087]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1a834c8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer6_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc41beb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer6_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc41be10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer6_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc41cf30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.17323 -0.214579 0.0464590.0956994 0.160346 -0.0151342 -0.106385 0.0670166 -0.0619403]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.88585 -0.74364 0.1557110.344746 0.533758 -0.0555545 -0.390516 0.239891 -0.199125]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4638691545 -0.7094838023 0.1943017393 -0.2551833391 -0.4816714525 0.08862743527 -1.246662021 -0.6691928506 -0.4370101988 -0.5953332186 -0.5229797363 0.4946106672 -1.15014708 0.185185194 0.7983567119 -0.8995850682 -0.8456157446 -1.121740341 -0.3646734655 -0.4495363235 -0.2456588447 0.5531499386 -1.047222018 -0.5409777164 -0.8014068604 -0.2398983538 -0.4034435749 -0.6143152714 -1.069929123 -0.6744322777 0.4236513376 2.86834383 -0.04825428128 0.4091398716 -0.129275769 -0.394715786 0.06413892657 -0.7999017835 -1.228420734 -0.2379585207 -1.191629887 -0.4292249382 -0.2913487256 0.1080761105 0.006064817309 -0.5773868561 0.6052529216 -1.192215562 -0.08549895883 -0.3021603227 -0.3416296244 -0.9069536924 -1.036425352 -1.180878758 -1.012220144 0.3234274983 -0.7495288253 -0.5062260628 0.5414540172 0.2662356794 -0.7921816111 1.482537866 0.05718161911 0.3893421292 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.02210799232 0.006838622037 0.01688409224 0.01077131834 0.008588282391 0.01519091334 0.003996456042 0.0071197832 0.008980538696 0.007665555924 0.008240742609 0.02279818431 0.004401402082 0.01673086733 0.0308898259 0.005654688459 0.005968253128 0.004528223537 0.009654235095 0.008868749253 0.01087439805 0.02417260781 0.004878549371 0.008093751967 0.006238022354 0.01093722042 0.009287101217 0.00752141932 0.004769020714 0.007082577329 0.02123649791 0.2447932363 0.01324759237 0.02093055286 0.01221658289 0.009368512779 0.01482342929 0.006247418467 0.004070025869 0.01095845923 0.004222554155 0.009050727822 0.01038872823 0.01548924856 0.01398709323 0.007804365829 0.02546546049 0.004220082425 0.01276326459 0.01027701516 0.009879290126 0.005613173824 0.004931507632 0.004268196877 0.005052331835 0.01921127737 0.006570179947 0.008379967883 0.02389153279 0.0181433782 0.006295836996 0.06122820452 0.01472065598 0.02052024938 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.14548874 40.13022232 40.13263702 40.13415527 40.13196945 40.13857269 40.12833405 40.13050079 40.13236237 40.1310463 40.13162231 40.14331818 40.12778473 40.13916016 40.15427399 40.12903595 40.12935257 40.12791061 40.13303757 40.13225174 40.13425827 40.1475563 40.12826157 40.13147736 40.1296196 40.13431931 40.13362503 40.13090515 40.12815094 40.13046646 40.14175797 40.36722183 40.13663101 40.14431381 40.13560104 40.13275146 40.13820648 40.12963104 40.12745285 40.13434219 40.12760544 40.13243484 40.13281631 40.13887024 40.13737106 40.13214111 40.14789581 40.12760162 40.13519287 40.13365936 40.13326263 40.12899399 40.12831497 40.12765121 40.1255722 40.14259338 40.1289978 40.13176346 40.14536667 40.14152527 40.12967682 40.18175125 40.13810349 40.14390182 

-------
======================
selected experts : 14, 21, 31, 46, 58, 61, 
layer6_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc47b4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0381875 0.16281 -0.0595574-0.0959639 -0.0746384 -0.10199 0.129345 0.000853485 -0.0417668]

layer6_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc47ae20>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21142 -0.0517691 -0.0130984-0.000264518 0.0857079 -0.117124 0.0229602 0.0678701 -0.103707]

layer7_wq's input 
<N9nntrainer6TensorE at 0x5682dc5555c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.06715 -0.156838 -0.037982-0.000744136 0.224419 -0.319354 0.0645911 0.178447 -0.305212]
==============================
layer7_wq's output 
<N9nntrainer6TensorE at 0x5682dc47b000>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.903018 0.200069 1.34658-0.212974 0.689655 0.979595 0.824704 0.675663 0.359885]
============================
layer7_wk's input 
<N9nntrainer6TensorE at 0x5682dc557b30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.06715 -0.156838 -0.037982-0.000744136 0.224419 -0.319354 0.0645911 0.178447 -0.305212]
==============================
layer7_wk's output 
<N9nntrainer6TensorE at 0x5682dc5578a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.66909 -0.428646 0.909704-0.847044 -0.0576201 0.999694 0.516561 1.05539 -0.210069]
============================
layer7_wv's input 
<N9nntrainer6TensorE at 0x5682dc558920>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.06715 -0.156838 -0.037982-0.000744136 0.224419 -0.319354 0.0645911 0.178447 -0.305212]
==============================
layer7_wv's output 
<N9nntrainer6TensorE at 0x5682dc5586b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.139538 0.504087 -0.0269906-0.0404803 -0.30488 0.0463377 0.531681 -0.183999 -0.504003]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.922215 -0.0706325 -0.8950441.02836 -1.17567 0.230268 -0.716784 0.789226 1.06264]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a187e4b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer7_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc55ad70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer7_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc55acd0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer7_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55bdf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21142 -0.0517691 -0.0130984-0.000264518 0.0857079 -0.117124 0.0229602 0.0678701 -0.103707]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.93991 -0.183725 -0.0447848-0.000973101 0.293043 -0.430874 0.0864527 0.243804 -0.345607]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.3026745021 -1.071165562 -0.3273747563 -0.3650847971 -0.2735459805 -0.6784827709 1.032438159 2.836415529 1.677007675 -1.012084246 -0.1210446581 0.1496284902 -1.072111249 -0.857732594 -0.7717418671 0.05227683112 -0.5959703326 -1.45846653 -0.6093594432 0.867061615 -1.10264802 -0.7392890453 0.1881039739 0.110251382 0.2924830019 -0.08666624129 -0.6546859741 -0.9960862994 0.6259451509 0.3693005443 0.2066856623 -0.7935817838 -0.7881087065 -0.8844150305 1.500858426 -0.2022871673 0.4411149323 -0.07829384506 -1.144552827 -0.7370305061 -0.7500447631 -0.7711327076 -0.4614872336 -0.4749506414 -1.833411813 -0.8816303015 -0.2007179558 -0.6693396568 0.4736348987 -0.004009608179 -0.3746697903 1.359379292 -1.315992475 -0.5028767586 -1.085083485 -0.9007630944 -1.366281986 -0.6700772643 -0.801158905 -0.9570243955 -1.029290915 -1.147143722 -2.838216066 -1.361460567 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01824202761 0.004617659841 0.009715076536 0.009355541319 0.01025235746 0.006838516798 0.0378447324 0.2298597097 0.07210052013 0.004898698069 0.01194137242 0.01565330476 0.004613294732 0.005716296379 0.006229598075 0.01420125738 0.007426712196 0.003134869039 0.007327937521 0.03207623214 0.004474549089 0.006435082294 0.01626730897 0.01504890248 0.0180570595 0.01235903427 0.0070032035 0.004977696575 0.02520390041 0.01949882694 0.0165724121 0.006095019169 0.006128469482 0.005565788597 0.06045577303 0.01100958697 0.02095062658 0.01246294565 0.004290917888 0.006449632347 0.006366238929 0.00623339368 0.0084957527 0.008382138796 0.002154678805 0.005581310019 0.01102687791 0.006901328918 0.02164314128 0.01342399698 0.009266297333 0.05248004198 0.003614888526 0.008151295595 0.004553837236 0.005475538317 0.003437592648 0.006896240171 0.006049010903 0.005175983068 0.004815128632 0.004279816058 0.0007888631662 0.003454208141 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
35.94260406 35.93374634 35.93789291 35.93466949 35.93747711 35.93597031 35.94981003 36.1570816 36.00027847 35.93307495 35.94107056 35.94478226 35.93374252 35.93293762 35.93535995  35.942379 35.93655777 35.93226624 35.93455124 35.96025467 35.93265152 35.93461227 35.9425354 35.94227219 35.93669891 35.93958282 35.93613434 35.93315506 35.94193649 35.94863129 35.94474792 35.93427277 35.9343071 35.9346962 35.98958588 35.9353714 35.9491272 35.93968582 35.93246841 35.93462753 35.93263626 35.93345642 35.93571854 35.93751144 35.93128586 35.93089676 35.93920517 35.93603134 35.94982147 35.9377861 35.93744278 35.97684097 35.93274689 35.93632889 35.9336853 35.9326973 35.93161392 35.93602753 35.93518066 35.9343071 35.93203735 35.93341064 35.9299202 35.93162918 

-------
======================
selected experts : 6, 7, 8, 19, 34, 51, 
layer7_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5969b0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00565025 0.0566365 0.0758908-0.164418 0.0241856 0.0410004 0.0588157 -0.00652726 0.0165999]

layer7_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55e510>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21707 0.0048674 0.0627924-0.164683 0.109893 -0.0761241 0.0817759 0.0613428 -0.0871072]

layer8_wq's input 
<N9nntrainer6TensorE at 0x5682dc59a250>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.71025 0.0132039 0.158897-0.433402 0.265852 -0.194175 0.206936 0.152125 -0.22748]
==============================
layer8_wq's output 
<N9nntrainer6TensorE at 0x5682dc5d3620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.113811 0.124451 -0.4443170.0557785 -0.156237 -0.0434516 0.0620928 0.0876601 -0.309255]
============================
layer8_wk's input 
<N9nntrainer6TensorE at 0x5682dc59bfb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.71025 0.0132039 0.158897-0.433402 0.265852 -0.194175 0.206936 0.152125 -0.22748]
==============================
layer8_wk's output 
<N9nntrainer6TensorE at 0x5682dc59bd20>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.407766 -1.14437 1.048860.735342 -0.108753 -0.838916 0.525454 -1.19989 0.509964]
============================
layer8_wv's input 
<N9nntrainer6TensorE at 0x5682dc59cda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.71025 0.0132039 0.158897-0.433402 0.265852 -0.194175 0.206936 0.152125 -0.22748]
==============================
layer8_wv's output 
<N9nntrainer6TensorE at 0x5682dc59cb30>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.155474 -0.0211943 -0.246304-0.226146 -0.513429 -0.183102 -0.704311 -0.585059 0.931872]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0951096 -0.139266 0.304641-0.328211 0.103383 -0.124939 -0.0907084 0.0575482 -0.00241073]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1474498
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer8_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc59f1f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer8_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc59f150>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer8_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a0270>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21707 0.0048674 0.0627924-0.164683 0.109893 -0.0761241 0.0817759 0.0613428 -0.0871072]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.00805 0.017441 0.211016-0.620099 0.37375 -0.28818 0.30792 0.222288 -0.290963]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.008404136 -0.4691090584 -0.9366872311 -0.7921546102 -1.274636269 0.006863810122 2.454214811 -1.383565426 -0.8426497579 0.05605497584 -1.409932137 0.1777789742 -1.179196596 -1.211033463 -1.666357994 1.034234285 -0.3294745088 -1.14750886 0.9802370667 1.069889188 -0.03552164137 -0.7446625829 -0.1001953781 -0.6484101415 -1.137970924 -1.197386622 0.05350415409 -0.1711198688 -0.7221972346 0.2002630532 -0.9857591391 -1.11968112 0.1529440433 -0.9305140972 0.003514394164 0.2896854579 -0.1185809597 -0.4627895951 -1.680969238 0.3894585669 -0.7379513383 -0.4079317153 -0.6289588809 -0.6414070129 -2.64396143 0.7762132287 -1.07730329 -0.1143154651 -0.9056591392 -1.619636178 -0.8199756145 -1.296906233 -0.08220855147 -1.223901033 -0.2582148612 -0.9574040771 -1.854082346 -1.161227226 -0.7291987538 -1.523873329 0.2886013985 -0.07492308319 1.134797335 1.669533372 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005677468609 0.009735708125 0.006099594291 0.007048077881 0.004350423347 0.01567039452 0.1811135709 0.0039014332 0.006701019593 0.01646051556 0.003799909726 0.01859120093 0.004786085337 0.004636111204 0.002940416336 0.0437785387 0.01119463891 0.00494017452 0.04147730768 0.04536761716 0.01502007525 0.007390880957 0.01407941896 0.008137633093 0.004987518769 0.004699814133 0.01641858183 0.01311543211 0.007558797952 0.01901394129 0.00580750173 0.005079578608 0.01813517697 0.006137364078 0.01561799366 0.0207925532 0.01382292435 0.009797427803 0.002897765487 0.02297411487 0.007440649439 0.01034990791 0.008297468536 0.008194821887 0.001106219366 0.03382237628 0.005299467128 0.01388201211 0.006291819271 0.003081058385 0.006854694802 0.004254610278 0.01433495339 0.00457683811 0.01202147361 0.005974529311 0.002437144518 0.004872865975 0.007506060414 0.003390699159 0.02077002451 0.01443977375 0.04841001704 0.08263579011 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.07800674 34.08301926 34.07843018 34.08033371 34.07667923 34.08895493 34.25439835 34.07718658 34.0790329 34.08879089 34.07708359 34.08615494 34.0742569 34.07791901 34.07622528 34.11515427 34.08352661 34.07822418 34.0871048 34.11102295 34.08734894 34.07971954 34.0873642 34.08046722 34.07731628 34.07703018 34.08970261 34.0854454 34.08084106 34.09134293 34.07909012 34.07836533 34.09046555 34.07847214 34.0822258 34.09217072 34.08710861 34.08212662 34.07522964 34.09435272 34.07977295 34.08363342 34.08062744 34.0786171 34.07439041 34.10710526 34.07858276 34.08621216 34.07862091 34.07636642 34.08013916 34.07658386 34.08571243 34.07786179 34.08053589 34.07925797 34.07572174 34.07720184 34.0798378 34.07667542 34.09405518 34.0867691 34.11597061 34.14256668 

-------
======================
selected experts : 6, 15, 18, 19, 62, 63, 
layer8_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5a3350>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.152072 0.210309 0.0329533-0.00769576 0.160583 0.0579157 0.109306 0.0401298 0.0594724]

layer8_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a2c90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.36914 0.215177 0.0957457-0.172378 0.270477 -0.0182084 0.191082 0.101473 -0.0276348]

layer9_wq's input 
<N9nntrainer6TensorE at 0x5682dc5e1750>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.68563 0.619512 0.26179-0.521262 0.719953 -0.0514344 0.53284 0.279286 -0.0840663]
==============================
layer9_wq's output 
<N9nntrainer6TensorE at 0x5682dc5a2e70>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.591752 -0.374015 0.415191-0.627025 0.363317 0.275043 0.417152 0.358708 0.439543]
============================
layer9_wk's input 
<N9nntrainer6TensorE at 0x5682dc5e3c80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.68563 0.619512 0.26179-0.521262 0.719953 -0.0514344 0.53284 0.279286 -0.0840663]
==============================
layer9_wk's output 
<N9nntrainer6TensorE at 0x5682dc5e39f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.461237 -0.0227207 -0.3632830.355216 -0.12193 -0.141143 -0.366343 -0.083101 -0.283239]
============================
layer9_wv's input 
<N9nntrainer6TensorE at 0x5682dc5e4a70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.68563 0.619512 0.26179-0.521262 0.719953 -0.0514344 0.53284 0.279286 -0.0840663]
==============================
layer9_wv's output 
<N9nntrainer6TensorE at 0x5682dc5e4800>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.194997 0.478782 0.0529553-0.439892 -0.131646 0.0185741 0.000719097 0.660515 0.598036]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.533049 0.45378 0.08469670.747242 -0.399287 0.219586 -0.379486 0.398344 -0.481654]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a126f488
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer9_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc5e6ec0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer9_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc5e6e20>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer9_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5e7f40>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.36914 0.215177 0.0957457-0.172378 0.270477 -0.0182084 0.191082 0.101473 -0.0276348]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.14448 0.728608 0.306867-0.611781 0.866882 -0.0649524 0.68162 0.345433 -0.087569]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7255349159 -0.5672965646 -0.7764482498 -0.6477704048 -0.03378194571 -0.7673395872 0.1534353197 -1.082969308 -0.07606554031 0.767480731 -0.2667455077 -0.748966217 -1.318661094 -1.149337053 -1.112321019 -0.1356878877 -1.085234404 -1.697420955 0.1044918671 -0.4385250807 2.16889739 -1.998455286 -1.768396854 -1.40848434 -1.780827403 -2.222319603 -2.025152922 -3.420464516 -0.6627473831 -0.01339121908 0.4632426202 -1.924889922 -0.2594430447 -0.2274001539 -1.100752831 2.526510239 0.1277280599 -0.03995922208 0.839887917 -0.6934179664 0.2299685776 -1.154621005 0.8696126342 1.671569228 -1.055778384 -1.093514442 -1.236648202 0.5946958661 -0.2920380831 -1.948354721 -0.1334101111 -1.829491615 -1.338919282 -1.027295113 -0.6525812745 -1.12422967 -1.035017014 -0.9695008993 -0.1200153977 0.3410769403 0.1406766176 -1.76957798 -1.523997784 -1.030200601 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007330521941 0.008587306365 0.00696664257 0.007923327386 0.01464061718 0.007030388806 0.01765496284 0.005127470475 0.01403446496 0.03262446076 0.01159803942 0.007160754874 0.004050824791 0.004798217677 0.00497915782 0.01322215516 0.005115868989 0.002773640212 0.01681167632 0.009767460637 0.1324862838 0.002052639611 0.002583602676 0.003702829126 0.002551685553 0.001640928211 0.001998563064 0.0004951558076 0.007805544417 0.01494221482 0.02406658046 0.0022093351 0.01168304496 0.01206346601 0.005037091672 0.1894437075 0.01720688678 0.01455045864 0.03507433087 0.007569777314 0.01905920543 0.004772930872 0.03613255918 0.08057197928 0.005268802866 0.005073684268 0.004397048615 0.02744756453 0.01130837668 0.002158097224 0.01325230394 0.002430483 0.003969588783 0.005421033595 0.007885301486 0.004920213483 0.005379334558 0.005743568297 0.01343101077 0.02129896544 0.01743113808 0.002580552828 0.003298882861 0.00540530635 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.4592247 34.46047974 34.45313644 34.4588623 34.46557999 34.45892334 34.44761276 34.45701981 34.46592712 34.48356247 34.46348953 34.45905304 34.45594406 34.45669174 34.45687103 34.46511459 34.45605469 34.45466614 34.46775055 34.46165848 34.57865524 34.45394516 34.45352173 34.45368958 34.45444489 34.45353317 34.45389175 34.45238876 34.44920731 34.46683502 34.47595978 34.45410156 34.4626236 34.46300125 34.45692825 34.63275528 34.46337891 34.46548843 34.48696899 34.45946121 34.44710922 34.45666504 34.48325729 34.5315094 34.45716095 34.4569664 34.4562912 34.47457123 34.46129227 34.45405197 34.46037674 34.45432281 34.45586395 34.45731354 34.45691681 34.45490646 34.45441055 34.45668411 34.46341705 34.47223663 34.46741486 34.45447159 34.45519257 34.45539093 

-------
======================
selected experts : 9, 20, 35, 38, 42, 43, 
layer9_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5eb020>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0103548 -0.0827766 -0.0817536-0.102075 0.068178 0.173603 -0.188488 -0.0705576 0.106281]

layer9_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5ea960>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.3795 0.1324 0.0139921-0.274454 0.338655 0.155395 0.00259337 0.0309151 0.0786466]

layer10_wq's input 
<N9nntrainer6TensorE at 0x5682ded33210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.45415 0.362037 0.0377992-0.777595 0.814453 0.432593 0.00709134 0.0763867 0.199506]
==============================
layer10_wq's output 
<N9nntrainer6TensorE at 0x5682dc5eab40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.38492 -1.21453 1.34427-0.00452872 -1.3604 1.30168 -0.661107 -1.8578 -1.70101]
============================
layer10_wk's input 
<N9nntrainer6TensorE at 0x5682ded34f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.45415 0.362037 0.0377992-0.777595 0.814453 0.432593 0.00709134 0.0763867 0.199506]
==============================
layer10_wk's output 
<N9nntrainer6TensorE at 0x5682ded34ce0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.873695 -0.283103 0.4851621.0017 0.0310412 -0.544273 1.10511 -0.63873 -0.25015]
============================
layer10_wv's input 
<N9nntrainer6TensorE at 0x5682ded35d60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.45415 0.362037 0.0377992-0.777595 0.814453 0.432593 0.00709134 0.0763867 0.199506]
==============================
layer10_wv's output 
<N9nntrainer6TensorE at 0x5682ded35af0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.13422 -0.16506 0.07610980.152348 -0.368472 -0.381889 0.432319 -0.0450181 0.801782]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.552463 1.14806 -1.02720.867149 -0.633815 -1.77295 1.88905 -0.565642 -0.811466]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a106a478
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer10_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded38210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer10_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded38170>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer10_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded39290>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.3795 0.1324 0.0139921-0.274454 0.338655 0.155395 0.00259337 0.0309151 0.0786466]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.96559 0.427465 0.0424089-0.931306 1.02643 0.529862 0.00897098 0.100321 0.23578]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.075698853 -2.146638155 -1.572076797 -1.239016533 -0.6601934433 -1.058405876 -0.8171054125 -0.5537326932 0.8124222159 -1.65486455 -1.263222814 -0.2799122632 -0.5027951002 -0.9667331576 1.368038416 -0.9534963369 -1.396287799 -0.8885353208 -0.773917675 -0.5835622549 -0.1159888133 -0.5864533782 -1.190278411 1.46242857 -0.7600318193 0.1094364524 -0.527754426 -1.326165557 -1.424989223 -0.2970946431 -0.1208939254 -1.036193252 -0.2115094513 -0.1717701852 -1.760190725 -0.5123511553 -0.834112525 -1.510728478 0.2634393275 -0.08949471265 0.3920693099 -0.2159163058 -0.9869779348 -0.1603210419 -0.5909483433 -0.3569854796 -1.103301883 -1.43753016 1.086938024 0.04133091494 -0.6025595069 -0.9155442715 -0.1440999508 -0.4863758683 -1.130069971 -0.870148778 -0.9056789875 1.548809886 -0.2099162936 -1.09917748 -1.344641328 -0.5869354606 -1.286455154 -1.634610772 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006908041891 0.002367292996 0.004205143079 0.005867147353 0.01046662498 0.007028541528 0.008946655318 0.01164238621 0.04564104602 0.003871030407 0.005726831034 0.01530949119 0.01225078478 0.007703325246 0.07955300808 0.007805970032 0.005013315007 0.008329886012 0.009341505356 0.01130022854 0.01803647913 0.01126760617 0.006160184741 0.08742783219 0.009472126141 0.02259709872 0.01194879878 0.005377478898 0.004871470388 0.01504868269 0.01794822514 0.007186411414 0.01639334857 0.01705792546 0.003484047018 0.01213427354 0.008795784786 0.004471199121 0.0263593886 0.01852072589 0.02997772209 0.01632126607 0.007548940834 0.01725434884 0.01121707261 0.01417386346 0.00671996735 0.004810759798 0.06005874649 0.02110935003 0.01108758152 0.008107917383 0.01753651351 0.01245359331 0.006542474031 0.008484461345 0.008188299835 0.09531574696 0.01641948894 0.006747740787 0.005279037636 0.01126217563 0.005595316179 0.00395023264 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.10935593 33.10577011 33.10760498 33.10926819 33.11386871 33.10089111 33.11234665 33.11504364 33.14713669 33.1072731 33.10912704 33.11775589 33.11565018 33.10538101 33.17913818 33.11120605 33.1084137 33.11077881 33.10606766 33.11183929 33.1204834 33.1146698 33.10956192 33.18510818 33.11001205 33.12123108 33.11439514 33.10877991 33.10731888 33.11845016 33.12039566 33.11058807 33.11979294 33.12046051  33.106884 33.11362839 33.11029053 33.10787201 33.12976074 33.12192154 33.11525726 33.10065079 33.11095047 33.12065506 33.11461639 33.11566925 33.10916901 33.10821152 33.15869141 33.12451172 33.11067581 33.11150742 33.12093735 33.11394882 33.10994339 33.11188507 33.10968399 33.19394684 33.11791229 33.10919571 33.10868073 33.11275482 33.10899734 33.10735321 

-------
======================
selected experts : 8, 14, 23, 40, 48, 57, 
layer10_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded3c110>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.100843 -0.160853 -0.002693580.1557 -0.206979 -0.0521097 0.0486964 -0.0564466 0.0430339]

layer10_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded3bb90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.48034 -0.0284524 0.0112985-0.118753 0.131675 0.103285 0.0512898 -0.0255316 0.12168]

layer11_wq's input 
<N9nntrainer6TensorE at 0x5682ded7c3b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.82488 -0.0757713 0.0285557-0.338408 0.321627 0.287321 0.136589 -0.0614967 0.319918]
==============================
layer11_wq's output 
<N9nntrainer6TensorE at 0x5682ded3ba40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.711116 -0.0312718 0.6831160.309559 0.223987 -1.01384 0.898509 0.212579 -1.42737]
============================
layer11_wk's input 
<N9nntrainer6TensorE at 0x5682ded7e110>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.82488 -0.0757713 0.0285557-0.338408 0.321627 0.287321 0.136589 -0.0614967 0.319918]
==============================
layer11_wk's output 
<N9nntrainer6TensorE at 0x5682ded7de80>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.919881 0.605903 -1.4669-0.890419 -1.10398 0.894191 -0.587251 0.00590786 1.58978]
============================
layer11_wv's input 
<N9nntrainer6TensorE at 0x5682ded7ef00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.82488 -0.0757713 0.0285557-0.338408 0.321627 0.287321 0.136589 -0.0614967 0.319918]
==============================
layer11_wv's output 
<N9nntrainer6TensorE at 0x5682ded7ec90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.272071 0.685627 -0.546734-0.0507568 0.0982439 -0.692871 -0.549821 0.199806 -0.310142]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.708413 -0.0693938 -0.7223570.201681 0.834386 0.617929 -0.25806 0.886518 0.00302541]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0e65468
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer11_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded813b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer11_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded81310>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer11_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded82430>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.48034 -0.0284524 0.0112985-0.118753 0.131675 0.103285 0.0512898 -0.0255316 0.12168]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.14691 -0.0994196 0.0364134-0.433081 0.431069 0.38543 0.191399 -0.0883474 0.390093]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.288918138 -0.845023632 -0.4500235617 0.09027478844 -0.02849121951 0.4326645136 0.861541748 -2.127013445 -1.683238268 -0.9644001126 -0.7943502069 -1.822052717 -0.2006771863 -1.047119379 -0.4974162877 0.2427326739 -0.09994769096 -0.3965860903 0.2931783795 -0.9949479103 -2.787274361 -0.0202193968 0.06953013688 -0.5222980976 0.183985889 0.3801911771 -0.7795951962 0.9515047073 -0.2640305758 -1.946425319 -0.3005286753 -0.3565134406 -0.8987566829 -1.200834036 -0.6032832861 -0.7825671434 0.3121511042 -1.317822576 -1.634918094 -2.074688435 -0.6773531437 -1.798682928 -0.8446490765 1.976724267 -0.8513905406 -1.06051755 1.735411763 -0.9552757144 -0.468685925 -0.08455939591 -0.4899786115 -1.069809794 -0.06575390697 -1.333945274 -1.214619875 -2.006838083 -0.262242198 -1.690782309 -0.7679491043 -0.9080834985 -1.099174023 -0.9894859791 -0.2361604422 -1.029676914 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.00526396744 0.008205294609 0.01217980962 0.02090687305 0.01856562868 0.02944333665 0.0452112034 0.002276842482 0.003548641223 0.007281980943 0.008631798439 0.003088699887 0.01562896371 0.006703861058 0.01161603816 0.02435009554 0.01728527993 0.01284837071 0.0256099645 0.007062897086 0.001176482299 0.01871983521 0.02047763392 0.01133057568 0.02296081185 0.0279381834 0.008760104887 0.04946710169 0.01466953009 0.002727479208 0.01414377335 0.01337369531 0.00777603453 0.005748672411 0.0104491422 0.008734109811 0.0261004921 0.005113993306 0.003724322887 0.002399150748 0.009703142568 0.00316173234 0.008208367042 0.1378998011 0.008153217845 0.006614640355 0.1083335504 0.007348729763 0.01195461117 0.01755333133 0.0117027564 0.00655346131 0.01788655482 0.005032203626 0.005669965874 0.002567582764 0.0146957878 0.003521970706 0.008862723596 0.007703845389 0.006363822613 0.007101578172 0.01508412324 0.006821820047 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.54701042 28.55090523 28.55535698 28.55216217 28.55602074 28.55926895 28.58028221 28.54593086 28.54481888 28.54712105 28.55228615 28.54674149 28.55403709 28.54988098 28.5547924 28.56037331 28.56046104 28.55602455 28.56115723 28.54594803 28.54483032 28.55951309 28.56365395 28.5454464 28.56327629 28.56777763 28.54764557 28.58119965 28.55212402 28.54590416 28.55350494 28.55559731 28.55095291 28.5489254 28.55314827 28.54618835 28.56927681 28.54542923 28.54547119 28.5455761 28.55287933 28.54490852 28.55138588 28.67392349 28.54942322 28.54788399 28.64864922 28.55052567 28.55560875 28.55548477 28.55440331 28.54686928 28.56058693 28.54820824 28.5488472 28.54526711 28.55739594 28.54669952 28.54727173 28.55088043 28.54906273 28.54980087 28.55778313 28.5495224 

-------
======================
selected experts : 5, 6, 25, 27, 43, 46, 
layer11_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded85530>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.333288 -0.129826 0.0946371-0.126506 0.0569822 -0.0248454 0.022742 -0.0304357 -0.0313503]

layer11_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded84d30>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.81363 -0.158279 0.105936-0.245259 0.188657 0.0784395 0.0740318 -0.0559673 0.0903302]

layer12_wq's input 
<N9nntrainer6TensorE at 0x5682dedc4470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.89637 -0.441801 0.292464-0.725737 0.48631 0.226125 0.217936 -0.14683 0.24387]
==============================
layer12_wq's output 
<N9nntrainer6TensorE at 0x5682ded84be0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.348987 0.440544 0.5327880.103167 -0.98111 -0.391637 0.483843 -0.561279 0.615396]
============================
layer12_wk's input 
<N9nntrainer6TensorE at 0x5682dedc61d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.89637 -0.441801 0.292464-0.725737 0.48631 0.226125 0.217936 -0.14683 0.24387]
==============================
layer12_wk's output 
<N9nntrainer6TensorE at 0x5682dedc5f40>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.94753 2.73744 -1.06041-0.612855 -0.205349 -1.58668 1.13056 1.90304 -0.65085]
============================
layer12_wv's input 
<N9nntrainer6TensorE at 0x5682dedc6fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.89637 -0.441801 0.292464-0.725737 0.48631 0.226125 0.217936 -0.14683 0.24387]
==============================
layer12_wv's output 
<N9nntrainer6TensorE at 0x5682dedc6d50>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.51248 -0.402007 0.1068260.234327 -0.535508 -0.147109 -0.676383 -0.230129 1.07105]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.407664 -0.386886 -0.4745570.263253 0.757663 -0.736141 0.535912 0.511798 0.00457725]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0c60458
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer12_attention_out's input 
<N9nntrainer6TensorE at 0x5682dedc9470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer12_attention_out's output 
<N9nntrainer6TensorE at 0x5682dedc93d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer12_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dedca4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.81363 -0.158279 0.105936-0.245259 0.188657 0.0784395 0.0740318 -0.0559673 0.0903302]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.24071 -0.499742 0.300544-0.811778 0.546739 0.266804 0.251812 -0.173294 0.260404]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.293932796 -0.3431039155 -2.383466959 -1.621967912 -0.7980388999 -0.5974785686 0.1122665331 -0.1272202879 -1.179748893 -1.615149617 -0.006524482276 1.812610626 -0.6442659497 -0.4597440958 -1.410847545 -0.171241641 0.3463445008 -0.6412830353 -0.8454797268 -1.184060097 0.4546080232 -0.3660334647 -0.001814156771 -0.4574493468 -1.220888734 1.647700906 -1.07535696 -1.064948797 -0.2735287845 -1.309849143 -0.6186333895 -0.214939326 -0.0545353815 0.04064106569 -1.461414933 2.050419092 -0.3244403005 -0.6647894382 -0.5618572235 0.7115014791 -1.880402684 2.990878344 -0.04464754835 -0.509827733 -1.141849995 -2.116267204 0.530513227 -0.2795463204 -0.5140702128 -1.890625715 -0.4986811876 -0.3700327575 -0.9741646647 -1.60545063 -0.9082166553 0.1884768605 -1.114508629 0.2282897979 -1.38516736 -0.4846554399 -0.957275033 0.7046700716 0.6681559682 -1.846594334 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003478836035 0.009002718143 0.001170186908 0.002505936194 0.005712127313 0.006980718113 0.01419510134 0.01117199287 0.003899629926 0.002523080911 0.01260515582 0.07772998512 0.006661632098 0.008011565544 0.003094984917 0.01069085672 0.01793896034 0.006681532599 0.005447466858 0.003882854478 0.01999012567 0.008798637427 0.01266467106 0.008029971272 0.003742454108 0.06591271609 0.00432872586 0.004374016076 0.00965138711 0.003423903836 0.006834593136 0.01023374964 0.01201426983 0.01321392972 0.002942370018 0.09859785438 0.009172319435 0.00652630534 0.007233863231 0.02584537677 0.00193523278 0.2525246143 0.01213365421 0.007620199583 0.004050256219 0.001528617111 0.0215665549 0.009593484923 0.007587940432 0.001915549859 0.007705613505 0.008763519116 0.004789690487 0.002547672251 0.005116208922 0.01531920396 0.004162525758 0.01594141312 0.003175493563 0.007814453915 0.004871272948 0.02566942573 0.02474903129 0.002001778223 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
30.80781364 30.81381416 30.80550575 30.80636406 30.80909348 30.80940819 30.81900597 30.81550598 30.80489731 30.8073349 30.81741714 30.87825012 30.81147385 30.81091499 30.80599976 30.81502533 30.82275009 30.81053925 30.81025887 30.80774117 30.8209877 30.81361008 30.81747627 30.81236458 30.8085537 30.87072372 30.80818558 30.80918503 30.81255531 30.80680466 30.81116867 30.8150444 30.81587219 30.81325722 30.80727768 30.89959526 30.81350708 30.81038475 30.81156921 30.83017921 30.8062706 31.05733681 30.81408501 30.8119545 30.80838585 30.80586243 30.82494736 30.80582237 30.81049156 30.80672646 30.81204224 30.81071472 30.80912399 30.80449867 30.80992699 30.8201313 30.80849648 30.81884575 30.80751038 30.81214905 30.80968285 30.83048058 30.81811714 30.80538368 

-------
======================
selected experts : 11, 25, 35, 39, 41, 61, 
layer12_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dedcd730>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.112173 -0.131077 0.02260420.128528 0.194601 0.0424895 0.20247 0.0769971 0.138645]

layer12_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dedccdf0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.9258 -0.289355 0.12854-0.116731 0.383258 0.120929 0.276502 0.0210298 0.228975]

layer13_wq's input 
<N9nntrainer6TensorE at 0x5682dee397f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.16659 -0.748282 0.326644-0.340257 0.865079 0.368764 0.781172 0.0493541 0.55791]
==============================
layer13_wq's output 
<N9nntrainer6TensorE at 0x5682dedccca0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.146461 -0.826287 0.551154-0.545832 0.223024 -1.19836 0.793292 0.190072 -0.0831282]
============================
layer13_wk's input 
<N9nntrainer6TensorE at 0x5682dc471a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.16659 -0.748282 0.326644-0.340257 0.865079 0.368764 0.781172 0.0493541 0.55791]
==============================
layer13_wk's output 
<N9nntrainer6TensorE at 0x5682dc4717a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.402265 0.759593 -0.07713470.614578 0.107329 0.575085 -0.997259 0.0339192 0.130419]
============================
layer13_wv's input 
<N9nntrainer6TensorE at 0x5682dc472820>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.16659 -0.748282 0.326644-0.340257 0.865079 0.368764 0.781172 0.0493541 0.55791]
==============================
layer13_wv's output 
<N9nntrainer6TensorE at 0x5682dc4725b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.566453 -0.334422 0.3136370.445715 -0.460067 0.359764 0.332423 0.159887 -0.479781]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0283897 0.838686 -0.07165670.772379 1.00326 0.69229 -0.230223 0.782584 0.596716]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0a5b448
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer13_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc474cd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer13_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc474c30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer13_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc475da0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.9258 -0.289355 0.12854-0.116731 0.383258 0.120929 0.276502 0.0210298 0.228975]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.34616 -0.91697 0.365072-0.389114 1.09424 0.417571 0.9341 0.065072 0.653747]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7220129371 -0.05478731543 0.6278259754 -0.9891938567 1.762662411 -1.380978107 1.996001959 -0.8052836061 -0.9301933646 -1.203303814 0.8459310532 2.089992046 -0.199139744 -1.273727894 0.3800617158 -1.414164662 1.100451708 -0.2400038391 2.241235256 -2.743719339 -1.01332128 -0.2049026638 -0.4105205238 -0.9677480459 -1.712805986 -0.8239360452 -0.2945116162 -0.7590095401 -1.885005236 -1.946353197 -1.634285212 0.4477111399 -1.928819418 0.2596154809 -1.967078924 0.3224657178 -1.111128688 -0.7384868264 -1.687330604 0.1799392998 -0.6839897633 -0.3906354308 -1.360973239 -0.6651363373 -0.4168076515 -0.9761619568 -0.7915734649 -0.1483076811 -0.4143925905 0.6110135317 0.3685078025 -1.747005105 0.08016446978 -0.8501906395 -0.5594712496 -0.5311316848 -1.084499002 0.2401874214 -0.3063743711 -0.02832869813 0.33382985 -0.3051034212 -0.5633391738 -0.5100511909 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006589851342 0.01284245402 0.02541576885 0.005044758786 0.07905992866 0.003409500234 0.09983768314 0.006063336506 0.005351358093 0.004072430544 0.03161004186 0.1096765697 0.01111620478 0.003795498982 0.01983812451 0.003298207885 0.04077199474 0.01067110803 0.127584517 0.0008726891829 0.004924498498 0.01105232816 0.00899818819 0.005154115614 0.002446694067 0.005951288622 0.0101050185 0.006350503769 0.002059654566 0.001937096706 0.002646554494 0.02122659422 0.001971361926 0.0175869856 0.001897363109 0.01872780733 0.004465650767 0.006482180674 0.002509825164 0.01624009199 0.006845243275 0.00917890761 0.003478393191 0.006975524127 0.008941792883 0.005110932048 0.006147037726 0.01169587206 0.008963414468 0.02499203756 0.01961023547 0.002364434302 0.01469795313 0.005797072779 0.007752943784 0.007975799963 0.004586168099 0.01724860258 0.009985852987 0.01318678353 0.01894184761 0.009998554364 0.007723012473 0.008145718835 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.72858047 28.73578644 28.74788284 28.7279892 28.80057335 28.72540092 28.82230568 28.72805405 28.72877312 28.72749329 28.75074005 28.82451439 28.73215294 28.72578621 28.74087524 28.7267189 28.76371574 28.72932434 28.85100555 28.72429466 28.7273922   28.73209 28.73098946 28.72809792 28.72634506 28.72889519 28.73018837 28.72881699 28.7250042 28.72392845 28.72511482 28.74417114 28.72491646 28.74053192 28.7200737  28.740242 28.72740936 28.72704315 28.72593117 28.73918343 28.73026657 28.73212242 28.72356224 28.72991943 28.72950172 28.72757912 28.72909164 28.72939491 28.73143005 28.74841309 28.74303055 28.72530937 28.73764229 28.72874069 28.73069763 28.73139763 28.72705269 28.7387619 28.73245239 28.73470116 28.74188614 28.73246574 28.73114395 28.73156738 

-------
======================
selected experts : 4, 6, 10, 11, 16, 18, 
layer13_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee45420>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.155227 -0.00390031 0.166556-0.0488616 0.0151408 -0.1858 0.310591 -0.101189 0.0405358]

layer13_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc478790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.08103 -0.293256 0.295096-0.165592 0.398399 -0.0648707 0.587092 -0.0801589 0.269511]

layer14_wq's input 
<N9nntrainer6TensorE at 0x5682dee98c10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04213 -0.643039 0.616261-0.404169 0.847593 -0.17188 1.41762 -0.160076 0.587455]
==============================
layer14_wq's output 
<N9nntrainer6TensorE at 0x5682dc478730>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.58019 0.258 -0.471951-0.137936 0.0589217 -0.443345 -1.4416 -2.72168 -0.39271]
============================
layer14_wk's input 
<N9nntrainer6TensorE at 0x5682dee9aab0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04213 -0.643039 0.616261-0.404169 0.847593 -0.17188 1.41762 -0.160076 0.587455]
==============================
layer14_wk's output 
<N9nntrainer6TensorE at 0x5682dee9a7d0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.12019 0.159095 1.60696-0.118079 1.05921 1.02661 0.26934 0.833747 0.0833444]
============================
layer14_wv's input 
<N9nntrainer6TensorE at 0x5682dee9b8a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04213 -0.643039 0.616261-0.404169 0.847593 -0.17188 1.41762 -0.160076 0.587455]
==============================
layer14_wv's output 
<N9nntrainer6TensorE at 0x5682dee9b630>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.13295 -0.965879 -0.733511-0.177862 0.0406729 0.341231 -0.450788 0.578666 0.315487]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.60078 -0.0324214 0.450276-0.197523 0.380785 0.234582 2.79156 -1.30113 0.183893]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2eb5568
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer14_attention_out's input 
<N9nntrainer6TensorE at 0x5682dee9dda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer14_attention_out's output 
<N9nntrainer6TensorE at 0x5682dee9dd00>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer14_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dee9ee70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.08103 -0.293256 0.295096-0.165592 0.398399 -0.0648707 0.587092 -0.0801589 0.269511]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.33592 -0.857385 0.754919-0.501429 1.02959 -0.206595 1.80842 -0.223897 0.696504]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.890654683 -0.677886188 -0.8622816205 -0.8444775343 -0.6838998199 -0.4321343005 -0.6509006023 -0.5058846474 1.295049429 -0.8424673676 -1.344491839 -1.465663314 0.8016123176 0.7685012817 -0.516190052 -0.9302549362 -1.699092507 0.3788572848 -3.006859779 -1.006314635 -1.602183938 -1.416317463 -0.9968240261 -1.496439219 -0.5641298294 -1.308431149 -0.3583960533 -0.7280638814 -1.764087915 -0.2883976698 -1.896824598 -1.733500719 1.287511587 -0.8243377209 -0.4451369345 -1.575756311 -0.472317487 -0.8194108605 -0.1870341748 -1.031679988 -0.5676518083 0.06790029258 -0.8494802117 -0.09206518531 -0.4842657745 -0.2350678742 -1.721546173 -0.3043273389 -1.466235518 1.14675498 -1.694718361 -0.5937050581 -0.3306755126 -0.7036556602 -0.9399239421 1.586244106 0.6639513373 0.7030807137 0.4497053325 -0.159288466 -1.697398186 -0.0456347391 -0.105351761 0.3423116803 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1113802493 0.00853699632 0.007099424489 0.007226955611 0.008485811763 0.01091525145 0.008770506829 0.0101392176 0.06139600277 0.007241496816 0.004383307416 0.00388309313 0.0374837555 0.03626295179 0.01003526524 0.006632889621 0.003074686043 0.02456082404 0.0008314664592 0.006147101987 0.003387565026 0.004079514649 0.006205718499 0.003765407018 0.00956552662 0.004544257652 0.01175054256 0.008119198494 0.002881201217 0.01260253135 0.0025230553 0.002970690606 0.06093495339 0.007373979315 0.01077424362 0.003478283528 0.01048533712 0.007410400081 0.01394695323 0.005993139464 0.009531894699 0.01799683087 0.007190891076 0.01533641573 0.01036080252 0.0132928649 0.003006418003 0.01240336709 0.003880871926 0.05293423682 0.003088165075 0.009286765009 0.01208082959 0.008319811895 0.006569064688 0.08214939386 0.03266312182 0.03396654502 0.02636403404 0.01433934085 0.003079900518 0.01606528275 0.0151339937 0.02367943898 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.27173233 27.16936684 27.16697502 27.16519547 27.16693115 27.17126846 27.16959953 27.16906166 27.22222519 27.16807175 27.16378212 27.16280556 27.1987896 27.19137001 27.1656189 27.16603279 27.16295052 27.1844368 27.16213799 27.16363907 27.16374016 27.16490936 27.16703606 27.15934944 27.1703949 27.16489601 27.17258072 27.16894913 27.16371155 27.17390823 27.16239929 27.16284561 27.22176361 27.16724968 27.17112732 27.16287804 27.16893005 27.16728592 27.17477608 27.1663456 27.17036057 27.17835045 27.16563606 27.17473602 27.17119026 27.17364502 27.16383553 27.1689415 27.16328049 27.21376419 27.16248703 27.16868591 27.17243385 27.1691494 27.16739845 27.24202538 27.19349289 27.19431877 27.18147087 27.17421532 27.16343307 27.17737198 27.16595078 27.18450928 

-------
======================
selected experts : 0, 8, 12, 32, 49, 55, 
layer14_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deea2ef0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0442295 0.142497 -0.183646-0.151549 0.0582103 0.0591179 -0.199296 0.0431362 -0.149447]

layer14_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deea2970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.12526 -0.150758 0.11145-0.317141 0.456609 -0.00575276 0.387797 -0.0370227 0.120064]

layer15_wq's input 
<N9nntrainer6TensorE at 0x5682deedb770>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.77349 -0.33165 0.211932-0.764679 0.868282 -0.0155153 0.910942 -0.0713222 0.244728]
==============================
layer15_wq's output 
<N9nntrainer6TensorE at 0x5682deea2820>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00260178 0.611024 -0.150906-0.25107 0.966889 -0.0170978 -0.14178 -0.448184 -0.40272]
============================
layer15_wk's input 
<N9nntrainer6TensorE at 0x5682deedd610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.77349 -0.33165 0.211932-0.764679 0.868282 -0.0155153 0.910942 -0.0713222 0.244728]
==============================
layer15_wk's output 
<N9nntrainer6TensorE at 0x5682deedd330>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.591653 -1.26591 0.07956451.14947 -0.494893 0.228183 1.02436 0.556575 0.497839]
============================
layer15_wv's input 
<N9nntrainer6TensorE at 0x5682deede400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.77349 -0.33165 0.211932-0.764679 0.868282 -0.0155153 0.910942 -0.0713222 0.244728]
==============================
layer15_wv's output 
<N9nntrainer6TensorE at 0x5682deede190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.461074 0.0829068 -0.469892-0.137902 -0.0689102 -0.205022 -0.708806 -0.3385 -0.00434557]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0888034 -0.604542 0.2769470.0954384 -0.378654 0.889824 0.454823 -0.118772 0.698719]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2badd50
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer15_attention_out's input 
<N9nntrainer6TensorE at 0x5682deee0900>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer15_attention_out's output 
<N9nntrainer6TensorE at 0x5682deee0860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer15_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682deee19d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.12526 -0.150758 0.11145-0.317141 0.456609 -0.00575276 0.387797 -0.0370227 0.120064]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.46972 -0.436579 0.277035-0.942053 1.15203 -0.0179463 1.16157 -0.099391 0.301433]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2218439579 -0.6005067229 -0.007580773905 -0.7548547983 0.0933939144 -0.8238271475 -0.3696285486 -1.379104376 -1.4727844 -1.010642409 0.03440863639 -0.8138206601 -0.7815232277 -0.4850285351 -1.464040756 1.524754405 -0.9279221892 -0.5366939902 -1.547908783 -0.245569557 -1.846567154 -0.4650019109 2.035564899 -1.926776528 -0.1271660626 -0.9479135871 0.1389866769 -0.8522074223 -1.067058682 0.2254901528 -0.4206766188 -0.4966990054 -1.859713674 -0.08688179404 0.07939142734 -0.3981376886 -0.7420488 0.1732515693 1.48654604 0.07724988461 -1.073909998 -0.9899170399 -0.7569380999 -2.455502748 -1.836840987 -0.6345955729 -0.5112048984 -1.380798697 0.3201414645 0.5749521255 0.1245499775 -0.6584037542 -0.3076282442 -0.5475282669 -1.27268219 -1.233708143 1.157920361 -1.180791736 0.08818650246 -1.08333075 -0.1766496301 0.6963065863 -1.426909804 -1.258859158 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01397671271 0.009570924565 0.01731643081 0.008202031255 0.01915627718 0.007655384485 0.01205655094 0.004393525887 0.004000630695 0.006350883748 0.01805901714 0.007732374128 0.007986186072 0.01074250136 0.004035764374 0.08015730232 0.006898571271 0.01020157803 0.003711097874 0.01364901103 0.002752939938 0.01095980778 0.1335934699 0.002540752059 0.01536466647 0.006762028206 0.02004988119 0.007441177499 0.006002511829 0.02186148986 0.01145652961 0.01061785966 0.002716985298 0.01599625498 0.01888991147 0.01171768177 0.008307741024 0.02074879594 0.07715238631 0.01884950139 0.005961526185 0.006483882666 0.008184961975 0.001497404883 0.002779845614 0.009250160307 0.01046494953 0.00438608788 0.02403180115 0.03100624494 0.01976250671 0.00903253071 0.01282771863 0.01009164937 0.004886881448 0.005081103183 0.05554296449 0.005357217509 0.01905678213 0.00590562867 0.01462287363 0.03500682861 0.004188432824 0.00495490199 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.90499115 25.90058517 25.89974785 25.89826202 25.90873909 25.8948555 25.90354729 25.89588356 25.89596748 25.89545822 25.91002655 25.89445496 25.89900017 25.90175629 25.89600372 25.9706955 25.89886665 25.90217018 25.89615631 25.90466309 25.89424324 25.90006638 26.02269936 25.89403152 25.90399551 25.89872932 25.91154099 25.89940834 25.89606285 25.91144562 25.90294838 25.90115547  25.894207 25.90701103 25.91085815 25.90177727 25.89836884 25.91271591 25.96912003 25.89555931 25.89793015 25.89320564 25.89967537 25.89441872 25.89474678 25.90074158 25.90100288 25.88777161 25.91552353 25.92297363 25.91077614 25.89575577 25.90336418 25.90205956 25.89542389 25.89704895 25.94751167 25.89446449 25.90816307 25.89453506 25.90659142 25.92649841 25.89329529 25.88690948 

-------
======================
selected experts : 15, 22, 38, 49, 56, 61, 
layer15_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deee4f80>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.211953 0.234548 -0.2150810.176693 -0.00234827 0.111494 -0.40818 0.163585 0.0598682]

layer15_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deee44b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.33721 0.0837894 -0.103631-0.140448 0.454261 0.105741 -0.0203833 0.126562 0.179933]

layer16_wq's input 
<N9nntrainer6TensorE at 0x5682def24710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.31761 0.218152 -0.219981-0.375548 0.953619 0.319948 -0.0516351 0.268658 0.409382]
==============================
layer16_wq's output 
<N9nntrainer6TensorE at 0x5682deee4360>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.618402 -0.131074 -0.5364070.337663 -0.519812 -0.376648 1.02457 0.418604 -0.127396]
============================
layer16_wk's input 
<N9nntrainer6TensorE at 0x5682def26470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.31761 0.218152 -0.219981-0.375548 0.953619 0.319948 -0.0516351 0.268658 0.409382]
==============================
layer16_wk's output 
<N9nntrainer6TensorE at 0x5682def261e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.42494 0.0491374 0.692216-1.36299 1.31172 0.350764 -1.39053 -0.210663 1.22936]
============================
layer16_wv's input 
<N9nntrainer6TensorE at 0x5682def27260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.31761 0.218152 -0.219981-0.375548 0.953619 0.319948 -0.0516351 0.268658 0.409382]
==============================
layer16_wv's output 
<N9nntrainer6TensorE at 0x5682def26ff0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.317676 0.0349983 -0.5024191.1096 -0.649026 -0.662572 0.484461 -0.665229 -0.147114]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.630711 0.0424935 0.194102-0.603385 0.555875 -0.321048 -0.470236 1.00192 0.693211]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a20924f8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer16_attention_out's input 
<N9nntrainer6TensorE at 0x5682def29710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer16_attention_out's output 
<N9nntrainer6TensorE at 0x5682def29670>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer16_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def2a790>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.33721 0.0837894 -0.103631-0.140448 0.454261 0.105741 -0.0203833 0.126562 0.179933]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.97402 0.23977 -0.261304-0.41508 1.14541 0.329869 -0.0595238 0.333967 0.453696]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.363337874 -1.736756444 -0.4215849638 1.753603697 -0.6389190555 -1.77861166 -0.2765093744 0.7122148871 -0.5134734511 -0.3759033382 -1.253976345 1.214964628 -0.7106405497 -0.3341830969 0.9082656503 -0.1438941211 -0.8174051046 -0.6503274441 -0.85016644 -0.2432413399 -0.9850304127 -2.22254467 -0.9448741674 0.2155602872 -1.159727931 -0.6424306035 -1.199065208 -0.3694017529 -0.7249289751 -2.222334862 -1.334394097 0.4562349319 -0.2326183468 -1.090725303 -0.700260818 -0.9060382843 -1.269330025 -2.373129845 -1.232488871 -0.5860313177 0.6837432384 -1.275163651 -2.348347187 -0.650632441 -0.553194344 -1.861816406 -0.8980414271 0.5922238827 -0.8130593896 -0.6252757907 -1.020447969 -0.6618753672 -0.5517811775 -0.8442652822 -2.194777489 -0.3334437609 -0.532897532 -0.5412735343 -0.8869378567 -0.002399519086 -0.6179801226 -0.02949033678 -0.2771101594 -1.085317016 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005518888123 0.003799074795 0.01415303815 0.1246011481 0.01138839684 0.003643345786 0.01636270806 0.04397974163 0.01291049644 0.01481456496 0.00615668064 0.07270998508 0.01060020551 0.01544570737 0.05350525305 0.01868311316 0.009526803158 0.01125921216 0.009219747037 0.01691621915 0.008056536317 0.002337236889 0.008386641741 0.02676444873 0.006765163038 0.01134847756 0.006504205056 0.01491119713 0.01044982299 0.002337727463 0.005680958275 0.03404724225 0.0170968771 0.007248459384 0.01071080659 0.008718749508 0.006062875036 0.002010501223 0.00629040366 0.01200691797 0.04274522141 0.006027609576 0.002060950501 0.0112557793 0.0124077322 0.003352471162 0.008788751438 0.03900688142 0.009568292648 0.01154483669 0.007776187733 0.011129939 0.01242527831 0.009274316952 0.00240304484 0.01545712817 0.01266214345 0.01255652681 0.008886882104 0.02152283676 0.01162937097 0.0209475942 0.01635288075 0.00728776725 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
23.53619194 23.52541542 23.54482651 23.65527534 23.53157425 23.53479385 23.54751396 23.56702614 23.53786469 23.54596519 23.53492546 23.60290718 23.54127502 23.54373741 23.57369041 23.54029846 23.53924751 23.53955078 23.53894043 23.54711342 23.53253365 23.53348732 23.53906059 23.55696106 23.53743935 23.53487206 23.53622437 23.54606247 23.54112434 23.53110695 23.53635406 23.56424522 23.54634285 23.53744507 23.54043198 23.53939247 23.53340149  23.533638 23.53744125 23.54172707 23.57294273 23.53336525 23.53225899 23.54145241 23.54117584 23.5325985 23.53946304 23.56920433 23.54024315 23.54079056 23.53463745 23.5422802 23.5397625 23.53184319 23.53355408 23.54708481 23.54333687 23.53846359 23.53860664 23.55171967 23.54230309 23.55066872 23.54750443 23.53891563 

-------
======================
selected experts : 3, 7, 11, 14, 40, 47, 
layer16_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def2d9d0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.06765 0.135349 0.03424350.176277 0.000973045 0.105585 0.174205 0.0174802 -0.465571]

layer16_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def2d090>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.40486 0.219138 -0.06938780.0358294 0.455234 0.211325 0.153822 0.144042 -0.285638]

layer17_wq's input 
<N9nntrainer6TensorE at 0x5682def6d870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8694 0.49753 -0.1226780.0816931 0.752081 0.563501 0.358153 0.244927 -0.532607]
==============================
layer17_wq's output 
<N9nntrainer6TensorE at 0x5682def2cf40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0256799 0.0705974 0.1823790.217593 0.266656 -0.00630807 -0.365624 -0.29495 -0.195453]
============================
layer17_wk's input 
<N9nntrainer6TensorE at 0x5682def6f5d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8694 0.49753 -0.1226780.0816931 0.752081 0.563501 0.358153 0.244927 -0.532607]
==============================
layer17_wk's output 
<N9nntrainer6TensorE at 0x5682def6f340>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.17511 -0.059102 1.942110.653518 0.191876 0.562744 -1.34005 -0.450133 0.671633]
============================
layer17_wv's input 
<N9nntrainer6TensorE at 0x5682def703c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8694 0.49753 -0.1226780.0816931 0.752081 0.563501 0.358153 0.244927 -0.532607]
==============================
layer17_wv's output 
<N9nntrainer6TensorE at 0x5682def70150>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.94471 -1.1771 0.439853-0.419611 0.35281 -0.0350813 -0.527458 -0.84754 -1.3832]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0353856 -0.0662669 -0.279557-0.0495637 -0.102974 0.246052 0.313187 -0.35013 -0.26748]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2297508
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer17_attention_out's input 
<N9nntrainer6TensorE at 0x5682def72870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer17_attention_out's output 
<N9nntrainer6TensorE at 0x5682def727d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer17_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def738f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.40486 0.219138 -0.06938780.0358294 0.455234 0.211325 0.153822 0.144042 -0.285638]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.91587 0.550459 -0.1555270.0906932 1.02477 0.567585 0.389361 0.34095 -0.634713]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.02730626427 -1.069718957 -1.153170466 1.221750617 -2.066622972 -0.6677621007 -0.7245548368 -0.7949968576 -0.4414895177 -1.43932271 -1.94204855 -0.9670998454 0.1795118153 -0.2821341157 -0.05507342517 -0.2822469175 0.2484291792 -1.22727263 -0.05082730949 -1.032768846 -1.087264657 -1.23376894 -1.694174886 0.5322695971 -1.270576835 -0.889942646 -0.7890108824 -1.251397491 1.160098314 -0.435328722 -1.485999465 -0.008478671312 -1.682764173 -2.35131669 -0.5163273811 -0.3666296601 -0.8657974005 -1.863427281 -1.073807955 -0.5735812187 -1.754856706 -0.1780351698 -1.234422684 0.2845253944 -2.078668356 -0.7848764062 0.08920755982 -0.5364621878 -1.624352455 -0.9305257797 -1.41782701 -1.152937055 -0.9347455502 -0.1895541549 1.260882735 0.2797592282 -0.7419340014 -0.0863994956 -0.2757208943 -1.148961782 -1.375760078 0.1735088974 -0.2640367746 -0.1926818788 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0220124498 0.007761654444 0.007140222937 0.07675857842 0.002864207374 0.0116017079 0.0109611759 0.01021561678 0.01454758272 0.005363366567 0.003244190244 0.008600451984 0.02707000449 0.01706074737 0.0214096345 0.01705882326 0.02900138684 0.006630245596 0.02150073647 0.00805381313 0.007626658771 0.006587312091 0.004156775307 0.03852025047 0.006349256262 0.00929030776 0.0102769509 0.006472205743 0.07216915488 0.01463748515 0.005118774716 0.02243081853 0.004204478581 0.002154584508 0.01349861547 0.01567841321 0.009517355822 0.003509547794 0.007729982957 0.01274747588 0.003912035376 0.01893248782 0.006583007518 0.03006735072 0.002829913748 0.01031952724 0.02473259531 0.01322954148 0.004457383417 0.008920826018 0.005479903426 0.007141890004 0.008883263916 0.01871565729 0.07982184738 0.02992438525 0.01077232696 0.02074935101 0.01717051305 0.007170338184 0.005715342704 0.02690799162 0.01737231202 0.01865720935 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
22.12599373 22.11984825 22.12065887 22.18264771 22.11352158 22.11892128 22.12447929 22.12373352 22.12758827 22.11888123 22.11485481 22.12164116 22.13248062 22.12962532 22.13445091 22.13105392  22.142519 22.12062454 22.12119102 22.12109566 22.11733055 22.11533737 22.11528969 22.14917755 22.11939049 22.11851692 22.12427139 22.1199894 22.17710304 22.12672424 22.11816025 22.13547134 22.11676788 22.11567307 22.12701607 22.1206131 22.12255859 22.11655045 22.11791039 22.12578773 22.11742973 22.12482071 22.12010002 22.13977051 22.10824203 22.12431335 22.13491249 22.12674713 22.11320686 22.12243843 22.11899757 22.12018204 22.1033268 22.12412643 22.18761826 22.14010429 22.1247673 22.13045311 22.12878036 22.11591911 22.11875534 22.1399498 22.13136673 22.12979126 

-------
======================
selected experts : 3, 23, 28, 43, 54, 55, 
layer17_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def76b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.253826 -0.0186747 0.03773680.0680806 -0.473988 0.129516 -0.478414 0.0785916 -0.034919]

layer17_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def761f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.65869 0.200463 -0.03165090.10391 -0.0187538 0.340841 -0.324593 0.222634 -0.320557]

layer18_wq's input 
<N9nntrainer6TensorE at 0x5682defb6420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.10791 0.463276 -0.06257080.239174 -0.0339414 0.879432 -0.750142 0.394667 -0.64561]
==============================
layer18_wq's output 
<N9nntrainer6TensorE at 0x5682def760a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.10673 -0.153221 0.5897311.9506 1.29427 -2.68213 1.67582 1.40147 -1.31853]
============================
layer18_wk's input 
<N9nntrainer6TensorE at 0x5682defb8180>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.10791 0.463276 -0.06257080.239174 -0.0339414 0.879432 -0.750142 0.394667 -0.64561]
==============================
layer18_wk's output 
<N9nntrainer6TensorE at 0x5682defb7ef0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.28275 1.297 -0.2089410.677472 1.33644 0.660171 -0.293485 1.65407 -1.16858]
============================
layer18_wv's input 
<N9nntrainer6TensorE at 0x5682defb8f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.10791 0.463276 -0.06257080.239174 -0.0339414 0.879432 -0.750142 0.394667 -0.64561]
==============================
layer18_wv's output 
<N9nntrainer6TensorE at 0x5682defb8d00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.591238 0.102822 -0.5731520.478514 0.657506 -1.73205 0.866751 -0.900636 0.185941]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-2.06402 0.448989 -1.70514-1.11584 1.92125 2.27547 -1.485 1.60227 -2.35555]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a249c518
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer18_attention_out's input 
<N9nntrainer6TensorE at 0x5682defbb420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer18_attention_out's output 
<N9nntrainer6TensorE at 0x5682defbb380>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer18_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682defbc4a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.65869 0.200463 -0.03165090.10391 -0.0187538 0.340841 -0.324593 0.222634 -0.320557]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.45462 0.491184 -0.07108980.258463 -0.0421222 0.885759 -0.807382 0.516579 -0.711064]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.062613368 -0.3103205264 -0.813877821 -0.05949025229 -1.83977294 -2.380988598 -1.19530642 0.3794342577 0.3779788911 -2.770207644 0.5257703662 -2.53913641 -0.9748841524 -1.182571411 -2.624329329 -1.193560004 0.9496892095 0.1868463457 -0.9716626406 -0.2941969931 -0.9582231045 0.3939257562 -1.022436738 -0.07888153195 -1.747231841 -0.07336111367 -0.8625987768 0.2567335069 -2.161632538 0.2967662215 -0.8609887362 1.667371035 0.07463056594 -0.2470603138 -0.6184720993 -0.4640968144 -1.307123542 -0.8273018599 -1.310783267 -0.7721133828 0.4477494657 -1.912881017 -0.8133640289 1.033631086 -0.767663002 0.2045336962 -0.9569313526 -1.185732603 1.950773239 -0.01261408255 -1.979505777 -1.264241338 0.571731925 -0.2704636157 -0.9788761139 0.2174901217 -0.8327384591 -1.441499591 -1.883395791 -1.240181923 0.1753808558 -0.3174679875 -0.3530494571 0.9615533352 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005993448198 0.01271725539 0.00768601615 0.01634284481 0.002755248221 0.001603665296 0.005248666741 0.02534837648 0.02531151287 0.00108662108 0.02934290655 0.001369086909 0.006543003954 0.005315935705 0.001257280237 0.005257840268 0.04483412579 0.02090789378 0.006564116571 0.01292396523 0.006652929354 0.02571838722 0.006239148788 0.01602898911 0.003022391582 0.01611771993 0.007320521399 0.02242135629 0.001997003565 0.02333715372 0.007332318462 0.09189544618 0.01868855022 0.0135477446 0.009344690479 0.01090458781 0.004693397786 0.00758352736 0.004676252604 0.00801381655 0.02714057639 0.002561004367 0.007689965889 0.0487600565 0.008049559779 0.02128098905 0.006661529187 0.005299157463 0.12200398 0.01712717302 0.002395937452 0.004899039865 0.03072302416 0.01323436294 0.006516935769 0.02155850641 0.007542411797 0.004103255458 0.002637640573 0.005018336698 0.02066954225 0.0126266852 0.01218530722 0.04536921531 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
24.21902084 24.21716309 24.21976089 24.22603226 24.21578407 24.21510887 24.21827698 24.23885345 24.2373867 24.21459198 24.23855591 24.21392059 24.21766281 24.21691322 24.21476173 24.21828651 24.2502327 24.2325058 24.21863747 24.22547531 24.2134819 24.23207092 24.21926689 24.22858047 24.21557426 24.22771454 24.21939468 24.22829628 24.19928932 24.23636436 24.21892929 24.30540085 24.23028564 24.21846962 24.22237206 24.22345543 24.21819878 24.20630646 24.2167511 24.22008896 24.23969078 24.21558952 24.21976471 24.26131058 24.2215538 24.23001671 24.2168293 24.21689606 24.33503151 24.22920227 24.21542358 24.21840477 24.23469162 24.22626305 24.2200222 24.23124886 24.22056961 24.21713066 24.21566582 24.21804619 24.23083687 24.22470093 24.22473717 24.25839806 

-------
======================
selected experts : 16, 31, 43, 48, 52, 63, 
layer18_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682defbf6e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.560586 0.0277587 -0.1215660.0890109 -0.0883643 -0.106343 -0.0221612 0.0365498 -0.135021]

layer18_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682defbeda0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.21927 0.228222 -0.1532170.192921 -0.107118 0.234498 -0.346754 0.259184 -0.455578]

layer19_wq's input 
<N9nntrainer6TensorE at 0x5682deffefd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.33037 0.452046 -0.2608050.377646 -0.173219 0.522538 -0.68146 0.419121 -0.835404]
==============================
layer19_wq's output 
<N9nntrainer6TensorE at 0x5682defbec50>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0782116 -0.28653 -0.0172082-0.619468 -0.0762679 -0.593608 0.282658 -0.80718 -0.135468]
============================
layer19_wk's input 
<N9nntrainer6TensorE at 0x5682df001130>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.33037 0.452046 -0.2608050.377646 -0.173219 0.522538 -0.68146 0.419121 -0.835404]
==============================
layer19_wk's output 
<N9nntrainer6TensorE at 0x5682df001100>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.05797 -0.676246 0.9896371.00173 0.42944 -0.338087 0.795811 1.07648 -0.594723]
============================
layer19_wv's input 
<N9nntrainer6TensorE at 0x5682df002000>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.33037 0.452046 -0.2608050.377646 -0.173219 0.522538 -0.68146 0.419121 -0.835404]
==============================
layer19_wv's output 
<N9nntrainer6TensorE at 0x5682df001d90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.917758 -0.238449 -0.2498290.0371437 1.04362 0.315361 0.489691 0.719257 0.336181]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.117864 0.272625 0.4111870.463639 0.573115 0.172415 0.791738 0.323396 0.452674]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a28a6538
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer19_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0044b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer19_attention_out's output 
<N9nntrainer6TensorE at 0x5682df004410>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer19_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df005580>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.21927 0.228222 -0.1532170.192921 -0.107118 0.234498 -0.346754 0.259184 -0.455578]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.9355 0.480299 -0.3034820.411978 -0.209686 0.522538 -0.756582 0.517384 -0.891803]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2560965121 0.5607023835 1.380713105 -1.156835437 -1.137527227 -0.9903067946 -1.374790668 -1.243409276 -1.533348918 -1.82641983 -0.8730707169 0.501588583 -1.044003844 -0.9129401445 -1.779503822 -2.349038363 -1.573071957 0.2331105024 -1.77170682 -1.189740181 -0.1851579547 -0.1333834082 0.828663528 -0.5412015915 -0.8152538538 -1.159140587 -1.81690979 -0.7082381845 0.1524386406 -0.7536927462 -0.3860671818 -0.6523693204 -0.5111266375 -1.121736884 -0.5304392576 -0.4721988142 0.4311973155 -0.5876043439 1.234532952 -0.3707628846 -1.116874456 -0.5162636638 -1.205090284 -0.6366769671 -1.703146935 -0.2628949583 -1.272262096 -0.930413425 -0.8881460428 -0.6206386685 -0.490003556 -0.1590138078 -0.4007500708 -0.7877420187 -1.791340947 -0.6367516518 -0.6509783864 -1.25172472 -0.5542578101 -0.6510242224 0.4458911121 1.347165823 -1.530253649 -2.132788897 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01686263829 0.03816425428 0.08665286005 0.006850772537 0.006984333508 0.008092115633 0.005509127863 0.006282622926 0.004701341968 0.003507056739 0.00909865275 0.03597360477 0.007669052109 0.008743029088 0.003675514599 0.00207956438 0.0045182514 0.02750333957 0.003704283852 0.006629019044 0.01810229942 0.01906422339 0.04989198968 0.01267961133 0.009640211239 0.006834999658 0.003540568054 0.01072908845 0.02537173033 0.01025232114 0.01480743941 0.01134557184 0.01306674257 0.007095494773 0.01281681098 0.0135854315 0.03352844343 0.01210468449 0.07486824691 0.01503579877 0.007130078971 0.01299979072 0.006528038532 0.01152501628 0.003967158496 0.01674838737 0.006103943102 0.008591587655 0.00896251481 0.01171134692 0.01334568765 0.01858180761 0.01459161192 0.009909112938 0.00363226328 0.01152415574 0.01136136334 0.00623059785 0.01251513977 0.0113608446 0.03402474523 0.08379410952 0.004715915769 0.002581596142 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.26359749 26.27917671 26.32623482 26.25310898 26.25419617 26.24576759 26.25081253 26.25301743 26.25143623 26.25024223 26.25011063 26.28175545 26.25297356 26.25547791 26.25041008 26.24929047 26.25125313 26.27137756 26.24996185 26.25288773 26.2653141 26.26532173 26.29138184 26.25798416 26.2568512 26.25357056 26.25027466 26.25698662 26.27162933 26.25460243 26.2620182 26.25855637 26.2602787 26.25430679 26.25764465 26.25936699 26.27835655 26.25645447 26.32160378 26.25366402 26.25386429 26.25973511 26.25326347 26.2553978 26.24450302 26.26348305 26.25283813 26.25532532 26.25474358 26.25415421 26.2596035 26.26436234  26.260849 26.2528286 26.23701477 26.25873566 26.25761986 26.25344276 26.25972748 26.25332642 26.28123665 26.32814407 26.25144958 26.24836159 

-------
======================
selected experts : 1, 2, 11, 22, 38, 61, 
layer19_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df008b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.302106 0.0097258 -0.285841-0.0748007 -0.230624 -0.0890906 -0.0904621 -0.372348 0.37356]

layer19_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df008060>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.52138 0.237948 -0.4390580.11812 -0.337743 0.145408 -0.437216 -0.113164 -0.082018]

layer20_wq's input 
<N9nntrainer6TensorE at 0x5682df047b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60653 0.37066 -0.6731660.17748 -0.470188 0.233641 -0.678386 -0.149907 -0.118205]
==============================
layer20_wq's output 
<N9nntrainer6TensorE at 0x5682df007f10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.07461 -0.517926 -0.684738-0.743797 1.84935 0.4878 1.43956 -0.376304 1.23786]
============================
layer20_wk's input 
<N9nntrainer6TensorE at 0x5682df0498e0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60653 0.37066 -0.6731660.17748 -0.470188 0.233641 -0.678386 -0.149907 -0.118205]
==============================
layer20_wk's output 
<N9nntrainer6TensorE at 0x5682df049650>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.186323 -1.42675 1.10225-1.13125 -0.496273 0.775429 0.251476 0.979608 0.500795]
============================
layer20_wv's input 
<N9nntrainer6TensorE at 0x5682df04a6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60653 0.37066 -0.6731660.17748 -0.470188 0.233641 -0.678386 -0.149907 -0.118205]
==============================
layer20_wv's output 
<N9nntrainer6TensorE at 0x5682df04a460>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.877532 -0.0883245 0.607350.314175 0.0202026 0.753049 -1.47165 -0.321368 0.507924]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.13695 0.361094 1.002590.130032 -1.19951 1.48971 0.302507 1.45686 1.70167]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2cb0558
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer20_attention_out's input 
<N9nntrainer6TensorE at 0x5682df04cb80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer20_attention_out's output 
<N9nntrainer6TensorE at 0x5682df04cae0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer20_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df04dc00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.52138 0.237948 -0.4390580.11812 -0.337743 0.145408 -0.437216 -0.113164 -0.082018]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.95207 0.41152 -0.7270190.205732 -0.546827 0.263961 -0.782959 -0.187384 -0.133798]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4138334095 -0.7941479683 -0.9165152907 -2.569709539 -1.421836019 -0.1668744236 -0.9031383395 -2.294758081 -1.237062454 -0.1760980487 -0.3693721592 -0.1580355465 -1.632927299 0.4013758898 -1.187618256 -0.1161043495 -0.6882314682 -0.03248381615 -0.8780407906 -0.3582237363 0.6017161012 -2.62579751 -0.9137005806 -0.3008619547 -1.031279802 -0.5180200934 -0.8078605533 0.3422093987 -1.578213811 -0.4726060033 -0.7385864258 -0.6835306287 -0.1002677679 -1.033990622 0.3952358961 -1.323274851 0.8766098619 1.240920305 -0.342014432 -0.6332079172 -1.222097993 -0.6673287749 -1.852769852 -1.920262098 -0.04423336685 -0.7442017794 -1.4834162 0.1318867505 1.003386855 0.03271181881 -0.3037775457 -2.032606363 -1.716417551 0.04686329514 -0.2210749388 -1.228260994 -0.8499057293 -0.2385745198 -0.2812626958 -0.5164778829 -0.6176597476 -0.6172142625 -0.09065865725 -1.061925769 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01473560743 0.01007394399 0.008913659491 0.00170640822 0.005377717782 0.01886344329 0.009033697657 0.002246429678 0.006469104905 0.01869025268 0.01540555339 0.01903091371 0.004354340024 0.03329729289 0.006797004491 0.01984586939 0.01119949669 0.02157675289 0.009263291024 0.01557826251 0.04068324715 0.001613333821 0.008938784711 0.01649798453 0.007947205566 0.01327762194 0.00993674621 0.03138435632 0.004599218257 0.01389451697 0.0106495088 0.01125226822 0.02016266063 0.007925692014 0.03309347481 0.005934752524 0.053555049 0.07709362358 0.01583283208   0.011833 0.006566638593 0.01143605821 0.00349498936 0.003266888903 0.02132471837 0.01058987528 0.005056547001 0.02543145977 0.06079375744 0.0230303295 0.01644995436 0.002919737948 0.004005557392 0.0233585611 0.01786824688 0.006526293699 0.009527615272 0.01755828224 0.01682452485 0.01329811662 0.0120184198 0.01202377584 0.02035734057 0.007707351353 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.40888786 25.40517998 25.40592575 25.39919662 25.40143585 25.41635323 25.40127754 25.39925957 25.40348244 25.40950394 25.41194153 25.41318321 25.40136719 25.42983246 25.4038105 25.41542816 25.40249062 25.41286659 25.40436935 25.41163635 25.43769646 25.39862633 25.40070534 25.41208076 25.40162277 25.41028976 25.40218163 25.42791939 25.39588928 25.41090775 25.40766144  25.408741 25.41622162 25.40398407 25.43010712 25.40247154 25.45056725 25.46504593 25.40855408 25.40693855 25.40357971 25.40701866 25.39859962 25.40075684 25.41690636 25.40807915 25.40206909 25.42244339 25.4573288 25.41956711 25.41107941 25.39993286 25.38671303 25.42037201 25.41392708 25.40258598 25.40701675 25.4112339 25.41145325 25.40697289 25.4076004 25.40760612 25.41260147 25.39995193 

-------
======================
selected experts : 13, 20, 34, 36, 37, 48, 
layer20_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df050e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.27992 -0.123736 0.109519-0.0913493 0.248634 0.13094 0.216233 -0.0920996 0.00966147]

layer20_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df050500>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.24146 0.114212 -0.3295390.026771 -0.0891088 0.276347 -0.220983 -0.205264 -0.0723565]

layer21_wq's input 
<N9nntrainer6TensorE at 0x5682df091030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.96238 0.168701 -0.4394620.0374619 -0.117234 0.439588 -0.314518 -0.266368 -0.100819]
==============================
layer21_wq's output 
<N9nntrainer6TensorE at 0x5682df0503b0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.15064 0.0532157 -0.042246-0.203928 0.30255 -0.100603 -0.534653 -0.137248 0.0665243]
============================
layer21_wk's input 
<N9nntrainer6TensorE at 0x5682df092d90>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.96238 0.168701 -0.4394620.0374619 -0.117234 0.439588 -0.314518 -0.266368 -0.100819]
==============================
layer21_wk's output 
<N9nntrainer6TensorE at 0x5682df092b00>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0929967 -0.866341 0.09207010.728006 0.901695 1.11479 1.49877 -0.121993 -0.628814]
============================
layer21_wv's input 
<N9nntrainer6TensorE at 0x5682df093b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.96238 0.168701 -0.4394620.0374619 -0.117234 0.439588 -0.314518 -0.266368 -0.100819]
==============================
layer21_wv's output 
<N9nntrainer6TensorE at 0x5682df093910>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.24552 -1.54342 0.110974-0.205941 -1.38733 0.791705 -0.401286 -0.701056 -0.336938]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.141622 -0.0739414 0.1633940.129127 -0.0315108 0.317277 0.164296 -0.52697 -0.50531]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1f8fcf0
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer21_attention_out's input 
<N9nntrainer6TensorE at 0x5682df096030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer21_attention_out's output 
<N9nntrainer6TensorE at 0x5682df095f90>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer21_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0970b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.24146 0.114212 -0.3295390.026771 -0.0891088 0.276347 -0.220983 -0.205264 -0.0723565]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.79932 0.206266 -0.5754390.0486684 -0.15347 0.528828 -0.417595 -0.360885 -0.124618]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1783123165 -0.29889974 -0.5538125634 0.3373761773 -0.472266376 -0.7141254544 -1.454328179 0.2542715371 -0.7339566946 -1.226141095 -1.311332822 -0.9130453467 -0.2845664322 0.2438750714 -0.8389728665 -1.112065434 -0.823212266 -0.7511786819 -0.5577736497 -0.945778966 -2.06117177 -0.1704679281 -0.1381780356 -1.486085892 -0.07875689864 -0.2048711777 0.07434412837 -0.4823636711 -0.7482740283 -2.119517803 -0.8294374347 -1.46167469 -1.50707984 -0.399132967 -0.5167472959 -1.082633853 -0.6440500021 0.2263461798 -1.25105834 2.997587919 -0.533398509 -0.1614771187 -0.9952273965 -1.202630043 -0.3438590467 -1.079587579 -0.7780657411 -1.948967695 -0.2780954838 -0.7075446844 -0.2848754823 -1.309324741 -0.4318304956 -1.394148946 -0.9812729359 1.677747846 -0.4324631393 -0.1824264973 -0.516405642 0.2792288959 -0.6079953313 0.2241086811 -0.6234211326 -0.5771641731 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01918534376 0.01190471742 0.009225965478 0.02249314077 0.01000983268 0.007859389298 0.003749063471 0.02069942281 0.007705063559 0.004710024688 0.004325386137 0.006441676989 0.0120765781 0.02048533782 0.006936945021 0.005279169418 0.007047140971 0.007573502138 0.009189493023 0.006234230939 0.00204349705 0.01353618503 0.01398039889 0.003631872125 0.01483630948 0.01307841484 0.01729086787 0.0099092694 0.007595532574 0.001927679172 0.00700340746 0.003721621353 0.003556420328 0.01076931972 0.009574345313 0.005436854437 0.008429896086 0.02012938447 0.004594114609 0.3216365874 0.009416241199 0.01365843415 0.005933457054 0.004822073504 0.01138134208 0.005453440361 0.007372586988 0.002286144067 0.01215497777 0.00791128166 0.01207284816 0.004334082361 0.01042288635 0.003981606103 0.006016835105 0.0859342292 0.01041629259 0.01337527577 0.009577617049 0.02122252807 0.008739378303 0.02008439414 0.008605599403 0.009013019502 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.65747643 25.65019608 25.64703941 25.66030693 25.64639282 25.64567375 25.64204025 25.65660477 25.64551926 25.64204597 25.63164902 25.63567162 25.64655304 25.65639114 25.64522743 25.64309311 25.64533806 25.64586449 25.64461899 25.64452553 25.63985634 25.65182686 25.65179443 25.64049149 25.65312576 25.65041542 25.65510368 25.64676857 25.64588547 25.64021873 25.64529419 25.64058113 25.64089394 25.64858246 25.64643478 25.64277267 25.64672089 25.65794373 25.64050102 25.95897293 25.64770699 25.65194893 25.64279366 25.64263535 25.64538002 25.64326668 25.64566231 25.64010048 25.64520073 25.64334106 25.65036392 25.6388092 25.64060783 25.64227295 25.64430809 25.72231674 25.64346123 25.6511879 25.63976097 25.65903664 25.64559937 25.65789795 25.64498901 25.64634895 

-------
======================
selected experts : 3, 7, 13, 39, 55, 59, 
layer21_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df09a2f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.643184 0.222712 -0.7929290.183264 0.747842 0.786664 0.0493223 0.199264 -0.0933151]

layer21_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df0999b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.88464 0.336924 -1.122470.210035 0.658733 1.06301 -0.171661 -0.00599937 -0.165672]

layer22_wq's input 
<N9nntrainer6TensorE at 0x5682df0d9be0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.15133 0.400246 -1.261070.249509 0.755238 1.36069 -0.190486 -0.00662968 -0.19986]
==============================
layer22_wq's output 
<N9nntrainer6TensorE at 0x5682df099860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.546149 1.16361 0.626299-1.24008 -0.672939 1.76016 -0.502856 -0.075978 -2.78427]
============================
layer22_wk's input 
<N9nntrainer6TensorE at 0x5682df0db940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.15133 0.400246 -1.261070.249509 0.755238 1.36069 -0.190486 -0.00662968 -0.19986]
==============================
layer22_wk's output 
<N9nntrainer6TensorE at 0x5682df0db6b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.747404 2.64771 1.071541.4648 -1.04922 -0.578845 1.52732 -0.831963 -0.0360067]
============================
layer22_wv's input 
<N9nntrainer6TensorE at 0x5682df0dc730>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.15133 0.400246 -1.261070.249509 0.755238 1.36069 -0.190486 -0.00662968 -0.19986]
==============================
layer22_wv's output 
<N9nntrainer6TensorE at 0x5682df0dc4c0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.654865 0.853878 0.4372470.199922 -0.88083 0.138692 0.835335 -0.370026 0.868068]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.704892 -1.07489 0.3168051.35266 -1.33278 -1.33219 0.101487 -0.498335 0.830847]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a30ba578
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer22_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0debe0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer22_attention_out's output 
<N9nntrainer6TensorE at 0x5682df0deb40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer22_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0dfc60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.88464 0.336924 -1.122470.210035 0.658733 1.06301 -0.171661 -0.00599937 -0.165672]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.43586 0.511943 -1.66420.315271 0.952389 1.69352 -0.265574 -0.00895006 -0.239526]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7397916913 -0.4645708799 -1.015678048 -0.1586270481 2.572156906 -1.184009671 0.1542642117 -0.7809244394 1.002029419 -0.7511141896 -0.4391508102 -0.6108403206 -0.4246154726 -1.049105287 -0.07224667072 -0.260074079 -1.30487287 0.001101973467 -1.751760244 -0.5972699523 0.02286567539 2.529406548 -1.568264842 0.06576365978 -2.270291805 -1.031431913 -0.950517118 -0.2471860498 -0.7377126217 -1.35686934 -1.336291909 -1.579776406 -0.5386202931 -0.6078422666 -0.1715735197 -2.634065151 -0.8631902933 0.9276689887 1.088684678 -0.5127094984 0.7183439732 -0.5988658071 0.1742632091 -0.2389595211 -0.3931342363 -0.6965096593 -1.324651122 -0.9061495662 -1.457275152 -0.810759604 -0.3742614985 -1.45335412 -0.3097060919 -0.9273035526 -1.475761294 -0.845074892 -1.814042211 -0.7738408446 -0.5757521391 0.7166854739 -0.4288810194 -0.4447434545 0.2580054104 -1.245664835 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006957845762 0.009162238799 0.005280303769 0.01244146097 0.1909131259 0.004462245386 0.01701211557 0.006677457131 0.03971349075 0.006879509892 0.009398129769 0.007915486582 0.00953573361 0.00510671502 0.01356394216 0.01124121994 0.003954240587 0.01459623408 0.002529195044 0.008023634553 0.01491738483 0.1829235107 0.003038599156 0.01557123382 0.001505868393 0.005197769962 0.005635829642 0.01138703711 0.006972326431 0.003753888886 0.003831934649 0.003003821475 0.008508292958 0.007939253934 0.01228142437 0.001046651974 0.006150119007 0.0368675068 0.04330838472 0.008731628768 0.0299043972 0.008010840975 0.01735576615 0.01148109697 0.009840706363 0.007265607361 0.003876801115 0.005891507491 0.003395279869 0.006481176242 0.01002819091 0.003408620367 0.01069691405 0.00576818781 0.00333309127 0.006262545008 0.0023764777 0.006724923849 0.008198156022 0.02985484339 0.00949514471 0.009345716797 0.01887176558 0.004195433576 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.01233864 27.01454353 27.00875282 27.01639175 27.19676971 27.00459862 27.02096176 27.01062775 27.04557037 27.0117836 27.01525497 27.01329613 27.01491547 27.01000977 27.01608276 27.01709938 27.00933456 27.02045441 27.00838661 27.00720596 27.01886749 27.1883049 27.00889587 27.01523018 27.00736427 27.01057816 27.01149368 27.01533699 27.01187706 27.00961113 27.00921249 27.00695419 27.01102829 27.01379585 27.00764847 27.00404358 27.00676155 27.03652573 27.04296684 27.01220512 27.03528595 27.01196098 27.0227356 27.01686096 27.01569748 27.01121521 27.00973511 27.01031876 27.00925255 27.01233864 27.01588631 27.00735855 27.01083183 27.01162529 27.00871277 27.01116562 27.00823402 27.00876808 27.01405525 27.03523636 27.01296806 27.01520348 27.02425194 27.01005363 

-------
======================
selected experts : 4, 8, 21, 37, 38, 40, 
layer22_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df0e2e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.488194 0.377901 0.466394-0.0167934 -0.273322 0.297149 -0.392417 -0.31235 -0.740184]

layer22_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dde69cd0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.39645 0.714826 -0.6560750.193241 0.385411 1.36016 -0.564077 -0.318349 -0.905855]

layer23_wq's input 
<N9nntrainer6TensorE at 0x5682de368560>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88793 0.625983 -0.5816860.159394 0.345913 1.2603 -0.483722 -0.260274 -0.776812]
==============================
layer23_wq's output 
<N9nntrainer6TensorE at 0x5682de2bfbc0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.81287 2.46712 -3.204050.161744 -0.160598 2.96982 -1.30325 1.66376 -2.68029]
============================
layer23_wk's input 
<N9nntrainer6TensorE at 0x5682de266760>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88793 0.625983 -0.5816860.159394 0.345913 1.2603 -0.483722 -0.260274 -0.776812]
==============================
layer23_wk's output 
<N9nntrainer6TensorE at 0x5682de82d610>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.31819 1.55241 -2.13453-1.49608 -1.32869 1.37024 -0.700615 -1.14271 -0.10444]
============================
layer23_wv's input 
<N9nntrainer6TensorE at 0x5682de40ebf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88793 0.625983 -0.5816860.159394 0.345913 1.2603 -0.483722 -0.260274 -0.776812]
==============================
layer23_wv's output 
<N9nntrainer6TensorE at 0x5682de7736d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0659388 0.12311 0.4507320.32833 -1.39694 -0.600461 -0.907153 -1.79537 1.35136]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-2.14289 -2.1866 2.35133-2.18251 -2.64622 -1.35764 -1.59524 -1.38628 1.1737]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a32bf588
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer23_attention_out's input 
<N9nntrainer6TensorE at 0x5682ddf81aa0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer23_attention_out's output 
<N9nntrainer6TensorE at 0x5682de55e330>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer23_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0fe910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.39645 0.714826 -0.6560750.193241 0.385411 1.36016 -0.564077 -0.318349 -0.905855]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.82589 0.919493 -0.8343850.245761 0.487359 1.82868 -0.750179 -0.404871 -1.13889]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.872992158 0.2064440399 -1.035467386 -0.640977025 -0.1961841881 -0.1090170741 -0.34689942 -1.025684476 -0.8059713244 -1.519582868 -1.232269287 -0.7925223112 -0.03936348855 0.9528845549 -0.4500332177 1.322859287 0.7175119519 0.7044981122 1.78325367 -0.5533096194 -0.7680734396 -0.7863910198 -1.033133268 -0.03407310322 -1.032354474 -0.9097954631 -0.4200244546 -0.2161732614 -0.6270029545 -0.3525469303 -0.06292621791 0.7336152792 -0.673283577 0.5641796589 -0.1569390148 -0.8231748343 -0.2828865051 -0.728974402 -0.8087525368 -0.003392666578 -2.537916422 -1.832093239 0.2140242308 -2.572942972 -0.5260803699 -0.7155008912 -1.603597641 -0.6312178969 0.1997449249 -0.2652683854 -2.51944685 -1.796715975 2.482131004 -0.3266799748 -0.3935008347 -1.422336698 -0.2271452546 -0.5259958506 -0.9059403539 0.8565720916 -0.8876277208 -1.621199846 -0.04766143113 -1.352401018 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.002359084319 0.01887257025 0.005450995173 0.008087249473 0.01261745673 0.01376664173 0.01085218042 0.00550458394 0.006857165601 0.003359132679 0.004477193113 0.00695001008 0.01475972496 0.03981127217 0.00978873577 0.05763470009 0.03146190196 0.03105511516 0.0913336426 0.008828241378 0.007122023962 0.006992754061 0.005463732872 0.01483801473 0.005467990413 0.006180937402 0.01008693594 0.01236775145 0.008201053366 0.01079106703 0.01441600733 0.03197265044 0.007830152288 0.02698942646 0.01312247664 0.006740206853 0.01156957727 0.00740600517 0.006838120986 0.01530030556 0.001213306561 0.002457568189 0.01901617274 0.001171544311 0.009071931243 0.007506465539 0.003088445636 0.008166558109 0.01874656416 0.01177521888 0.00123592373 0.002546067117 0.1837169975 0.01107383985 0.01035805792 0.003702206304 0.0122327935 0.009072699584 0.006204812787 0.03615581244 0.006319486536 0.003034558613 0.01463775244 0.003970390651 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.91904831 26.93460846 26.92214012 26.92429924 26.92739868 26.92997932 26.92611122 26.92171669  26.923069 26.92004776 26.92116547 26.92030144 26.93097115 26.95459366 26.9260006 26.97241592 26.94099808 26.94726753 27.00563812 26.92170334 26.92333412 26.92320442 26.92215347 26.93152618 26.92215729 26.92144012 26.92439079 26.92905617 26.92489052 26.92652702 26.93015099 26.94627762 26.92118073 26.94034004 26.92838097 26.92247581 26.9282589 26.92314148 26.92304993 26.92817497 26.91504097 26.91866875 26.93570518 26.91690636 26.92480659 26.92371941 26.91643906 26.92008781 26.93495941 26.9260807 26.91792488 26.91875839 27.10040665 26.92633247 26.92323303 26.91848373 26.92749214 26.91908646 26.92241669 26.95189095 26.92300797 26.91733932 26.93132591 26.91922951 

-------
======================
selected experts : 13, 15, 18, 31, 52, 59, 
layer23_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee1eb60>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.506976 0.458975 -0.696784-1.91816 -0.823732 0.977666 0.0765063 1.047 0.0117463]

layer23_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de7806d0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.90343 1.1738 -1.35286-1.72492 -0.43832 2.33783 -0.487571 0.728649 -0.894109]

layer24_wq's input 
<N9nntrainer6TensorE at 0x5682de5e9620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.51394 0.90817 -1.07843-1.27391 -0.357113 1.82248 -0.362945 0.518912 -0.686532]
==============================
layer24_wq's output 
<N9nntrainer6TensorE at 0x5682de23a580>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.47825 -0.488654 0.184464-0.519587 0.487288 -0.0527524 -0.216239 0.226775 -0.161041]
============================
layer24_wk's input 
<N9nntrainer6TensorE at 0x5682de680bc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.51394 0.90817 -1.07843-1.27391 -0.357113 1.82248 -0.362945 0.518912 -0.686532]
==============================
layer24_wk's output 
<N9nntrainer6TensorE at 0x5682de1e9fa0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00326021 1.4771 1.20550.866987 -0.189965 0.885759 -0.672452 0.556131 0.303197]
============================
layer24_wv's input 
<N9nntrainer6TensorE at 0x5682de7cdb70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.51394 0.90817 -1.07843-1.27391 -0.357113 1.82248 -0.362945 0.518912 -0.686532]
==============================
layer24_wv's output 
<N9nntrainer6TensorE at 0x5682de067420>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.291303 3.60319 -1.58111-0.0753707 2.08941 -3.37433 2.6696 -1.44074 0.555183]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.404505 0.551254 0.1924750.516673 -0.150533 0.466447 -0.215469 -0.227507 -0.519114]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a36c95a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer24_attention_out's input 
<N9nntrainer6TensorE at 0x5682de40b530>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer24_attention_out's output 
<N9nntrainer6TensorE at 0x5682de646540>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer24_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de7c4940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.90343 1.1738 -1.35286-1.72492 -0.43832 2.33783 -0.487571 0.728649 -0.894109]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.0039 1.3829 -1.57006-2.02208 -0.503555 2.8639 -0.597287 0.854176 -1.03242]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.369717717 0.4141850471 -0.1664281189 0.3237210214 -0.750937283 -0.8741667867 -0.1055953726 -1.083861828 -0.4515500367 -0.7865809202 -1.144575119 -0.08553080261 -0.3235462606 -0.9011095762 -0.8509297967 0.184768945 -0.1499087811 -0.6074998379 -0.9416130185 -0.3370392323 -0.6768990755 -0.3038922846 -0.9472158551 -0.4724726975 -0.1225259677 0.7403610349 -0.8168305159 -1.12814188 -0.7372927666 -0.6504989862 -0.9537336826 -0.6664224863 -0.2640016377 0.5276591778 -0.6773705482 -0.5016269684 -0.7963917255 0.2570232451 -0.4677351713 -0.005658693612 -0.9181857705 0.3472033143 -0.233420372 -1.923967242 -0.7331756353 0.5005047917 -1.65133512 -0.4732036889 -0.7726078033 -0.7602410913 -0.958774209 0.01471002214 -1.592873096 -0.923161149 0.342824012 -0.5423586369 -0.1020421833 -0.0777990818 -0.727165103 -1.42258203 -0.2568499744 -1.058764815 -0.324097693 0.5694395304 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.08025097102 0.03086510301 0.01727072708 0.02819549479 0.00962634664 0.008510274813 0.018353967 0.006900400389 0.01298624929 0.00928927213 0.006493918132 0.01872595213 0.01475961693 0.008284046315 0.008710343391 0.0245376844 0.01755839773 0.01111106295 0.007955217734 0.01456180308 0.01036611199 0.01505257189 0.007910770364 0.01271736529 0.01804584078 0.04276851192 0.00901248306 0.006601516157 0.009758595377 0.01064342353 0.007859376259 0.01047528442 0.01566516608 0.03457394242 0.01036122721 0.01235195249 0.009198580869 0.02637626044 0.0127777569 0.02028298564 0.008143787272 0.02886542305 0.01615162566 0.002978660865 0.009798854589 0.0336477384 0.003912223969 0.01270807255 0.009419984184 0.009537200443 0.007819862105 0.02070036158 0.004147758707 0.008103369735 0.02873928659 0.01185894478 0.01841929741 0.0188712962 0.00985792838 0.004917789251 0.0157775972 0.007075770292 0.01475147903 0.0360490568 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.91096115 28.8606205 28.8479805 28.85270691 28.83985901 28.83778954 28.84954071 28.83808708 28.84369659 28.83999825 28.83434296 28.84991264 28.84594536 28.83517838 28.83846855 28.85572433 28.84779167 28.83752823 28.83532715 28.8457489 28.84155273 28.84051704 28.83576202 28.8439045 28.84923172 28.87395477 28.83829117 28.83778763 28.84094429 28.84135246 28.83904648 28.84070778 28.84685135 28.86480713 28.84154701 28.84353828 28.84086227 28.85756302 28.83776474 28.85146904 28.83551598 28.86005211 28.84733772 28.83178139  28.839077 28.86435699 28.83509827 28.84246445 28.83774567 28.83881569 28.83805275 28.85188675 28.8343811 28.83738136 28.85992622 28.84113884 28.84960556 28.8500576 28.84152031 28.83610344 28.84696388 28.83540154 28.84593773 28.86675835 

-------
======================
selected experts : 0, 1, 25, 33, 45, 63, 
layer24_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df21d1f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.605617 -0.646749 0.3423190.583574 -0.679776 -0.100882 -0.309929 0.861299 0.362823]

layer24_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de2b2790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.29781 0.527051 -1.01054-1.14134 -1.1181 2.23694 -0.7975 1.58995 -0.531286]

layer25_wq's input 
<N9nntrainer6TensorE at 0x5682ddf10a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.7088 0.347731 -0.73638-0.730544 -0.814756 1.43181 -0.537945 1.05683 -0.397611]
==============================
layer25_wq's output 
<N9nntrainer6TensorE at 0x5682de7d58a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.83559 3.91835 -4.080750.0644075 -3.05639 2.98326 -3.06824 -0.246444 -1.04628]
============================
layer25_wk's input 
<N9nntrainer6TensorE at 0x5682de480fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.7088 0.347731 -0.73638-0.730544 -0.814756 1.43181 -0.537945 1.05683 -0.397611]
==============================
layer25_wk's output 
<N9nntrainer6TensorE at 0x5682de0aef30>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.475826 0.562091 -0.47697-0.568508 -0.792714 -0.737048 -0.359451 -0.803374 -0.195476]
============================
layer25_wv's input 
<N9nntrainer6TensorE at 0x5682ddd64050>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.7088 0.347731 -0.73638-0.730544 -0.814756 1.43181 -0.537945 1.05683 -0.397611]
==============================
layer25_wv's output 
<N9nntrainer6TensorE at 0x5682de58dbd0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.840023 -4.61997 -2.585693.21929 -0.908869 1.03073 -2.44439 0.160528 -3.1034]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-4.35016 -3.33786 3.08568-2.67119 -1.47768 -4.00722 0.402373 -3.05171 3.24211]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a38ce5b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer25_attention_out's input 
<N9nntrainer6TensorE at 0x5682df211490>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer25_attention_out's output 
<N9nntrainer6TensorE at 0x5682dddde7f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer25_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0184b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.29781 0.527051 -1.01054-1.14134 -1.1181 2.23694 -0.7975 1.58995 -0.531286]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.08507 0.581282 -1.09462-1.24754 -1.20011 2.55523 -0.895266 1.73789 -0.570258]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3521238267 0.7037926912 -0.8344409466 -0.2512977123 -0.403291285 -1.932332873 -0.543863833 0.06713044643 -0.4288933575 -0.004103213549 -0.8570634127 -1.144786596 -0.09808783978 -0.003877218813 -0.6428384185 -0.8870458603 -0.6276754737 -0.985355854 -0.3978602886 0.09748359025 -0.8429579735 0.2512204945 -0.4472000003 -1.10507071 1.46047616 -0.5447825789 -1.209560871 -0.8008135557 -0.2794691622 -0.915550828 -1.310251117 -0.01395785809 -0.7888618708 0.691167593 -0.7541944385 0.01394310407 -0.9679329395 0.4135997593 0.5579542518 -0.3448362052 -0.94643116 0.2649400532 1.001892567 -0.8317495584 -1.023207664 -0.8339598775 -0.7867859006 -0.05729614943 0.08660242707 -0.7493286729 0.1543898433 -0.2039871514 -0.7524009943 -0.5948024392 -0.2189787924 -1.112606168 -0.4913251698 -0.4672349393 -0.7243953347 -0.7608498931 -0.421402812 -0.4930419922 -0.4981641471 -0.9012343884 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0139128631 0.03999403864 0.008589124307 0.01538879983 0.01321888436 0.002865104936 0.01148536801 0.0211590603 0.01288475003 0.01970425434 0.008396997117 0.006297489628 0.01793671958 0.01970870793 0.01040305197 0.008148972876 0.01056199521 0.007385967299 0.01329087093 0.02181115001 0.008516280912 0.02543581463 0.01265101787 0.006552632432 0.08523514867 0.01147481985 0.005902505014 0.008882866241 0.01496132556 0.007919964381 0.005337122362 0.01951102912 0.008989665657 0.03949228302 0.009306780063 0.02006307058 0.007515779696 0.02992030978 0.03456674144 0.01401462499 0.007679132279 0.02578718588 0.05388382077 0.008612271398 0.007111619692 0.008593257517 0.009008348919 0.01868351549 0.02157510631 0.00935217645 0.02308833599 0.01613434963 0.009323486127 0.01091497112 0.01589427516 0.006503441371 0.01210492663 0.01240007859 0.009588289075 0.009245045483 0.01298162527 0.01208416373 0.01202242356 0.00803416688 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.70204735 28.73098946 28.69720078 28.7068615  28.704216 28.69386101 28.70248222 28.71024704 28.70388031 28.70974731 28.69986916 28.69777107 28.70988655 28.70975113 28.69758415 28.69628334 28.7020359 28.69456673 28.70428658 28.71328354 28.69665146 28.71357155 28.70364761 28.69802475 28.7767086 28.70199394 28.69737625 28.70035553 28.7007122 28.69367027 28.69633293 28.71098328 28.70046234 28.73096466 28.70030212 28.71153641 28.69851112 28.72139359 28.72556305 28.70405769 28.69676781 28.71630669 28.74535751 28.69913101 28.69858551 28.70006561 28.69857407 28.70729637 28.7125721 28.7003479 28.7112236 28.70665359 28.69650459 28.70191193 28.70689011 28.69511604 28.70214653 28.70387268 28.70106125 28.70024109 28.69968605 28.70308113 28.70349503 28.69950676 

-------
======================
selected experts : 1, 24, 33, 37, 38, 42, 
layer25_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df270060>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.929537 0.615093 0.4607850.747286 1.42073 -1.73008 0.312851 -0.646419 -0.217662]

layer25_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddfd81b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.22735 1.14214 -0.549755-0.394058 0.302637 0.50686 -0.484649 0.943529 -0.748947]

layer26_wq's input 
<N9nntrainer6TensorE at 0x5682de245ed0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.35866 0.893325 -0.415162-0.276328 0.24759 0.380491 -0.342032 0.665878 -0.555488]
==============================
layer26_wq's output 
<N9nntrainer6TensorE at 0x5682de21e590>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-4.69165 2.99857 0.631250.0792068 -5.66683 2.75762 3.25285 2.31526 -2.07136]
============================
layer26_wk's input 
<N9nntrainer6TensorE at 0x5682de23ab70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.35866 0.893325 -0.415162-0.276328 0.24759 0.380491 -0.342032 0.665878 -0.555488]
==============================
layer26_wk's output 
<N9nntrainer6TensorE at 0x5682de320f60>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.52201 -0.0364019 1.006851.02954 -0.914028 -0.0709108 -0.168282 0.383635 0.519894]
============================
layer26_wv's input 
<N9nntrainer6TensorE at 0x5682dde7eae0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.35866 0.893325 -0.415162-0.276328 0.24759 0.380491 -0.342032 0.665878 -0.555488]
==============================
layer26_wv's output 
<N9nntrainer6TensorE at 0x5682ddeee690>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-3.73006 -3.97706 -7.653534.56543 1.57953 2.92632 3.35135 -1.13161 0.936454]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.22154 -3.63064 -0.5346130.344875 -0.207196 -6.29877 -2.4779 3.13073 0.869325]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a116cc80
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer26_attention_out's input 
<N9nntrainer6TensorE at 0x5682df278ee0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer26_attention_out's output 
<N9nntrainer6TensorE at 0x5682df278e40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer26_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df27a260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.22735 1.14214 -0.549755-0.394058 0.302637 0.50686 -0.484649 0.943529 -0.748947]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.35154 1.20137 -0.578262-0.416263 0.308807 0.553649 -0.516316 0.983972 -0.777683]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.2759172022 -0.1387059689 -0.7067614198 -1.268479586 -0.3612571657 1.021911383 -0.2966087461 -0.26906389 -0.1048665121 0.0133791212 -1.354461908 -1.306173325 -0.02691921592 0.2491696626 0.3892656267 -1.124330401 -0.1418023109 -0.3649367988 -0.5551408529 -0.3173350692 -0.7594336271 0.4147895873 -0.08907012641 -0.3768146932 -0.1962184012 -0.3255196214 -0.07426039129 0.01923182607 -0.04550541565 -0.9463357925 -0.6037111282 -0.5362623334 -0.813598752 -0.7713258266 -1.054637551 -1.169281721 -1.212759495 -0.35141325 0.1003354192 1.251168966 -0.6620184779 -0.4314883053 -0.9407871962 -0.7866211534 -0.9597117305 -1.313242674 -0.192396909 -0.334353596 -0.5201273561 -0.7273904085 0.04272904992 -0.5805600882 -0.5623420477 0.1588353813 0.4589306712 -0.6584821939 -1.201208353 -0.9459183812 0.04744794592 -0.6764290333 -0.6047253013 0.1458210498 -0.9528331757 -0.4144361615 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.02648847364 0.01749799959 0.009914824739 0.005653715692 0.01400669292 0.05585191771 0.0149421161 0.01535941381 0.01810025424 0.02037220635 0.005187908188 0.005444572307 0.01956756413 0.02578936704 0.02966767736 0.006530360784 0.01744390279 0.01395524852 0.01153806597 0.01463560667 0.009406105615 0.03043466061 0.01838844456 0.01379047055 0.01652003825 0.01451631077 0.01866279915 0.02049179003 0.01920723729 0.007802597713 0.01099105086 0.01175795775 0.008910172619 0.009294907562 0.007001713384 0.0062433118 0.005977682769 0.01414525602 0.02222300135 0.07024306059 0.01036851667 0.01305673737 0.007846012712 0.009153821506 0.007698924746 0.005406218581 0.01658329181 0.01438863948 0.01194921136 0.009712387808 0.02097899094 0.01124847401 0.01145527698 0.02356182784 0.03180817142 0.01040524896 0.006047131959 0.007805855479 0.02107822336 0.01022017282 0.01097990945 0.0232571736 0.007752065547 0.01328129135 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.08602142 33.07798386 33.07230759 33.0670929 33.07544708 33.11633682 33.07638168 33.07012177 33.07667923 33.0779953 33.06758118 33.06783676 33.08100891 33.08818436 33.09110641 33.06797028 33.07888412 33.07539368 33.0720253 33.07130814 33.07084656 33.09187317 33.07696533 33.07522964 33.07700729 33.07595444 33.07914734 33.07621002 33.07969284 33.07019424 33.07338333 33.07319641 33.06558228 33.07073593 33.06653214 33.06863785 33.06741714 33.07463074 33.08461761 33.12691498 33.06990051 33.07449722 33.06928635 33.07059479 33.07009125 33.06779861  33.078022 33.07678223 33.07434082 33.07019806  33.080513 33.07364273 33.07289505 33.08595657 33.09038544 33.07279968 33.06748581 33.06733704 33.08251953 33.07165909 33.07337189 33.08279037 33.06728363 33.07376862 

-------
======================
selected experts : 0, 5, 14, 21, 39, 54, 
layer26_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df27d4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-3.32686 1.13824 2.549562.01513 -2.48562 -0.516023 -2.50276 -2.9583 0.0558259]

layer26_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddd52130>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.900489 2.28039 1.99981.62107 -2.18298 -0.00916255 -2.98741 -2.01477 -0.693121]

layer27_wq's input 
<N9nntrainer6TensorE at 0x5682de328070>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.777849 1.42344 1.298731.02722 -1.47964 -0.0060371 -1.88361 -1.30845 -0.454505]
==============================
layer27_wq's output 
<N9nntrainer6TensorE at 0x5682ddefef30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.73188 1.85899 0.7583631.4781 1.7505 1.43621 -1.66906 1.5717 -0.972143]
============================
layer27_wk's input 
<N9nntrainer6TensorE at 0x5682de1e5e50>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.777849 1.42344 1.298731.02722 -1.47964 -0.0060371 -1.88361 -1.30845 -0.454505]
==============================
layer27_wk's output 
<N9nntrainer6TensorE at 0x5682ddfc8350>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.743974 1.18005 0.6682281.29277 0.611509 0.311492 -0.605846 0.68516 0.0157546]
============================
layer27_wv's input 
<N9nntrainer6TensorE at 0x5682de7969c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.777849 1.42344 1.298731.02722 -1.47964 -0.0060371 -1.88361 -1.30845 -0.454505]
==============================
layer27_wv's output 
<N9nntrainer6TensorE at 0x5682de46fef0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.19192 2.79636 -1.47562-2.0129 -0.243943 0.46185 0.810476 2.93607 -2.04597]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.45221 -2.08479 -1.53079-0.645422 -2.02518 1.01272 -1.48467 -1.74694 -2.26301]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a054ec20
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer27_attention_out's input 
<N9nntrainer6TensorE at 0x5682de426170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer27_attention_out's output 
<N9nntrainer6TensorE at 0x5682de0d2950>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer27_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de6e6390>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.900489 2.28039 1.99981.62107 -2.18298 -0.00916255 -2.98741 -2.01477 -0.693121]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.726749 1.79009 1.550921.25719 -1.75492 -0.00739473 -2.36393 -1.56252 -0.535355]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5099403262 -1.220533609 -0.0565347448 -0.2577859163 -0.2888199985 -0.2733395696 -0.3190815151 -0.1558616161 0.7160744667 -0.7994988561 -0.4760230482 -1.204645514 -0.2987708151 0.2233734429 -0.08029260486 -1.236840963 -1.258179665 -0.3760178685 -0.8201752305 -1.427593231 0.6406546235 -0.3322273195 -0.5550384521 -1.472351193 -1.734372973 -0.6209437847 -0.126408428 0.6248345971 -0.194844991 -0.5386272669 0.632547617 -0.9789749384 0.249084428 0.1696014851 -0.2190168798 -0.4187732339 -0.5208759308 -0.8158570528 0.09890311211 0.1262154281 -1.107846975 -0.1528904587 -0.8031591177 0.1494600177 -0.8999056816 -0.1750700027 0.5058190823 0.3375385106 -0.01996741071 -1.69429338 0.4086866975 -0.1200674474 -0.7148858905 -0.694650948 -0.348574698 -0.5709431767 -1.013030648 -0.2335567027 0.4432167411 0.1251413524 -0.1332988739 0.1675446182 -1.052818179 1.052858591 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01116948295 0.005488154478 0.01757699437 0.01437283214 0.01393363532 0.01415101252 0.01351829711 0.01591503248 0.03806138411 0.008361408487 0.01155481953 0.005576048046 0.01379567198 0.02325451188 0.01716432534 0.005399383605 0.005285388324 0.01277011819 0.008190300316 0.004461711738 0.03529637679 0.01334175188 0.01067695022 0.00426641712 0.003282984253 0.009995969012 0.01639075018 0.03474238142 0.01530654822 0.01085361745 0.03501138464 0.006987694185 0.02386016026 0.02203709632 0.01494099572 0.01223563403 0.01104800403 0.008225743659 0.02053290792 0.02110143751 0.006142788101 0.01596238837 0.008330859244 0.02159767598 0.007562637795 0.0156122474 0.03084407747 0.02606684528 0.01823163591 0.003417237429 0.02798902243 0.01649501547 0.009099684656 0.009285693057 0.01312542334 0.01050848048 0.006753730122 0.01472532749 0.02897236496 0.02107878588 0.01627820171 0.02199181356 0.006490292493 0.05330255628 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
31.50262451 31.49694252 31.5090313 31.50630569 31.50395775 31.50369835 31.50592613 31.50689316 31.52903938 31.50029373 31.50348663 31.49559975 31.50382042 31.51518631 31.50814247 31.49542427 31.49674034 31.50088692 31.50012207 31.48542595 31.5272274 31.50527382 31.50260925 31.49238396 31.49378395 31.50145149 31.50784492 31.52381325 31.50723839 31.49897003 31.52694321 31.49796677 31.51531601 31.51349258 31.50448799 31.50369072 31.49773407 31.49443626 31.51294136 31.51255608 31.49807549 31.50789452 31.4988327 31.51352882 31.49997139 31.50658989 31.5118084 31.51752281 31.5106411 31.49534988 31.51992035 31.50794983 31.50055504 31.49930954 31.50458145 31.49910164 31.49868584 31.50522614 31.52090454 31.51301003 31.50820923 31.51344681 31.49842262 31.54475784 

-------
======================
selected experts : 8, 20, 27, 30, 46, 63, 
layer27_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df2fed10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.78379 -4.10973 0.174737-0.765252 2.4391 -2.11893 -2.19582 -0.143156 2.99934]

layer27_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de4dbd00>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.883297 -1.82934 2.174540.855816 0.256112 -2.1281 -5.18323 -2.15792 2.30621]

(93919)layer0_wq's input 
<N9nntrainer6TensorE at 0x5682dde663b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5682de7965e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.13528 -2.40334 2.68629-0.919085 2.00659 2.0107 -1.72146 -1.10937 2.11685]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5682ddd56d10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5682de0a36b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.89838 -1.3551 1.40273-1.31928 1.80822 0.0189238 -3.15912 0.501596 1.80267]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5682e0a65b00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5682dde490d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0171632 -0.00860554 -0.02487710.023363 0.0279423 0.00942741 0.0125607 0.108111 -0.0271058]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.07678 2.43011 -2.775140.599566 -2.71443 -0.83739 1.88082 -0.81035 -0.357612]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a259f120
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer0_attention_out's input 
<N9nntrainer6TensorE at 0x5682e0a64030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer0_attention_out's output 
<N9nntrainer6TensorE at 0x5682e0a638e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer0_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dde13420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00261426 -0.0209141 0.0150320.00392139 -0.0209141 -0.00326782 -0.0169927 0.00326782 0.00718921]

layer0_ffn_gate's input 
<N9nntrainer6TensorE at 0x5682ddfb82c0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.016856 -0.133765 0.09458650.0238624 -0.133223 -0.0193776 -0.108684 0.0207315 0.0444924]
==============================
layer0_ffn_gate's output 
<N9nntrainer6TensorE at 0x5682dde852c0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.0745774 -0.045048 -0.104621-0.0199713 -0.0449096 0.327996 0.0860863 0.095988 -0.0662891]
============================
layer0_ffn_up's input 
<N9nntrainer6TensorE at 0x5682de34f990>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.016856 -0.133765 0.09458650.0238624 -0.133223 -0.0193776 -0.108684 0.0207315 0.0444924]
==============================
layer0_ffn_up's output 
<N9nntrainer6TensorE at 0x5682dde690c0>
data addr: 0x7fc0a7fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.107725 -0.084519 -0.0651140.108516 -0.371791 -0.215119 -0.0580026 -0.266965 0.0745787]
============================
layer0_ffn_down's input 
<N9nntrainer6TensorE at 0x5682dc3e1140>
data addr: 0x7fc0aafd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[0.0038672 0.00186083 0.00322812-0.00107278 0.00816106 -0.0410134 -0.00260401 -0.0134272 -0.00238998]
==============================
layer0_ffn_down's output 
<N9nntrainer6TensorE at 0x5682dc3e0770>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.019992 -0.0625515 0.0377594-0.0686288 -0.133513 -0.0569278 -0.00148558 0.141268 0.0288674]
============================
layer0_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3e1bb0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0173777 -0.0834656 0.0527914-0.0647074 -0.154427 -0.0601957 -0.0184783 0.144535 0.0360566]

layer1_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e48b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wq's output 
<N9nntrainer6TensorE at 0x5682dc3e2330>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.796753 0.125337 -0.343608-0.150926 0.507089 0.41414 -0.255773 -0.0929489 0.288512]
============================
layer1_wk's input 
<N9nntrainer6TensorE at 0x5682dc3e6610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wk's output 
<N9nntrainer6TensorE at 0x5682dc3e6380>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.57238 0.950343 0.763138-0.230196 1.08302 0.869608 -0.770607 0.449956 1.26046]
============================
layer1_wv's input 
<N9nntrainer6TensorE at 0x5682dc3e7400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wv's output 
<N9nntrainer6TensorE at 0x5682dc3e7190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.181 0.0291937 0.03531750.0125654 -0.00638554 0.189028 -0.105657 -0.2298 0.067497]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.615648 0.521059 0.3236640.189965 -0.641967 -0.128565 0.219783 -0.160484 0.0306891]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a34c4998
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer1_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ea340>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer1_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ea2a0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer1_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3eb440>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0173777 -0.0834656 0.0527914-0.0647074 -0.154427 -0.0601957 -0.0184783 0.144535 0.0360566]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00849878 -0.127214 0.076729-0.116416 -0.229304 -0.113028 -0.033535 0.248681 0.0424914]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.1702160239 -0.2239896655 -0.1769756079 0.04392522946 0.2368980944 0.6970673203 -0.3592808545 0.1850829422 0.05595271289 -0.5391097665 -0.4449483454 -0.1334935427 -0.4149801433 -0.1864147633 -0.1508485675 1.056051373 -0.3195793629 0.2847701907 -0.2090599388 0.2084010988 0.0856358707 -0.2458385676 0.4397518933 -0.2768904567 -0.3535001278 -0.3292910159 -0.614720583 -0.2910648882 -0.5341821313 1.065764666 -0.4363492429 -0.01145206578 -0.3598379493 0.01293567009 -0.4634871483 0.6671438813 0.07331451029 4.606241703 -0.1133288145 -0.4652608633 -0.276211381 -0.27166453 0.3908366859 -0.07471401989 -0.2063711286 -0.08803310245 0.8862541914 0.1459055394 0.1584375054 -0.7652307153 -0.911662221 -0.3270534873 -0.7755787373 -0.1130612567 -0.363222748 -0.1517439485 1.124939442 0.2087254822 -0.1229620501 0.2299077511 -0.002020265907 -0.2369497269 -0.2072182894 0.03846488521 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005106037483 0.004838720895 0.005071639083 0.006325348746 0.0076716966 0.0121545922 0.00422643451 0.007284310181 0.00640188437 0.003530820133 0.003879443277 0.005297030788 0.003997462802 0.005023993552 0.005205893889 0.01740384474 0.004397606011 0.008047888987 0.004911503755 0.007456163876 0.006594760343 0.004734145477 0.009397014044 0.004589401186 0.004250939004 0.004355106037 0.003273693845 0.004524807911 0.003548261477 0.01757371798 0.003912945744 0.005984588526 0.004224081524 0.006132334471 0.003808184993 0.01179627329 0.006514005363 0.6060009599 0.005404926836 0.003801435698 0.004592518788 0.004613446537 0.008948416449 0.005617718678 0.004924725275 0.005543392152 0.01468599215 0.007004447747 0.007092781365 0.002816258464 0.002432641573 0.00436486071 0.002787265228 0.005406372715 0.00420980854 0.005201234482 0.01864502393 0.007458582055 0.005353110842 0.007618254982 0.00604130188 0.004776413552 0.004920556676 0.006290904246 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
62.86117935 62.85995483 62.8611412 62.86048889 62.86183548 62.86727142 62.85934448 62.86240387 62.86151886 62.85865021 62.85899734 62.86041641 62.8591156 62.86014175 62.86032486 62.8706131 62.85951614 62.86316681 62.86003113 62.86257553 62.86171341 62.85985184 62.85974503 62.86066055 62.85936737 62.85947418 62.85839081 62.8605957 62.85675812 62.87173843 62.85998535 62.86110306 62.86029434 62.86125183 62.85987854 62.86691284 62.8616333 63.45921326 62.86052322 62.85892105 62.85971069 62.86068344 62.86215973 62.86073685 62.86004257 62.86066055 62.86789703 62.86212158 62.86125565 62.85793304 62.85755157 62.85948181 62.85790634 62.86052322 62.85932922 62.85936356 62.87281036 62.86257553 62.86046982 62.86273575 62.86116028 62.8598938 62.86003876 62.86140823 

-------
======================
selected experts : 5, 15, 29, 37, 46, 56, 
layer1_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e0a3ef10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00353315 -0.0549329 0.126958-0.123369 0.276545 -0.191098 0.106235 0.309095 -0.178975]

layer1_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3ee080>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0209109 -0.138399 0.179749-0.188076 0.122118 -0.251294 0.0877565 0.45363 -0.142918]

layer2_wq's input 
<N9nntrainer6TensorE at 0x5682dc3ee2c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wq's output 
<N9nntrainer6TensorE at 0x5682dc3ee260>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.311247 0.115223 -0.416898-0.165847 -0.237754 -0.201397 0.366615 0.127884 -0.336297]
============================
layer2_wk's input 
<N9nntrainer6TensorE at 0x5682dc3edf00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wk's output 
<N9nntrainer6TensorE at 0x5682dc3ede70>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0170464 -0.00491821 -0.00816116-0.0380695 0.0298006 -0.00619471 0.0300897 0.0291104 -0.00756178]
============================
layer2_wv's input 
<N9nntrainer6TensorE at 0x5682dc3ee380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wv's output 
<N9nntrainer6TensorE at 0x5682dc3ee3b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0488053 0.00885962 0.00802386-0.00675694 -0.00410349 -0.01637 0.00385213 -0.0244586 -0.011974]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.290645 0.160238 0.3947140.21333 0.304375 0.0666626 -0.310591 0.233011 -0.0764486]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0856838
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer2_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ee500>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer2_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ee620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer2_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3fefb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0209109 -0.138399 0.179749-0.188076 0.122118 -0.251294 0.0877565 0.45363 -0.142918]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00114894 -0.0176881 0.0220069-0.0260591 0.0151698 -0.0354185 0.0120544 0.0614986 -0.0157906]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2300609797 -0.0573739633 -0.0792670846 -0.07990511507 -0.02465081401 0.3291009963 -0.0433845073 0.0155646475 -0.0844059214 0.0009286757559 0.03862661868 -0.08860354871 -0.003646862693 -0.01065728627 0.02001750097 0.02708270214 0.04012955353 0.008215387352 -0.02356889471 -0.008847231045 -0.1422992498 2.097109318 -0.2351353914 0.4799684286 -0.5973323584 0.03877436742 0.04228200763 0.03647579625 -0.1728328317 0.0651492998 0.9051232338 0.01538673695 -0.1603259444 -0.3426310718 0.1016679481 0.5145780444 -0.05423829705 -0.0345232375 -0.1464090049 0.08176235855 -0.0002122647129 -0.1026671231 0.08935724944 0.1386951506 0.009488531388 0.03291593865 -0.3518608809 -0.01619542576 0.1929396689 -0.04016084224 0.006257107947 0.08056685328 -0.2241435498 -0.1660892814 0.1276066601 0.09963126481 -0.1244759187 0.005371605046 -0.127043888 -0.3551532924 -0.3419806063 -0.0312563628 -0.01512844954 -0.1615694612 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01110433694 0.01319743972 0.01291164756 0.0129034128 0.01363644563 0.01942377351 0.01338336244 0.01419601869 0.01284546684 0.01398975775 0.01452721003 0.01279165968 0.01392589416 0.01382860821 0.01425937004 0.01436047349 0.01454906166 0.01409207098 0.01365120709 0.01385366265 0.01212291792 0.1138072386 0.01104813442 0.02258679084 0.007691104431 0.0145293558 0.01458041091 0.01449599955 0.01175835636 0.01491766516 0.03455388919 0.01419349387 0.01190633792 0.009922111407 0.01547250804 0.02338219807 0.0132388873 0.01350248232 0.01207319647 0.01516756415 0.01397380698 0.01261302177 0.01528319623 0.0160561502 0.01411002409 0.01444448438 0.009830952622 0.01375223417 0.01695116423 0.01342657488 0.01406450011 0.01514944155 0.01117024291 0.01183791552 0.01587909646 0.0154410284 0.01234092377 0.01405205205 0.01230927277 0.009798639454 0.009928567335 0.0135466652 0.01376691833 0.01189154293 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
53.42486572 53.42695999 53.42667389 53.42666626 53.42739868 53.43127823 53.4271431 53.42795563 53.42660522 53.42774963 53.42828751 53.4236908 53.4276886 53.42758942 53.42802048 53.42812347 53.42735672 53.42785263 53.42741394 53.42666245 53.42588425 53.52566147 53.4248085 53.43539429 53.42145157 53.42829132 53.42738724 53.42825699 53.42551804 53.42868042 53.44831467 53.42795563 53.42566681 53.42368317 53.42923355 53.43714523 53.42699814 53.42631149 53.42583466 53.42892838 53.42773438 53.42637253 53.42904282 53.4298172 53.4278717 53.4282074 53.42359161 53.42751312 53.42785263 53.42718887 53.42782593 53.42700195 53.42493057 53.42559814 53.42868805 53.42920303 53.42610168 53.42781448 53.42511749 53.4235611 53.42273712 53.42635345 53.42752838 53.42565155 

-------
======================
selected experts : 5, 21, 23, 30, 35, 48, 
layer2_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e09f8dd0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00287643 0.0675208 -0.00951222-0.0402701 -0.0273482 0.0245452 0.04068 0.00865384 -0.00745776]

layer2_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc401970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0180344 -0.0708777 0.170237-0.228346 0.0947696 -0.226748 0.128437 0.462284 -0.150376]

layer3_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e86c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wq's output 
<N9nntrainer6TensorE at 0x5682dc409160>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.367673 -0.164716 0.417190.0188933 -0.448419 0.281779 -0.241015 -0.0599261 0.228738]
============================
layer3_wk's input 
<N9nntrainer6TensorE at 0x5682dc41f6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wk's output 
<N9nntrainer6TensorE at 0x5682dc41f440>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0494961 -0.00890612 -0.00339991-0.0380567 -0.012209 -0.0539861 0.0167038 0.0355852 0.0534441]
============================
layer3_wv's input 
<N9nntrainer6TensorE at 0x5682dc4204c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wv's output 
<N9nntrainer6TensorE at 0x5682dc420250>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00987394 -0.0372493 0.01608040.0108743 -0.00258411 -0.0155564 0.00276103 0.00223089 -0.00269894]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.364985 -0.17059 -0.412141-0.067413 0.264335 -0.458919 0.184141 -0.166648 -0.300322]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a16798a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer3_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc422910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer3_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc422870>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer3_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc423990>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0180344 -0.0708777 0.170237-0.228346 0.0947696 -0.226748 0.128437 0.462284 -0.150376]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00117001 -0.00973031 0.0224832-0.0335967 0.012626 -0.0336243 0.0186737 0.0650705 -0.0180309]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.7030926943 0.730641067 0.9185103774 1.089624643 0.6388058662 0.8775565028 0.3533841074 0.9655683041 0.9445055723 0.9198542237 0.6780980229 1.313909769 1.142851233 1.079918623 0.7256379724 0.9863049984 0.9989354014 0.95402354 0.8960082531 0.8800563216 0.8590018153 0.3948054016 1.023362279 0.8607522845 1.028882027 1.132201791 0.9340718389 1.035694122 1.269880891 1.17101717 1.161755562 0.8632258773 7.094688416 0.9837840796 1.429793835 0.3792514503 1.048365355 0.4638099968 1.291579366 0.9866654277 1.075057983 0.7833786011 0.8463903069 0.3343887925 1.796683669 1.537041783 0.5512750745 1.040719032 0.6032510996 0.8395021558 0.1258548796 0.3762799203 0.7514244914 1.113770843 0.7281199098 1.025203586 0.4975908697 0.7822400331 1.484714389 1.298515081 0.8620041013 0.9687132239 0.9522148371 0.9354790449 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001474627294 0.0015158155 0.001829098328 0.002170455642 0.001382811344 0.001755702426 0.001039455179 0.001917229616 0.001877269591 0.001831557835 0.001438226667 0.002716168528 0.002289112192 0.002149492037 0.001508250833 0.001957401866 0.001982280519 0.001895222114 0.001788399648 0.001760097337 0.001723426278 0.001083415002 0.002031297656 0.001726445742 0.00204254128 0.002264863113 0.001857784577 0.002056502737 0.002599173458 0.002354503609 0.00233279774 0.001730722026 0.8800697327 0.001952473191 0.003049893072 0.001066694036 0.002082727384 0.001160815358 0.002656187862 0.001958106412 0.00213906914 0.00159790169 0.001701827976 0.001019896823 0.004401725251 0.003395171836 0.00126691896 0.002066862537 0.001334509347 0.001690146164 0.0008279253379 0.001063528936 0.001547649037 0.002223502612 0.00151199894 0.002035042038 0.001200698782 0.001596083166 0.00322208018 0.002674675314 0.001728608971 0.001923268428 0.001891797525 0.001860400545 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
42.53669739 42.53292084 42.53704834 42.53739166 42.53564835 42.53697586  42.532444 42.53809357 42.53709793 42.53800583 42.53570557 42.53793716 42.5346489 42.53736877 42.53672791 42.53717804 42.53720474 42.53616333 42.53796387 42.53507233 42.53694534 42.53725815 42.53820419 42.53694916 42.53726196 42.53748703 42.53707886 42.53727722 42.53781891 42.53757477 42.53755569 42.53695297 43.41242981 42.53717422 42.53827286 42.53628922 42.53730392 42.53638077 42.53787613 42.53717804 42.53736115 42.53681946 42.53787613 42.53623962 42.53771591 42.53861618 42.53648758 42.53728867 42.53750992 42.53691101 42.53700256 42.5362854 42.53581619 42.53744507 42.53673172 42.53630066 42.53642273 42.53776932 42.53749084 42.53408051 42.53694916 42.53714371 42.53711319 42.53708267 

-------
======================
selected experts : 11, 32, 34, 44, 45, 58, 
layer3_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc426710>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.40804 -0.163766 -0.0283651-0.0258024 0.375191 -0.636849 0.150238 0.480676 -0.0173886]

layer3_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc426050>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.426075 -0.234644 0.141872-0.254149 0.469961 -0.863597 0.278674 0.942961 -0.167765]

layer4_wq's input 
<N9nntrainer6TensorE at 0x5682dc44b9a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wq's output 
<N9nntrainer6TensorE at 0x5682dc492890>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0362699 0.0761985 -0.162530.0108048 0.133773 0.0730457 0.019711 0.0756074 0.0487248]
============================
layer4_wk's input 
<N9nntrainer6TensorE at 0x5682dc44d700>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wk's output 
<N9nntrainer6TensorE at 0x5682dc44d470>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00265456 0.0108227 0.006283270.0177541 -0.0206112 0.00339958 -0.00927054 0.0110561 -0.0341779]
============================
layer4_wv's input 
<N9nntrainer6TensorE at 0x5682dc44e4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wv's output 
<N9nntrainer6TensorE at 0x5682dc44e280>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00723192 0.0269832 0.01238150.00259692 -0.0625021 0.0233134 -0.0178625 -0.0133778 -0.0104791]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0813748 -0.0223576 0.1626810.00822159 -0.152405 -0.00192201 -0.0737523 -0.025799 -0.0898704]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1e8d8e8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer4_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc450940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer4_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4508a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer4_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4519c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.426075 -0.234644 0.141872-0.254149 0.469961 -0.863597 0.278674 0.942961 -0.167765]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0182407 -0.0208817 0.0120996-0.0239882 0.0418232 -0.0826764 0.0268667 0.0864598 -0.0135161]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4858219922 -0.6959101558 -1.212872982 -0.5218012333 -0.3581064343 -0.6095018983 -0.9364464879 -0.09696792811 0.1423784941 -0.6651900411 -0.3415829241 -0.6328966618 -0.448492974 0.1721494049 -0.6025950313 -0.3689320683 0.2208227664 -0.4570725858 -0.2653499246 -0.5709964633 -0.5247528553 -0.8439400792 -0.7144295573 -0.4792812765 -0.2926749885 -0.719201386 5.035842419 -0.5945936441 -0.8254883885 -0.2731153667 -0.396169126 -0.2761000395 -0.4569109082 -0.4405405819 -0.4258541465 -0.9477441907 -0.5268508196 -0.8339192271 -0.6794077754 -0.0201159101 -0.3519995511 -0.3451288044 -0.7215133309 -0.1839890182 -0.3048131168 -0.4804430902 -0.3798335195 -0.1730620563 -0.3575777709 -0.1691406071 -0.5078726411 -0.7150136232 -0.4467060566 -0.5603669286 -0.3437692225 -0.2371052802 -0.9603158832 -0.3850839734 -0.2239291668 -0.5798804164 -0.4820096195 -0.009696807712 -0.3213909268 -0.4072785378 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003149774857 0.002552933758 0.001522388076 0.003038462717 0.003578868229 0.002783339238 0.002007131465 0.004646830726 0.005903418176 0.002632576274 0.003638495924 0.002718978561 0.003269575769 0.006081810221 0.002802630188 0.00354033336 0.006385156885 0.003241643542 0.003926715348 0.002892603399 0.003029507585 0.002201662865 0.002506090095 0.003170444164 0.003820870072 0.002494159155 0.7876041532 0.002825144911 0.002242664341 0.003896341659 0.003445207141 0.003884728299 0.003242167644 0.003295679577 0.003344439203 0.001984582981 0.003023159457 0.002223837189 0.002595413011 0.005018029362 0.003600790864 0.003625615733 0.002488400089 0.004259552807 0.003774773097 0.00316676381 0.003501948435 0.004306353163 0.003580761142 0.004323271569 0.003081081435 0.002504626755 0.003275422612 0.002923513297 0.00363054988 0.004039204679 0.001959790243 0.003483609762 0.004092779011 0.002867019502 0.003161807079 0.005070585292 0.003712710226 0.003407144919 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.82080841 40.8202095 40.81822586 40.82165146 40.82218933 40.82139587 40.82061768 40.8213501 40.81974792 40.82124329 40.82129669 40.82133102 40.82188034 40.8237381 40.82141495 40.82215118 40.8230896 40.81994629 40.82253647 40.82150269 40.82068634 40.82081223 40.81825638 40.81987381 40.8214798 40.82110596 41.60335541 40.81953049 40.82085419 40.82250595 40.82205582 40.82249451 40.82185364 40.82190704 40.82195663 40.81868744 40.81877518 40.81797409 40.82120514 40.82172012 40.82125854 40.82223511 40.82109833 40.82191849 40.8223877 40.81796265 40.82211304 40.82196426 40.82123947 40.8153038 40.82073975 40.81825638 40.82188797 40.82057953 40.82128906 40.82265091 40.8205719 40.82209396 40.81984329 40.8214798 40.82177353 40.82368088 40.82232285 40.82201767 

-------
======================
selected experts : 8, 13, 16, 26, 39, 61, 
layer4_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc454a40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0859682 -0.410187 -0.0549648-0.0186526 0.0215153 0.136957 0.138183 0.141585 -0.052018]

layer4_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc454380>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.512043 -0.644831 0.0869074-0.272801 0.491476 -0.72664 0.416858 1.08455 -0.219783]

layer5_wq's input 
<N9nntrainer6TensorE at 0x5682dc4a0910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wq's output 
<N9nntrainer6TensorE at 0x5682dc454560>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.275413 -0.275119 -0.4205730.130582 -0.153064 -0.171391 0.250294 0.344814 -0.237526]
============================
layer5_wk's input 
<N9nntrainer6TensorE at 0x5682dc4a2670>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wk's output 
<N9nntrainer6TensorE at 0x5682dc4a23e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0251711 0.00994586 -0.00368810.0447051 -0.0208935 -0.0184831 -0.00454087 0.00173929 -5.86053e-05]
============================
layer5_wv's input 
<N9nntrainer6TensorE at 0x5682dc4a3460>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wv's output 
<N9nntrainer6TensorE at 0x5682dc4a31f0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00785 0.000318006 -0.00348613-0.00889498 -0.0160193 0.010875 -0.0116615 -0.00481091 -0.00860701]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.388233 -0.0286037 0.43293-0.080648 0.215491 0.0797941 -0.425798 0.0154876 -0.145242]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1c888d8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer5_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc4a58b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer5_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4a5810>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer5_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a6930>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.512043 -0.644831 0.0869074-0.272801 0.491476 -0.72664 0.416858 1.08455 -0.219783]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0104662 -0.0263608 0.00340267-0.011859 0.0191012 -0.0313787 0.0180013 0.0458975 -0.00822548]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.07918033749 -0.2179847509 -0.1854854673 -0.02147212252 -0.2435834855 -0.04457190633 -0.05281364918 0.02368463762 -0.7193178535 -0.03581977263 1.976906419 -0.0489499718 -0.1354791224 0.1448095441 -0.05553285405 -0.09898391366 -0.3166708648 -0.1941818893 -0.1947810501 -0.2095515877 -0.3199042678 -0.01641224325 -0.1026784554 -0.07198929787 -0.6075111628 -0.3197972476 -0.03667161986 -0.07751637697 0.02160535939 -0.2651851773 -0.04437225312 -0.3091673255 -0.003033100627 -0.08875891566 -0.05681180954 0.985704422 -0.1130490974 -0.03929310292 -0.3192313612 0.09553340077 -0.003807086032 -0.145200029 -0.2841767073 -0.1278078854 2.390167236 -0.05618714541 -0.1036904231 -0.02516179718 0.9318757057 -0.4884956181 -0.7425076962 -1.161397815 -0.01418332662 0.03714296594 1.100428462 -0.02066170983 -0.01740192436 -0.5280942917 -0.0759184286 -1.118462682 -0.1128986701 -0.281962961 -0.1339662522 0.06412689388 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01403941866 0.01043018512 0.01077472791 0.01269510575 0.0101665752 0.0124052139 0.0123033952 0.01328151859 0.006317798514 0.01251426246 0.09365288168 0.0123510221 0.01132723037 0.01499172207 0.01226998307 0.01174825523 0.009450029582 0.01068143174 0.01067503355 0.01051851641 0.00941952318 0.01275950484 0.01170493197 0.01206971519 0.00706517417 0.009420530871 0.01250360627 0.01200318988 0.01325392816 0.009949313477 0.01240768936 0.009521204047 0.01293136273 0.01186899748 0.01225430053 0.03475742415 0.01158417203 0.01247087214 0.009425864555 0.01427089516 0.01292135939 0.01121765375 0.009762142785 0.01141445898 0.1415787339 0.01226195786 0.01169309299 0.01264835335 0.03293593973 0.007958122529 0.006172975991 0.004060437903 0.01278797723 0.0134614734 0.03898267075 0.01270540152 0.01274688449 0.007649149746 0.01202238444 0.00423857104 0.01158591546 0.009783779271 0.01134438068 0.01382966246 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.25190735 33.25020599 33.25246048 33.25437927 33.24994278 33.25027466 33.25398636 33.24829102 33.24704742 33.25419998 33.33438492 33.25308228 33.2530098 33.2538147 33.25395584 33.25343323 33.25113297 33.24378204 33.25235748 33.25220108 33.2415657 33.25444412 33.25338745 33.25375366 33.24398041 33.25110626 33.25418854 33.25368881 33.25493622 33.25067902 33.25409317 33.2492981 33.24889374 33.25355148 33.25393677 33.27548599 33.2532692 33.25415421 33.24729538 33.25309372 33.25460434 33.25290298 33.2504921 33.25309753 33.38135529 33.2539444 33.25337601 33.25337982 33.27366638 33.24964142 33.24594879 33.2457428 33.25065613 33.25419235 33.27780533 33.25057602 33.25443268 33.24456406 33.25370789 33.24592209 33.2532692 33.24670029 33.25112152 33.24883652 

-------
======================
selected experts : 10, 13, 35, 44, 48, 54, 
layer5_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc4a9a10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.230467 0.147142 0.06459260.0019409 -0.181316 0.0733079 0.0421877 0.0761149 -0.146847]

layer5_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a9350>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.74251 -0.497689 0.1515-0.27086 0.310161 -0.653332 0.459045 1.16066 -0.36663]

layer6_wq's input 
<N9nntrainer6TensorE at 0x5682dc4e8620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wq's output 
<N9nntrainer6TensorE at 0x5682dc4a9530>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.695634 -0.228144 -0.5810460.323757 -0.197663 -0.540155 0.504746 0.847593 -0.763714]
============================
layer6_wk's input 
<N9nntrainer6TensorE at 0x5682dc4ea380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wk's output 
<N9nntrainer6TensorE at 0x5682dc4ea0f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0214494 -0.00297009 0.00338558-0.00782245 0.00143022 0.00439973 0.00877311 -0.0147463 -0.046852]
============================
layer6_wv's input 
<N9nntrainer6TensorE at 0x5682dc4eb170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wv's output 
<N9nntrainer6TensorE at 0x5682dc4eaf00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0156485 0.0104525 0.01945610.00157869 0.0098697 0.000841773 -0.0121287 0.00979754 -0.00119108]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.627357 -0.377333 0.614835-0.253793 0.427534 0.384775 -0.98504 -0.0536589 -0.30236]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1a838c8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer6_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc41beb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer6_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc41be10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer6_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc41cf30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.74251 -0.497689 0.1515-0.27086 0.310161 -0.653332 0.459045 1.16066 -0.36663]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0147305 -0.0212876 0.00626695-0.0120428 0.0127428 -0.0295996 0.0207973 0.051278 -0.014547]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.04598842189 0.871989727 0.1590040326 -0.8808486462 -0.7566508055 -0.0392893441 0.2642817199 0.3292520642 0.2644926012 0.08304589987 0.0166921448 -0.2166069597 1.023880839 -0.08878401667 -0.2583498955 0.2684820294 0.1323997676 -0.9021778703 0.135657087 0.2334127873 0.1226155683 0.1617766619 0.007764321752 1.611345887 0.2760307789 -0.5341758728 -0.6800649762 0.1462279111 0.2474199682 -0.1545801759 -0.6242238879 -0.3659591973 0.0122226933 -0.2061981857 -0.1350325495 -0.7296162844 1.269290686 -0.002525131684 0.3083646595 -0.1382303983 0.2969625592 0.06327658892 0.1928350031 0.676184237 0.2964215279 0.01302839536 0.08529359847 0.2071783841 -0.05202829838 -0.6404911876 -0.05744434148 0.4427712262 0.3092009425 0.38174209 -0.3089568913 0.2807747126 0.3261196911 0.22609815 -0.1027657315 0.3057509661 0.296938926 0.3073717356 0.02158760652 -0.1024745256 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01360130031 0.03106763959 0.01522868965 0.005383443553 0.006095350254 0.01248949207 0.01691936329 0.01805511862 0.01692293212 0.01411478501 0.01320861373 0.01046012156 0.03616377339 0.01188637782 0.01003247313 0.01699057966 0.01482888218 0.005269835237 0.01487726346 0.01640505902 0.01468450017 0.01527097076 0.013091214 0.06507385522 0.01711932197 0.007614096161 0.006580508314 0.01503536291 0.01663646474 0.0111294724 0.006958425511 0.009008944035 0.01314970851 0.01056956686 0.01134916861 0.006262382492 0.04622254521 0.01295720413 0.01768190227 0.01131293271 0.01748143882 0.01383848768 0.01575270295 0.02554294653 0.01747198217 0.01316030882 0.0141465487 0.01598027907 0.0123313982 0.006846146192 0.01226479094 0.02022558078 0.01769669354 0.01902814396 0.009537393227 0.01720072888 0.01799864694 0.01628550142 0.01172134187 0.01763574779 0.01748102345 0.01766435429 0.01327343471 0.01172475517 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.13698196 40.15444946 40.13098145 40.12876511 40.12947845 40.13587189 40.14125443 40.14143753 40.14030457 40.13749695 40.13659286 40.13098145 40.1595459 40.13431549 40.13341522 40.14037323 40.1382103 40.12865067 40.13825989 40.13978577 40.13806534 40.1386528 40.13647461 40.18845749 40.14050293 40.1309967 40.1309166 40.13841629 40.14001846 40.13451385 40.12747955 40.13143921 40.13653183 40.13395309 40.13473129 40.1296463 40.16960526 40.13634109 40.14106369 40.13469696 40.14086533 40.13722229 40.13817978 40.14892578 40.14085388 40.13749695 40.13657379 40.13936234 40.13476181 40.13022995 40.13564682 40.14360809 40.14107895 40.14241028 40.13005829 40.14058304 40.14042664 40.13966751 40.13319778 40.14101791 40.14086533 40.13818741 40.13665771 40.13510895 

-------
======================
selected experts : 1, 12, 23, 36, 43, 51, 
layer6_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc47b4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0510724 -0.0072978 0.002230830.066627 0.0371369 -0.00985265 -0.0324661 0.0408974 0.107894]

layer6_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc47ae20>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.793582 -0.504987 0.153731-0.204233 0.347298 -0.663184 0.426579 1.20156 -0.258736]

layer7_wq's input 
<N9nntrainer6TensorE at 0x5682dc5555c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wq's output 
<N9nntrainer6TensorE at 0x5682dc47b000>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.657963 0.508159 0.759416-0.493352 0.0679253 0.91612 0.356312 0.745763 0.297703]
============================
layer7_wk's input 
<N9nntrainer6TensorE at 0x5682dc557b30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wk's output 
<N9nntrainer6TensorE at 0x5682dc5578a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00883845 -0.00656046 -0.02105710.0099999 0.028946 0.0126508 0.00832559 -0.0132098 -0.0295955]
============================
layer7_wv's input 
<N9nntrainer6TensorE at 0x5682dc558920>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wv's output 
<N9nntrainer6TensorE at 0x5682dc5586b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0188292 0.010387 -0.0138226-0.0142297 0.00276319 0.00587439 0.00344935 -0.0125941 0.00343755]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0454976 -0.830103 -0.8117650.401431 -0.488897 -0.777733 -0.81774 -0.120089 0.528383]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a187e8b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer7_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc55ad70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer7_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc55acd0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer7_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55bdf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.793582 -0.504987 0.153731-0.204233 0.347298 -0.663184 0.426579 1.20156 -0.258736]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0163221 -0.0230185 0.00675105-0.00965002 0.0152515 -0.0313355 0.0206301 0.0554378 -0.0110747]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.168024302 0.6618694067 -0.4694300592 -0.07413705438 0.7391534448 -0.06975306571 0.1814451218 0.4088294804 0.2756572068 -0.01008156221 0.5435899496 0.4069769084 -0.6550350189 0.07319442928 -0.56976825 0.3659587801 0.6475477815 0.04731979966 0.2641719878 0.295361042 0.4828495979 0.6668714285 -0.2184385061 -0.2693095505 -0.4303425848 0.4009917974 0.5435461998 -0.2240395248 0.3005890548 0.2294455171 0.1688566357 1.472923517 0.4575823247 0.5258388519 0.4786459804 -0.03981018811 0.3397579789 -0.005647979677 0.05844898149 0.6566990614 -0.944694221 0.03326295689 1.298671484 1.307865739 0.6658383608 0.252460748 0.4188720584 0.521461308 0.061222516 0.3877601027 0.6422598958 0.1709300727 0.5699272752 -0.7041506171 -0.5168834329 -0.1764284968 -0.09934764355 0.5614067316 0.6186754107 0.6668535471 0.02402624302 1.682482243 0.5926005244 -0.3600988984 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03339649364 0.02013170719 0.006494766567 0.009643552825 0.02174926735 0.009685923345 0.01245188154 0.01563099958 0.01368203759 0.01028148923 0.01788596809 0.01560206991 0.005394563079 0.01117435098 0.005874720402 0.01497504953 0.01984544285 0.01088892762 0.01352579426 0.0139542995 0.01683190651 0.02023265883 0.008347717114 0.007933680899 0.006753655616 0.01550896745 0.01788518578 0.00830109138 0.01402744371 0.01306415349 0.01229611319 0.04530195147 0.01641193777 0.01757127605 0.01676130109 0.009980333038 0.01458778512 0.0103271734 0.01101079024 0.02002788708 0.00403793063 0.01073693391 0.03805749863 0.03840902448 0.02021176741 0.01336831506 0.01578876749 0.0174945239 0.01104137115 0.01530511118 0.01974077895 0.01232163515 0.01836329512 0.005136006977 0.006193765905 0.008705874905 0.009403472766 0.01820749603 0.01928065158 0.02023229748 0.01063821744 0.05586336926 0.01878440939 0.007245117333 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
35.95775986 35.94926071 35.93467331 35.93495941 35.94897079 35.93881607 35.92441559 35.94285583 35.9418602 35.93845749 35.94701767 35.94473267 35.93452454 35.93839645 35.93500519 35.94315338 35.94897461 35.9400177 35.94075012 35.94213104 35.94500732 35.94841003 35.93461609 35.93515778 35.92539215 35.94273376 35.94701385 35.93647766 35.93075943 35.94219589 35.94047165 35.97348022 35.94458771 35.94670105 35.94589233 35.93434143 35.94276428 35.93754959 35.9391861 35.94820404 35.9303093 35.93796158 35.96528244 35.96754074 35.94934082 35.93868256 35.94396591 35.94662476 35.93921661 35.93966675 35.94791794 35.93668365 35.94749451 35.93331146 35.93532562 35.93592834 35.93758011 35.9473381 35.94841003 35.94936371 35.9378624 35.98499298 35.94791412 35.93542099 

-------
======================
selected experts : 0, 4, 31, 42, 43, 61, 
layer7_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5969b0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0358682 0.0494057 -0.02676070.00325278 -0.0567075 -0.0131402 0.0472899 0.0318014 0.108935]

layer7_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55e510>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.757714 -0.455581 0.12697-0.20098 0.29059 -0.676324 0.473869 1.23336 -0.149801]

layer8_wq's input 
<N9nntrainer6TensorE at 0x5682dc59a250>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wq's output 
<N9nntrainer6TensorE at 0x5682dc5d3620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.17101 -0.653928 0.222739-0.618268 0.202001 -0.518507 -0.352742 -0.371231 0.40923]
============================
layer8_wk's input 
<N9nntrainer6TensorE at 0x5682dc59bfb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wk's output 
<N9nntrainer6TensorE at 0x5682dc59bd20>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0122512 -0.0240249 0.0049726-0.00696511 -0.00671129 0.0076463 -0.00612936 0.00283497 -0.00945466]
============================
layer8_wv's input 
<N9nntrainer6TensorE at 0x5682dc59cda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wv's output 
<N9nntrainer6TensorE at 0x5682dc59cb30>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0125965 -0.00244861 0.007529460.00303611 0.0145719 0.00140784 -0.0154647 -0.0179054 0.00261313]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.383115 0.556856 -0.2933160.588077 0.0642362 0.552746 0.504854 -0.0857979 -0.0598084]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1474898
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer8_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc59f1f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer8_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc59f150>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer8_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a0270>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.757714 -0.455581 0.12697-0.20098 0.29059 -0.676324 0.473869 1.23336 -0.149801]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0170022 -0.0222015 0.005803-0.0102922 0.013441 -0.0348208 0.0242669 0.0607834 -0.0068052]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.04677072912 0.0153601896 0.2453148216 0.3004711866 -0.3885725439 0.05983536318 -0.01540975925 0.05687586218 0.2940652668  0.1836714 -0.01984599419 0.4423549771 0.2803600132 0.05182646215 0.1945592016 0.2888280451 0.1189836785 0.1493378282 -0.5161525607 0.266795069 -0.8293113112 0.2661831379 0.08042082191 0.07239897549 0.05997288972 0.3686698079 -1.536476731 -0.3078627288 -0.7882967591 0.24841474 0.2563607693 -0.04476862773 0.5374804139 -0.3126162291 4.726294041 0.2904126942 -0.4587142169 0.1429113746 0.2790945172 -0.3088897169 0.3767482638 0.1019092426 0.2512847781 0.5570003986 0.134382531 -0.3317438364 0.1961397231 -0.2455921173 -0.03754698113 0.2989471853 0.1975146532 0.2983741462 0.5875585675 0.003402953502 0.7836763859 -0.401131928 0.07859761268 0.2543839812 0.2182640433 0.1351471692 0.2176695615 0.1511563063 0.435500294 0.8533852696 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005646863021 0.005472250748 0.006887059659 0.007277598605 0.003653760534 0.005721122492 0.005306432024 0.005704214796 0.007231128402 0.006475340109 0.005282944534 0.008387016132 0.007132700179 0.005675485358 0.00654622633 0.007193353958 0.006069725845 0.006256790832 0.003216125071 0.007036597934 0.002351417439 0.007032294292 0.005840115249 0.005793454591 0.005721908063 0.007791236974 0.001159342472 0.003960882314 0.002449864987 0.006908441894 0.006963555235 0.005152905826 0.009224010631 0.003942098934 0.6082729101 0.007204764523 0.003406262491 0.00621671183 0.007123679388 0.003956816625 0.007854430005 0.005966967437 0.006928298157 0.009405835532 0.006163916085 0.003867413383 0.006556582171 0.004215370398 0.005190253723 0.007266516332 0.006565601565 0.007262352388 0.009697696194 0.005407207645 0.01179889683 0.003608158557 0.005829476751 0.006949805655 0.006703258492 0.006168629508 0.006699273828 0.006268180441 0.008329719305 0.01265072823 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.07797623 34.07875824  34.079216 34.08056259 34.07598495 34.0790062 34.07859039 34.07898712 34.07956314 34.07880402 34.0785675 34.07595062 34.07660294 34.07896042 34.07983017 34.07857132 34.07839966 34.07954025 34.04884338 34.07269287 34.07468033 34.07936096 34.07912445  34.078125 34.07805252 34.08012009 34.07444382 34.07629013 34.07573318 34.07923889 34.08024597 34.07843781 34.08155441 34.07627487 34.67488098 34.07858276 34.07669067 34.07854843 34.07945251 34.07533264 34.08018494 34.07925034 34.07925797 34.07983017 34.0794487 34.07715225 34.07984161 34.07654572 34.07752228 34.08055115 34.07984924 34.07959366 34.08107376 34.07868958 34.08031464 34.07689285 34.07911301 34.07928085 34.0790329 34.07945251 34.07998276 34.07859802 34.0758934 34.07258224 

-------
======================
selected experts : 32, 34, 43, 52, 54, 63, 
layer8_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5a3350>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0681935 -0.0987799 -0.1255480.266272 -0.427989 -0.0341151 -0.182963 0.2666 0.19531]

layer8_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a2c90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.68952 -0.554361 0.00142260.0652915 -0.137399 -0.71044 0.290906 1.49996 0.0455094]

layer9_wq's input 
<N9nntrainer6TensorE at 0x5682dc5e1750>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wq's output 
<N9nntrainer6TensorE at 0x5682dc5a2e70>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141972 0.0167292 -0.2640250.310849 -0.154788 0.0734234 -0.210784 -0.00362809 -0.189374]
============================
layer9_wk's input 
<N9nntrainer6TensorE at 0x5682dc5e3c80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wk's output 
<N9nntrainer6TensorE at 0x5682dc5e39f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00161957 -0.00211483 -0.01375779.81252e-05 -0.00883225 0.00970442 -0.0232949 -0.00734125 -0.0170646]
============================
layer9_wv's input 
<N9nntrainer6TensorE at 0x5682dc5e4a70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wv's output 
<N9nntrainer6TensorE at 0x5682dc5e4800>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.011892 -0.000943265 -0.006786920.0114438 -0.0217582 0.0152061 -0.00763955 -0.0135636 0.0142479]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0801383 -0.11838 0.298472-0.27794 0.102407 -0.137344 0.120551 -0.172947 -0.0673027]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a126f888
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer9_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc5e6ec0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer9_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc5e6e20>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer9_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5e7f40>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.68952 -0.554361 0.00142260.0652915 -0.137399 -0.71044 0.290906 1.49996 0.0455094]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0163705 -0.0284533 6.91121e-050.00351246 -0.00667504 -0.0384142 0.0157296 0.0773991 0.00218593]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3258353472 0.183533296 -0.09342952073 -1.036007285 2.088111162 0.008346061222 -0.7364020944 -1.349478364 0.3679609299 0.1264469326 1.101921201 0.259608686 0.4678474665 -1.35572803 0.4126421809 -0.07927054912 0.1937977076 0.3577730358 -0.3610570133 -0.1297360808 0.3895307481 1.095702529 0.1365136802 0.2798104882 0.4129787385 0.1292768866 0.1402641833 -0.1215476245 -0.04986479506 -0.7106806636 0.4740997851 0.4535753131 -0.2847249806 1.092014313 -1.758917809 -0.2847560942 -0.2298212647 -0.6525506973 -0.1235622168 0.4583579898 -0.7284759879 0.4226437807 1.040506482 0.5733621716 0.317548275 -0.7666806579 -0.6158863902 -0.1706359237 -0.3159227073 0.4458977878 -0.1455331892 -0.06074886769 0.1500902325 -0.07550656796 -0.2112460881 -0.4560808241 -0.04254198447 -0.6656578779 -0.3927685916 -0.1671101898 -0.002543612383 0.1304136366 0.551289022 -0.1643009335 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009224582464 0.01535192225 0.01163802482 0.004534433596 0.1031122804 0.01288486551 0.006118428428 0.003314241767 0.01846114546 0.01450008154 0.0384603776 0.01656539738 0.02040040493 0.003293594345 0.01930471882 0.01180397905 0.01551031135 0.0182740204 0.008905332536 0.01122306567 0.01886367425 0.03822194785 0.0146467872 0.01690345071 0.01931121573 0.01454117335 0.01470182277 0.0113153439 0.01215623971 0.00627784431 0.02052835561 0.02011131682 0.009611711837 0.03808123246 0.002200730843 0.009611411951 0.01015418675 0.006653590593 0.01129257306 0.02020773478 0.006167116109 0.01949876361 0.03616941348 0.02267061174 0.01755353995 0.005935947411 0.006902066525 0.01077330578 0.009316476993 0.01995750144 0.01104716957 0.01202464849 0.01484699547 0.01184849534 0.01034456585 0.008098075166 0.01224558335 0.006566950586 0.008627361618 0.01081135683 0.01274531428 0.01455771364 0.02217568457 0.01084177103 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.46111679 34.46724319 34.45780945 34.45547485 34.55405045 34.4647789 34.43607712 34.45520782 34.47035217 34.46543884 34.49035263 34.46846008 34.47229385 34.45518494 34.47119904 34.46369553 34.46644974 34.47016525 34.45984268 34.46311569 34.46503448 34.49011612 34.46558762 34.46688843 34.47120285 34.46643448 34.4665947 34.46320724 34.45355988 34.45817184 34.47241974 34.47200394 34.46055222 34.4890213 34.45409393 34.45292282 34.45632553 34.45759201 34.46318436 34.4720993 34.43421936 34.47138977 34.48329544 34.47360992 34.46944809 34.45782852 34.45879364 34.45789719 34.45930099 34.47185135 34.45817184 34.46391678 34.46673965 34.4637413 34.45937729 34.45808411 34.46127701 34.45750427 34.45861435 34.46175003 34.46273041 34.46644974 34.47406769 34.46082687 

-------
======================
selected experts : 4, 10, 21, 33, 42, 43, 
layer9_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5eb020>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.104579 -0.000398263 -0.07572780.115588 0.014312 0.0643511 0.122948 -0.0377023 0.091618]

layer9_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5ea960>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.584942 -0.554759 -0.07430520.18088 -0.123087 -0.646088 0.413854 1.46226 0.137127]

layer10_wq's input 
<N9nntrainer6TensorE at 0x5682ded33210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wq's output 
<N9nntrainer6TensorE at 0x5682dc5eab40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37707 -0.407332 -0.004689360.264799 -0.450686 0.237675 0.354465 0.042499 -0.208016]
============================
layer10_wk's input 
<N9nntrainer6TensorE at 0x5682ded34f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wk's output 
<N9nntrainer6TensorE at 0x5682ded34ce0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0208244 0.0187902 -0.0183501-5.44079e-05 0.00482989 0.0189981 -0.00186447 -0.0230889 0.00503917]
============================
layer10_wv's input 
<N9nntrainer6TensorE at 0x5682ded35d60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wv's output 
<N9nntrainer6TensorE at 0x5682ded35af0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0224915 0.00636522 0.0154213-0.00975636 0.0199064 0.0167431 -0.0279089 -0.0151201 0.023924]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.554739 -0.0191178 0.0355357-0.262446 0.286985 -0.421007 -0.232938 0.270539 0.119792]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a106a878
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer10_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded38210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer10_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded38170>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer10_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded39290>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.584942 -0.554759 -0.07430520.18088 -0.123087 -0.646088 0.413854 1.46226 0.137127]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.01385 -0.0297634 -0.003742470.0101995 -0.00619941 -0.0366087 0.0237897 0.0788518 0.00683152]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.2405900508 0.2403998226 0.002393446397 0.09837586433 1.045801878 -0.8216309547 -1.209175825 0.3056552112 -0.2752718031 0.3853158951 -1.040553689 -0.4904887974 0.2650624514 -0.7685959339 -0.8298601508 -1.237736106 0.03745195642 -0.165141806 -0.4367792606 -0.7191370726 -0.961849153 0.3766517937 -0.4394464791 0.6722314358 -0.05634330213 0.07336346805 0.2354294658 -0.00606180029 -1.113972902 0.9323561192 -0.3637063205 0.3454566598 0.2466523647 0.2701610923 0.3343005478 -0.5620473027 -1.098581672 0.1022080481 -0.1563752741 0.02149196714 0.1330704093 -1.023319602 -0.3335804641 -0.1875314862 0.009166814387 -0.7846198082 0.1157286912 -0.9036570191 -0.8283277154 1.769645333 -0.7296331525 -0.4721302688 -0.02899205871 0.1692908704 0.2316015065 1.04218781 -0.1277344823 0.7623437047 -0.3691411912 0.1704837829 -0.1390079856 0.9013450146 0.08754011244 0.1399177164 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01815791614 0.01815446094 0.01430930384 0.01575081982 0.0406223461 0.006276959088 0.004260303918 0.01937864535 0.01084001828 0.02098551393 0.005042806268 0.008741025813 0.01860776357 0.006618842017 0.006225516088 0.004140350502 0.01481986418 0.01210204791 0.009223339148 0.006954433862 0.00545573514 0.02080447786 0.00919877179 0.02795924433 0.01349302847 0.01536173839 0.01806444861 0.01418882515 0.004685831722 0.03626570851 0.009922552854 0.0201654993 0.01826832816 0.01870287955 0.01994178072 0.008137387224 0.004758510739 0.01581129432 0.01220860705 0.01458521653 0.01630687527 0.005130467936 0.01022602711 0.01183409803 0.01440655533 0.006513629574 0.01602652669 0.005782634486 0.006235063076 0.08377727866 0.006881820504 0.008902981877 0.01386717334 0.01690834761 0.01799543202 0.04047580063 0.0125633264 0.03059572168 0.009868769906 0.01692852937 0.01242249086 0.03515832499 0.01558106858 0.0164189171 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.12060547 33.12155533 33.11771011 33.11915207 33.1440239 33.10013962 33.1076622 33.12277985 33.11233521 33.12438583 33.10844421 33.11118698 33.12200928 33.10429764 33.10581207 33.10754013 33.11822128 33.11454773 33.1059494 33.10749435 33.10790253 33.12420654 33.11259842 33.12563705 33.11403275 33.1139946 33.1205101 33.11759186 33.10713196 33.13966751 33.11236954 33.12356567 33.12166977 33.12210464 33.12334442 33.10963058 33.10625076 33.1192131 33.11560822 33.11798477 33.1015892 33.08945847 33.11362839 33.11523438 33.1178093 33.10800934 33.11847305 33.10918427 33.10486603 33.18717957 33.1064682 33.11230469 33.11726761 33.11840057 33.12139511 33.14387512 33.11405563 33.12922668 33.11136246 33.11937714 33.11582184 33.1366539 33.11898041 33.11981964 

-------
======================
selected experts : 4, 29, 49, 55, 57, 61, 
layer10_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded3c110>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00871513 -0.0179093 -0.129039-0.00419578 -0.0721665 -0.0473022 0.0376891 -0.0830591 0.0259834]

layer10_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded3bb90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.576227 -0.572668 -0.2033450.176684 -0.195253 -0.693391 0.451544 1.3792 0.163111]

layer11_wq's input 
<N9nntrainer6TensorE at 0x5682ded7c3b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wq's output 
<N9nntrainer6TensorE at 0x5682ded3ba40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.574647 -0.344996 -0.3160790.0666121 0.327954 0.336796 -0.180087 0.539557 0.764458]
============================
layer11_wk's input 
<N9nntrainer6TensorE at 0x5682ded7e110>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wk's output 
<N9nntrainer6TensorE at 0x5682ded7de80>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0108217 0.0526808 0.006898240.0209765 0.0171261 0.0374855 -0.0384892 0.0369667 0.0138322]
============================
layer11_wv's input 
<N9nntrainer6TensorE at 0x5682ded7ef00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wv's output 
<N9nntrainer6TensorE at 0x5682ded7ec90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00918804 0.00942161 0.0280262-0.0530578 0.0101649 0.00276343 0.00300308 0.0247157 0.0975801]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.636708 -0.20939 0.32169-0.0292996 -0.447466 -0.144081 -0.347459 -0.450361 0.357439]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0e65868
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer11_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded813b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer11_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded81310>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer11_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded82430>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.576227 -0.572668 -0.2033450.176684 -0.195253 -0.693391 0.451544 1.3792 0.163111]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0134085 -0.0321063 -0.01051490.0103385 -0.0102559 -0.0415165 0.027036 0.0765732 0.00839005]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8536322117 -0.350666672 -0.2271159291 -0.814027369 -0.24312675 -0.4555317461 -0.1419058442 2.084069014 -0.5543870926 0.160293147 -0.3175723851 -1.9721241 -0.2567070723 -1.214590073 -0.7125858068 0.09249140322 -0.09203302115 -0.7283654809 1.177680373 -0.4151083827 -0.1389609128 0.09961105138 -1.649830222 -0.6365466118 -0.4705213308 -0.9583889842 -0.7093999982 -1.075470805 -0.6670421362 -0.1231312156 -0.5486690998 -0.05667171255 0.2446939349 -0.4024503827 -0.2572669983 -0.4099058807 -0.1073041111 -1.158459306 -0.703230381 -0.5467608571 -0.07921869308 -0.1965308785 -2.247526884 -0.1062458828 -0.2751447856 -1.356668234 -0.3595725298 -0.07924947888 -1.645887733 -0.6230176091 -1.833443165 -0.3092767894 -0.6894958615 -0.2229477465 -0.4004736543 0.674198091 -0.08846428245 -0.1153771728 -0.8708809018 -1.661915421 -0.03361873329 0.5712429285 -1.02976048 -0.3162067533 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007948376238 0.01314357575 0.0148720555 0.00826948788 0.01463583857 0.01183508057 0.01619486138 0.1500050426 0.01072108932 0.02190889977 0.01358583197 0.002597307786 0.0144384224 0.005540084559 0.009152381681 0.02047267929 0.01702302694 0.009009093046 0.06059911102 0.0123232957 0.01624262705 0.0206189584 0.003585040569 0.009875463322 0.01165900286 0.007157857995 0.009181586094 0.006367004942 0.009578852914 0.01650178619 0.01078256872 0.01763575152 0.02383830771 0.01248027664 0.01443033852 0.01238757465 0.01676503941 0.005859945901 0.009238407016 0.01080316398 0.01724256761 0.01533394586 0.001972048776 0.01678278856 0.01417464856 0.004806319252 0.01302704029 0.01724203676 0.00359920226 0.01000997704 0.002983677667 0.0136990035 0.009366167709 0.01493417192 0.01250497065 0.0366274491 0.01708388515 0.01663023792 0.007812452968 0.003541974584 0.01804703102 0.03304409236 0.006664795801 0.01360439882 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.54969406 28.55584335 28.55804825 28.53952599 28.55208969 28.54166031 28.55126572 28.69365883 28.55199051 28.5617485 28.55723953 28.5462513 28.55284691 28.5487175 28.55232811 28.55649757 28.56019974 28.55218506 28.59614563 28.5512085 28.55989647 28.5614109 28.54676247  28.543993 28.55197525 28.54699707 28.54806709 28.53809929 28.54703331 28.55967903 28.5501442 28.55985832 28.56701469 28.55565643 28.55713081 28.54984283 28.55994225  28.546175 28.55098534 28.55397987 28.56041908 28.55707932 28.54514885 28.55280685 28.55544472 28.54607582 28.55334282 28.56041908 28.54725266 28.54794121 28.54568291 28.55401421 28.5520668 28.55811119 28.55568123 28.57932663 28.55978394 28.55980682 28.54622078 28.5467186 28.56074715 28.57574463 28.54936409 28.55630493 

-------
======================
selected experts : 7, 9, 18, 32, 55, 61, 
layer11_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded85530>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.333239 -0.0966277 0.0164065-0.155013 -0.154962 0.0912206 0.0206473 0.0287376 0.173099]

layer11_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded84d30>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.242987 -0.669296 -0.1869380.0216705 -0.350215 -0.60217 0.472191 1.40794 0.336209]

layer12_wq's input 
<N9nntrainer6TensorE at 0x5682dedc4470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wq's output 
<N9nntrainer6TensorE at 0x5682ded84be0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.242823 0.417797 0.07170260.586705 0.501475 0.360597 0.460942 0.30801 0.72607]
============================
layer12_wk's input 
<N9nntrainer6TensorE at 0x5682dedc61d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wk's output 
<N9nntrainer6TensorE at 0x5682dedc5f40>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0059719 0.0473741 0.01258060.0277794 0.0201364 0.0578011 0.0204722 0.00987752 -0.0366265]
============================
layer12_wv's input 
<N9nntrainer6TensorE at 0x5682dedc6fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wv's output 
<N9nntrainer6TensorE at 0x5682dedc6d50>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00766343 -0.0528842 0.0304772-0.00113746 -0.0263957 0.00103918 0.00807294 -0.021785 0.00503729]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.15747 -0.456859 -0.00279749-0.591064 -0.611941 -0.0838809 -0.51271 0.210868 -0.199676]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0c60858
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer12_attention_out's input 
<N9nntrainer6TensorE at 0x5682dedc9470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer12_attention_out's output 
<N9nntrainer6TensorE at 0x5682dedc93d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer12_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dedca4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.242987 -0.669296 -0.1869380.0216705 -0.350215 -0.60217 0.472191 1.40794 0.336209]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00532087 -0.0374544 -0.009399940.00127128 -0.0179888 -0.0363026 0.0284667 0.0772668 0.0171785]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.515114903 0.1988955289 -0.9148083925 0.4729863703 0.09639342874 -0.6808546782 0.1147310883 -0.4401502907 -0.1680116206 -0.3849343359 0.007665990852 0.2398532033 -0.804179132 -1.055164337 -0.8419640064 0.1758016348 -0.00687226234 -0.1439996511 -1.990939736 0.1290771216 0.2109279782 -1.326081753 0.06457764655 -1.200477242 -0.4049041867 -0.09832254797 -0.5622937083 -0.5176398158 -0.5233002305 -1.259488463 -1.66703105 -1.807760835 -1.113789678 -1.614046335 0.0009765264113 1.904020071 -0.4413326979 -0.8838368654 -0.04244723171 0.2512405515 -0.04221006855 -0.5307527184 -0.7680432796 -1.219922185 -0.0778702423 -1.0996387 -0.5135358572 -0.5197799802 -0.987991631 -0.5169560909 0.6045063138 -0.9295527935 -0.9713642001 -0.537006259 0.2595245838 0.04104918987 -0.4304583073 -1.368692636 0.4785416722 -0.1011550277 -0.1014918387 2.315051079 -0.7431070209 -0.141637668 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003567925189 0.01980618946 0.00650317641 0.02605176158 0.01787659712 0.008217320777 0.01820743643 0.01045362372 0.01372319274 0.0110470634 0.01635878161 0.02063424699 0.007263921667 0.005651577841 0.006994576193 0.01935403235 0.01612267829 0.01405670401 0.002217009896 0.01847052574 0.02004594728 0.004310342018 0.01731679216 0.004887211602 0.01082864497 0.01471366175 0.009251681156 0.009674167261 0.009619562887 0.004607154522 0.003065062687 0.002662693616 0.005329777021 0.003231843235 0.01624971814 0.1089750677 0.01044126973 0.006707741413 0.01555919368 0.02087055892 0.01556288544 0.009548139758 0.007531210314 0.004793098196 0.01501769014 0.005405734293 0.009713950567 0.009653486311 0.006044249982 0.009680784307 0.02971361391 0.006407993846 0.006145589985 0.009488614276 0.02104417048 0.01691411063 0.01055543404 0.004130532965 0.02619688772 0.0146720456 0.01466710307 0.1643749475 0.007721371017 0.0140899457 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
30.80790329 30.82461739 30.8108387 30.82991028 30.82125664 30.81064415 30.82301903 30.81478882 30.81472015 30.81585884 30.82117081 30.82115364 30.81207466 30.8085556 30.80989838 30.82368851 30.8209343 30.81791496 30.80702782 30.82232857 30.82104301 30.80912209 30.8221283 30.80922127 30.8156395 30.81952477 30.81311035 30.81448555 30.81252289 30.80798721 30.80739975 30.80747414 30.80918694 30.80327415 30.82058525 30.90997124 30.81477547 30.81056595 30.81989288 30.82520485 30.8198967 30.81435966 30.80948257 30.80912781 30.8193531 30.80974007 30.81309509 30.8058815 30.80894852 30.81449318 30.83404922 30.80835915 30.81048012 30.81143951 30.82585526 30.82172585 30.81488991 30.80703545 30.83053207 30.81900597 30.81947899 30.96918678 30.80108833 30.81747055 

-------
======================
selected experts : 3, 35, 50, 54, 58, 61, 
layer12_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dedcd730>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.261759 0.0260365 0.00151380.0209557 -0.246369 0.0859744 -0.00723364 -0.109461 0.183084]

layer12_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dedccdf0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0187714 -0.64326 -0.1854240.0426262 -0.596584 -0.516196 0.464957 1.29847 0.519293]

layer13_wq's input 
<N9nntrainer6TensorE at 0x5682dee397f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wq's output 
<N9nntrainer6TensorE at 0x5682dedccca0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.544315 0.211178 0.4857970.142756 0.287921 -0.0756668 -0.190495 0.334301 0.515609]
============================
layer13_wk's input 
<N9nntrainer6TensorE at 0x5682dc471a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wk's output 
<N9nntrainer6TensorE at 0x5682dc4717a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00536536 0.0270588 0.0105784-0.0175378 -0.0381201 -0.00524855 -0.0441706 0.0075387 0.00437258]
============================
layer13_wv's input 
<N9nntrainer6TensorE at 0x5682dc472820>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wv's output 
<N9nntrainer6TensorE at 0x5682dc4725b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0538234 0.00921317 -0.00105804-0.0519059 -0.0114752 0.000672776 0.0390768 0.0122256 -0.005239]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.195968 -0.549974 -0.465836-0.198431 -0.219 0.201651 -0.171274 -0.344544 0.254724]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0a5b848
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer13_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc474cd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer13_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc474c30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer13_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc475da0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0187714 -0.64326 -0.1854240.0426262 -0.596584 -0.516196 0.464957 1.29847 0.519293]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.000411249 -0.0366582 -0.009470430.00255523 -0.0306305 -0.0320535 0.0282469 0.0722525 0.0266621]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8210696578 0.01764702797 0.1705377102 -1.32864821 -0.6457030773 0.2107856125 -0.5317567587 0.4186590016 0.1665709466 -0.09206339717 -0.7631891966 0.5217927694 -0.4000129104 -0.0318245478 -0.6582522988 -0.6459796429 -0.1373912543 -0.6905651093 -0.9183356166 -0.1151067689 -1.146143317 -1.225360155 -0.8136463761 -1.787121296 -0.08054890484 0.2638849914 0.1978272647 -1.86265564 -0.3499395549 -1.720562339 -0.5657072663 -1.050999761 -0.5782107711 0.1856319308 -0.4710305333 0.3538194895 -0.02123886347 0.2299393564 -0.5446910262 -0.2708410919 0.1396059841 -0.009761870839 -0.4558828175 -0.8684517741 -1.109177709 -1.336254835 -0.4432338178 -0.7737660408 0.2498282343 3.344063044 0.06941227615 0.2823231816 -0.2373957634 -0.1085118875 0.5851342678 -0.1705833822 -0.638215065 -0.5434451699 0.4397984147 -0.7761206031 -0.911747992 -1.731405616 -0.6584652066 -1.277460694 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.00578087708 0.01337345783 0.01558271982 0.003479806008 0.00688897213 0.01622268371 0.007720416412 0.01997105218 0.01552102901 0.01198386867 0.006125349551 0.02214070037 0.008807573467 0.01272794977 0.006803059019 0.006887066178 0.01145279221 0.006586750038 0.005245073233 0.0117108766 0.004176533781 0.003858446609 0.005823947955 0.002200101269 0.01212265249 0.01710737869 0.01601382345 0.002040040214 0.009259826504 0.002351521747 0.007462702692 0.004593420774 0.007369973231 0.01581971347 0.008203774691 0.01871722937 0.01286340132 0.01653640531 0.007621199358 0.01002201065 0.01510809734 0.01301188301 0.008328989148 0.005513353739 0.004333809949 0.003453437472 0.008435011841 0.006060902029 0.01686858758 0.3722955287 0.01408396848 0.01742573269 0.01036286913 0.0117883645 0.02358849533 0.01107888855 0.00694074994 0.007630701177 0.02039772272 0.00604665 0.005279738922 0.002326161368 0.006801612675 0.003662566189 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.72777176 28.73631859 28.73805046 28.72642326 28.72840309 28.73821259 28.73018837 28.74196243 28.73894119 28.73540497 28.72525406 28.73697853 28.72984505 28.73471832 28.72784042 28.73030853 28.73439789 28.7252388 28.72866631 28.73513222 28.72664452 28.72489548 28.72781372 28.72514343 28.73602104 28.74005127 28.73609734 28.72450829 28.73220444 28.72434235 28.72993088 28.72753716 28.73031425 28.73876381 28.72637939 28.74023056 28.73580742 28.73709679 28.73104286 28.73296547 28.73852921 28.73595619 28.72841263 28.7284584 28.72489357 28.72592163 28.73137856 28.7237606 28.73933601 29.09571648 28.73750496 28.7403698 28.73330688 28.73473167 28.74653244 28.73450089 28.72940826 28.72914505 28.74286461 28.72756004 28.7282238 28.72479439 28.7302227 28.72708321 

-------
======================
selected experts : 7, 11, 35, 49, 54, 58, 
layer13_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee45420>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.337035 -0.127108 -0.2176710.144968 -0.150565 0.148819 0.00124518 -0.257126 0.256935]

layer13_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc478790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.355807 -0.770368 -0.4030950.187594 -0.747149 -0.367376 0.466202 1.04135 0.776228]

layer14_wq's input 
<N9nntrainer6TensorE at 0x5682dee98c10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wq's output 
<N9nntrainer6TensorE at 0x5682dc478730>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.310121 0.128975 0.07752420.61004 -0.194837 0.0533598 0.711713 0.43598 -0.135811]
============================
layer14_wk's input 
<N9nntrainer6TensorE at 0x5682dee9aab0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wk's output 
<N9nntrainer6TensorE at 0x5682dee9a7d0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00563616 -0.0128344 0.0348296-0.0478778 0.0302346 0.0681164 0.063781 -0.00346803 -0.0459049]
============================
layer14_wv's input 
<N9nntrainer6TensorE at 0x5682dee9b8a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wv's output 
<N9nntrainer6TensorE at 0x5682dee9b630>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0533198 0.0518202 0.0305033-0.0279568 0.0927579 0.00337922 0.0188315 0.0349787 0.00499831]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.1051 -0.319005 -0.00585832-0.614919 0.147189 -0.138363 -0.758775 0.347671 0.175422]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2eb5968
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer14_attention_out's input 
<N9nntrainer6TensorE at 0x5682dee9dda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer14_attention_out's output 
<N9nntrainer6TensorE at 0x5682dee9dd00>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer14_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dee9ee70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.355807 -0.770368 -0.4030950.187594 -0.747149 -0.367376 0.466202 1.04135 0.776228]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.00819254 -0.0462011 -0.02115290.0116523 -0.0396076 -0.0239998 0.0294573 0.0596645 0.0411491]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3146974742 -0.7524214983 -0.5073871613 1.047515512 -1.900506973 -0.5483075976 -0.8108694553 -1.170781374 -0.3059524596 -2.787629366 -0.9951738119 -0.8819032907 -0.03284237161 -1.08283782 -1.844440937 -0.9865199924 -0.8003217578 -1.080387592 0.4031157792 -1.560947061 -0.3382537067 -0.08784183115 0.1755543947 -0.5047937036 -1.889325738 -0.3198569417 -0.09724221379 -0.5367322564 -0.489025116 -0.007524366491 -2.364694357 -2.770090342 -0.593550086 -1.921137214 -0.9594412446 -0.5471981168 -0.2572587132 -1.150555253 -0.003611662425 -0.3223264217 -0.2941896915 0.8458377719 0.2309077829 -1.740465164 -0.182038337 0.1403097957 -0.5310169458 -2.140178204 -1.20871079 0.02241208963 -1.441024542 -1.899502873 -1.541872621 0.405549556 -0.9199211597 1.239122152 -0.1296442747 -0.2416889817 -0.3628253043 -0.6105259061 -1.894799471 2.003627777 -1.867062569 -0.0566174984 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01456574071 0.00940224342 0.01201291662 0.05687666684 0.002982800826 0.01153126452 0.00886845123 0.006187853869 0.01469367556 0.001228434499 0.007375736721 0.008260346018 0.01930814981 0.006756681949 0.003154811682 0.007439842448 0.008962488733 0.006773257162 0.02985897474 0.004188835621 0.01422663592 0.01827489026 0.02378188446 0.01204411406 0.003016339615 0.01449078415 0.01810390316 0.01166552026 0.01223553717 0.01980323717 0.001875124522 0.001250170055 0.0110211866 0.002921894891 0.007644057274 0.01154406741 0.01542687323 0.006314285565 0.01988087222 0.01445504278 0.01486753579 0.04648862034 0.02513540722 0.003500495572 0.01663204841 0.02295829915 0.01173238363 0.002347125672 0.005957548507 0.02040503547 0.004722532351 0.00298579759 0.004269502126 0.02993173338 0.007952199318 0.06888867915 0.01752669737 0.01566894539 0.01388132386 0.01083567459 0.002999873599 0.1479682177 0.003084245836 0.01885451004 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.17491913 27.17023087 27.17188835 27.21484566 27.16142845 27.17188454 27.16969872 27.16510963 27.17552376 27.16205788 27.16677475 27.16718292 27.18061447 27.16186333 27.15873909 27.1668396 27.1688385 27.16664886 27.19116592 27.16168022 27.17457962 27.17910385 27.18461227 27.16762924 27.16384506 27.17484283 27.1789341 27.17249489 27.17306519 27.18111038 27.16175079 27.16112518 27.1718502 27.16279793 27.16799736 27.17094231 27.17387199 27.1661911 27.18070984 27.1748085 27.17569733 27.20684052 27.1835804 27.16289902 27.17746162 27.18331146 27.17256165 27.15888596 27.16535568 27.18123436 27.16412163 27.16238403 27.16462135 27.19076157 27.16878128 27.22876549 27.17835617 27.17602158 27.16898918 27.17071152 27.16335297 27.30927467 27.15390015 27.17968369 

-------
======================
selected experts : 3, 18, 41, 53, 55, 61, 
layer14_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deea2ef0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.415789 0.0136436 -0.07160960.00549867 -0.0739112 0.0502533 -0.0109407 -0.342321 0.111997]

layer14_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deea2970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.771596 -0.756724 -0.4747040.193093 -0.82106 -0.317123 0.455262 0.699027 0.888225]

layer15_wq's input 
<N9nntrainer6TensorE at 0x5682deedb770>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wq's output 
<N9nntrainer6TensorE at 0x5682deea2820>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.246993 -0.0980489 0.2560660.161456 0.156527 -0.0754717 0.249379 -0.286325 0.0365459]
============================
layer15_wk's input 
<N9nntrainer6TensorE at 0x5682deedd610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wk's output 
<N9nntrainer6TensorE at 0x5682deedd330>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0280981 0.0160434 -0.020244-0.0687225 -0.0147608 0.0326301 -0.00132725 -0.034869 -0.0117971]
============================
layer15_wv's input 
<N9nntrainer6TensorE at 0x5682deede400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wv's output 
<N9nntrainer6TensorE at 0x5682deede190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.027509 -0.0128741 -0.01039650.00837937 0.0063715 0.011103 0.00334155 -0.0227479 -0.0511434]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0872421 0.251014 -0.235492-0.190214 -0.102984 0.139968 0.098614 0.36667 0.217741]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2bae150
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer15_attention_out's input 
<N9nntrainer6TensorE at 0x5682deee0900>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer15_attention_out's output 
<N9nntrainer6TensorE at 0x5682deee0860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer15_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682deee19d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.771596 -0.756724 -0.4747040.193093 -0.82106 -0.317123 0.455262 0.699027 0.888225]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0191901 -0.0468997 -0.0252540.0122755 -0.0443351 -0.0211728 0.0291847 0.0401629 0.0477256]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-2.068495512 0.06064449251 -0.2854043543 -2.37253499 -0.5997478962 -1.363569617 -0.4294730723 0.3454683125 -2.21794486 -0.3285040855 -1.38233602 -0.9914281368 -1.088238001 -0.1005136892 0.2885901928 -0.3372989893 0.335038662 0.4939994216 -0.1296791434 -1.760103464 -1.571818233 -0.3351227045 0.3463970125 -1.455619454 4.249740124 -1.797733426 -0.3779758513 0.04171392322 -2.804435015 -1.001756907 -0.419159323 -0.5463706255 -1.305555463 -0.07715242356 0.08199023455 -0.2658957541 -1.742617965 -0.8322230577 0.1008040458 0.6929460168 0.6067660451 -1.113214135 -0.4716964066 0.1628283262 -0.9055261016 -3.344549894 -1.85081017 -1.61446631 -0.8867996931 -0.2743210196 -1.716823936 0.4269520342 -1.464987159 -0.145443514 -2.872466326 -0.7048119903 0.2177646607 -0.8569467664 -1.120281219 -0.7068556547 0.1902229339 -0.1809620261 -2.570884466 -1.580011606 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001140439766 0.009588398971 0.006783580873 0.0008414522745 0.004953830503 0.002307903487 0.005873415619 0.01274804026 0.0009821263375 0.006497419905 0.002264996292 0.003348395927 0.003039433155 0.008161237463 0.01204319112 0.006440527271 0.01261577383 0.01478937082 0.00792664662 0.001552405418 0.001874029636 0.006454559043 0.01275988482 0.002104946179 0.6324805021 0.001495074364 0.00618380215 0.009408589453 0.00054633338 0.003313987516 0.005934304558 0.005225438625 0.002445755294 0.008354138583 0.009795268998 0.006917216349 0.001579788863 0.003926256206 0.009981297888 0.01804475859 0.01655478589 0.002964461222 0.005630582571 0.0106199868 0.00364874443 0.0003183383669 0.001417789841 0.001795786549 0.003717715852 0.00685918238 0.00162106799 0.01383029483 0.002085319255 0.007802668959 0.0005104016745 0.004459770396 0.01121973339 0.00383037352 0.002943584695 0.004450664856 0.0109149348 0.007530393079 0.0006900612498 0.001858737436 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.89215469 25.90060234 25.88921547 25.89090157 25.89453697 25.88950729 25.89736366 25.90423965 25.89295006 25.89560509 25.8942337 25.89007187 25.89405441 25.89917564 25.90401077 25.89697838 25.90458298 25.90675735 25.90037155 25.89256668 25.89336586 25.89556122 25.90186691 25.89359665 26.52111053 25.89346313 25.89767456 25.90137672 25.89060593 25.89289665 25.8974247 25.8957634 25.89393616 25.89936829 25.90176392 25.89697838 25.89163971 25.8958931 25.90194893 25.89475441 25.90852165 25.88968658 25.89712143 25.90354156 25.89561653 25.89180946 25.89195442 25.88518143 25.89520836 25.8988266 25.89263535 25.90055275 25.89262199 25.89977074 25.89104843 25.89642715 25.9031868 25.89293671 25.89204979 25.89307976 25.90288353 25.89902115 25.88979721 25.88381386 

-------
======================
selected experts : 17, 22, 24, 39, 40, 51, 
layer15_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deee4f80>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.420765 0.217941 0.222422-0.14563 -0.174842 -0.00262449 -0.196889 0.0361661 0.230033]

layer15_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deee44b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.19236 -0.538783 -0.2522820.0474629 -0.995903 -0.319747 0.258373 0.735193 1.11826]

layer16_wq's input 
<N9nntrainer6TensorE at 0x5682def24710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wq's output 
<N9nntrainer6TensorE at 0x5682deee4360>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.355268 0.197313 -0.389867-0.372069 -0.160161 -0.638674 0.37698 0.298585 0.319134]
============================
layer16_wk's input 
<N9nntrainer6TensorE at 0x5682def26470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wk's output 
<N9nntrainer6TensorE at 0x5682def261e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0315604 -0.0124703 -0.07055450.0248561 0.0810568 -0.00435547 0.0442637 0.0670922 -0.00547626]
============================
layer16_wv's input 
<N9nntrainer6TensorE at 0x5682def27260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wv's output 
<N9nntrainer6TensorE at 0x5682def26ff0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.037477 0.0743753 0.0621462-0.163479 0.00509745 -0.0277609 -0.0101428 -0.0310047 -0.0741977]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.381546 0.139896 0.343820.414993 0.440517 0.489388 -0.458067 0.146428 0.126309]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a20928f8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer16_attention_out's input 
<N9nntrainer6TensorE at 0x5682def29710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer16_attention_out's output 
<N9nntrainer6TensorE at 0x5682def29670>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer16_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def2a790>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.19236 -0.538783 -0.2522820.0474629 -0.995903 -0.319747 0.258373 0.735193 1.11826]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0341949 -0.0347478 -0.01433670.00316139 -0.0565951 -0.0224808 0.0170047 0.0437227 0.0635483]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.05211476982 -0.6416469216 -2.025191069 -0.1436697394 -0.6531259418 -0.6036865711 0.08149973303 0.3208004832 -3.047298193 -1.111545444 -1.02949369 -3.965992212 -1.467410803 -1.43652916 -1.315266013 -1.292850018 -1.682392359 -2.04670763 -1.666963696 0.1243281886 -0.3349597156 0.08837586641 -1.756295681 -0.1972560436 -0.1667171866 -0.7029651999 -1.273959517 -0.3595299125 -1.542718649 -0.3003361225 -0.304392606 -0.9442470074 -1.322111726 -0.8383237123 -1.063028097 -0.2437692136 0.8430628181 -0.2073403895 -1.313209176 -0.1361294836 2.023962736 -1.132570505 0.9384945631 -2.073050261 -0.5370718837 -2.903338671 -0.1327673644 -1.958109021 -3.113909483 -1.157161355 -1.999120355 -0.06422943622 -0.9717085361 -1.779744625 -0.4174019694 0.0480931066 -1.076514125 -2.244340897 -0.8149682879 -0.7359886765 -0.1602908522 -0.7065141797 0.3943091333 2.630728483 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01854330115 0.009265955538 0.002322868444 0.01524610445 0.009160199203 0.009624456055 0.01909628138 0.02425916307 0.0008358515333 0.005791831296 0.006287102588 0.0003335380461 0.004057565238 0.004184823018 0.004724340513 0.004831436556 0.003272654954 0.002273422666 0.003323538462 0.01993191056 0.0125916535 0.01922804117 0.003039516509 0.01445062645 0.01489873882 0.008714850992 0.004923572764 0.01228604373 0.003763220971 0.01303525735 0.01298248675 0.006846563891 0.00469210837 0.007611574605 0.006079763174 0.01379387639 0.04089700431 0.01430563349 0.004734066781 0.01536150184 0.1332139671 0.005671328399 0.0449921675 0.002214316046 0.01028742176 0.0009652726003 0.01541323401 0.002484036377 0.0007819882012 0.005533565767 0.002384223277 0.01650666818 0.00666110497 0.0029690722 0.01159520727 0.01846887544 0.005998322275 0.001865730737 0.007791439071 0.0084317578 0.01499479171 0.00868397858 0.02610959671 0.2443795055 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
23.54921722 23.53088188 23.53299713 23.54591942 23.52934647 23.5407753 23.55024719 23.54730606 23.52578926 23.53694344 23.53505516 23.53053093 23.53473091 23.53247643 23.52490997 23.5264473 23.53299332 23.53056526 23.53304291 23.55012894 23.53706932 23.5503788 23.53371429 23.54464722 23.54557228 23.53223801 23.53464317 23.54343605 23.53443718 23.54180336 23.5436573 23.53704453 23.53393745 23.53780937 23.53580093 23.54446793 23.5682354 23.54593277 23.53588486 23.54508209 23.66341019 23.53300858 23.57518959 23.53241158 23.53905678 23.53021049 23.54608727 23.53268051 23.53145599 23.53477859 23.52924538 23.54765701 23.53399849 23.5255394 23.54274559 23.55009651 23.53667259 23.5277729 23.53751183 23.53862953 23.54566956 23.53840446 23.55726051 23.7760067 

-------
======================
selected experts : 7, 36, 40, 42, 62, 63, 
layer16_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def2d9d0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.431278 -0.0191207 -0.0520095-0.191345 -0.0821877 0.0657345 0.0929842 -0.17835 0.119429]

layer16_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def2d090>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.62364 -0.557904 -0.304292-0.143882 -1.07809 -0.254013 0.351357 0.556844 1.23769]

layer17_wq's input 
<N9nntrainer6TensorE at 0x5682def6d870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wq's output 
<N9nntrainer6TensorE at 0x5682def2cf40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0986049 0.941314 -0.409761-0.228745 -0.439152 -0.517336 0.20517 0.411878 0.786435]
============================
layer17_wk's input 
<N9nntrainer6TensorE at 0x5682def6f5d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wk's output 
<N9nntrainer6TensorE at 0x5682def6f340>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0270154 -0.012093 0.0181588-0.0148033 -0.0128511 0.0329365 -0.048675 0.0630503 0.0434794]
============================
layer17_wv's input 
<N9nntrainer6TensorE at 0x5682def703c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wv's output 
<N9nntrainer6TensorE at 0x5682def70150>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.274216 -0.0489666 0.0310645-0.0363662 -0.0251874 -0.0699952 -0.236286 -0.151216 0.111659]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.647937 -0.689909 0.3802920.274967 0.630245 0.25156 -0.456305 -0.0593656 0.721241]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2297908
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer17_attention_out's input 
<N9nntrainer6TensorE at 0x5682def72870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer17_attention_out's output 
<N9nntrainer6TensorE at 0x5682def727d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer17_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def738f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.62364 -0.557904 -0.304292-0.143882 -1.07809 -0.254013 0.351357 0.556844 1.23769]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0535453 -0.0381172 -0.018551-0.00990592 -0.0660084 -0.0185562 0.0241901 0.0358498 0.0748043]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.447009921 -1.251222968 0.4436779618 1.208736181 0.4357713461 -1.42989099 0.6122367978 0.2530575395 0.4667769969 0.4646663964 -2.264201641 -0.3218255341 -1.396860361 -0.2306746393 -0.1178826988 0.7724598646 0.2812962234 0.5701763034 -0.05667025223 -0.4016815722 0.5942981243 -0.2179611325 -1.151953578 1.020982146 0.1786067039 -0.5935477614 0.4067239463 0.5758956671 -0.2033901215 -1.378864169 0.6396024823 -0.2597191632 0.6028248668 -0.01780005358 -0.4718881547 -1.254062057 -0.4256217182 0.6643728614 -0.9968361259 0.7363439798 0.7514398098 0.1557527333 0.05587822571 -0.2031203806 0.02681217901 0.5725940466 1.238481522 0.2346255332 -0.7182914615 -0.5017694831 0.2432640791 -0.7048752308 5.43648386 -0.1543168426 -0.4374468923 0.8873459697 -0.7013961077 -0.7799318433 -0.2013331503 0.02283242717 -2.182951212 -0.4535562098 0.4822836518 -1.40295589 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01393856574 0.00093840505 0.005110653583 0.01098340377 0.005070406478 0.0007848665118 0.006048960611 0.004223680589 0.005230078474 0.00521905208 0.000340768398 0.00237696385 0.0008112239884 0.002603807254 0.002914699493 0.007100104354 0.004344652407 0.00579981273 0.003098689485 0.002194530331 0.005941415206 0.002637122059 0.001036340487 0.009103251621 0.003920644056 0.001811402966 0.00492524216 0.005833080504 0.002675829455 0.000825955125 0.006216780283 0.002529268386 0.005992292892 0.003221508116 0.002045743633 0.0009357446106 0.002142617013 0.006372694392 0.001210233429 0.006848250981 0.006952414755 0.003832058283 0.003467825241 0.002676551463 0.003368479898 0.005813853815 0.01131501887 0.0041465424 0.001598967589 0.001985518262 0.004182518926 0.001620563678 0.753051281 0.002810416045 0.002117428463 0.007964508608 0.00162621215 0.001503382344 0.002681339392 0.003355100984 0.0003696118365 0.002083592117 0.005311812274 0.000806294207 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
22.11791992 22.11302567 22.11862755 22.11687088 22.11572647 22.1081028 22.11956596 22.11774063 22.11827087 22.11873627 22.11195183 22.11541748 22.10622215 22.11516762 22.11595535 22.12109375 22.1178627 22.11979485 22.10278893 22.11523628 22.11564445 22.11138725 22.11216927 22.11976051 22.11696243 22.11103821 22.11891937 22.11935043 22.1076107 22.11291313 22.11925697 22.11557007 22.11855698 22.11673927 22.11556435 22.1058712 22.11518288 22.11941338 22.11139107 22.11988831 22.12047005 22.10972023 22.11698532 22.11237907 22.10877991 22.1198082 22.12149429 22.11766434 22.11034775 22.11550331 22.11770058 22.11466217 22.84749603 22.10822105 22.10991287 22.11814499 22.11562157 22.11120605 22.11429214 22.11210442 22.11341095 22.11512375 22.11930656 22.11194038 

-------
======================
selected experts : 0, 3, 23, 46, 52, 55, 
layer17_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def76b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.34535 0.153269 -0.0514444-0.155825 0.00398532 -0.280045 -0.110691 -0.0676852 -0.0705817]

layer17_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def761f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.96899 -0.404635 -0.355736-0.299706 -1.07411 -0.534058 0.240666 0.489158 1.16711]

layer18_wq's input 
<N9nntrainer6TensorE at 0x5682defb6420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wq's output 
<N9nntrainer6TensorE at 0x5682def760a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.892632 0.785006 0.2843590.732417 0.502672 0.0353727 -0.273241 0.803194 -0.858658]
============================
layer18_wk's input 
<N9nntrainer6TensorE at 0x5682defb8180>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wk's output 
<N9nntrainer6TensorE at 0x5682defb7ef0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0625939 0.0209839 -0.02201980.140951 0.13563 0.073881 -0.0576498 0.0120187 -0.0372709]
============================
layer18_wv's input 
<N9nntrainer6TensorE at 0x5682defb8f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wv's output 
<N9nntrainer6TensorE at 0x5682defb8d00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0673743 0.132851 -0.8126420.0689228 0.0105354 -0.0484212 -0.0431445 0.0169316 0.0487522]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0106315 -1.18866 -0.197012-0.760579 -0.460747 0.204065 -0.514356 -0.6747 -0.225142]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a249c918
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer18_attention_out's input 
<N9nntrainer6TensorE at 0x5682defbb420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer18_attention_out's output 
<N9nntrainer6TensorE at 0x5682defbb380>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer18_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682defbc4a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.96899 -0.404635 -0.355736-0.299706 -1.07411 -0.534058 0.240666 0.489158 1.16711]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0721664 -0.027966 -0.0225376-0.0210278 -0.0680496 -0.039148 0.0168854 0.032015 0.073025]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7184080482 -1.151590586 -1.859447241 -0.977907002 -1.203753948 0.2016505301 0.3415195346 0.1751564294 -0.9603215456 0.07764619589 -0.7337498069 0.7458074093 -0.4427110255 -2.942986965 -1.691908717 -1.262107611 -1.842625141 3.898965359 -0.4046615362 0.1811235845 0.07861576974 0.7561917901 -2.544876337 -0.3593176007 -1.128900528 -0.5133380294 -0.7166668773 -1.134882569 -0.3825878203 -0.8983453512 -1.73834765 0.4515714049 -2.509013414 0.3447127342 -1.726599813 -1.201112628 0.3410312831 -1.635834694 -0.9594169855 -1.42271924 -0.5482043624 -0.2436633706 -0.3327748179 -0.1896322966 -0.08608092368 -0.4912527204 0.02922016196 0.4147014618 0.102746658 -1.13919425 -0.06142451242 -0.05008335412 0.8983634114 -0.6112719774 0.4918267131 -0.466303587 -0.5821825266 0.1258903295 -0.5778212547 0.5221877098 -2.873530388 -0.7968274951 -1.698697209 0.7144367695 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005024361424 0.003258007113 0.001605217811 0.003875982948 0.003092415631 0.01260832138 0.01450112276 0.0122786602 0.003944747616 0.01113788877 0.004947867244 0.02172609232 0.006619339809 0.00054319849 0.001897994196 0.00291712652 0.001632448984 0.508605063 0.006876053289 0.01235214714 0.01114869118 0.02195287496 0.0008088270552 0.007195016835 0.003332777182 0.006167961285 0.005033118185 0.003312900197 0.007029520813 0.004196962342 0.001811869093 0.01618812606 0.0008383603999 0.01454750076 0.001833280083 0.00310059404 0.01449404284 0.002007463016 0.003948317841 0.002484290162 0.005956612993 0.008077182807 0.007388552651 0.008525605313 0.009455773048 0.006305697374 0.01061137579 0.01560213789 0.01142099407 0.003298647236 0.009691816755 0.009802358225 0.0253067147 0.00559254596 0.01685307547 0.006465000566 0.005757619161 0.01168839727 0.005782783963 0.01737259701 0.000582268287 0.004645407666 0.001885153819 0.0210551098 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
24.21805191 24.20770264 24.21368027 24.21356583 24.21611977 24.22611237 24.22752953 24.2257843 24.21601868 24.2246418 24.21416092 24.23427773 24.21773911 24.21214104 24.2154026 24.21594429 24.20703125 24.7202034 24.21895027 24.22490311 24.21797752 24.22830582 24.21383667 24.21974564 24.21588326 24.21776581 24.21710777 24.20918846 24.20432091 24.21722412 24.21340942 24.22969246 24.21243668 24.21946907 24.21486092 24.21565247 24.22799873 24.20072937 24.21602249 24.21455765 24.21850777 24.22110558 24.21946335 24.22107697 24.22296143 24.21504211 24.22077751 24.22719955 24.22444916 24.21537209 24.22271919 24.22330666 24.22927475 24.2186203 24.23035812 24.21615601 24.21878624 24.22471619 24.21881104 24.23040009 24.21074867 24.21672058 24.21443558 24.23408318 

-------
======================
selected experts : 11, 17, 21, 52, 59, 63, 
layer18_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682defbf6e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.57986 0.0943264 -0.0378901-0.0561241 -0.00075978 -0.0367193 -0.33725 -0.0977015 -0.0766937]

layer18_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682defbeda0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.54885 -0.310308 -0.393626-0.35583 -1.07486 -0.570777 -0.0965837 0.391457 1.09041]

layer19_wq's input 
<N9nntrainer6TensorE at 0x5682deffefd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wq's output 
<N9nntrainer6TensorE at 0x5682defbec50>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.361323 -0.227422 0.290729-0.417 -0.367518 -0.121355 0.565305 -0.199414 0.142538]
============================
layer19_wk's input 
<N9nntrainer6TensorE at 0x5682df001130>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wk's output 
<N9nntrainer6TensorE at 0x5682df001100>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00226154 -0.0396273 0.06855920.0128666 0.0418959 -0.0108973 0.0969948 -0.022773 -0.0303774]
============================
layer19_wv's input 
<N9nntrainer6TensorE at 0x5682df002000>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wv's output 
<N9nntrainer6TensorE at 0x5682df001d90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0179469 0.0446899 0.0160040.00136719 0.031549 0.0285391 -0.0551306 0.0632468 -0.0651789]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0640633 0.422103 -0.3373720.380253 0.38157 -0.0648154 -0.1497 0.580453 -0.200152]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a28a6938
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer19_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0044b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer19_attention_out's output 
<N9nntrainer6TensorE at 0x5682df004410>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer19_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df005580>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.54885 -0.310308 -0.393626-0.35583 -1.07486 -0.570777 -0.0965837 0.391457 1.09041]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.104808 -0.0219663 -0.0262252-0.0255591 -0.0707731 -0.0427812 -0.00708838 0.0262844 0.0717968]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.870427072 -0.4297446311 0.3893831074 -2.882740974 -1.749268174 -1.140577197 -1.86351347 -2.083424807 -0.1198053062 -1.283785939 -3.595624924 -1.68920207 -0.931278646 1.751794577 -0.9549500942 -2.474923849 -0.3612092137 -2.245876074 0.4594415128 -1.703000188 -0.006122693419 -0.2473336458 -0.1874592602 -1.355520844 -1.34108603 -4.318873405 -0.1267712563 -3.603009701 0.3241306543 -2.305549383 -0.7661187053 -1.171770692 -0.2226484567 -1.774108052 -3.001091003 -2.214206457 -0.9160502553 -1.340917349 -0.1638941765 0.6700047255 -0.1463842988 -0.7276086211 -0.6233993769 -0.04615239799 -1.428402066 -0.2105231136 -1.808840513 -0.7044687271 -3.060681105 -1.606765389 -5.207351685 -3.351971865 -2.702824354 -1.067015171 -1.12849617 -0.5040866733 -2.808013678 -1.055145264 -0.2338203192 -3.263477802 -0.8612078428 0.8286098838 -0.3876197636 -1.732399702 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01169053651 0.01816437021 0.0412062481 0.001562778838 0.004854657222 0.008922977373 0.004330544267 0.003475651378 0.02476425841 0.00773241045 0.0007661184645 0.005155193619 0.01100036036 0.1609351188 0.01074302476 0.002349688904 0.01945292763 0.002954503521 0.04419661686 0.005084549543 0.02774578705 0.02179919556 0.02314427681 0.007197155152 0.007301797625 0.000371700502 0.02459235303 0.0007604820421 0.03860328719 0.002783356002 0.01297582407 0.008648932911 0.02234400995 0.004735553171 0.001388349221 0.003049568972 0.01116916165 0.00730303023 0.02369614877 0.05455511436 0.02411472239 0.01348527148 0.01496639382 0.0266570691 0.00669127563 0.02261658758 0.004573899787 0.01380095724 0.001308034523 0.005598178133 0.0001528733992 0.0009774920763 0.001870830311 0.009604114108 0.009031428955 0.01686296798 0.001684035524 0.009718793444 0.02209577523 0.001067937468 0.01179881394 0.06393178552 0.01894588955 0.004937242717 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.25842476 26.25917625 26.28078842 26.2478199 26.25206566 26.24659729 26.24963379 26.25020981 26.27149963 26.25446701 26.24177933 26.25093651 26.25630379 26.40766907 26.25747681 26.24956131 26.26618767 26.24682808 26.29045486 26.25134277 26.27495766 26.26805687 26.26463318 26.25250053 26.25451279 26.24710655 26.27132607 26.24701881 26.28486061 26.24713326 26.26018715 26.25586128 26.26955605 26.2519474 26.24621582 26.2488308 26.2559967 26.25165367 26.27043152 26.29318428 26.27084923 26.26021957 26.26170158 26.2705307 26.24722672 26.26935196 26.25130844 26.26053619 26.24708939 26.24804115 26.24641037 26.24675751 26.24812889 26.25252342 26.24241447 26.26407433 26.24794197 26.2569294 26.26930809 26.24303436 26.25901031 26.30828285 26.26568031 26.25071907 

-------
======================
selected experts : 2, 13, 18, 28, 39, 61, 
layer19_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df008b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.291141 -0.0548041 0.1960420.0124939 0.0760055 -0.388228 -0.0445634 -0.0385717 0.00012557]

layer19_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df008060>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.83999 -0.365113 -0.197585-0.343336 -0.998859 -0.959005 -0.141147 0.352885 1.09054]

layer20_wq's input 
<N9nntrainer6TensorE at 0x5682df047b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wq's output 
<N9nntrainer6TensorE at 0x5682df007f10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.443588 -0.365536 0.0309314-0.373895 1.03147 -0.199066 0.619521 -0.0463079 0.570942]
============================
layer20_wk's input 
<N9nntrainer6TensorE at 0x5682df0498e0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wk's output 
<N9nntrainer6TensorE at 0x5682df049650>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.061873 -0.0443794 0.0643148-0.0113864 0.0207143 0.00327355 0.052702 0.0385123 0.0354851]
============================
layer20_wv's input 
<N9nntrainer6TensorE at 0x5682df04a6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wv's output 
<N9nntrainer6TensorE at 0x5682df04a460>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00685912 -0.00390602 -0.02020850.0231271 -0.0199988 0.0483193 -0.0235687 0.0313001 0.0278894]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0133097 0.574639 -0.07432030.367737 -0.818267 0.658778 -0.307024 0.540081 0.258146]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2cb0958
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer20_attention_out's input 
<N9nntrainer6TensorE at 0x5682df04cb80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer20_attention_out's output 
<N9nntrainer6TensorE at 0x5682df04cae0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer20_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df04dc00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.83999 -0.365113 -0.197585-0.343336 -0.998859 -0.959005 -0.141147 0.352885 1.09054]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.134808 -0.0267069 -0.0138377-0.0252921 -0.0684 -0.0736309 -0.0106906 0.0247141 0.0752436]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.07704258 -2.381285906 -0.1274219602 0.474237591 -1.869292617 0.430000782 -0.9043648243 -0.4669285119 0.2660955489 -1.392124534 -0.8622024655  0.1724381 0.3264771998 0.9078991413 0.1739273667 -0.3697404861 -0.88002038 0.2017908543 0.6609428525 -2.082634687 0.03842191026 -1.76477313 -0.5597907901 -2.003566265 -0.2413147092 -0.1986148357 0.2799862325 -0.3508349657 -0.9200164676 0.4224737883 0.5498284101 0.2064149082 1.088294625 -1.623036504 -0.8739697933 -0.8394398689 0.6316232085 5.037063122 -0.5610482693 -2.034821033 -0.7283396125 -0.5939122438 -4.271018505 0.4074138105 0.9174279571 -0.8665634394 -1.88837862 -2.123327732 0.770165205 -1.222227216 0.05432872102 -0.7720525861 -1.608665943 -0.2474517077 0.5766109824 -1.176881194 -1.034535289 -0.09248919785 -1.464740157 -2.865098953 -1.450525284 -0.5726585388 0.5862969756 -0.6457912326 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001647277153 0.0004470343119 0.004257765133 0.007771037985 0.0007459277986 0.007434765808 0.001957760425 0.00303204637 0.006310796365 0.001202065847 0.002042069333 0.005746577401 0.006703590509 0.01198991202 0.005755141377 0.003341520205 0.002006005961 0.00591775449 0.009366217069 0.0006026201881 0.005025818478 0.0008281121845 0.002763161901 0.0006522025797 0.003799431259 0.003965181299 0.006399069447 0.003405294614 0.001927357749 0.007379014976 0.008381230757 0.005945181008 0.01436020341 0.0009542113403 0.002018181141 0.002089085523 0.009095588699 0.7448846698 0.002759689698 0.0006321334513 0.002334567253 0.002670469228 6.755236245e-05 0.007268719841 0.01210470591 0.002033183817 0.0007318261196 0.0005785898538 0.01044717059 0.001424668473 0.005106402561 0.002234714571 0.0009680227959 0.003776186146 0.008608734235 0.001490758266 0.001718807616 0.004409128334 0.001117871027 0.0002755647292 0.00113387499 0.002727833577 0.008692523465 0.002535460284 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.39579964 25.39555168 25.40126991 25.40526009 25.39680481 25.40492439 25.39420128 25.40004539 25.40332413 25.39201546 25.39857864 25.39989853 25.40371704 25.40852547 25.40276718 25.39892387 25.3932972 25.39720917 25.40447235 25.39666176 25.40203857 25.3978405 25.39453125 25.39623451 25.39747429 25.40097809 25.39864349 25.39994049 25.39321709 25.40439224 25.4053936 25.40343475 25.41041946 25.39701271 25.39903069 25.39862442 25.40610886 26.1328373 25.39548111 25.39573669 25.39934731 25.39825249 25.39517212 25.40475845 25.40768623 25.39952278 25.39774513 25.39759064 25.40698242 25.39796066 25.3997345 25.39924812 25.38367653 25.40078926 25.4046669 25.39755058 25.39920807 25.39808464 25.39574623 25.39394951 25.39671516 25.39830971 25.40093613 25.39477921 

-------
======================
selected experts : 13, 18, 32, 37, 44, 48, 
layer20_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df050e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0120884 -0.209664 0.05369820.136559 0.0140424 -0.212215 -0.0268751 0.245811 -0.552276]

layer20_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df050500>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8279 -0.574777 -0.143887-0.206777 -0.984817 -1.17122 -0.168022 0.598696 0.538261]

layer21_wq's input 
<N9nntrainer6TensorE at 0x5682df091030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wq's output 
<N9nntrainer6TensorE at 0x5682df0503b0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.332466 -0.309924 0.2384420.07408 0.479344 -0.182912 -0.21657 -0.208468 -0.599435]
============================
layer21_wk's input 
<N9nntrainer6TensorE at 0x5682df092d90>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wk's output 
<N9nntrainer6TensorE at 0x5682df092b00>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0128925 -0.14536 -0.03713740.107526 -0.0377128 0.0351184 0.0651516 -0.0369747 -0.00649811]
============================
layer21_wv's input 
<N9nntrainer6TensorE at 0x5682df093b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wv's output 
<N9nntrainer6TensorE at 0x5682df093910>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0628524 0.476884 -0.03043020.0533559 0.0167144 -0.0309751 -0.0983312 -0.00852327 0.00372253]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0172372 0.454191 -0.228177-0.101379 -0.337944 0.386032 0.293813 -0.0635248 -1.09451]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1f900f0
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer21_attention_out's input 
<N9nntrainer6TensorE at 0x5682df096030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer21_attention_out's output 
<N9nntrainer6TensorE at 0x5682df095f90>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer21_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0970b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8279 -0.574777 -0.143887-0.206777 -0.984817 -1.17122 -0.168022 0.598696 0.538261]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.144591 -0.045282 -0.0109603-0.0163982 -0.073989 -0.0977705 -0.0138507 0.0459169 0.0404394]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.06304276 -0.6021475196 -2.169597626 -1.313102484 -2.742123365 -0.4679281712 0.3970277607 -2.853251934 -0.06517066061 -1.92474246 -4.035582066 0.06261336058 -2.236532211 -2.247601271 -0.04237207025 -1.586821675 -1.129099131 -0.2283283621 -2.213349104 -0.2064970732 -3.909958363 -0.2399390191 -1.702290535 -2.80487442 -1.139941931 -2.144385815 0.2781732678 -0.2992320657 -0.5869427323 -0.1516870111 -1.931723356 -3.424999952 -0.7316350341 -2.441805601 -2.182060957 -1.475407958 0.5334613919 -1.330709934 -1.049032211 3.90513134 0.4757867754 0.219257772 -2.52214694 -0.5174241662 0.6447601318 -0.966193676 0.1037304252 -1.640603065 -1.418705821 -1.239153266 -0.990398109 -3.344450474 -2.827080965 -0.2736230493 -0.09573896229 -0.2715366781 -0.3317405581 -0.1800187677 -1.254295468 0.3095138967 -0.3546442688 -3.898478985 -2.363801718 -1.45413053 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.004216297995 0.006684909109 0.001394314109 0.003283458995 0.0007865307853 0.007645156235 0.01815648749 0.0007038065814 0.01143672224 0.001781146857 0.0002157614508 0.0129956333 0.001304041129 0.001289685839 0.01170045976 0.00249722111 0.003946784884 0.009715008549 0.001334625646 0.009929428808 0.0002446422877 0.009602860548 0.002224894706 0.0007386920042 0.00390421995 0.001429914031 0.01612181589 0.009050031193 0.006787329447 0.01048885286 0.001768756192 0.0003973252606 0.005872997455 0.001062042895 0.00137704378 0.002791536273 0.02081057988 0.003226152388 0.004275786225 0.6061524749 0.01964429393 0.01519943215 0.0009800546104 0.007275962271 0.02326058596 0.004645070527 0.01354111452 0.002366464585 0.002954395954 0.003535471857 0.004533989821 0.0004306539777 0.0007224691217 0.009284785949 0.01109241135 0.009304176085 0.008760559373 0.01019585505 0.003482341068 0.01663508452 0.008562188596 0.0002474668145 0.001148203155 0.002851569559 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.64250755 25.64497566 25.63920784 25.64109612 25.63716888 25.64545822 25.65644646 25.63661003 25.64925003 25.63911819 25.62753868 25.64222527 25.63578033 25.63719559 25.64999008 25.64031029 25.64223671 25.64800453 25.63676453 25.64822006 25.63805771 25.64789391 25.64003754 25.63759804 25.64219475 25.63876724 25.65393448 25.64591026 25.64507866 25.64877892 25.64005852 25.63725662 25.64320946 25.63887596  25.638237 25.64012909 25.65910149 25.64103889 25.6401825 26.24348831 25.65793419 25.65349007 25.63784027 25.6450901 25.65725899 25.64245796 25.65183067 25.64018059 25.63599968 25.63896561 25.64282417 25.63490677 25.63090706 25.64757538 25.64938354 25.6456871 25.64180565 25.64801025 25.63366699 25.65444946 25.64542198 25.63806152 25.63753128 25.64018822 

-------
======================
selected experts : 6, 36, 39, 40, 44, 59, 
layer21_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df09a2f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.215912 0.0337436 -0.14080.25848 -0.380119 0.226237 0.102527 -0.408488 0.198852]

layer21_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df0999b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04381 -0.541033 -0.2846860.0517024 -1.36494 -0.944982 -0.0654953 0.190208 0.737113]

layer22_wq's input 
<N9nntrainer6TensorE at 0x5682df0d9be0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wq's output 
<N9nntrainer6TensorE at 0x5682df099860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0645966 2.94181 1.97864-1.35017 -2.31954 0.353108 -0.301218 -1.04382 -2.49729]
============================
layer22_wk's input 
<N9nntrainer6TensorE at 0x5682df0db940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wk's output 
<N9nntrainer6TensorE at 0x5682df0db6b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0181593 0.194621 0.1058130.081483 -0.104169 -0.00915633 0.00530279 0.0582135 -0.174956]
============================
layer22_wv's input 
<N9nntrainer6TensorE at 0x5682df0dc730>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wv's output 
<N9nntrainer6TensorE at 0x5682df0dc4c0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.305374 -0.118744 0.1250070.0234811 0.348752 0.0440496 -0.268004 -0.125917 0.012953]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.26859 -1.87401 -2.122581.11023 1.88436 -1.3979 1.03444 0.332029 0.509516]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a30ba978
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer22_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0debe0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer22_attention_out's output 
<N9nntrainer6TensorE at 0x5682df0deb40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer22_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0dfc60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04381 -0.541033 -0.2846860.0517024 -1.36494 -0.944982 -0.0654953 0.190208 0.737113]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.197024 -0.0466002 -0.02392610.00439924 -0.111864 -0.0853393 -0.0057438 0.0160851 0.0604106]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.199773863 -1.673453927 -1.750790596 -1.891195297 -0.7850407362 -0.5988141298 0.3508761823 0.4396923184 -0.5164562464 -0.1288634688 -0.439224124 -0.1732848287 -0.6426890492 0.3127274215 -1.910321116 -0.2244655788 0.03051177971 -1.879820585 0.03443358094 0.8580367565 -1.790165305 0.5585227013 -0.4073811471 -1.642910004 0.4139422178 -0.3693930805 -0.7692814469 -0.3295662105 -2.578949928 -0.6650422812 -2.566251755 -2.248004675 -0.9758638144 0.04356760532 0.9725430608 -2.060469627 -0.793438375 0.1285246015 0.4450246394 -1.208471537 -0.1679882407 0.3906342387 -1.493481159 -0.03915252537 -0.4554958344 -0.8757504225 0.291896075 -2.210798025 -0.09234327823 -0.6468251944 0.1034733579 -1.954865456 4.743592262 -3.236852884 -0.3848002851 -3.316403866 -0.5754801035 -1.129412532 0.2965017557 -0.4800824225 0.2253926992 -1.031445861 -1.540406108 -0.7616586685 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007627194747 0.001171743148 0.001084539806 0.0009424721356 0.002848821692 0.00343196257 0.008871312253 0.009695276618 0.003726577386 0.005490849726 0.004025793634 0.00525227515 0.003284640145 0.008539254777 0.0009246177506 0.004990224726 0.006439546589 0.0009532533586 0.006464849226 0.01473142672 0.00104266603 0.01091861352 0.004156050738 0.001208084868 0.009448808618 0.004316968843 0.002894073259 0.00449236948 0.00047378405 0.003212032374 0.0004798386362 0.0006596416351 0.002353920834 0.00652417168 0.01651863754 0.0007957077469 0.002824998694 0.007102672476 0.009747110307 0.00186539907 0.005280168727 0.009231120348 0.00140279287 0.006006208714 0.003960817587 0.002601779765 0.008363208733 0.0006846469478 0.005695081782 0.003271082649 0.006926949136 0.000884335197 0.7173318863 0.0002453900233 0.004250964615 0.0002266253578 0.003512985772 0.00201886124 0.008401816711 0.003864621744 0.007825120352 0.002226654906 0.001338487375 0.002916218247 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.01300812 27.00655174 27.00455856 27.00489235 27.00870705 27.00356674 27.0128212 27.01364517 27.00958443 27.01039505 27.00988388 27.01063347 27.00866508 27.01344299 27.00344467 27.01084709 27.01181984 27.00681114 27.01232147 27.01391411 27.00499344 27.01629829 27.01001358 27.00086594 27.01530647 27.00969696 27.00875092 27.00844193 27.00537682 27.00906944 27.00586128 27.00461006 27.00487328 27.01238251 27.0118866 27.00379181 27.00343704 27.00676155 27.00940514 27.00533867 27.01066017 27.01318169 27.00678253 27.01138687 27.00981903 27.00655174 27.01422119 27.00511169 27.01155281 27.00912857 27.01278496 27.00483513 27.71746826 27.00610352 27.00963211 27.00513077 27.0093708 27.00406075 27.01425934 27.00924492 27.01129913 27.00808334 27.00671959 27.0087738 

-------
======================
selected experts : 7, 19, 21, 34, 38, 52, 
layer22_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df0e2e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0903192 0.42473 0.3125610.306603 0.951165 1.31895 0.790386 1.13406 0.257965]

layer22_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dde69cd0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.9535 -0.116303 0.02787510.358305 -0.413771 0.373971 0.724891 1.32427 0.995078]

layer23_wq's input 
<N9nntrainer6TensorE at 0x5682de368560>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wq's output 
<N9nntrainer6TensorE at 0x5682de2bfbc0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88475 1.19701 -2.95799-0.774949 -0.550968 3.72149 -2.80755 0.835098 0.0767813]
============================
layer23_wk's input 
<N9nntrainer6TensorE at 0x5682de266760>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wk's output 
<N9nntrainer6TensorE at 0x5682de82d610>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.16132 0.101492 -0.1736-0.0632329 0.00180998 0.100202 -0.12567 -0.0723858 0.0486436]
============================
layer23_wv's input 
<N9nntrainer6TensorE at 0x5682de40ebf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wv's output 
<N9nntrainer6TensorE at 0x5682de7736d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.133239 0.0820239 -0.446299-0.364692 0.117455 0.266068 0.109828 0.368292 0.705527]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.979703 -2.9656 2.847441.11459 -1.25532 -3.54643 0.872369 -2.7962 3.11566]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a32bf988
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer23_attention_out's input 
<N9nntrainer6TensorE at 0x5682ddf81aa0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer23_attention_out's output 
<N9nntrainer6TensorE at 0x5682de55e330>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer23_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0fe910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.9535 -0.116303 0.02787510.358305 -0.413771 0.373971 0.724891 1.32427 0.995078]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.248394 -0.0111696 0.002646840.0340224 -0.0390645 0.037539 0.0719775 0.125744 0.0934063]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4227033556 -0.08820123225 -1.093985319 -1.440326333 0.1767097861 -0.6456956863 -1.188692927 -2.515872002 -0.1630707234 0.6196206212 0.6059263349 -1.085564375 -0.3715315461 0.8512659073 0.2090708166 0.6669648886 1.468102455 -1.003164649 4.688289642 -1.688715458 -1.784513116 -0.9512995481 0.2725952566 -1.258306623 0.1121827066 -1.115008235 -1.628750801 -2.018517733 0.472153604 -0.4246005118 -0.5433605313 -0.1163094714 0.03554884717 -1.526789784 -1.247554541 -1.311082482 0.3014304638 -2.34950757 0.6530562043 -0.4077222347 -0.4513951242 -0.467533648 -1.078356385 0.04713717103 0.2013515085 -1.248224258 -0.7126752138 -1.343229294 -2.383528709 -0.6903945208 0.5946252346 -0.4792165756 0.7827592492 -0.3523043096 -1.912632704 -0.1119556129 -0.1083869934 0.8989235163 -1.450334668 0.4656749964 0.7065121531 -0.6281039715 0.8132551908 0.9489036798 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009099072777 0.005459014326 0.001996675739 0.001412191894 0.007114813197 0.003126060357 0.001816254109 0.0004817149311 0.005065225065 0.01107942872 0.010928737 0.002013560617 0.004112116061 0.01396752708 0.007348821498 0.01161659043 0.02588262036 0.002186505357 0.6479145885 0.001101589063 0.001000956749 0.002302900888 0.007830799557 0.001694118953 0.00667021377 0.001955138287 0.001169666299 0.0007921153447 0.009560336359 0.003899579169 0.003462907393 0.005307705607 0.006178144366 0.00129521871 0.001712431898 0.001607028535 0.008059890009 0.0005689071259 0.01145613473 0.003965955228 0.003796479665 0.003735701554 0.002028127434 0.006250156555 0.007292313501 0.001711285789 0.002923537046 0.001556189149 0.0005498776445 0.002989406232 0.01080592722 0.003692311235 0.01304269768 0.004191944841 0.0008805895341 0.005330865271 0.005349923857 0.01464930177 0.00139812869 0.009498597123 0.01208519842 0.00318153901 0.01344657689 0.01540008187 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.92578888 26.92119408 26.91868591 26.91762352 26.92189598 26.91933823 26.9170742 26.91669464  26.921278 26.92776871 26.92761803 26.91536522 26.92032433 26.92874908 26.9235611 26.92639732 26.93541908 26.9183979 27.56221962 26.91397667 26.91721344 26.91851425 26.92452049 26.91838264 26.92335892 26.91721344 26.91547394 26.91748047 26.92624855 26.91963577 26.91919899 26.91961288 26.91952896 26.91464615 26.91697121 26.91734314 26.92474937 26.91630363 26.92766762 26.9168396 26.91762352 26.91994858 26.91871643 26.92198563 26.92302704 26.91792297 26.91627502 26.91347694 26.9167614 26.91729355 26.92749405 26.91990471 26.92973137 26.91945076 26.91375542 26.92011261 26.92060852 26.92466164 26.91761017 26.92523384 26.92877388 26.91748619 26.93013573 26.93065834 

-------
======================
selected experts : 13, 16, 18, 57, 62, 63, 
layer23_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee1eb60>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0869226 -0.195127 -0.00683361-0.561033 0.658098 0.719169 0.109476 -0.258927 -0.228366]

layer23_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de7806d0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.86657 -0.31143 0.0210415-0.202728 0.244327 1.09314 0.834367 1.06534 0.766711]

layer24_wq's input 
<N9nntrainer6TensorE at 0x5682de5e9620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wq's output 
<N9nntrainer6TensorE at 0x5682de23a580>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.336158 -0.169375 -0.425678-0.648299 -0.123858 -0.259336 0.708369 -0.032059 -0.618515]
============================
layer24_wk's input 
<N9nntrainer6TensorE at 0x5682de680bc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wk's output 
<N9nntrainer6TensorE at 0x5682de1e9fa0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0118696 -0.0472703 0.113450.103728 0.0296149 -0.0224001 -0.0348054 0.0611872 -0.0188398]
============================
layer24_wv's input 
<N9nntrainer6TensorE at 0x5682de7cdb70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wv's output 
<N9nntrainer6TensorE at 0x5682de067420>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0733123 0.0836663 -0.00333526-0.468789 0.0173092 0.0456101 -0.047658 0.045135 -0.0803263]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.347911 -0.143694 0.3471760.693514 0.230853 0.17118 -0.368396 0.605887 -0.600019]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a36c99a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer24_attention_out's input 
<N9nntrainer6TensorE at 0x5682de40b530>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer24_attention_out's output 
<N9nntrainer6TensorE at 0x5682de646540>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer24_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de7c4940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.86657 -0.31143 0.0210415-0.202728 0.244327 1.09314 0.834367 1.06534 0.766711]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.272563 -0.0340113 0.00226365-0.0220298 0.0260193 0.124133 0.094748 0.115767 0.0820663]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.929450631 -1.128785849 -0.6543552279 -0.8471324444 -1.39042747 -0.55434829 -0.02498121932 -0.4676400721 -2.470920801 -1.70237565 -0.9748182893 -1.800919175 -0.2439994067 -1.728101611 -1.238625407 -0.255404681 -0.2346673757 -1.047284842 -2.222267866 -0.4669069946 -0.6821814775 0.1248121113 -1.806736708 -0.9977571964 -0.1882074773 -1.306464791 -1.56954062 -1.755864024 -0.8727980852 -1.033334374 -1.979539037 5.464857101 -1.646643162 -0.4878594875 0.3052386045 -0.8554965258 -0.3183939159 -0.9714736342 1.016834497 -2.717564344 -1.23928678 -0.06641087681 0.3262445629 -1.273775458 -1.078132153 0.4311248064 0.4545654655 -2.53660512 -1.765888453 -1.713524938 -1.485613465 -1.774708033 -1.024132609 -1.954378843 0.06704782695 -0.327961266 0.04493098333 -2.279580355 0.0472863242 -0.5062567592 -1.145820975 -1.043580055 -1.944802403 -2.451274872 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0005397897912 0.001202122658 0.001931931009 0.001593196415 0.0009253784083 0.002135128016 0.003625144018 0.002328525297 0.0003140994813 0.0006773952045 0.001402220107 0.0006138258614 0.002912103198 0.0006601905916 0.001077075489 0.002879079431 0.002939406782 0.001304200152 0.0004027686082 0.002330232412 0.001878913492 0.004210945219 0.0006102650659 0.001370421145 0.003079192713 0.001006430946 0.0007736269617 0.0006421142025 0.001552826958 0.001322522294 0.0005134185776 0.8780751228 0.0007162198308 0.002281915629 0.00504356809 0.001579926931 0.002703321865 0.001406917698 0.01027495414 0.0002454432251 0.001076363376 0.003478022991 0.005150632001 0.001039873925 0.001264583552 0.005720176734 0.005855846219 0.0002941310522 0.00063570973 0.0006698846119 0.0008413577452 0.0006301276735 0.001334747649 0.0005264999345 0.003974594176 0.002677580575 0.003887654282 0.0003803341533 0.003896822687 0.002240319503 0.001181818079 0.001309041283 0.0005315663293 0.0003203311935 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.83124924 28.83095741 28.8326416 28.82610321 28.83115768 28.83141327 28.83481216 28.83351517 28.83102417 28.83138657 28.82925034 28.83180046 28.83409882 28.8275547 28.83083534 28.83406448 28.83317184 28.82772255 28.82777405 28.83351707 28.83306503 28.82967567 28.82846069 28.83255577 28.83426476 28.83219337 28.83005333 28.83182907 28.83273888 28.83203125 28.83169937 29.70830727 28.83190346 28.83251381 28.83622932 28.83276558 28.83436584 28.83259392 28.8352623 28.83143234 28.82844734 28.83466339 28.83633614 28.82984161 28.83054352 28.8364296 28.83704185 28.83004951 28.82896042 28.82994843 28.83107376 28.83181572 28.83156776 28.82980537 28.83516121 28.83195686 28.83507347 28.83156586 28.83555984 28.83342743 28.83236885 28.82963371 28.83171844 28.83102989 

-------
======================
selected experts : 31, 34, 38, 42, 45, 46, 
layer24_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df21d1f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.833895 -0.802753 -0.3862-2.35492 0.648108 1.42702 0.936258 -1.31322 -0.598527]

layer24_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de2b2790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.70047 -1.11418 -0.365158-2.55765 0.892435 2.52016 1.77062 -0.247877 0.168184]

layer25_wq's input 
<N9nntrainer6TensorE at 0x5682ddf10a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wq's output 
<N9nntrainer6TensorE at 0x5682de7d58a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.64346 4.6151 -3.59633-1.6699 -4.39449 -0.0783202 -2.1087 -2.86507 -0.238884]
============================
layer25_wk's input 
<N9nntrainer6TensorE at 0x5682de480fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wk's output 
<N9nntrainer6TensorE at 0x5682de0aef30>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0538789 0.0193812 -0.0043537-0.242867 0.037277 -0.198658 0.0676407 -0.0872147 0.0887407]
============================
layer25_wv's input 
<N9nntrainer6TensorE at 0x5682ddd64050>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wv's output 
<N9nntrainer6TensorE at 0x5682de58dbd0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.241149 -0.135526 -0.009660890.227738 -0.432866 0.166314 -0.223882 0.00738034 -0.38231]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.76484 -5.01721 3.377072.07788 3.91987 -1.98804 3.55414 -0.152758 3.35521]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a38ce9b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer25_attention_out's input 
<N9nntrainer6TensorE at 0x5682df211490>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer25_attention_out's output 
<N9nntrainer6TensorE at 0x5682dddde7f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer25_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0184b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.70047 -1.11418 -0.365158-2.55765 0.892435 2.52016 1.77062 -0.247877 0.168184]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.566076 -0.200941 -0.0646798-0.457149 0.156638 0.47074 0.325032 -0.0443051 0.0295192]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-2.033876419 -0.6662036777 -2.519889355 -1.634744644 -1.620467186 -1.470805049 -1.356907725 -0.6036100984 -2.662803173 -3.570815802 -0.7119606137 -2.638509989 -2.228242636 -2.593982458 -1.716693759 -1.688163757 -3.056198359 -2.286839008 -2.550026178 -0.5139263868 -0.06882531941 -1.386721492 -2.962647438 -2.006780863 -2.144985676 -2.108816862 -1.044886827 0.2158241868 1.383966804  -0.539756 -2.881628513 -1.352892756 -1.068458796 -0.9172226787 -1.361247182 -0.08626000583 -2.900213718 -2.272035122 -0.9135314226 -1.731878757 -2.158599854 -2.207988501 -1.664811611 -0.8823071718 -3.022545099 -0.1656448096 -2.413261414 -1.190886617 -0.6852507591 -0.8799331188 -2.690348148 -2.977132082 -2.799127102 -2.899184465 -2.980380535 -1.859682441 -1.973814964 -1.156326056 -1.944438696 -1.011434793 -0.5033848286 -1.838603735 -1.536196589 2.701905012 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003711364232 0.01457157079 0.002282764297 0.005531900097 0.005611447617 0.006517372094 0.007303609047 0.01551281009 0.001978765707 0.0007980854134 0.01391984802 0.002027424518 0.003055776004 0.002119740704 0.00509664556 0.00524414517 0.001335195615 0.002881864319 0.002214994747 0.01696835272 0.0264816191 0.007089074235 0.001466133283 0.003813301679 0.003321082564 0.003443400143 0.00997806713 0.03520191088 0.1132098287 0.01653567515 0.001589863212 0.007332991809 0.009745614603 0.01133679319 0.007271982264 0.02602392063 0.001560588018 0.00292484439 0.01137871668 0.00501983799 0.003276173491 0.003118299181 0.005368050653 0.01173961349 0.001380893984 0.02403789014 0.002539620269 0.008622624911 0.01429665275 0.01176751871 0.00192500453 0.001445050235 0.00172659161 0.001562194782 0.001440364053 0.004417588003 0.003941104282 0.008925837465 0.004058597609 0.01031749882 0.01714816876 0.004511693027 0.006104826927 0.4229192436 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.69184685 28.70556831 28.69089508 28.69700432 28.69660759 28.69751358 28.69829941 28.70460129 28.69297409 28.69083977 28.70539284 28.69350052 28.69500542 28.69216156 28.69227791 28.69337845 28.69280815 28.69006348 28.6932106 28.70844078 28.71461678 28.69522476 28.69246292 28.6952858 28.6947937 28.6939621 28.70145035 28.72667503 28.79896164 28.70228577 28.6925869 28.69880676 28.70121956 28.70281029 28.69826889 28.71749687 28.69255638 28.69439697 28.70237541 28.69506264 28.69236565 28.69363785 28.69684029 28.70225906 28.69285393 28.71551132 28.69210434 28.69723511 28.70529366 28.70276451 28.69005966 28.6919651 28.68890762 28.69255829 28.69243622 28.6930294 28.69398308 28.7003994 28.69553185 28.70131302 28.70385361 28.69550705 28.69757843 29.11439133 

-------
======================
selected experts : 20, 27, 28, 35, 45, 63, 
layer25_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df270060>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.44193 3.30931 -0.1478391.66089 -1.97504 -0.568949 3.54565 0.684309 -1.95359]

layer25_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddfd81b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.1424 2.19513 -0.512997-0.896758 -1.0826 1.95121 5.31627 0.436431 -1.78541]

layer26_wq's input 
<N9nntrainer6TensorE at 0x5682de245ed0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wq's output 
<N9nntrainer6TensorE at 0x5682de21e590>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-7.19763 4.21139 1.345270.336204 -5.75587 3.75966 4.87192 1.62306 1.39669]
============================
layer26_wk's input 
<N9nntrainer6TensorE at 0x5682de23ab70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wk's output 
<N9nntrainer6TensorE at 0x5682de320f60>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.146106 -0.197982 -0.1023530.20076 -0.00982388 -0.0815199 -0.115575 0.150995 -0.0874328]
============================
layer26_wv's input 
<N9nntrainer6TensorE at 0x5682dde7eae0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wv's output 
<N9nntrainer6TensorE at 0x5682ddeee690>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.787365 1.20748 2.441630.378884 -1.00658 -1.26723 0.465748 0.381196 -1.92399]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[7.89188 2.69443 -1.29689-0.490782 3.32613 -6.01681 -4.06401 3.13906 0.763877]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a116d080
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer26_attention_out's input 
<N9nntrainer6TensorE at 0x5682df278ee0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer26_attention_out's output 
<N9nntrainer6TensorE at 0x5682df278e40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer26_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df27a260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.1424 2.19513 -0.512997-0.896758 -1.0826 1.95121 5.31627 0.436431 -1.78541]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.23653 0.539361 -0.126048-0.221282 -0.258047 0.497869 1.323 0.106318 -0.433065]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.229813457 -0.05995209515 -2.346139908 -1.001055837 -0.8235158324 -0.05465627834 -0.1190630272 0.5707327127 0.606651783 0.7820273638 0.002560531255 -0.5726556778 -0.5510423183 -1.395941615 -0.6992129683 -0.1102071032 -0.01739729755 -1.311926961 -0.3690626919 0.4405331016 -0.3804124296 0.1966792345 -0.3727973402 -0.2154888511 0.1727482677 -0.1869333088 0.1713048369 1.859833717 -1.653277993 -1.194599271 -0.2070242614 -2.092623711 0.7438879013 -0.4336843491 -0.8664966226 -0.5564077497 -0.4844253659 -1.836260319 0.4542253315 4.332145214 0.1508646607 0.1188326254 -0.7216179967 -0.6991884112 0.1267536134 0.3779300153 -1.579019308 -0.1242448017 0.3456149697 -0.2343725562 -2.290715456 -0.7030614018 0.944742322 0.4067699015 0.230991438 -1.112182736 -0.7881058455 -1.062981129 -1.485591888 -0.741122663 -1.58641994 0.2200573087 0.5616708994 0.5927568078 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.002155417111 0.006943775341 0.000705857412 0.002709440188 0.003235818585 0.006980645005 0.006545219105 0.01304663718 0.01352377981 0.01611620188 0.007391705178 0.004158448894 0.004249306396 0.001825504005 0.003664107528 0.00660344027 0.007245643996 0.001985500567 0.005097421817 0.01145390794 0.005039894953 0.008975305595 0.005078420509 0.005943563767 0.008763066493 0.006115731318 0.008750427514 0.0473530665 0.00141131226 0.00223267125 0.005994088482 0.0009095313144 0.0155131137 0.004778436851 0.003099687397 0.004226566292 0.004542022478 0.001175316633 0.01161181554 0.5611246228 0.008573383093 0.00830311235 0.003582925536 0.003664198564 0.008369144984 0.01075883955 0.001520104008 0.006511391141 0.01041672565 0.005832380615 0.0007460833876 0.003650033148 0.01896395534 0.01107364334 0.009288612753 0.002424475737 0.003352451371 0.002546746517 0.00166896882 0.003513719188 0.001508895191 0.009187606163 0.01292894501 0.01333716605 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.06168747 33.06742859 33.06309891 33.06414795 33.06467438 33.06746674 33.06798553 33.06781006 33.07210159 33.07374191 33.06978607 33.06655121 33.06568909 33.06422043 33.06510544 33.06804276 33.06868362 33.06342316 33.06558228 33.06812668 33.06647873 33.0704155 33.06365585 33.06738281 33.0692482 33.06755447 33.06923676 33.10306931 33.06189728 33.06462479 33.06838608 33.06234741 33.07218552 33.06621933 33.06263351 33.06661987 33.06598282 33.06166077 33.07400513 33.61779404 33.06810379 33.06974411 33.06502151 33.06510544 33.07076263 33.07315063 33.06295776 33.06890488 33.07281113 33.06631851 33.06027985 33.06604385 33.08040237 33.07346725 33.06786728 33.06481934 33.06479263 33.06208038 33.06311035 33.06495285 33.06390381 33.06871796 33.07246017 33.07382202 

-------
======================
selected experts : 8, 9, 27, 32, 39, 52, 
layer26_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df27d4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.09747 -1.72508 -0.102068-3.96982 0.264923 0.310013 0.223394 0.572912 -0.468745]

layer26_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddd52130>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[8.23987 0.470053 -0.615066-4.86658 -0.817679 2.26123 5.53967 1.00934 -2.25415]

layer27_wq's input 
<N9nntrainer6TensorE at 0x5682de328070>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wq's output 
<N9nntrainer6TensorE at 0x5682ddefef30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-3.71408 1.9354 2.356543.03328 2.67895 4.20827 -1.76141 2.67573 -0.578456]
============================
layer27_wk's input 
<N9nntrainer6TensorE at 0x5682de1e5e50>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wk's output 
<N9nntrainer6TensorE at 0x5682ddfc8350>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.400105 -0.24232 0.401053-0.150454 0.0979789 0.371003 -0.358186 -0.0571382 0.698908]
============================
layer27_wv's input 
<N9nntrainer6TensorE at 0x5682de7969c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wv's output 
<N9nntrainer6TensorE at 0x5682de46fef0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.420768 -0.0722796 -0.2112940.196022 -0.195416 0.81495 0.146881 0.813715 -0.146626]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.8924 1.54577 -1.98675-3.28738 -4.33733 -2.46452 -1.23888 -2.9542 -4.31689]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a054f020
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer27_attention_out's input 
<N9nntrainer6TensorE at 0x5682de426170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer27_attention_out's output 
<N9nntrainer6TensorE at 0x5682de0d2950>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer27_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de6e6390>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[8.23987 0.470053 -0.615066-4.86658 -0.817679 2.26123 5.53967 1.00934 -2.25415]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.05855 0.114221 -0.147658-1.16832 -0.203481 0.564918 1.35693 0.242312 -0.538953]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.987653255 -0.7842393517 -2.230341911 -0.758665204 -1.053579092 -1.312015295 1.44309485 -0.69209975 -1.784579635 -1.067586184 -0.6883801222 -1.15128839 -0.1300299764 -0.478109628 -0.1315491945 -0.6079538465 -0.1765194386 1.365325212 -1.465485215 -1.203162909 -0.4411250651 -0.5796673298 -0.9326632023 -0.09328451753 -2.341962814 -0.3186990917 -1.199958563 2.033224821 -0.1808017492 -1.539794326 1.491401196 -1.677116752 -0.9739207029 -0.5623084307 -0.4002993405 -1.290343404 -0.2136254013 2.042429447 0.2812911868 -0.07124047726 -0.1099433899 -0.68425107 -0.9261820316 -1.498537898 -1.244819045 -0.7785608768 0.3858971894 -1.06656611 -0.2841586769 -1.134593248 -2.137027025 -0.7241751552 -2.135964632 -1.843329668 -0.5121998787 -1.465894222 -2.073708057 -0.02629480883 -0.6666491628 -2.23829031 -0.3608047664 -1.097417712 -1.685164094 -0.1254190207 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.002409837907 0.008028305136 0.001890555723 0.008236270398 0.006132691167 0.004736021161 0.07446338981 0.008803178556 0.00295244297 0.006047389004 0.008835984394 0.005561813246 0.01544341724 0.0109037105 0.01541997306 0.009575990029 0.01474189386 0.06889185309 0.004062212072 0.00528065348 0.01131452806 0.009850728326 0.006920925807 0.01602144539 0.001690881327 0.01278808154 0.005297601689 0.1343485564 0.0146788964 0.003771294607 0.078148745 0.003287396161 0.00664119469 0.01002322044 0.01178601291 0.004839781206 0.01420490444 0.1355908811 0.02330117859 0.01637854613 0.01575675793 0.008872545324 0.006965926848 0.00393013889 0.005065199919 0.00807402283 0.02587066963 0.006053561345 0.01323750429 0.005655448884 0.002075465396 0.00852529332 0.002077671699 0.002783984412 0.01053826418 0.004060550593 0.002211132087 0.01713148504 0.009030101821 0.001875588438 0.01226080861 0.005869649351 0.003261048347 0.01551478729 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
31.49386406 31.49948311 31.49334526 31.50016785 31.49615669 31.49428368 31.56687164 31.49978065 31.49393082 31.49798012 31.50076866 31.4955864 31.50546837 31.50283623 31.50639915 31.49960136 31.50619698 31.55700874 31.49599457 31.48624611 31.50324631 31.50178337 31.49885368 31.50413895 31.49219322 31.50424385 31.49675179 31.62341881 31.50661087 31.49188805 31.5700798 31.49426651 31.49809647 31.5014782 31.50133324 31.49629402 31.50089073 31.62180138 31.51571083 31.50783348 31.50768852 31.5008049 31.49746704 31.49586296 31.49747467 31.49905205 31.50683594  31.497509 31.50564575 31.4975872 31.49400711 31.49998093 31.49353218 31.4928093 31.50199318 31.4926548 31.49414253 31.50763321 31.5009613 31.49380684 31.50419235 31.49732399 31.49519348 31.50696945 

-------
======================
selected experts : 6, 17, 27, 30, 37, 46, 
layer27_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df2fed10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-2.73092 -1.75519 1.56366.56381 4.80255 3.19545 -10.1483 2.09887 -0.0882844]

layer27_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de4dbd00>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.50894 -1.28514 0.9485321.69723 3.98487 5.45668 -4.60863 3.10822 -2.34244]

(93958)Ilayer0_wq's input 
<N9nntrainer6TensorE at 0x5682dde663b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00470756 -0.0465267 -0.01080840.0123846 0.0280342 -0.012272 -0.0514805 -0.00136512 0.0315807]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5682de7965e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.166964 -1.09071 1.079920.0058572 0.676155 0.796471 -0.433137 -0.820415 0.66633]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5682ddd56d10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00470756 -0.0465267 -0.01080840.0123846 0.0280342 -0.012272 -0.0514805 -0.00136512 0.0315807]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5682de0a36b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.86394 -0.0748888 0.168426-0.845703 0.365969 -0.525742 -1.64801 0.556798 0.671278]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5682e0a65b00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00470756 -0.0465267 -0.01080840.0123846 0.0280342 -0.012272 -0.0514805 -0.00136512 0.0315807]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5682dde490d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0143575 0.0228836 0.003861170.00985081 0.0516625 0.0180623 0.0077625 -0.0177031 0.00990551]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.09327 -0.149287 -0.639619-0.870144 -0.52588 -0.902774 0.740596 0.558754 -0.537642]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a259f520
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer0_attention_out's input 
<N9nntrainer6TensorE at 0x5682e0a64030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer0_attention_out's output 
<N9nntrainer6TensorE at 0x5682e0a638e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer0_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dde13420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00302124 -0.0292053 -0.008056640.00805664 0.0161133 -0.00805664 -0.0312195 -0.00100708 0.0241699]

layer0_ffn_gate's input 
<N9nntrainer6TensorE at 0x5682ddfb82c0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0210257 -0.201616 -0.05471740.052916 0.110786 -0.051565 -0.21552 -0.00689597 0.16145]
==============================
layer0_ffn_gate's output 
<N9nntrainer6TensorE at 0x5682dde852c0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[0.0710219 -0.0243796 -0.08894840.12087 0.0489584 -0.104624 0.0413304 0.0387468 -0.0774261]
============================
layer0_ffn_up's input 
<N9nntrainer6TensorE at 0x5682de34f990>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0210257 -0.201616 -0.05471740.052916 0.110786 -0.051565 -0.21552 -0.00689597 0.16145]
==============================
layer0_ffn_up's output 
<N9nntrainer6TensorE at 0x5682dde690c0>
data addr: 0x7fc0a7fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.129525 -0.047763 -0.2889950.0299654 -0.331167 -0.346303 -0.0853519 -0.0627946 -0.10754]
============================
layer0_ffn_down's input 
<N9nntrainer6TensorE at 0x5682dc3e1140>
data addr: 0x7fc0aafd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.00476281 0.000575125 0.01228160.00192028 -0.0083051 0.017169 -0.00180026 -0.00124011 0.00400212]
==============================
layer0_ffn_down's output 
<N9nntrainer6TensorE at 0x5682dc3e0770>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.000936617 0.0861878 0.002459120.0408338 -0.0465336 -0.0519033 -0.00198296 0.0126573 0.0261818]
============================
layer0_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3e1bb0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00208462 0.0569825 -0.005597520.0488904 -0.0304203 -0.0599599 -0.0332024 0.0116502 0.0503517]

layer1_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e48b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.003422 0.090049 -0.007508580.0856461 -0.0376385 -0.0657403 -0.0496224 0.0147001 0.09129]
==============================
layer1_wq's output 
<N9nntrainer6TensorE at 0x5682dc3e2330>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-2.2137 1.49018 1.76725-0.873064 2.77531 0.719708 -1.12149 1.2827 1.41735]
============================
layer1_wk's input 
<N9nntrainer6TensorE at 0x5682dc3e6610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.003422 0.090049 -0.007508580.0856461 -0.0376385 -0.0657403 -0.0496224 0.0147001 0.09129]
==============================
layer1_wk's output 
<N9nntrainer6TensorE at 0x5682dc3e6380>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.00567 1.59998 1.3431.87863 0.238808 1.73569 -2.11491 -0.212269 1.81347]
============================
layer1_wv's input 
<N9nntrainer6TensorE at 0x5682dc3e7400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.003422 0.090049 -0.007508580.0856461 -0.0376385 -0.0657403 -0.0496224 0.0147001 0.09129]
==============================
layer1_wv's output 
<N9nntrainer6TensorE at 0x5682dc3e7190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0673909 0.0620003 0.109753-0.102173 0.0435433 0.0182136 -0.0732091 -0.0083449 0.147085]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.801029 2.54548 -1.75505-0.897339 -2.60593 -1.19561 0.470467 -1.6376 1.01959]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a34c4d98
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer1_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ea340>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer1_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ea2a0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer1_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3eb440>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00208462 0.0569825 -0.005597520.0488904 -0.0304203 -0.0599599 -0.0332024 0.0116502 0.0503517]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0031794 0.270845 -0.02537140.274307 -0.140865 -0.351105 -0.187914 0.062511 0.185047]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4307895005 -0.1841507256 0.135800615 0.04447042197 -0.0499409847 -0.4950153232 -0.5512891412 1.30370307 1.275840998 0.5842041373 -0.3279032111 -1.648462653 -0.02648603171 -0.0264756158 -0.2227101475 2.397724152 -0.6761419773 -0.2701722682 0.5824278593 0.1082199812 0.001042265445 -0.4016340971 1.609354734 -0.5031391382 -0.5605567694 -0.6605211496 -0.1350102723 -1.336895704 -0.5455344915 2.85885191 -0.6387345195 -0.1259180605 -0.6464231014 -0.07153322548 -0.07752400637 0.3379843533 -0.1304998696 -0.5933691859 0.4696699679 -1.348541856 -0.9087414145 -1.581966996 1.002173305 1.892059326 -0.8242944479 0.5786972046 -0.6346139908 0.05505080894 -0.4305692911 -0.01128564775 -1.803298354 -0.3296391964 -0.5814422369 -0.3645513356 -0.6953773499 -0.8920446634 0.763395071 0.3901729286 -0.1331802905 -0.1245460138 1.428204656 -1.546777725 -0.6999182105 -0.2506659031 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01537049562 0.008310415782 0.01144394744 0.01044507604 0.009504062124 0.00608998118 0.005756739527 0.03679505363 0.03578401729 0.01791905425 0.00719766831 0.001921675866 0.009729616344 0.009729715995 0.007996070199 0.109879531 0.005081052426 0.007625424769 0.01788725331 0.01113263052 0.01000117604 0.006686069537 0.04994963109 0.006040709093 0.005703633651 0.005161046516 0.008728994057 0.002624170622 0.005789962132 0.1742537022 0.005274720956 0.008808720857 0.005234321579 0.009301048703 0.009245495312 0.01400822587 0.008768454194 0.005519520957 0.01597988047 0.002593786223 0.00402658619 0.002053803531 0.02721678093 0.06626883894 0.004381389357 0.01782064326 0.005296500865 0.01055617724 0.006495380308 0.009878640063 0.001646022662 0.007185184397 0.005585746374 0.006938662846 0.004984250292 0.004094382282 0.02143565007 0.01475870889 0.00874498114 0.008820815012 0.04167348519 0.00212736195 0.004961668514 0.007775629871 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
62.87144089 62.86343002 62.86751556 62.86460876 62.86366653 62.86120605 62.86087418 62.89191437 62.89090347 62.87303543 62.86231613 62.85704041 62.86484909 62.86484909 62.8631134 62.96308899 62.86019897 62.86274338 62.87300491 62.86624908 62.86511993 62.86180496 62.90029907 62.86211395 62.86082077 62.86027908 62.86384583 62.85869598 62.85900116 63.02841949 62.8613472 62.86392593 62.86130524 62.86441803 62.8653183 62.86912537 62.86388779 62.85873032 62.87109756 62.85771179 62.85914612 62.85812378 62.88042831 62.92138672 62.85950089 62.87294006 62.85850525 62.86567307 62.86066055 62.86499786 62.85676193 62.86230469 62.86070251 62.86205673 62.86010361 62.85825729 62.87559891 62.86987686 62.86386108 62.86393738 62.89678955 62.8572464 62.86008072 62.86289215 

-------
======================
selected experts : 7, 15, 22, 29, 43, 60, 
layer1_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e0a3ef10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0245953 -0.0391809 -0.02191010.0561746 -0.0766892 -0.0429587 -0.0702658 0.0359129 -0.109381]

layer1_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3ee080>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.02668 0.0178016 -0.02750760.105065 -0.10711 -0.102919 -0.103468 0.0475631 -0.0590292]

layer2_wq's input 
<N9nntrainer6TensorE at 0x5682dc3ee2c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.105586 0.0526663 -0.07292650.347169 -0.253097 -0.340076 -0.320027 0.139803 -0.165567]
==============================
layer2_wq's output 
<N9nntrainer6TensorE at 0x5682dc3ee260>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.728063 0.116087 -0.7897090.168591 -0.62339 -0.0035476 0.975437 0.2551 -0.481121]
============================
layer2_wk's input 
<N9nntrainer6TensorE at 0x5682dc3edf00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.105586 0.0526663 -0.07292650.347169 -0.253097 -0.340076 -0.320027 0.139803 -0.165567]
==============================
layer2_wk's output 
<N9nntrainer6TensorE at 0x5682dc3ede70>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.49132 0.0543507 -0.20134-2.59986 0.763209 -1.86359 -0.642021 1.05378 -0.949512]
============================
layer2_wv's input 
<N9nntrainer6TensorE at 0x5682dc3ee380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.105586 0.0526663 -0.07292650.347169 -0.253097 -0.340076 -0.320027 0.139803 -0.165567]
==============================
layer2_wv's output 
<N9nntrainer6TensorE at 0x5682dc3ee3b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.725264 -0.00604983 -0.4373230.0222086 -0.0746775 -0.442288 0.476208 0.433268 0.273971]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0952053 0.731087 0.6064650.533163 0.613092 0.112898 -0.991427 0.183374 -0.72555]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0856c38
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer2_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ee500>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer2_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ee620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer2_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3fefb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.02668 0.0178016 -0.02750760.105065 -0.10711 -0.102919 -0.103468 0.0475631 -0.0590292]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0471549 0.0731857 -0.1083330.468274 -0.428001 -0.466616 -0.457182 0.20742 -0.209794]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.0934920162 0.5232843757 -0.8450167775 -0.3234837353 -0.0336504057 2.137332201 -0.5679025054 0.006714668591 -0.3903882802 0.1523206532 0.2629042566 -0.2128079832 0.240971595 0.1091089919 -0.5416561365 -0.6098800302 1.601985097 -0.7315782309 -0.3482190669 1.016847491 -0.2046647668 0.06216091663 0.1674819887 -0.1112588271 -0.535158813 -0.2945003808 -0.5575503707 0.02658708766 -1.601998091 0.1779913604 -0.6792650819 -0.06728672981 -0.1698344648 -0.322052598 -0.0734956935 -0.309035331 -0.6906391978 -0.7844748497 0.08373695612 0.03448255733 0.4836958349 -0.1885450035 -0.5079341531 1.050334334 0.06574561447 0.2271577567 0.693333745 -0.1737065762 -0.3850834966 0.2595508099 1.380516768 0.5898442268 -0.4565664828 -0.9783053398 0.5971566439 -0.1786491424 0.2759366035 -0.8576596379 -1.095670342 0.5211244226 -0.1892276555 -0.1837007254 0.04368966445 0.7588869333 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0116348099 0.0215586666 0.005487521645 0.009244323708 0.01235231012 0.1082913876 0.007239780389 0.01286111027 0.00864607282 0.01487696543 0.01661652513 0.01032621227 0.01625604741 0.01424779743 0.007432313636 0.006942163687 0.06340093166 0.006146699656 0.009018465877 0.03531616926 0.01041064411 0.01359435264 0.01510423888 0.01142992266 0.007480761502 0.009516175836 0.007315116934 0.01311924774 0.002574088285 0.01526381262 0.006476812065 0.01194373332 0.01077963877 0.009257561527 0.01186980586 0.009378859773 0.00640356075 0.005830009468 0.01389084943 0.01322324108 0.02072186209 0.01057982072 0.007687221281 0.03651881963 0.01364316978 0.01603303291 0.0255548507 0.01073797885 0.008692059666 0.01656089723 0.05080578476 0.02304243855 0.008092412725 0.004802747164 0.02321155183 0.01068503596 0.01683449559 0.005418580491 0.004270893056 0.02151214704 0.01057260111 0.01063119527 0.01334555261 0.02728618123 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
53.42539597 53.43531799 53.41925049 53.42300415 53.42611313 53.52014542 53.42100143 53.42662048 53.42240906 53.42863846 53.43037796 53.4212265 53.43001556 53.42800903 53.42119217 53.42070389 53.47620773 53.41990662 53.42277908 53.44812393 53.42417145 53.42544937 53.42886353 53.4242363 53.42124176 53.42327881 53.42012405 53.42687988 53.41633606 53.42902374 53.42023849 53.42570496 53.42454147 53.42301941 53.42563248 53.42314148 53.42016602 53.41863632 53.42765045 53.42698288 53.43448257 53.42433929 53.42144775 53.45027924 53.4274025 53.42979431 53.4393158 53.42449951 53.41959381 53.43032074 53.46456528 53.43489456 53.42185211 53.41856384 53.4360199 53.42444611 53.4305954 53.41917801 53.41707993 53.43527222 53.42338181 53.42343903 53.42710495 53.44104767 

-------
======================
selected experts : 5, 16, 19, 43, 50, 63, 
layer2_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e09f8dd0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0519867 0.00856681 -0.0284037-0.0400309 0.0270178 0.0200372 0.0438958 -0.00988634 -0.0751584]

layer2_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc401970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0786666 0.0263684 -0.05591130.0650342 -0.0800917 -0.0828815 -0.0595725 0.0376768 -0.134188]

layer3_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e86c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.371832 0.0749493 -0.1526720.168237 -0.191842 -0.199847 -0.150303 0.0950594 -0.426412]
==============================
layer3_wq's output 
<N9nntrainer6TensorE at 0x5682dc409160>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.0692 -0.458864 1.38395-1.07684 -0.394386 1.17786 -0.148935 -0.389548 0.619026]
============================
layer3_wk's input 
<N9nntrainer6TensorE at 0x5682dc41f6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.371832 0.0749493 -0.1526720.168237 -0.191842 -0.199847 -0.150303 0.0950594 -0.426412]
==============================
layer3_wk's output 
<N9nntrainer6TensorE at 0x5682dc41f440>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[3.77456 0.805306 0.5845431.64642 -2.70246 1.18473 0.379973 0.740736 -1.26943]
============================
layer3_wv's input 
<N9nntrainer6TensorE at 0x5682dc4204c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.371832 0.0749493 -0.1526720.168237 -0.191842 -0.199847 -0.150303 0.0950594 -0.426412]
==============================
layer3_wv's output 
<N9nntrainer6TensorE at 0x5682dc420250>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.181916 -0.197801 -0.242114-0.0812725 0.0323169 -0.359375 0.0569709 0.188467 -0.595215]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.136723 -1.15545 -1.6899-0.468155 0.59498 -1.09037 0.300294 0.289401 -1.54785]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1679ca8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer3_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc422910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer3_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc422870>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer3_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc423990>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0786666 0.0263684 -0.05591130.0650342 -0.0800917 -0.0828815 -0.0595725 0.0376768 -0.134188]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.140693 0.0997921 -0.2035630.263778 -0.294157 -0.338814 -0.238772 0.146199 -0.443554]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7289729714 -0.5335597396 -0.1839262992 -0.5233195424 0.3554777801 0.2119001746 1.552555442 -0.6535074711 -0.00459009409 -0.07510069758 0.5618703961 0.1054131314 0.253040731 -0.1304226369 -1.080092669 -0.1675660461 -1.218974829 -0.8078290224 -0.05679995567 -0.01361918356 0.1924585104 -0.1846369505 -0.4339244068 -0.5550991893 -0.09112460911 -0.4543816149 -0.3196879923 -0.5018143058 -0.2495882511 0.2730513811 -0.9791836739 0.1265223324 -0.4175069928 -0.1767056584 1.010258198 0.4161131382 -0.3894725144 0.1850838661 -0.7227553725 -0.01342593506 0.02664080262 -0.4128195047 -1.153370023 -0.5147992373 -0.3168607652 -0.4345905781 -0.4674172699 -0.5376713276 1.158827305 -1.018765807 1.621137977 -0.1733201444 0.3592012525 0.07649448514 0.09867663682 -0.5094680786 -0.08239448071 0.6137117743 -0.8467483521 1.075052023 1.401985168 -0.4103972316 -0.1727882624 -1.128186226 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006799882744 0.008267388679 0.01172768231 0.008352482691 0.02011279576 0.01742278039 0.06658197194 0.007332900073 0.01403126772 0.0130759906 0.02472336777 0.01566284709 0.01815451123 0.01237224694 0.004786435049 0.01192112826 0.004165780731 0.006284268107 0.01331749279 0.01390514988 0.01708732359 0.01171935163 0.009133546613 0.008091217838 0.01286813058 0.008948598057 0.01023886167 0.008534051478 0.0109823579 0.01852145605 0.00529463822 0.01599699259 0.009284732863 0.01181267016 0.0387114957 0.02137007378 0.009548707865 0.01696177572 0.006842294708 0.01390783675 0.01447639242 0.009328356944 0.004448239692 0.008423952386 0.01026785001 0.009127464145 0.008832703345 0.008233467117 0.04491203278 0.005089159124 0.07130856067 0.01185273007 0.02018782683 0.01521638595 0.01555769052 0.008468980901 0.0129809631 0.02603886276 0.00604438642 0.0413028039 0.05727496371 0.009350981563 0.01185903698 0.004561685026 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
42.54202271 42.53967285 42.54694748 42.54357529 42.55437851 42.55264282 42.59798813 42.54350662 42.54925156 42.54925156 42.55899048 42.55088425 42.55051422 42.54759216 42.54000854 42.54714203 42.53938675 42.54055023 42.54949188 42.54721832 42.55230713 42.54789352 42.54530716 42.54331207 42.54808807 42.54417038 42.54545975 42.54375458 42.54620361 42.55374146 42.5405159 42.55121994 42.54164505 42.54703522 42.57393265 42.55659103 42.54476929 42.55218124 42.54206467 42.54912949 42.54969788 42.54454803 42.54062271 42.54364395 42.54358292 42.54434967 42.54405212 42.54345322 42.58108521 42.54030991 42.60748291 42.54707336 42.5544548 42.55043793 42.55077744 42.54273605 42.54820251 42.5622139 42.54030991 42.57270813 42.59249496 42.54457092 42.54708099 42.53978348 

-------
======================
selected experts : 6, 34, 48, 50, 59, 60, 
layer3_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc426710>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.060015 -0.0205406 0.0372005-0.0560069 0.0877867 -0.00908835 -0.0705842 0.0198905 0.0873397]

layer3_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc426050>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.138682 0.00582782 -0.01871080.00902725 0.007695 -0.0919698 -0.130157 0.0575673 -0.0468479]

layer4_wq's input 
<N9nntrainer6TensorE at 0x5682dc44b9a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.350666 0.016757 -0.05298880.0273912 0.0195685 -0.28172 -0.383648 0.175507 -0.140796]
==============================
layer4_wq's output 
<N9nntrainer6TensorE at 0x5682dc492890>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.969563 0.721811 -1.201660.176894 1.05716 -0.291057 0.800175 0.638609 0.780764]
============================
layer4_wk's input 
<N9nntrainer6TensorE at 0x5682dc44d700>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.350666 0.016757 -0.05298880.0273912 0.0195685 -0.28172 -0.383648 0.175507 -0.140796]
==============================
layer4_wk's output 
<N9nntrainer6TensorE at 0x5682dc44d470>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.985035 -1.19871 1.55621-0.124086 -1.33027 0.445463 -1.51528 -0.496529 -0.296997]
============================
layer4_wv's input 
<N9nntrainer6TensorE at 0x5682dc44e4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.350666 0.016757 -0.05298880.0273912 0.0195685 -0.28172 -0.383648 0.175507 -0.140796]
==============================
layer4_wv's output 
<N9nntrainer6TensorE at 0x5682dc44e280>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.232352 0.0497875 0.2972450.215731 1.04167 0.073453 -0.145023 0.023658 -0.0093237]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.967191 -0.724987 0.8589130.858806 -1.09184 0.101007 -0.995657 -0.238263 -1.15971]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1e8dce8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer4_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc450940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer4_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4508a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer4_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4519c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.138682 0.00582782 -0.01871080.00902725 0.007695 -0.0919698 -0.130157 0.0575673 -0.0468479]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.254483 0.0222303 -0.06839880.0365216 0.0293528 -0.377398 -0.53786 0.226246 -0.16178]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4233067334 -0.8003293872 0.6444360018 -0.4378878772 -1.36439085 -0.1103366837 -0.7561166883 0.1250419915 0.3909090459 0.02027952112 -0.2909910083 0.1024083048 -0.9229542017 -0.448563695 -1.051607847 -0.5025811195 -0.5787528753 0.1923734844 -0.9440920353 -0.5193585753 -0.08674078435 -1.059256077 -0.4905348122 -0.6434621215 -0.8703958392 1.485964775 -0.1829965711 -0.744075954 -0.7400940061 -1.118461967 -0.506603539 -0.1404953897 0.03317378461 -0.8824873567 -0.2091689259 0.6334250569 0.6675570011 -1.059693217 0.1148692369 -0.3503339589 -0.3829305768 -0.5799865723 0.864215374 -0.6390654445 -0.493824482 0.3954688013 1.241177559 -0.1369689256 0.2495298237 2.187966347 2.07179904 1.488792062 -0.8710832596 -0.5833969712 0.1309114397 0.8206555247 -0.95511657 0.3027754426 -1.015067458 -0.1963151693 0.06178678945 0.2862616777 -1.829807281 -0.1472508758 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01924641244 0.005661497824 0.02400960401 0.008134627715 0.003220791463 0.01128733344 0.005917424336 0.01428285614 0.01863286458 0.01286225859 0.009421806782 0.01396321505 0.005008136388 0.008048247546 0.004403545521 0.007625034545 0.007065791171 0.01527765673 0.004903385881 0.007498172577 0.01155683771 0.004369994625 0.007717443164 0.006623048335 0.005278395023 0.05570014566 0.01049628574 0.005989104975 0.006013001315 0.004118775483 0.007594425697 0.01095200609 0.01302918326 0.005214955658 0.01022513676 0.02374668419 0.02457119711 0.004368084949 0.01413829438 0.008878955618 0.008594199084 0.007057080045 0.0299112089 0.00665223226 0.007692097686 0.01871802099 0.04360603169 0.01099069603 0.01617630944 0.1123910472 0.1000647023 0.05585784465 0.005274767522 0.007033053786 0.01436693408 0.02863625437 0.004849625286 0.01706096902 0.004567428492 0.0103574153 0.0134073738 0.01678154245 0.002022249857 0.01087826863 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.83690262 40.82331848 40.8407135 40.82674408 40.82183075 40.82989883 40.82452774 40.83098602 40.83247375 40.8314743 40.82707977 40.83257294 40.82361984 40.82570648 40.82301331 40.82623672 40.82376862 40.83198166 40.82351303 40.82611084  40.829216 40.82298279 40.82346725 40.82332611 40.82293701 40.87430954 40.82624817 40.82269287 40.82462311 40.82273102 40.82620621 40.82956314 40.83164215 40.82382584 40.82883453 40.84045029 40.84032059 40.82011795 40.83274841 40.82558441 40.82625198 40.82566833 40.84852219 40.8243103 40.82630157 40.83351517 40.86221695 40.82864761 40.8338356 40.92337418 40.91772079 40.87160873 40.82388687 40.82469177 40.83202362 40.84724808 40.82345963 40.83567047 40.82031631 40.82896805 40.83201981  40.835392 40.82063293 40.82949066 

-------
======================
selected experts : 25, 42, 46, 49, 50, 51, 
layer4_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc454a40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0478261 -0.0202937 0.1414030.138244 0.0105741 0.0660352 -0.078456 -0.0414171 -0.0757324]

layer4_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc454380>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.186508 -0.0144659 0.1226920.147271 0.0182691 -0.0259347 -0.208613 0.0161502 -0.12258]

layer5_wq's input 
<N9nntrainer6TensorE at 0x5682dc4a0910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37183 -0.0395841 0.2973610.381879 0.0397548 -0.0713048 -0.551814 0.0452452 -0.319453]
==============================
layer5_wq's output 
<N9nntrainer6TensorE at 0x5682dc454560>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.27904 -1.01169 -0.9215611.36454 -0.72238 -0.498745 1.54375 0.659523 -1.45093]
============================
layer5_wk's input 
<N9nntrainer6TensorE at 0x5682dc4a2670>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37183 -0.0395841 0.2973610.381879 0.0397548 -0.0713048 -0.551814 0.0452452 -0.319453]
==============================
layer5_wk's output 
<N9nntrainer6TensorE at 0x5682dc4a23e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[3.24098 0.412286 -2.08267-1.41415 0.314497 -1.61792 -1.16653 0.709432 -1.39033]
============================
layer5_wv's input 
<N9nntrainer6TensorE at 0x5682dc4a3460>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37183 -0.0395841 0.2973610.381879 0.0397548 -0.0713048 -0.551814 0.0452452 -0.319453]
==============================
layer5_wv's output 
<N9nntrainer6TensorE at 0x5682dc4a31f0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.139015 0.095336 -0.0847325-0.0599647 0.125625 -0.379508 -0.338026 -0.0653292 0.0863798]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.89098 -0.554556 1.6449-0.0745707 0.623638 0.617782 -1.6777 0.0586365 0.557123]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1c88cd8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer5_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc4a58b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer5_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4a5810>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer5_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a6930>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.186508 -0.0144659 0.1226920.147271 0.0182691 -0.0259347 -0.208613 0.0161502 -0.12258]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.345097 -0.0535328 0.4348510.579535 0.0642743 -0.101381 -0.815489 0.0618702 -0.415289]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.6644698381 0.3958806396 -0.8431923985 0.2933754027 -0.9926815033 0.3259683251 0.4573433399 -1.295527816 -0.8638315797 -0.5962546468 1.083653688 -0.5674967766 -0.2397421151 -0.5430603027 -1.03829217 -0.1272376031 -0.290961802 1.88923049 -0.6655781865 -0.4766088128 1.197840452 -0.892660141 -1.295008659 0.4723694921 -0.5369101167 -0.04444982111 -0.7701082826 -0.6128735542 -0.4972300231 -0.9362294674 0.0592253916 -0.4229903519 0.525193572 -0.3231920004 -0.5599902868 -0.8925861716 0.3094721735 -0.1731057167 0.5254550576 0.6374439001 0.4803516567 -1.244556785 -1.547644854 -0.3532342017 0.2070346922 -0.2350983173 -0.2090717554 -1.477300048 0.4622754753 -0.6229419112 0.3936619759 -1.05861032 -0.765895009 -1.137443542 -0.4172428548 0.1035719812 0.1171668693 -0.9444702864 -0.2407902479 -0.0649222061 -1.223350048 -0.465829283 -0.371851325 -0.9839936495 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03131745011 0.02394085377 0.006934529636 0.02160837501 0.005971654784 0.0223242566 0.02545848116 0.004411337432 0.006792874075 0.008876888081 0.04762506858 0.009135873988 0.012679209 0.00936187245 0.005705402233 0.01418901514 0.01204613503 0.1065842882 0.008282355964 0.01000511926 0.05338586867 0.006599840242 0.004413628019 0.02584391087 0.009419627488 0.0154136857 0.007460313383 0.008730582893 0.009800913744 0.006318463944 0.01709747873 0.01055622008 0.02724579349 0.01166407671 0.009204710834 0.006600328255 0.0219590161 0.01355289109 0.02725291811 0.03048240207 0.02605102956 0.00464201672 0.003428286873 0.01131887082 0.01982096769 0.01273822412 0.01307410747 0.003678134643 0.02558435686 0.008643120527 0.0238877926 0.005590649322 0.007491810247 0.005166843999 0.01061706711 0.01787275821 0.0181173943 0.0062666093 0.01266592741 0.01510133874 0.004741509445 0.01011355128 0.01111009717 0.006023761351 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.26918793 33.26371765 33.24861908 33.26329422 33.24574661 33.26019287 33.26714325 33.23941803 33.24752426 33.25056076 33.28835678 33.24986649 33.25436401 33.2481842 33.24739075 33.25587463 33.25373077 33.33968353 33.24996567 33.25168991 33.28553391 33.24828339 33.24609756 33.26752853 33.24633408 33.25709915 33.24914551 33.2504158 33.25148392 33.24704742 33.25878143 33.25033188 33.26320648 33.2533493 33.25088882 33.24732971 33.26364136 33.25523758 33.26512146 33.26930618 33.26773453 33.24632645 33.2441597 33.25300217 33.25959778 33.25442123 33.25475693 33.24440765 33.26631546 33.25032806 33.26366425 33.24727631 33.24536133 33.24589539 33.24943924 33.25574112 33.25979996 33.24318314 33.25434875 33.25678635 33.24642563 33.24702835 33.25088501 33.24103165 

-------
======================
selected experts : 0, 10, 17, 20, 38, 39, 
layer5_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc4a9a10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0342631 0.0553379 -0.039758-0.0504181 0.0299267 0.0941602 0.0995771 -0.124148 0.0256439]

layer5_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a9350>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.152245 0.040872 0.08293390.0968529 0.0481958 0.0682255 -0.109036 -0.107998 -0.0969364]

layer6_wq's input 
<N9nntrainer6TensorE at 0x5682dc4e8620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.481221 0.135603 0.2714360.327848 0.136133 0.21565 -0.334867 -0.321996 -0.291189]
==============================
layer6_wq's output 
<N9nntrainer6TensorE at 0x5682dc4a9530>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.08021 0.134619 -1.689510.372374 -0.432704 -1.72997 0.560465 1.13711 -2.68552]
============================
layer6_wk's input 
<N9nntrainer6TensorE at 0x5682dc4ea380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.481221 0.135603 0.2714360.327848 0.136133 0.21565 -0.334867 -0.321996 -0.291189]
==============================
layer6_wk's output 
<N9nntrainer6TensorE at 0x5682dc4ea0f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.24336 0.122814 -0.1984340.556906 0.592433 -1.41524 -0.579507 0.669371 0.388004]
============================
layer6_wv's input 
<N9nntrainer6TensorE at 0x5682dc4eb170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.481221 0.135603 0.2714360.327848 0.136133 0.21565 -0.334867 -0.321996 -0.291189]
==============================
layer6_wv's output 
<N9nntrainer6TensorE at 0x5682dc4eaf00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.270678 -0.163141 -0.07282670.287713 0.071787 -0.199607 0.473052 -0.0426461 0.254859]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.435504 -0.997655 1.306861.13368 0.122377 1.77906 -0.990385 -0.79138 1.03653]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1a83cc8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer6_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc41beb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer6_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc41be10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer6_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc41cf30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.152245 0.040872 0.08293390.0968529 0.0481958 0.0682255 -0.109036 -0.107998 -0.0969364]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.24061 0.139268 0.2732950.343046 0.157741 0.246238 -0.393529 -0.380101 -0.3064]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4410547912 -1.218328714 -0.749876678 -0.9559231997 -0.1196647584 0.1754807979 -0.5955162048 -1.395718694 -1.214615464 2.168490887 0.1459833086 0.8688387871 -0.7450354695 0.1884209365 0.9173011184 0.175174281 -0.9830300212 -1.049170732 -0.6121963263 -0.0005945349112 -0.5670848489 0.2899364531 0.5462858081 -0.2541283667 0.09138106555 0.06696138531 -1.341629744 -1.249254823 -0.4981438816 -1.828889728 0.9308676124 0.9007117152 0.7550630569 0.6048219204 0.6557562947 0.1265725344 0.4342204928 -0.3482604623 -1.431741595 0.3023626208 2.698046684 -1.048008323 -0.1608816832 -0.9697629213 -0.1068262458 -0.6657227874 -0.5831062198 0.0226062946 -1.022549629 -0.3982205987 -0.1861209869 -0.4678562284 0.5408172607 -0.1379685253 -0.3198312521 -0.4305019677 -0.6436776519 -0.3965961635 -0.2285197973 -0.2880137563 -0.3232179582 0.3415495753 0.3171806037 -0.8836710453 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01893318258 0.00360215595 0.005754514132 0.004682996776 0.01080702711 0.01451731566 0.006715008989 0.003016637405 0.003615557216 0.1065220684 0.01409534365 0.02904075198 0.005782441236 0.01470639277 0.03048279695 0.0145128658 0.004557759501 0.004266059492 0.00660392968 0.01217356324 0.006908665877 0.0162777286 0.02103414759 0.009447337128 0.0133463433 0.01302437484 0.003184296191 0.003492460819 0.007401756942 0.001956136664 0.03089915961 0.02998127788 0.02591765299 0.02230215259 0.02346752398 0.0138243828 0.0188042298 0.008598613553 0.002909902483 0.0164812617 0.1808934212 0.004271020647 0.01037064847 0.004618631676 0.01094666682 0.006259738468 0.006798860617 0.01245930512 0.00438115187 0.008179579861 0.01011217758 0.00762936892 0.02091943286 0.0106110163 0.008846570738 0.007919748314 0.006399268284 0.008192877285 0.009692393243 0.009132574312 0.008816663176 0.01713993214 0.01672729664 0.005033876281 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.14231491 40.12698364 40.12150955 40.12806702 40.13418961 40.13790131 40.13105011 40.12639999 40.1269989 40.22990417 40.13747787 40.14956284 40.12916565 40.13713455 40.15386581 40.13789368 40.12794113 40.1276474 40.12998581 40.13555527 40.13029099 40.13965988 40.14441681 40.13283157 40.13673019 40.13640594 40.12752151 40.12687683 40.13078308 40.12533951 40.15142059 40.1524086 40.14929962 40.14568329 40.14685059 40.13720703 40.14218521 40.1319809 40.12629318 40.13986206 40.30427551 40.12765503 40.13280106 40.12800217 40.13433075 40.13059616 40.12922668 40.13584137 40.12680817 40.13156128 40.13349533 40.13101196 40.14430237 40.13399506 40.12936783 40.13130188 40.12882996 40.13157654 40.13116837 40.13251495 40.13219833 40.13766098 40.14011002 40.12841797 

-------
======================
selected experts : 9, 11, 14, 30, 31, 40, 
layer6_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc47b4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.116619 0.06211 0.0381594-0.153191 0.0637205 -0.0967168 0.0778489 0.131376 0.107361]

layer6_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc47ae20>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.268863 0.102982 0.121093-0.0563378 0.111916 -0.0284913 -0.0311867 0.0233776 0.010425]

layer7_wq's input 
<N9nntrainer6TensorE at 0x5682dc5555c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.644431 0.295358 0.332417-0.150038 0.27742 -0.073543 -0.0830561 0.0581881 0.029045]
==============================
layer7_wq's output 
<N9nntrainer6TensorE at 0x5682dc47b000>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.732738 0.628422 1.19-0.581977 -0.188778 0.047805 -0.324582 0.481942 0.357657]
============================
layer7_wk's input 
<N9nntrainer6TensorE at 0x5682dc557b30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.644431 0.295358 0.332417-0.150038 0.27742 -0.073543 -0.0830561 0.0581881 0.029045]
==============================
layer7_wk's output 
<N9nntrainer6TensorE at 0x5682dc5578a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.62036 0.00124264 1.4656-1.44503 -0.546472 0.551392 -0.13881 0.625616 -0.065592]
============================
layer7_wv's input 
<N9nntrainer6TensorE at 0x5682dc558920>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.644431 0.295358 0.332417-0.150038 0.27742 -0.073543 -0.0830561 0.0581881 0.029045]
==============================
layer7_wv's output 
<N9nntrainer6TensorE at 0x5682dc5586b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.152496 -0.0865679 0.2932710.462981 -0.2989 0.268249 0.458184 0.729476 0.53018]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.810459 -0.52438 -1.17704-0.607761 0.194238 -0.0139324 0.089142 -0.574173 0.583571]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a187ecb8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer7_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc55ad70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer7_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc55acd0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer7_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55bdf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.268863 0.102982 0.121093-0.0563378 0.111916 -0.0284913 -0.0311867 0.0233776 0.010425]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.407589 0.34599 0.391955-0.196204 0.362251 -0.0992247 -0.111167 0.0794998 0.0328892]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.098373771 0.2836256325 -0.2417769879 -0.3635024428 -0.606269002 0.2527832985 1.537901521 0.4816333354 0.09163210541 -1.234294653 -1.267491341 0.1218170673 -1.077616811 -0.6664997339 -1.141363263 -1.204203129 0.3488199711 -0.7398209572 -0.5408400297 -0.4675128162 0.485101819 0.2313048244 -0.05166152492 0.2560469806 1.058061838 -0.336117357 -0.6226214767 -0.9360643625 0.6463159323 -1.137920022 -0.1322301924 -0.1359293163 -0.3121391535 -0.7324919105 -0.521625936 0.09431058168 -0.3835838437 -0.3052536845 -0.400924474 -0.5267472863 0.1987118423 -1.661210179 -0.8067662716 -0.8190937042 -0.7711262703 0.4742020965 -0.4262674153 -0.8152752519 -0.8452249765 -0.2902589738 -0.3541771472 -0.3275723457 -0.3245003223 -0.08514315635 -1.52711904 -0.1305801272 -0.6654924154 -0.6012252569 -0.7324240804 -0.9401038289 1.551528454 -0.654296875 1.070305347 0.1213589758 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005570847541 0.02218789048 0.01312008314 0.01161640882 0.009112547152 0.02151401155 0.07777520269 0.02704641409 0.01831193827 0.004862858914 0.004704077728 0.01887311041 0.005687691271 0.008579893969 0.005336435977 0.005011413712 0.02368261106 0.007973313332 0.009728706442 0.01046889275 0.0271403864 0.02105685323 0.01586728729 0.02158434317 0.04813371971 0.01193892118 0.008964744397 0.006552566774 0.03188823164 0.005354842171 0.01463902555 0.01458497252 0.0122286547 0.008031964302 0.009917442687 0.01836105064 0.01138546225 0.01231314428 0.0111897327 0.009866783395 0.02038160898 0.003173106583 0.007457012311 0.007365650497 0.00772757316 0.02684617229 0.01090971567 0.007393830456 0.007175670471 0.01249916758 0.01172524225 0.0120413769 0.01207842398 0.01534481905 0.003628436942 0.01466319896 0.008588538505 0.009158621542 0.008032510057 0.006526151206 0.07884228975 0.008685233071 0.04872666672 0.01886446774 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
35.92993164 35.95131683 35.94129562 35.93693161 35.93633652 35.95064545 35.98973846 35.95426941 35.94648743 35.93304062 35.93383408 35.94800186 35.93481827 35.93580246 35.93446732 35.93318939 35.95281219 35.93710327 35.93695068 35.93864441 35.95531845 35.94923401 35.94213867 35.94880676 35.96677399 35.93916321 35.93809509 35.93473053 35.94861984 35.93448639 35.94281769 35.94276047 35.9404068 35.93716431 35.93904877 35.94272232 35.93956375 35.93953705 35.93936539 35.9380455 35.94665146 35.93039703 35.93468094 35.93649673 35.93685913 35.9521637 35.93908691 35.93652344 35.93535233 35.93686295 35.93990326 35.93640518 35.94120789 35.94352341 35.93275833 35.9418869 35.93676376 35.93828964 35.93716431 35.9356575 36.00606537 35.93781662 35.97785568 35.94704056 

-------
======================
selected experts : 6, 20, 24, 28, 60, 62, 
layer7_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5969b0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0117731 -0.00431516 0.09412550.0485652 -0.0529214 -0.069048 -0.0954666 0.055075 0.0510467]

layer7_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55e510>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.25709 0.0986668 0.215219-0.00777257 0.0589949 -0.0975393 -0.126653 0.0784525 0.0614716]

layer8_wq's input 
<N9nntrainer6TensorE at 0x5682dc59a250>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.541513 0.253167 0.515135-0.0193481 0.134994 -0.235332 -0.30315 0.184024 0.151843]
==============================
layer8_wq's output 
<N9nntrainer6TensorE at 0x5682dc5d3620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0237115 0.0685095 -0.414937-0.247035 -0.467361 0.0607781 -0.238849 0.292587 -0.135862]
============================
layer8_wk's input 
<N9nntrainer6TensorE at 0x5682dc59bfb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.541513 0.253167 0.515135-0.0193481 0.134994 -0.235332 -0.30315 0.184024 0.151843]
==============================
layer8_wk's output 
<N9nntrainer6TensorE at 0x5682dc59bd20>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.896541 -1.61613 1.186980.590892 0.540082 -0.798445 -0.046022 -2.45929 -0.234835]
============================
layer8_wv's input 
<N9nntrainer6TensorE at 0x5682dc59cda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.541513 0.253167 0.515135-0.0193481 0.134994 -0.235332 -0.30315 0.184024 0.151843]
==============================
layer8_wv's output 
<N9nntrainer6TensorE at 0x5682dc59cb30>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.15903 -0.87771 0.1879420.172852 0.341283 -0.0373287 0.476336 0.355474 0.699468]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0589694 0.0421711 0.04931780.480381 0.470774 0.0221873 0.0919551 -0.366333 0.578787]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1474c98
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer8_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc59f1f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer8_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc59f150>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer8_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a0270>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.25709 0.0986668 0.215219-0.00777257 0.0589949 -0.0975393 -0.126653 0.0784525 0.0614716]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.401212 0.334407 0.684099-0.0276827 0.189782 -0.349262 -0.451087 0.2689 0.194218]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5820931196 -0.2350897938 -0.4585057497 -0.3865448833 0.7096521854 0.06612271816 -0.6608039141 -0.3367446661 -0.8939000368 -0.4477111101 -1.01867187 -0.6945809126 -0.962595582 1.454297066 0.001071602106 0.02070719749 -0.7310253978 -1.269895792 0.4321978688 0.4479066133 -0.2188422233 -0.8506630659 -1.137848377 -0.3327110112 0.3433792889 0.1516014189 0.6872583628 -1.29946208 -0.8785806894 -0.856221199 -0.2928788364 -1.726149082 -0.4915761352 -0.9426625967 1.706531644 -0.5457578897 -1.037370682 -1.509035707 -0.5542669296 0.1647266001 -0.8272060752 -0.7226264477 0.09949754179 1.002302289 -0.6495707631 -0.2562497854 -0.1520896554 -0.1404538006 0.3654158711 -1.098366261 -0.5634807944 -0.00612174347 0.2465134561 -0.5623323917 -0.5518009067 -1.863395095 -0.1223517507 -0.4435008764 0.2245500088 -1.699274421 0.5346589684 -0.5374289751 0.04647413269 1.446173787 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009014371783 0.01275372691 0.01020020247 0.01096127369 0.03280449286 0.01723661833 0.008332048543 0.01152096875 0.006599627901 0.01031090599 0.005825479981 0.008055317216 0.006161484402 0.06907621026 0.01615104638 0.0164713189 0.007767030969 0.004531338345 0.02485630102 0.02524984069 0.01296263654 0.006891234312 0.005170994438 0.01156753115 0.02274380066 0.0187747851 0.03207804263 0.004399325233 0.006701508537 0.006853039376 0.01203759294 0.002871298464 0.009868394583 0.006285533309 0.08889402449 0.009347935207 0.005717563909 0.003567544976 0.00926873181 0.01902283169 0.007054793648 0.007832539268 0.01782159321 0.04395716265 0.008426170796 0.01248669345 0.01385745872 0.01401964389 0.02325055934 0.005379240494 0.009183721617 0.01603528298 0.0206440445 0.009194273502 0.009291616268 0.002503070515 0.01427573897 0.01035440993 0.02019557171 0.00294950977 0.02753815055 0.009426117875 0.0169012472 0.06851735711 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.0813446 34.08603668 34.08253098 34.08424377 34.10513687 34.09051895 34.08161545 34.08480453 34.0789299 34.0826416 34.07910919 34.07561874 34.07563019 34.14236069 34.08943558 34.08784866 34.0800972 34.07781601 34.07048416 34.09090424 34.08529282 34.07921982 34.07845688 34.08389664 34.0950737 34.09110641 34.10536194 34.07672882 34.07998657 34.07918167 34.08532333 34.07615662 34.0821991 34.07862091 34.15550232 34.08072662 34.07900238 34.07589722 34.08160019 34.0904007 34.07938385 34.08111572 34.09015274 34.11437988 34.08171082 34.08576965 34.08714294 34.08634949 34.09558105 34.07866287 34.08246613 34.08836746 34.09202194 34.08247757 34.07780838 34.07578659 34.08755875 34.08268356 34.09252548 34.07623291 34.10082245 34.08175659 34.08446503 34.12844849 

-------
======================
selected experts : 4, 13, 26, 34, 43, 63, 
layer8_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5a3350>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0659566 0.0530296 0.1635850.0778446 -0.0195666 0.0881568 0.183909 0.170824 0.0908925]

layer8_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a2c90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.191133 0.151696 0.3788040.0700721 0.0394283 -0.00938249 0.0572556 0.249276 0.152364]

layer9_wq's input 
<N9nntrainer6TensorE at 0x5682dc5e1750>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628368 0.419554 0.9949620.203553 0.100819 -0.02546 0.153375 0.659083 0.445254]
==============================
layer9_wq's output 
<N9nntrainer6TensorE at 0x5682dc5a2e70>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.990122 -0.0779878 1.01044-0.451464 -0.0806437 1.01568 0.814009 0.598821 0.507806]
============================
layer9_wk's input 
<N9nntrainer6TensorE at 0x5682dc5e3c80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628368 0.419554 0.9949620.203553 0.100819 -0.02546 0.153375 0.659083 0.445254]
==============================
layer9_wk's output 
<N9nntrainer6TensorE at 0x5682dc5e39f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.93641 -0.107036 -0.8609020.46931 0.199984 -0.895828 -0.831834 -0.632928 -0.362626]
============================
layer9_wv's input 
<N9nntrainer6TensorE at 0x5682dc5e4a70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628368 0.419554 0.9949620.203553 0.100819 -0.02546 0.153375 0.659083 0.445254]
==============================
layer9_wv's output 
<N9nntrainer6TensorE at 0x5682dc5e4800>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.249564 -0.310188 -0.025437-0.134065 -1.11543 0.202387 0.0279106 0.0432688 0.980205]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.206076 -0.971575 -0.965173-0.541534 0.257644 -0.98576 -0.991281 -0.196367 -0.710499]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a126fc88
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer9_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc5e6ec0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer9_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc5e6e20>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer9_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5e7f40>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.191133 0.151696 0.3788040.0700721 0.0394283 -0.00938249 0.0572556 0.249276 0.152364]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.287586 0.493438 1.166280.2389 0.121394 -0.0321514 0.1962 0.815181 0.463806]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5784392953 -2.692181826 -0.5327215791 -1.096446872 0.06641447544 -0.5960524678 0.4831649363 -0.9647579789 0.7627049088 -0.09703366458 -2.138244867 -1.655194521 -0.7575159669 -0.2602666914 -1.185462832 -1.286947131 -1.109573603 -0.4413939416 -0.1912102252 0.1474581361 2.318176985 -1.217723966 1.076936603 -1.016357303 -1.984680414 -0.8027300239 -0.8972060084 -0.9883889556 -0.08658076823 -0.681370914 -1.071043372 -0.9319506288 -0.4055244625 -1.134295821 0.2941918075 0.5751672387 -0.2030042708 0.5597757101 -1.342829466 -1.232607245 0.2436300069 1.034404755 0.596901238 2.314760923 -0.914604485 -1.468491554 -1.077005982 -0.7855711579 -1.070604563 -1.898351192 0.5030686259 -0.6025437117 -1.22859478 -0.6789172292 -1.126736045 -0.4787145555 0.06532867253 0.009236903861 0.5657193065 -0.2974469364 -0.4449689388 -1.005197048 0.08275671303 -0.4499510229 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.008367558941 0.001010676147 0.008758983575 0.004984606989 0.01594612747 0.00822146982 0.02419065125 0.005686207209 0.03199265152 0.0135416165 0.00175866764 0.002850820543 0.006995628588 0.01150215697 0.004560073372 0.004120005295 0.004919602536 0.009596587159 0.01232452411 0.01729226671 0.1515595168 0.004415306728 0.04380455986 0.005400244147 0.002050576499 0.006686371285 0.006083591841 0.005553410854 0.01368390862 0.007549115457 0.005112856161 0.005875850562 0.009947058745 0.004799470771 0.02002523467 0.02652184106 0.01218002196 0.02611675672 0.003896083683 0.004350080155 0.01903789304 0.04198053479 0.02710457519 0.1510426551 0.005978662521 0.00343600614 0.005082459655 0.006802092306 0.005115099251 0.002235467779 0.02467696182 0.008168275468 0.004367568996 0.00756766228 0.004835891072 0.009245037101 0.01592881791 0.01505993959 0.02627244778 0.01108235773 0.009562339634 0.005460849497 0.01620886102 0.009514818899 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.4602623 34.45290375 34.45492935 34.45592499 34.46688461 34.46011353 34.45414734 34.45758057 34.48388672 34.46448135 34.45365143 34.45474243 34.45888901 34.46339417 34.45645142 34.45601273 34.45586014 34.46149063 34.46326447 34.46918488 34.59772873 34.45630646 34.49474335 34.45538712 34.45394516 34.45858002 34.45797729 34.45744705 34.45508575 34.45944214 34.45700455 34.45776749 34.46088791 34.45573807 34.4719162 34.46983337 34.45835114 34.4770546 34.45578766 34.45624161 34.44709015 34.4938736 34.47422791 34.60198212 34.45787048 34.4553299 34.45697403 34.45392609 34.45510101 34.45412827 34.47180176 34.46006012 34.45626068 34.45946121 34.45386887 34.45923233 34.46496201 34.4659996 34.47625732 34.46202087 34.45954895 34.4573555 34.4681015 34.45949936 

-------
======================
selected experts : 8, 20, 22, 41, 42, 43, 
layer9_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5eb020>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0292678 -0.0956209 -0.113527-0.268267 0.0155715 -0.0378454 0.0868689 0.020848 -0.0885791]

layer9_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5ea960>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.220401 0.0560755 0.265277-0.198195 0.0549998 -0.0472279 0.144125 0.270124 0.063785]

layer10_wq's input 
<N9nntrainer6TensorE at 0x5682ded33210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.39589 0.154817 0.723569-0.566966 0.133552 -0.132746 0.397908 0.673894 0.163371]
==============================
layer10_wq's output 
<N9nntrainer6TensorE at 0x5682dc5eab40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.181234 -0.342398 1.430770.0895295 -0.553066 0.257564 0.0833396 -1.49051 -1.00958]
============================
layer10_wk's input 
<N9nntrainer6TensorE at 0x5682ded34f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.39589 0.154817 0.723569-0.566966 0.133552 -0.132746 0.397908 0.673894 0.163371]
==============================
layer10_wk's output 
<N9nntrainer6TensorE at 0x5682ded34ce0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.53692 -0.0485435 -0.1724740.715683 0.119405 -0.883975 1.76163 -0.277954 0.280245]
============================
layer10_wv's input 
<N9nntrainer6TensorE at 0x5682ded35d60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.39589 0.154817 0.723569-0.566966 0.133552 -0.132746 0.397908 0.673894 0.163371]
==============================
layer10_wv's output 
<N9nntrainer6TensorE at 0x5682ded35af0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.559905 -0.0366422 0.3549090.866707 -0.239438 -0.0393911 0.553588 0.34391 1.07834]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.379743 0.0766639 -0.781803-1.20163 0.589685 -0.156503 0.557649 1.38477 0.731075]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a106ac78
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer10_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded38210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer10_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded38170>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer10_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded39290>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.220401 0.0560755 0.265277-0.198195 0.0549998 -0.0472279 0.144125 0.270124 0.063785]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.317078 0.182795 0.81181-0.679041 0.168312 -0.162594 0.503378 0.885047 0.193075]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.06926098466 -1.889656901 -2.135423183 -1.227051497 -0.4244788289 -0.7646638155 -0.2025152743 -0.2169721425 1.188247561 -0.662728548 -1.118843555 0.2492176294 0.9456104636 -1.251841784 -0.3659493923 -0.8920525908 -0.1320210993 -0.5265669227 0.1242789775 -1.218567133 -0.7645328045 -0.8224347234 -1.494637251 1.817089558 -0.5894706845 -0.3520736098 -0.3152672648 0.9674650431 0.737018168 0.09049356729 -0.4484396577 -1.74812007 -0.8611502647 0.1298037916 0.4455396831 0.7185868621 1.352536917 -0.9928257465 -0.9874344468 0.2044235319 0.3249462843 -0.4133012295 -1.023074627 -0.9486420751 -0.08636790514 0.4954489172 -1.477710724 -0.9838752151 -0.9046508074 -0.6560556293 -0.6540198922 -0.6196044087 -1.701559186 -0.4007335007 -1.854149699 0.3188380301 -1.211869359 0.8672431707 -1.061550379 -1.684293866 -1.357903361 -1.057067871 -0.7432658076 -1.377599716 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01834772527 0.002587229479 0.002023485489 0.005018811673 0.01119834371 0.007969174534 0.01398141962 0.01378074847 0.05617614463 0.008824360557 0.005592358299 0.02196526341 0.04407334328 0.004895923194 0.01187333651 0.00701599149 0.01500260178 0.01011154335 0.01938546821 0.005061573815 0.007970217615 0.007521834224 0.00384051865 0.105354853 0.009495083243 0.01203923579 0.01249061152 0.04504714906 0.03577548265 0.01874146052 0.01093321107 0.002980599878 0.007236186881 0.01949286275 0.02672994137 0.03512213379 0.06620669365 0.006343425252 0.00637771748 0.02100306191 0.02369326726 0.01132421568 0.00615441706 0.006629985757 0.01570339315 0.0280978661 0.003906078404 0.006400457118 0.006928157993 0.008883440867 0.008901544847 0.00921322871 0.003122661263 0.01146743447 0.002680745209 0.0235489849 0.00509558944 0.04075130448 0.005922118668 0.003177043051 0.004403242376 0.005948724225 0.008141535334 0.004317363258 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.1207962 33.10598755 33.10542297 33.10842133 33.11460114 33.10183334 33.11738205 33.11718369 33.15766907 33.11222458 33.10899353 33.12441254 33.1474762 33.10257339 33.11146164 33.11041641 33.11840439 33.11256027 33.11611176 33.10560226 33.11041641 33.11092377 33.10724258 33.20303345 33.11003494  33.110672 33.11493683 33.14844894 33.13822174 33.12214279 33.11338043 33.10638046 33.11063766 33.12289429 33.13013077 33.13661575 33.16770172 33.10974503 33.10977936 33.12440491 33.10897446 33.09565353 33.10955429 33.11003113 33.11910629 33.1295929 33.10635376 33.10980225 33.1055603 33.11228561 33.10848618 33.11261368 33.10652542 33.11296082 33.10608292 33.12694931 33.10659027 33.13938522 33.10741425 33.10562515 33.10780334 33.10744095 33.11154175 33.10771942 

-------
======================
selected experts : 8, 12, 23, 27, 36, 57, 
layer10_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded3c110>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.161962 -0.0780533 0.1249870.0509749 0.26931 0.0336457 -0.056708 0.0038211 0.0792823]

layer10_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded3bb90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.382363 -0.0219779 0.390264-0.14722 0.32431 -0.0135822 0.0874166 0.273945 0.143067]

layer11_wq's input 
<N9nntrainer6TensorE at 0x5682ded7c3b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.633897 -0.0508481 0.85691-0.364473 0.688197 -0.032825 0.202248 0.573248 0.326785]
==============================
layer11_wq's output 
<N9nntrainer6TensorE at 0x5682ded3ba40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.657842 0.365413 0.2754280.0422222 -0.275213 -0.197291 0.727014 -0.487024 -0.91165]
============================
layer11_wk's input 
<N9nntrainer6TensorE at 0x5682ded7e110>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.633897 -0.0508481 0.85691-0.364473 0.688197 -0.032825 0.202248 0.573248 0.326785]
==============================
layer11_wk's output 
<N9nntrainer6TensorE at 0x5682ded7de80>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.47571 0.339769 -0.600838-1.8889 -1.66195 2.8416 -0.0334167 -0.885505 2.48664]
============================
layer11_wv's input 
<N9nntrainer6TensorE at 0x5682ded7ef00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.633897 -0.0508481 0.85691-0.364473 0.688197 -0.032825 0.202248 0.573248 0.326785]
==============================
layer11_wv's output 
<N9nntrainer6TensorE at 0x5682ded7ec90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.427054 0.818584 0.0928597-0.0225618 0.314247 -0.0656768 -0.627374 -0.441628 -0.612546]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.163798 0.734474 -0.130446-0.246225 0.236317 0.242529 -0.451309 0.749708 0.608157]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0e65c68
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer11_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded813b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer11_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded81310>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer11_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded82430>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.382363 -0.0219779 0.390264-0.14722 0.32431 -0.0135822 0.0874166 0.273945 0.143067]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.481761 -0.0667179 1.0927-0.466439 0.922375 -0.0440336 0.283404 0.823539 0.398467]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1634536982 0.2338491082 1.390282989 -0.3676809072 -0.5225353837 0.1594894528 1.739082575 -2.323273182 -1.632861614 -0.00858733058 -1.730676174 -1.526996255 0.113975741 -0.1351315677 -2.58881259 0.814460218 -0.05961622298 -0.1475380659 0.4953226447 -0.9851433039 -1.164471626 0.004394590855 0.316722542 -0.2453278005 1.028160095 -0.268912673 -1.446122289 -0.4320624769 0.7278697491 -0.5316099524 -1.532606602 -1.846465111 -1.457428217 -0.6088111997 -0.6791196465 -0.2312903404 -1.189405918 -0.5066782236 -1.544893384 -0.2530484796 -0.3886814713 -0.8982741237 -2.302025318 2.996816397 -1.963040948 -0.8953847885 1.07270515 -2.094770432 -1.289910674 -1.249869108 -0.7210344076 -0.9068789482 -0.1988134235 -0.3278206587 -0.8654219508 -0.7071698308 1.135054111 -1.895164251 -0.7949581146 -1.250328422 -0.9984998107 -0.09211537242 0.314479351 0.6850012541 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01535347197 0.01647323184 0.05236145854 0.009026882239 0.007731883321 0.01529272459 0.07421530038 0.001277129399 0.00254728063 0.01292677131 0.002309917705 0.002831740072 0.01461229846 0.01139023341 0.0009792926721 0.02943981625 0.0122836791 0.01124979462 0.02139613964 0.004868297838 0.00406907592 0.01309567876 0.01789659448 0.01020175777 0.03645388037 0.009963966906 0.003070269711 0.00846402999 0.02699785866 0.007662036456 0.002815898741 0.002057357691 0.003035753267 0.007092775311 0.006611220073 0.01034597401 0.003968872596 0.007855464704 0.002781510819 0.01012329664 0.008839287795 0.00531011587 0.001304555917 0.2610479593 0.001830971567 0.00532548083 0.03811443225 0.001604989404 0.003589371918 0.003736011917 0.00633983966 0.005264619365 0.01068749465 0.009393963031 0.005487461574 0.00642835116 0.04056647047 0.001959566958 0.005888078362 0.003734296653 0.004803707357 0.01189088821 0.01785649173 0.02586495504 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.5571003 28.55917358 28.59553719 28.5402832  28.545187 28.54511833 28.60928535 28.54493141 28.54381752 28.55276489 28.54596329 28.5464859 28.55302048 28.55456734 28.54415512 28.56546402 28.55545998 28.55442619 28.55694389 28.54375267 28.54772186 28.55388832 28.5610733 28.54431915 28.57676888 28.54980278 28.54195595 28.54019737 28.56445312 28.55083847 28.5421772 28.54428101 28.54621315 28.55027008 28.54931068 28.54780006 28.54714584  28.548172 28.54452705 28.55330086 28.5520153 28.5470562 28.54448128 28.79707146 28.54310036 28.54659462 28.57843018 28.54478073 28.54724312 28.54166794 28.54903984 28.54557991 28.55338669 28.55257034 28.54866409 28.54912758 28.58326721 28.5451355 28.54429626 28.54691124 28.54750443 28.55459023 28.56055641 28.56856537 

-------
======================
selected experts : 2, 6, 24, 43, 46, 56, 
layer11_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded85530>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.110667 -0.0970047 -0.1928990.0703382 -0.0718385 -0.0774949 0.0410839 -0.230315 -0.184965]

layer11_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded84d30>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.271696 -0.118983 0.197365-0.0768817 0.252471 -0.0910772 0.1285 0.0436299 -0.0418973]

layer12_wq's input 
<N9nntrainer6TensorE at 0x5682dedc4470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.587024 -0.265787 0.436063-0.182064 0.520833 -0.210122 0.302734 0.0916035 -0.090523]
==============================
layer12_wq's output 
<N9nntrainer6TensorE at 0x5682ded84be0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.195443 0.0918374 -0.399431-0.0701363 -0.641462 -1.13066 0.0613714 -0.661867 -0.174475]
============================
layer12_wk's input 
<N9nntrainer6TensorE at 0x5682dedc61d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.587024 -0.265787 0.436063-0.182064 0.520833 -0.210122 0.302734 0.0916035 -0.090523]
==============================
layer12_wk's output 
<N9nntrainer6TensorE at 0x5682dedc5f40>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.81585 4.64406 -2.971531.07527 0.725059 -2.12363 0.344063 3.10269 -0.357611]
============================
layer12_wv's input 
<N9nntrainer6TensorE at 0x5682dedc6fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.587024 -0.265787 0.436063-0.182064 0.520833 -0.210122 0.302734 0.0916035 -0.090523]
==============================
layer12_wv's output 
<N9nntrainer6TensorE at 0x5682dedc6d50>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.606237 -0.376929 -0.2368030.537972 -0.0929719 0.621698 -0.115335 -0.129155 -0.282883]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.143505 -0.161364 0.182030.362394 0.433076 1.22569 0.225569 0.625262 -0.336533]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0c60c58
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer12_attention_out's input 
<N9nntrainer6TensorE at 0x5682dedc9470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer12_attention_out's output 
<N9nntrainer6TensorE at 0x5682dedc93d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer12_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dedca4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.271696 -0.118983 0.197365-0.0768817 0.252471 -0.0910772 0.1285 0.0436299 -0.0418973]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.268638 -0.300644 0.448109-0.203649 0.585551 -0.247921 0.349791 0.108113 -0.0966601]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5848432779 -0.06417887658 -1.037602186 -1.280631304 -1.952714562 -0.7851061225 0.4353520572 -0.9345266223 -1.532158494 -1.828743815 0.4825015366 2.507848501 0.07632251829 -0.888548851 -0.5898402929 -0.4689797163 -1.602545977 -0.6417217255 -1.735739827 -0.5481534004 1.384607673 -1.051821113 -1.005732775 1.02190423 -1.972499847 3.210705757 -0.7393202186 -0.4116578698 1.16415596 -1.84118855 -2.054331779 -1.744372249 1.187615275 -0.9100969434 -1.870270967 0.6191681623 -0.4727206528 -0.5952572227 0.1113234684 0.4223324656 -1.865560293 1.320002913 -0.8549823761 0.6602346301 -0.7330172658 -1.084182143 0.5193742514 0.9488451481 -0.7109173536 -1.60622704 -1.243872404 -1.451077938 -0.1899505407 -0.8899843097 0.0192386359 0.5107498169 -0.5357310176 0.801186204 -1.535245895 -0.2447298169 -0.4390060008 0.4783777595 -0.001597560942 -1.822441101 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005956804845 0.01002616808 0.003787760623 0.002970547648 0.001516891061 0.004875736777 0.01652260497 0.004199019168 0.002309934236 0.001717094216 0.01732029393 0.1312660128 0.01153862383 0.004396587145 0.005927111488 0.006688552909 0.002152934205 0.005627445411 0.001884453231 0.006179417484 0.04269086942 0.003734284313 0.003910419997 0.02970399708 0.001487173839 0.2650936544 0.00510416599 0.007083156146 0.03424475342 0.001695858315 0.001370321726 0.001868255436 0.03505761549 0.004302861635 0.001647249097 0.01985678263 0.006663579494 0.005895091686 0.01194963511 0.01630888321 0.001655026223 0.04002003744 0.004546669312 0.02068920434 0.005136439577 0.00361537328 0.01797086187 0.02761122957 0.005251217168 0.002145023551 0.003081772011 0.002505026758 0.008841237985 0.004390281159 0.01089840103 0.01781653985 0.006256658584 0.02382090315 0.002302813111 0.008369946852 0.006892068777 0.01724901795 0.01067366824 0.001727950992 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
30.81029129 30.81483841 30.80812263 30.80682755 30.80489731 30.80730247 30.82133484 30.80853271 30.80330658 30.80652809 30.82213211 30.93178558 30.81635094 30.80730057 30.80883217 30.81102371 30.80696487 30.80948448 30.80669594 30.81003761 30.84368706 30.80854607 30.80872154 30.83403778 30.80629921 31.06990433 30.80896187 30.81189537 30.83714867 30.8050766 30.80570412 30.80668068 30.83891487 30.80434608 30.80598259 30.82085419 30.81099892 30.80975342 30.81628418 30.82064438 30.80599022 30.84483147 30.80649757 30.82502365 30.80947113 30.80794907 30.82135201 30.82383919 30.80815506 30.80695724 30.80741882 30.8044548 30.8131752 30.80634117 30.81571007 30.82262802 30.81059074 30.82672501 30.80663681 30.81270409 30.81170273 30.82205963 30.80404091 30.80510902 

-------
======================
selected experts : 11, 20, 25, 28, 32, 41, 
layer12_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dedcd730>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0773612 -0.0899024 -0.0828959-0.0931412 -0.197045 0.172348 -0.07765 0.0527294 0.366331]

layer12_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dedccdf0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349057 -0.208885 0.11447-0.170023 0.0554258 0.0812705 0.0508505 0.0963593 0.324434]

layer13_wq's input 
<N9nntrainer6TensorE at 0x5682dee397f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.461882 -0.434706 0.234089-0.398826 0.100677 0.199437 0.115611 0.181985 0.636145]
==============================
layer13_wq's output 
<N9nntrainer6TensorE at 0x5682dedccca0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.638957 -0.286022 -0.2500940.205265 0.251586 -0.456803 0.130424 0.103303 0.140089]
============================
layer13_wk's input 
<N9nntrainer6TensorE at 0x5682dc471a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.461882 -0.434706 0.234089-0.398826 0.100677 0.199437 0.115611 0.181985 0.636145]
==============================
layer13_wk's output 
<N9nntrainer6TensorE at 0x5682dc4717a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.526126 2.17734 1.116081.92351 -0.739024 1.67844 -2.07329 0.114944 0.717841]
============================
layer13_wv's input 
<N9nntrainer6TensorE at 0x5682dc472820>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.461882 -0.434706 0.234089-0.398826 0.100677 0.199437 0.115611 0.181985 0.636145]
==============================
layer13_wv's output 
<N9nntrainer6TensorE at 0x5682dc4725b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.260204 -0.896868 0.430393-0.162672 0.192095 -0.0549694 -0.108279 0.371327 -0.0893489]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.455521 0.531577 0.3139420.0782353 -0.32785 0.405559 -0.161952 -0.0381235 -0.131381]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0a5bc48
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer13_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc474cd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer13_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc474c30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer13_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc475da0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349057 -0.208885 0.11447-0.170023 0.0554258 0.0812705 0.0508505 0.0963593 0.324434]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.342213 -0.532703 0.261629-0.456094 0.127347 0.225833 0.138244 0.239942 0.745421]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8907374144 -0.2349317372 0.4580129087 -0.9498534799 0.8698978424 -0.1809544414 -0.4279190898 -1.527326465 0.4683110118 -1.227486372 -0.1315159798 2.054972887 -0.3449802697 -0.4493123293 -0.4004764557 -1.177681446 -0.4874285161 -1.356473684 3.522906542 -0.8342306614 -0.8314092755 -0.8831923008 -0.8793950677 -0.8831965923 -1.476154804 -1.014450431 -1.720691442 -1.865071416 -0.9642260075 -1.74390769 -0.981577754 -0.2707402706 -1.329746127 -1.580141306 -1.104965568 -0.227812171 -0.3364129663 1.441262126 -2.311327696 -0.09721283615 -0.556394577 -2.072245598 -0.4464695454 -0.6179936528 -0.519634068 -0.9891636968 -0.3636598587 0.2545301914 1.943602204 -0.0002803578973 0.4254202247 -0.4662814438 -1.054075718 0.08678603917 -0.05748613551 -0.07400264591 -1.778453827 0.4547889531 -1.29742372 -1.191100597 0.5785340071 -0.7324755192 0.7080338001 -0.008419480175 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.004408756271 0.008494324982 0.01698520593 0.004155681003 0.02564190328 0.008965425193 0.007003505249 0.002332646865 0.01716102846 0.00314824027 0.009419801645 0.08387292176 0.007609136403 0.006855268497 0.00719836168 0.003309007501 0.006598890759 0.002767256228 0.364030093 0.00466505345 0.004678234458 0.004442146514 0.004459045362 0.004442127421 0.002455118345 0.003895724425 0.001922523137 0.001664056676 0.004096380901 0.001878403593 0.004025915638 0.008195537142 0.002842215821 0.00221264502 0.003558590543 0.008555017412 0.007674606517 0.04540362582 0.001065029297 0.009748536162 0.00615913095 0.001352675608 0.006874785293 0.005791181233 0.006389754824 0.00399549026 0.007468319964 0.01385796536 0.07503330708 0.01074079983 0.01644054055 0.006739923265 0.003744372167 0.01171788108 0.01014360972 0.009977446869 0.001814620453 0.01693053544 0.002935583936 0.003264899831 0.01916074939 0.005164738279 0.02180989459 0.01065373421 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.72639847 28.73143768 28.73945236 28.72710037 28.74715614 28.73095512 28.72947121 28.72432327 28.74058151 28.72657013 28.72854996 28.79871178 28.72864532 28.7288456 28.72823524 28.72673035 28.72954369 28.72142029 29.08745193 28.72808647 28.72714615 28.72547913 28.72644997 28.72738647 28.72635269 28.72683907 28.72200584 28.72413063 28.72704124 28.72386932 28.72649384 28.73114014 28.72578621 28.72515678  28.721735 28.73006821 28.73061943 28.76596451 28.7244854 28.73269272 28.72957993 28.72429657 28.72695732 28.72873497 28.72694969 28.72646332 28.73041344 28.73155785 28.79750061 28.73416138 28.73986244 28.72968483 28.72668839 28.73466301 28.73308754 28.73339844 28.72428131 28.73844337 28.72540283 28.72477913 28.74210548 28.72763252 28.74523163 28.73407555 

-------
======================
selected experts : 4, 11, 18, 37, 48, 62, 
layer13_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee45420>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0729003 -0.406801 -0.0252013-0.0780241 0.037404 -0.3087 0.00187028 0.0189472 0.107898]

layer13_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc478790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.276157 -0.615686 0.0892683-0.248047 0.0928298 -0.22743 0.0527207 0.115307 0.432332]

layer14_wq's input 
<N9nntrainer6TensorE at 0x5682dee98c10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.36022 -1.20466 0.166346-0.540219 0.176226 -0.537696 0.113592 0.205466 0.840868]
==============================
layer14_wq's output 
<N9nntrainer6TensorE at 0x5682dc478730>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.12488 -0.544552 -0.317194-0.0739089 -0.0644269 -0.186063 -0.590938 -2.86144 -0.181958]
============================
layer14_wk's input 
<N9nntrainer6TensorE at 0x5682dee9aab0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.36022 -1.20466 0.166346-0.540219 0.176226 -0.537696 0.113592 0.205466 0.840868]
==============================
layer14_wk's output 
<N9nntrainer6TensorE at 0x5682dee9a7d0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.98509 -0.163158 2.52324-0.284793 0.998914 1.36633 0.93989 1.91786 0.308451]
============================
layer14_wv's input 
<N9nntrainer6TensorE at 0x5682dee9b8a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.36022 -1.20466 0.166346-0.540219 0.176226 -0.537696 0.113592 0.205466 0.840868]
==============================
layer14_wv's output 
<N9nntrainer6TensorE at 0x5682dee9b630>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.182041 -0.249189 -0.7183710.144929 0.19251 0.802127 -0.24679 0.0621993 0.0480825]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0805634 -2.19207 0.1299360.298649 0.0307729 0.194482 1.75039 2.33949 0.07575]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2eb5d68
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer14_attention_out's input 
<N9nntrainer6TensorE at 0x5682dee9dda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer14_attention_out's output 
<N9nntrainer6TensorE at 0x5682dee9dd00>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer14_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dee9ee70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.276157 -0.615686 0.0892683-0.248047 0.0928298 -0.22743 0.0527207 0.115307 0.432332]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.276598 -1.60621 0.203773-0.670218 0.214065 -0.646295 0.144906 0.287383 0.996957]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
2.169183016 -0.1604429483 -0.9380071163 1.747939944 -0.8642760515 0.1506029963 -1.677625179 -0.8631830812 0.1483230442 -0.08318985999 -1.837387323 -1.404093146 -1.562247038 0.2200235873 -0.9583565593 -1.2070961 -0.4648033679 0.3947082162 -1.420911908 -1.946756005 -1.052036047 -0.1699156612 -0.2060705721 -0.6792519093 -1.332456946 -0.8604491353 -0.2004051059 0.3646580279 -0.4279718995 0.6756101847 -1.140719056 -1.863321185 -0.36134848 -0.4934558272 -1.52702415 -1.021582603 -1.233463764 -0.6591947675 -0.408067733 0.9524257183 1.252907276 0.1095041335 -1.392297745 -0.7397685647 -0.05964815244 -1.079560161 -0.3602063656 1.245722413 0.01374107972 0.6682664156 -1.669662714 -1.121862054 -2.291163206 -1.056569099 -0.3179639578 0.9675385952 -0.3354649842 0.9148709178 -0.1700505018 0.08554217219 -1.779774308 -0.8672316074 -0.3966808021 -1.210223794 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1360198706 0.01323910523 0.006083686836 0.08926039934 0.006549192593 0.01806942001 0.002903720364 0.006556356326 0.01802826859 0.01430241019 0.002474976005 0.003817229765 0.003258838784 0.01936837658 0.005961137824 0.004648394883 0.00976509694 0.02306522615 0.003753564786 0.002218567999 0.005428060889 0.01311428845 0.0126486104 0.007880301215 0.004100714345 0.00657430524 0.01272047404 0.02238242328 0.01013146713 0.03054583073 0.004967411514 0.002411615569 0.01082945429 0.009489273652 0.003375670407 0.005595907103 0.004527429119 0.008039953187 0.01033514552 0.04028759897 0.05440876633 0.01734184287 0.003862521611 0.007417555433 0.01464311127 0.005280696321 0.01084182784 0.05401924998 0.01575817168 0.03032233194 0.002926933579 0.005061970092 0.001572166802 0.005403510761 0.01130962465 0.0409010835 0.0111134164 0.03880266473 0.01311252173 0.01693123579 0.002621754073 0.006529865786 0.01045350265 0.004633877892 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.29637337 27.17406845 27.16596031 27.24722862 27.16499519 27.17842293 27.16373253 27.16547775 27.1788578 27.17513275 27.16187477 27.1627388 27.16456604 27.17447662 27.1615448 27.16404724 27.16964149 27.18294144 27.16506004 27.15970993 27.16578102 27.17394447 27.17347908 27.1634655 27.16493034 27.16692734 27.17354965 27.18321228 27.17096138 27.19185257 27.16484261 27.16228676 27.17165947 27.16936493 27.16372871 27.16499519 27.1629734 27.16791534 27.17116547 27.20063972 27.21523857 27.17769432 27.16230774 27.16681671 27.17547226 27.16563416 27.17167091 27.21055794 27.17515755 27.19115257 27.16232681 27.16446114 27.16192436 27.16623306 27.17214012 27.20077705 27.17194366 27.19915581 27.16822052 27.1768074 27.16297531 27.16783714 27.16127014 27.16546249 

-------
======================
selected experts : 0, 3, 39, 40, 47, 55, 
layer14_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deea2ef0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.279306 0.135505 -0.261712-0.00655481 0.0436773 0.142907 0.18215 0.0979225 -0.15622]

layer14_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deea2970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.555463 -0.480181 -0.172444-0.254602 0.136507 -0.0845226 0.234871 0.213229 0.276112]

layer15_wq's input 
<N9nntrainer6TensorE at 0x5682deedb770>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.634636 -0.924824 -0.287091-0.537457 0.227262 -0.199578 0.483027 0.359632 0.49273]
==============================
layer15_wq's output 
<N9nntrainer6TensorE at 0x5682deea2820>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.233871 0.664037 0.2406980.172847 0.303741 0.385071 0.666595 -0.662647 0.309314]
============================
layer15_wk's input 
<N9nntrainer6TensorE at 0x5682deedd610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.634636 -0.924824 -0.287091-0.537457 0.227262 -0.199578 0.483027 0.359632 0.49273]
==============================
layer15_wk's output 
<N9nntrainer6TensorE at 0x5682deedd330>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.92189 -2.39179 0.02301212.86165 -1.21816 1.07583 1.87755 0.562447 1.75388]
============================
layer15_wv's input 
<N9nntrainer6TensorE at 0x5682deede400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.634636 -0.924824 -0.287091-0.537457 0.227262 -0.199578 0.483027 0.359632 0.49273]
==============================
layer15_wv's output 
<N9nntrainer6TensorE at 0x5682deede190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.453229 -0.0764084 0.201708-0.115856 0.961992 -0.409499 -0.061211 -0.629738 -0.174694]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.57042 0.412627 -0.00489695-0.29629 -0.231447 -0.432401 -0.322015 0.883038 0.423813]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2bae550
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer15_attention_out's input 
<N9nntrainer6TensorE at 0x5682deee0900>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer15_attention_out's output 
<N9nntrainer6TensorE at 0x5682deee0860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer15_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682deee19d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.555463 -0.480181 -0.172444-0.254602 0.136507 -0.0845226 0.234871 0.213229 0.276112]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.565129 -1.21742 -0.375283-0.662125 0.301531 -0.230849 0.615923 0.501165 0.606899]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.9196115136 -0.7669365406 -0.1744032204 -0.2425152659 -0.2824247777 -1.25149405 -1.074480534 -1.513965726 -1.402485013 -1.540763378 -0.1442510784 -0.7152411938 -1.841566443 -0.6420508027 0.04125054926 1.053928852 0.3776424229 -0.5294575691 -1.38181293 -0.04154314101 -1.268128037 -0.3668287992  1.1564219 -0.6394540071 -0.5798906684 -1.367501974 -0.1567556113 -1.181677222 -0.6673570871 0.073171556 0.06182174385 -0.3293156624 -1.589536548 -0.4025172889 0.5978791714 -0.7584404349 -0.4674280584 -0.4243714213 0.5434920788 -0.5038707256 -0.7242248058 -0.7007819414 0.5043699741 -2.407653093 -1.076235056 -0.1618063748 -0.6935269237 -1.068996668 1.034954309 0.138767764 0.5236951113 -1.64547205 0.9407889843 -1.954601169 -0.7338450551 -1.331152916 -0.2034887075 -1.151724339 2.390234232 -1.969763517 -0.3684638143 1.214165568 -1.248273849 -0.7750394344 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006471737288 0.007539226674 0.01363517623 0.01273737662 0.01223904733 0.004643934313 0.005543219857 0.003571873531 0.003993112594 0.00347742741 0.01405256521 0.007939218543 0.002574073849 0.008542086929 0.01691678911 0.04657132179 0.02368160337 0.009560103528 0.004076518584 0.01557259727 0.004567326047 0.0112484172 0.05159774423 0.008564296179 0.009089913219 0.004135276191 0.0138779385 0.004979746882 0.008328628726 0.01746550389 0.01726839133 0.011678393 0.00331189204 0.01085405517 0.02951608226 0.007603552658 0.01017189119 0.01061942242 0.02795366012 0.009807872586 0.007868215442 0.008054846898 0.02688117139 0.001461411826 0.005533502903 0.01380802132 0.008113497868 0.005573702045 0.04569597915 0.01864958368 0.0274057053 0.003131724428 0.04158939049 0.002298955806 0.00779288495 0.004288354889 0.01324430294 0.005131159909 0.1772020012 0.002264360897 0.01123004034 0.05466489494 0.00465891324 0.007478383835 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.89748573 25.89855385 25.89606667 25.9027977 25.90182304 25.8918438 25.89703369 25.8950634 25.89596176 25.89258385 25.90602112 25.89466095 25.89358902 25.89955711 25.90888405 25.93710899 25.91564941 25.9015274 25.89652061 25.9065876 25.89605904 25.90035439 25.94070435 25.90005493 25.89772034 25.89610291 25.9053688 25.89694786 25.89838982 25.90704918 25.90876007 25.90221596 25.89480209 25.90186882 25.92148399 25.89766312 25.90023232 25.90258789 25.91992188 25.88651657 25.89983559 25.8947773 25.9183712 25.89438248 25.89750099 25.90529823 25.89865112 25.88895798 25.93718719 25.91061783 25.91841888 25.88985443  25.932127 25.89426613 25.89833069 25.89625549 25.9052124 25.89423752 26.06630898 25.89089394 25.90319824 25.94615555 25.8937664 25.88943291 

-------
======================
selected experts : 15, 22, 48, 52, 58, 61, 
layer15_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deee4f80>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0327959 0.187632 -0.1807630.204037 0.164419 -0.0681101 0.291705 0.0602662 -0.180333]

layer15_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deee44b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.588259 -0.292549 -0.353207-0.0505649 0.300926 -0.152633 0.526576 0.273495 0.0957787]

layer16_wq's input 
<N9nntrainer6TensorE at 0x5682def24710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.24158 -0.706571 -0.695522-0.125426 0.586026 -0.428421 1.23742 0.538557 0.20215]
==============================
layer16_wq's output 
<N9nntrainer6TensorE at 0x5682deee4360>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.102363 0.226864 0.0246720.308009 -0.648733 0.0484672 0.830685 0.0413778 -0.381088]
============================
layer16_wk's input 
<N9nntrainer6TensorE at 0x5682def26470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.24158 -0.706571 -0.695522-0.125426 0.586026 -0.428421 1.23742 0.538557 0.20215]
==============================
layer16_wk's output 
<N9nntrainer6TensorE at 0x5682def261e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.9102 -0.102631 -0.171847-0.533853 2.44988 0.0296557 -1.81455 -0.814734 0.755135]
============================
layer16_wv's input 
<N9nntrainer6TensorE at 0x5682def27260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.24158 -0.706571 -0.695522-0.125426 0.586026 -0.428421 1.23742 0.538557 0.20215]
==============================
layer16_wv's output 
<N9nntrainer6TensorE at 0x5682def26ff0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0874291 -1.24879 -0.3393321.28179 0.497896 0.352713 -0.0204428 0.3092 -1.14995]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.188508 0.162511 0.232461-0.203569 0.64717 0.0661378 -0.769603 0.315375 0.860814]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2092cf8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer16_attention_out's input 
<N9nntrainer6TensorE at 0x5682def29710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer16_attention_out's output 
<N9nntrainer6TensorE at 0x5682def29670>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer16_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def2a790>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.588259 -0.292549 -0.353207-0.0505649 0.300926 -0.152633 0.526576 0.273495 0.0957787]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.694387 -0.776591 -0.826173-0.138629 0.703886 -0.441706 1.42648 0.669477 0.224033]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2243914902 -1.273052216 -0.3731522858 0.7100962996 -1.470478892 -1.412188768 -0.6100212336 0.3334301412 -1.558926463 3.685372591 -1.342689157 2.300887823 -1.008253455 -1.188391924 -0.5533849001 -0.7647204995 -1.543614745 -1.685294986 -0.8623319864 -1.274074912 -0.7444522977 -0.1626450568 -0.0900862366 1.783777118 -1.973642945 -1.383884192 -0.04768214375 0.01108001545 -1.786719918 -1.643375397 -1.694744349 0.89670223 0.2155798376 -0.7740887403 -0.7881854773 -2.029365301 -0.8679792285 -1.80484283 -1.472986341 0.3872671127 0.8609884977 -1.821317554 -3.562850237 -0.8730406761 -0.6067320704 -2.005383253 0.7215870023 0.3278435469 -1.254088759 0.5948729515 -0.8321160078 0.3374435306 2.182619333 -1.570125222 -0.9135497212 -2.348448277 -1.675305605 -0.09843407571 0.3884909153 -0.2105440795 -0.694961071 -1.161129594 -0.6163506508 -1.226319551 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007750793826 0.002715930808 0.006679440383 0.01973281801 0.002229345264 0.002363155829 0.005270711146 0.01353957411 0.002040633699 0.386665225 0.002533235587 0.0968413949 0.003539315425 0.002955875359 0.005577840377 0.004515274428 0.002072119853 0.001798390062 0.004095360171 0.002713154303 0.004607725888 0.00824446138 0.008864907548 0.05774079263 0.001347894431 0.002430999419 0.009248900227 0.009808670729 0.001624933095 0.00187538052 0.001781476196 0.02378105 0.01203436684 0.004473173525 0.00441055838 0.001274840906 0.00407229783 0.001595750335 0.002223761752 0.01428848319 0.02294672094 0.00156967598 0.0002750881831 0.004051737487 0.005288076587 0.00130578375 0.01996086724 0.0134641435 0.002767925384 0.01758523658 0.004220994655 0.01359402388 0.0860394612 0.002017908031 0.00389088667 0.000926573528 0.001816444681 0.008791213855 0.01430597994 0.007858868688 0.004841504153 0.00303756725 0.00523745548 0.002845865209 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
23.53842545 23.52433205 23.53735352 23.55040741 23.52241516 23.53351402 23.53642082 23.53658676 23.52699471 23.91781616 23.5313015 23.62703896 23.53421402 23.53124809 23.52576256 23.52613068 23.53179169 23.53009033 23.53381538 23.53290939 23.52908516 23.53939438 23.53953934 23.58793831 23.53202248 23.5259552 23.53896904 23.54096031 23.53229904 23.53064346 23.53245544 23.55397797 23.54127884 23.53466988 23.5341301 23.53194809 23.53141022 23.53322411 23.53337479 23.54400826 23.55314445 23.52890778 23.5304718 23.53424835 23.53405571 23.53055191 23.55063438 23.54366112 23.53344154 23.54683113 23.53108215 23.54474449 23.61337662 23.52458763 23.53504181 23.53255463 23.53248978 23.53469849 23.54402542 23.53805542 23.53551483 23.53275871 23.5363884 23.53447342 

-------
======================
selected experts : 9, 11, 23, 31, 40, 52, 
layer16_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def2d9d0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.275041 -0.0150698 0.1121280.106804 0.0153342 0.117826 -0.297133 -0.0696298 -0.113063]

layer16_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def2d090>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.863299 -0.307619 -0.2410780.0562393 0.31626 -0.0348067 0.229443 0.203865 -0.0172845]

layer17_wq's input 
<N9nntrainer6TensorE at 0x5682def6d870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.955608 -0.647937 -0.3954220.118961 0.484722 -0.0861039 0.495614 0.321594 -0.0298995]
==============================
layer17_wq's output 
<N9nntrainer6TensorE at 0x5682def2cf40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0768425 0.187951 -0.32892-0.0927655 -0.281091 0.0565282 0.16259 0.139941 -0.147259]
============================
layer17_wk's input 
<N9nntrainer6TensorE at 0x5682def6f5d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.955608 -0.647937 -0.3954220.118961 0.484722 -0.0861039 0.495614 0.321594 -0.0298995]
==============================
layer17_wk's output 
<N9nntrainer6TensorE at 0x5682def6f340>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.58195 0.714871 2.247810.698659 0.00432331 0.300537 -2.55857 -0.410296 0.803148]
============================
layer17_wv's input 
<N9nntrainer6TensorE at 0x5682def703c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.955608 -0.647937 -0.3954220.118961 0.484722 -0.0861039 0.495614 0.321594 -0.0298995]
==============================
layer17_wv's output 
<N9nntrainer6TensorE at 0x5682def70150>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.346848 -1.11488 0.153260.0998686 0.317869 -0.707371 0.349783 -0.456701 -0.521514]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.202028 -0.0203716 0.12180.31931 0.286649 -0.00631925 -0.206635 -0.0576298 0.433738]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2297d08
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer17_attention_out's input 
<N9nntrainer6TensorE at 0x5682def72870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer17_attention_out's output 
<N9nntrainer6TensorE at 0x5682def727d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer17_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def738f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.863299 -0.307619 -0.2410780.0562393 0.31626 -0.0348067 0.229443 0.203865 -0.0172845]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.971084 -0.716866 -0.50130.132066 0.660469 -0.0867279 0.5388 0.447673 -0.0356316]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5649166703 -1.567571998 0.3276652992 2.513124704 -0.1520899236 -0.8303835988 -3.270487309 -1.296907067 -0.04425581917 -0.9040798545 -2.194829941 -0.8708052635 -0.01627292112 -1.334774017 -1.348267436 -0.3647217751 0.8149148822 -1.805742145 -0.7421472073 -1.794073939 0.04781312495 -0.8486894369 -2.223347902 -0.2245208025 -1.042313933 -1.049682975 -0.2846728563 -0.4662835598 0.1692023426 -1.313108087 -2.433745384 -0.4951153398 -0.1207370013 -1.148418069 -1.066797137 0.3209392726 1.22931695 -2.256134033 -1.501471758 -2.023600817 -2.457115412 -0.7980403304 -0.4143774509 -0.1150985137 -0.3079393506 -0.4383943379 2.676130772 -0.9510215521 -0.9202147722 -1.216504931 -1.759028435 -2.573677063 0.2100169212 -1.125802994 2.914211035 1.666934848 -2.273659468 -0.2277843654 -1.183776975 -0.9288334846 -0.7405062914 -0.147444278 -0.6151849627 -0.9241185188 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006672522053 0.002448174171 0.01629046351 0.1448993236 0.01008273568 0.005116808694 0.0004459392221 0.003209153889 0.0112307854 0.004753278103 0.001307457336 0.00491410261 0.01154949237 0.003089904552 0.003048492363 0.008151424117 0.02651815116 0.001929329243 0.005588814616 0.001951972954 0.01231388748 0.005023993552 0.001270698267 0.009378253482 0.004139606375 0.004109213129 0.0088307634 0.007364203688 0.01390316896 0.003157581203 0.00102959841 0.007154912688 0.01040386595 0.003722875379 0.004039485939 0.01618126035 0.04013430327 0.001229712274 0.00261546718 0.00155164185 0.001005815924 0.005285007879 0.007756545208 0.0104626948 0.008627676405 0.007572476752 0.1705528498 0.004535308108 0.004677199759 0.003477833932 0.002021593042 0.0008951509953 0.01448236126 0.003808027133 0.2163993418 0.0621685572 0.001208349015 0.00934769772 0.003593538655 0.004637062084 0.005597992335 0.01012968458 0.00634539593 0.004658977035 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
22.11065292 22.11453629 22.12980843 22.25078773 22.12073898 22.11243629 22.11396408 22.11672783 22.12427139 22.11827087 22.11291695 22.11795425 22.11696053 22.11565399 22.11608887 22.12214661 22.14003563 22.11592484 22.10527802 22.11499214 22.12201691 22.11377335 22.11240387 22.12003517 22.11717987 22.11333466 22.12282562 22.12088203 22.11883736 22.11524391 22.11407089 22.12019539 22.12296867 22.11724091 22.11755753 22.12111664 22.15317535 22.11427116 22.11279488 22.11459351 22.11452293 22.11117363 22.12127495 22.12016487 22.11403847 22.12156677 22.28073311 22.11805344 22.11342621 22.11699486 22.11553955 22.11393547 22.10892677 22.1092205 22.32419586 22.17234802 22.11520386 22.11905098 22.11520386 22.11338615 22.11863899 22.12317085 22.12034035 22.11579323 

-------
======================
selected experts : 3, 16, 36, 46, 54, 55, 
layer17_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def76b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.119878 0.0427516 0.0836584-0.082742 -0.192372 -0.123712 -0.352863 0.0408223 0.0129357]

layer17_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def761f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.743421 -0.264867 -0.15742-0.0265027 0.123888 -0.158519 -0.12342 0.244688 -0.00434877]

layer18_wq's input 
<N9nntrainer6TensorE at 0x5682defb6420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.2624 -0.541026 -0.275062-0.0539179 0.198178 -0.361506 -0.252102 0.383386 -0.00774135]
==============================
layer18_wq's output 
<N9nntrainer6TensorE at 0x5682def760a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.5232 0.418725 1.278382.72879 1.82538 -3.37991 2.63293 1.65801 -2.0232]
============================
layer18_wk's input 
<N9nntrainer6TensorE at 0x5682defb8180>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.2624 -0.541026 -0.275062-0.0539179 0.198178 -0.361506 -0.252102 0.383386 -0.00774135]
==============================
layer18_wk's output 
<N9nntrainer6TensorE at 0x5682defb7ef0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.25415 1.13258 -0.5479561.12094 1.30056 1.08249 0.19233 2.1954 -1.79507]
============================
layer18_wv's input 
<N9nntrainer6TensorE at 0x5682defb8f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.2624 -0.541026 -0.275062-0.0539179 0.198178 -0.361506 -0.252102 0.383386 -0.00774135]
==============================
layer18_wv's output 
<N9nntrainer6TensorE at 0x5682defb8d00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0587756 -2.15294 1.13441-0.139991 1.24529 -1.41666 1.10897 -0.340765 -0.298185]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.11726 -2.30078 1.42716-2.65401 -2.39022 3.00709 -3.08786 -0.382669 -0.744287]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a249cd18
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer18_attention_out's input 
<N9nntrainer6TensorE at 0x5682defbb420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer18_attention_out's output 
<N9nntrainer6TensorE at 0x5682defbb380>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer18_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682defbc4a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.743421 -0.264867 -0.15742-0.0265027 0.123888 -0.158519 -0.12342 0.244688 -0.00434877]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.853795 -0.573618 -0.312511-0.0582662 0.245943 -0.364107 -0.271338 0.501814 -0.00852619]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.6273706555 -0.3092482686 -0.5520982742 0.7557987571 -0.8661976457 -1.701852083 -0.7072938085 -0.8364729881 2.185483932 -1.531793118 0.2034626007 -1.502796769 -2.203984737 -1.11043334 -3.4694345 -1.465497494 0.04039787501 -0.8558729887 -0.8649594784 -0.1077571064 -1.545637369 -0.1326479465 -1.634534836 0.9015256166 -0.9431143999 0.08800459653 0.1092985123 0.880182445 -1.240120649 1.658906698 -0.6974722147 0.2955052853 -0.584644258 -0.2497467101 -0.6149420738 -0.1882206351 -1.878281355 0.670244813 -1.747626901 -0.8226674795 -0.1309736073 -0.2170142829 -0.9305517077 -0.02207532339 -2.079432011 -0.9483323097 -0.7753231525 -1.186023712 -0.00827340968 0.1153657958 -0.4481774271 -1.542468667 -0.3585171103 0.4268810451 -0.4900393784 -1.062475324 0.4979901612 -0.4232053757 -0.2158964276 0.3050209582 -0.2451109588 -1.548001289 -0.1942561567 0.5499870181 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03072108515 0.01204115618 0.00944495108 0.03493109718 0.00689903181 0.002991355257 0.008087218739 0.007107180543 0.1459205896 0.003545877058 0.02010646276 0.003650200088 0.001810483402 0.005404031835 0.0005107596517 0.003788920352 0.01708116755 0.006970629096 0.006907578558 0.01472904719 0.003497125115 0.0143669527 0.003199657658 0.04041108862 0.006388275418 0.01791401207 0.01829956099 0.03955772892 0.004746739287 0.08618406951 0.008167039603 0.02204495855 0.009142503142 0.01277936529 0.008869660087 0.01359032094 0.002507527126 0.03206687048 0.00285751326 0.007205978502 0.01439102925 0.01320458762 0.006469034124 0.01604669914 0.002050629118 0.006355028134 0.007555346936 0.005010596476 0.01626971178 0.01841092855 0.01047929376 0.003508224618 0.01146227773 0.02513998747 0.01004966535 0.005669514183 0.02699276246 0.01074427739 0.0132193584 0.02225573175 0.01283874549 0.003488867776 0.01350854617 0.0284334328 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
24.24374962 24.21648598 24.22151947 24.24462128 24.21992683 24.21649551 24.22111511 24.22061157 24.35799408 24.21705055 24.22932053 24.21620178 24.21293068 24.21700096 24.21401596 24.21681595 24.22247887 24.2185688 24.2189827 24.22727966 24.21032715 24.22071838 24.21622849 24.25296211 24.21893883 24.22951126 24.23037338 24.24543381 24.20203972 24.2992115 24.21976471 24.23554993 24.22073936 24.21770096 24.22189713 24.22614098 24.21601295 24.23078918 24.21493149 24.21928024 24.22694206 24.22623253 24.21854401 24.22859764 24.21555519 24.21509171 24.21772194 24.21660805 24.22929764 24.23048592 24.22350693 24.21701241 24.21543121 24.23816872 24.22355461 24.21535873 24.24002075 24.22377205 24.22624779 24.2352829 24.22300529 24.21556282 24.22605896 24.2414608 

-------
======================
selected experts : 3, 8, 23, 27, 29, 37, 
layer18_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682defbf6e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0224344 0.0454053 -0.0709348-0.187937 0.124586 0.226347 -0.290267 -0.267766 -0.0996515]

layer18_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682defbeda0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.765856 -0.219462 -0.228355-0.214439 0.248474 0.0678284 -0.413687 -0.0230783 -0.104]

layer19_wq's input 
<N9nntrainer6TensorE at 0x5682deffefd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1351 -0.389111 -0.347942-0.37575 0.359667 0.135294 -0.727746 -0.0334059 -0.170709]
==============================
layer19_wq's output 
<N9nntrainer6TensorE at 0x5682defbec50>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.673518 0.446467 0.06407090.0890631 -0.215499 -0.0496878 -0.193079 -0.477774 -0.15175]
============================
layer19_wk's input 
<N9nntrainer6TensorE at 0x5682df001130>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1351 -0.389111 -0.347942-0.37575 0.359667 0.135294 -0.727746 -0.0334059 -0.170709]
==============================
layer19_wk's output 
<N9nntrainer6TensorE at 0x5682df001100>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.884585 -1.93369 1.787090.760586 0.241383 -0.515798 1.96247 1.30788 -1.42562]
============================
layer19_wv's input 
<N9nntrainer6TensorE at 0x5682df002000>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1351 -0.389111 -0.347942-0.37575 0.359667 0.135294 -0.727746 -0.0334059 -0.170709]
==============================
layer19_wv's output 
<N9nntrainer6TensorE at 0x5682df001d90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.888076 -0.00238157 -0.1487370.265708 -0.512243 0.150262 0.424696 -0.238823 -1.16209]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.61918 -0.519207 0.0332472-0.104556 0.203434 0.0867368 0.377732 0.350523 0.0169855]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a28a6d38
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer19_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0044b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer19_attention_out's output 
<N9nntrainer6TensorE at 0x5682df004410>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer19_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df005580>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.765856 -0.219462 -0.228355-0.214439 0.248474 0.0678284 -0.413687 -0.0230783 -0.104]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.838065 -0.41343 -0.404878-0.409909 0.435386 0.135294 -0.80797 -0.0412379 -0.182234]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.6672039032 1.011161685 0.3233934939 -0.5856403112 0.2339823842 -1.09533155 -0.2589462996 -1.10770607 -0.5928098559 -1.665809155 0.1330215782 1.439721942 -0.8517971039 -0.3086450398 -0.06121952832 -2.85298562 -1.539274931 0.7510276437 -1.042135715 -0.7157807946 0.00371193327 -0.07794098556 -0.5857000351 -0.1359512359 0.2269063443 -1.96133101 -0.1968873888 -0.7613671422 -0.9728127718 0.08115919679 0.6174609065 0.7811871767 -0.2542393506 -0.6601142883 -0.5794465542 -0.4633648992 -1.890489697 -0.8679003119 -1.077695847 -0.3713322282 -1.334422827 0.2955068052 -1.211002588 -0.4735624194 -2.129509211 1.023646951 -0.8193566203 -1.493514538 0.2843222618 -1.879455209 0.4954262972 1.167628288 -0.9052318335 -0.4109098315 -1.314629674 -2.20801115 0.2125170231 -0.6533298492 0.8769615293 -0.951233983 -2.019967318 1.744927764 -0.07661728561 -0.1612648964 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.008408664726 0.0450434871 0.02264321409 0.009123252705 0.02070653066 0.005480164662 0.01264826953 0.005412767641 0.00905807782 0.003097692272 0.01871804893 0.06914381683 0.00699132029 0.01203502994 0.01541355159 0.0009450486978 0.0035155355 0.03472619876 0.005779579282 0.008009960875 0.01644758508 0.01515795942 0.00912270695 0.01430366002 0.02056052536 0.002305126982 0.01345807593 0.007653013803 0.006194451358 0.01777203195 0.03038434684 0.03578947484 0.01270794496 0.008468491025 0.009179935791 0.01030987035 0.002474348294 0.006879640743 0.005577668082 0.01130374894 0.004314769991 0.02202049457 0.004881557077 0.01020527072 0.001948300865 0.04560939223 0.00722184265 0.003680144902 0.02177557722 0.002501802519 0.02689372748 0.05267257988 0.00662754802 0.01086511184 0.004401023034 0.001801204169 0.02026679181 0.008526139893 0.03938670084 0.006329572294 0.002173849382 0.09382154047 0.01517803781 0.01394612622 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.25514412 26.28605652 26.2622261 26.25538063 26.26791763 26.24315453 26.25795174 26.25214767 26.25579262 26.24983215 26.25973129 26.31492424 26.25229454 26.25876999 26.2621479 26.24815559 26.25024986 26.27860069 26.25203705 26.25426865 26.26365852 26.26141548 26.25061226 26.25960732 26.26777267 26.2490406 26.26019287 26.25391006 26.25245285 26.26212311 26.27759552 26.28300095 26.25992012 26.25568008 26.25400734 26.25609016 26.2473011 26.25123024 26.25231171 26.24993134 26.25104904 26.26875496 26.25161552 26.25407982 26.24248314 26.29234314 26.25395584 26.25041389 26.26755714 26.24494553 26.2731514 26.29845428 26.25288582 26.25378418 26.23778343 26.24901199 26.26652527 26.2557373 26.28659821 26.24829674 26.24938583 26.33817291 26.2619133 26.25972748 

-------
======================
selected experts : 1, 11, 45, 51, 58, 61, 
layer19_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df008b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.215267 -0.39338 -0.000695813-0.0864399 -0.112795 -0.0509957 0.289701 0.168486 -0.00108794]

layer19_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df008060>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.981122 -0.612842 -0.229051-0.300879 0.135679 0.0168326 -0.123986 0.145408 -0.105088]

layer20_wq's input 
<N9nntrainer6TensorE at 0x5682df047b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.958103 -0.910237 -0.334845-0.431053 0.180098 0.0257885 -0.183428 0.183659 -0.144409]
==============================
layer20_wq's output 
<N9nntrainer6TensorE at 0x5682df007f10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.876517 0.0806131 -1.10045-0.950074 1.5474 -0.0318424 1.07022 0.0833046 1.55108]
============================
layer20_wk's input 
<N9nntrainer6TensorE at 0x5682df0498e0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.958103 -0.910237 -0.334845-0.431053 0.180098 0.0257885 -0.183428 0.183659 -0.144409]
==============================
layer20_wk's output 
<N9nntrainer6TensorE at 0x5682df049650>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.846784 -2.53762 1.45796-1.87529 0.273083 1.54017 1.20665 1.44815 1.83976]
============================
layer20_wv's input 
<N9nntrainer6TensorE at 0x5682df04a6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.958103 -0.910237 -0.334845-0.431053 0.180098 0.0257885 -0.183428 0.183659 -0.144409]
==============================
layer20_wv's output 
<N9nntrainer6TensorE at 0x5682df04a460>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.58004 -0.259193 0.555010.26039 0.126245 -0.290294 -0.940173 -0.403823 -0.0109447]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.171333 0.86338 -0.1058781.44997 -1.52897 -0.24022 -1.00426 0.379161 0.454705]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2cb0d58
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer20_attention_out's input 
<N9nntrainer6TensorE at 0x5682df04cb80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer20_attention_out's output 
<N9nntrainer6TensorE at 0x5682df04cae0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer20_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df04dc00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.981122 -0.612842 -0.229051-0.300879 0.135679 0.0168326 -0.123986 0.145408 -0.105088]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.0499 -1.01058 -0.361632-0.49967 0.209454 0.0291351 -0.211703 0.229574 -0.163459]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8655126095 -0.70669806 -1.061430693 -2.783363581 -0.2065856159 -1.022460699 0.2129929066 -1.197860122 -1.765060186 -0.4202759564 -1.40267086 0.1384142488 -0.4667899311 0.519497931 -0.8139014244 -0.7501202226 -0.5346457958 -0.2915263474 0.2705768645 -1.274973035 -0.9905731678 -1.995363832 0.3463840187 0.3722329736 -0.7950048447 0.1706930399 -0.4584597349 -0.921906352 -0.128356114 -1.033184409 -1.007602215 0.4361215532 2.485273838 -0.09640012681 -0.3592478633 -0.608148098 -0.2030857652 0.9808261991 -0.533608377 -1.060790062 -0.230525136 -0.3972931206 -0.6110050678 -0.6829974651 -0.7350553274 0.05229857937 -0.8097520471 0.1194356456 -0.5318554044 -1.408503294 -1.412146211 -0.8701547384 -0.1973832399 0.2585422397 0.1805107296 0.8161994219 -1.081575871 -1.17308712 0.1499855518 -0.9741865396 -1.142312765 0.02617833763 -0.6642144322 -1.035818815 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007350394502 0.008615549654 0.006042608991 0.001079937094 0.0142062353 0.006282737944 0.02161223255 0.005271981936 0.002989800414 0.01147293393 0.004295619205 0.02005905658 0.01095150225 0.02936385572 0.007739717606 0.008249448612 0.01023303065 0.01304937527 0.02289328352 0.004880724475 0.00648630783 0.002374775475 0.02469623089 0.02534292266 0.007887362503 0.02071710117 0.01104311086 0.006947348826 0.01536220685 0.006215723231 0.006376787089 0.02701488696 0.2096711695 0.01586105116 0.01219491009 0.009507857263 0.01425604336 0.04657634348 0.01024365239 0.006046481431 0.01387018524 0.01173966751 0.009480731562 0.008822181262 0.008374665864 0.01840394735 0.007771899924 0.01968195476 0.01026162598 0.004270638339 0.004255109467 0.007316350937 0.01433757041 0.02261942253 0.0209215004 0.03950653225 0.005922097713 0.005404216703 0.0202925168 0.006593472324 0.005573113449 0.01792945713 0.008989455178 0.006199370604 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.40150261 25.40372086 25.40305519 25.39856911 25.41026497 25.40377235 25.41385651 25.40228462 25.40000343 25.40228653 25.40083122 25.41421127 25.40796471 25.42589951 25.40475273 25.40383148 25.40152359 25.40434074 25.41799927 25.40093994 25.4034996 25.39938736 25.41646385 25.42092514 25.40156174 25.41773033 25.40328789 25.40348244 25.40665245 25.40322876 25.40338898 25.42450523 25.60573006 25.41192055 25.4092083 25.40604401 25.41126823 25.43452835 25.40296555 25.40115166 25.41088295 25.40732193 25.40458679 25.40631104 25.40395737 25.41589355 25.40478516 25.41669464 25.40679741 25.40080643 25.39888382 25.4043293 25.39704514 25.41963196 25.41698074 25.43556595 25.40341187 25.39907837 25.41492081 25.40026855 25.40115547 25.41351128 25.40123367 25.39844322 

-------
======================
selected experts : 13, 23, 31, 32, 37, 55, 
layer20_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df050e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.885376 -0.319169 0.5262190.70381 -0.196865 -0.350957 0.573935 -0.108444 0.136571]

layer20_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df050500>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.8665 -0.932011 0.2971680.402931 -0.061186 -0.334124 0.449949 0.0369634 0.0314824]

layer21_wq's input 
<N9nntrainer6TensorE at 0x5682df091030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.34343 -1.12902 0.3250060.462413 -0.0660174 -0.435887 0.5252 0.0393383 0.0359756]
==============================
layer21_wq's output 
<N9nntrainer6TensorE at 0x5682df0503b0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.438507 -0.128789 0.342350.258348 0.64409 -0.20004 -0.185343 -0.0576341 -0.281783]
============================
layer21_wk's input 
<N9nntrainer6TensorE at 0x5682df092d90>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.34343 -1.12902 0.3250060.462413 -0.0660174 -0.435887 0.5252 0.0393383 0.0359756]
==============================
layer21_wk's output 
<N9nntrainer6TensorE at 0x5682df092b00>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.141955 -1.32763 -0.06101911.14812 1.04022 0.493206 2.01475 -0.189959 -0.493183]
============================
layer21_wv's input 
<N9nntrainer6TensorE at 0x5682df093b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.34343 -1.12902 0.3250060.462413 -0.0660174 -0.435887 0.5252 0.0393383 0.0359756]
==============================
layer21_wv's output 
<N9nntrainer6TensorE at 0x5682df093910>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.848235 -1.16323 -0.1315370.66145 -1.24199 0.601555 0.0756982 -0.25 0.0249144]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.247887 0.383962 0.00306864-0.42888 -0.669201 0.0838968 0.192273 -0.0265481 -0.903204]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1f904f0
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer21_attention_out's input 
<N9nntrainer6TensorE at 0x5682df096030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer21_attention_out's output 
<N9nntrainer6TensorE at 0x5682df095f90>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer21_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0970b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.8665 -0.932011 0.2971680.402931 -0.061186 -0.334124 0.449949 0.0369634 0.0314824]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.79419 -1.38042 0.4255680.600742 -0.0864228 -0.524375 0.697324 0.0532971 0.0444677]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.338927716 -0.8085083365 -0.3935043216 -0.2765239775 -1.24435389 -0.5573443174 -1.160563588 -1.030288935 0.6692617536 -1.052990317 -0.06676454842 -0.3132822514 -0.6337903738 -0.5771283507 -1.292338848 -0.7287265062 0.2857293487 -0.967897892 -0.9411482811 -1.694105983 -0.8988958001 0.2688181698 0.01038398501 -1.540452242 -1.435884714 0.8472945094 0.6545837522 -1.271214008 0.688174367 0.7262431979 1.963293791 -1.16886127 -2.187511683 -0.9855898023 -1.560562253 -1.163798332 -1.570108056 0.5532386899 0.03886730224 -1.896592736 -1.347119093 -1.031612039 -0.1494785547 0.2236829996 0.130858317 -1.156510353 1.787328124 -1.326728463 -0.7687029839 -0.6601318717 -0.3301847577 -0.3158607781 0.6373904347 2.850577593 0.06893432885 0.979413867 -0.1041699052 0.04358827695 0.4303562045 0.220823437 0.630808413 -0.0217722021 -0.3897924423 -0.5688437819 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01735400409 0.005509022158 0.008342735469 0.009378045797 0.003562781261 0.007081964053 0.003874171525 0.004413228948 0.02414692938 0.004314171616 0.01156670786 0.009039585479 0.006560752634 0.006943230517 0.003395857988 0.005966550205 0.01645492762 0.004697345663 0.00482469378 0.00227229367 0.005032917485 0.01617899351 0.01249438897 0.002649691654 0.002941768151 0.02885231189 0.02379508875 0.003468357958 0.02460796013 0.02556281723 0.08807505667 0.003842158942 0.001387333847 0.004614972044 0.002596938284 0.003861661302 0.002572266385 0.02150174603 0.01285538543 0.001855775598 0.003214836353 0.00440739328 0.01064847689 0.01546498947 0.01409406774 0.00388990785 0.07386386395 0.003281061538 0.005732734222 0.006390187424 0.008888077922 0.009016307071 0.02338946983 0.2138924152 0.0132477805 0.0329275392 0.0111420434 0.01291621756 0.01901545003 0.01542082801 0.02323602512 0.01209900714 0.00837376155 0.007000990678 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.65564346 25.64379883 25.64615631  25.647192 25.63994598 25.64489555 25.64216423 25.64031982 25.6619606 25.64165115 25.63888931 25.63826942 25.64103699 25.64284897 25.64168549 25.64377975 25.6547451 25.6429882 25.64025497 25.64056206 25.64284706 25.65446854 25.65030861 25.6395092 25.64123154 25.66618919 25.66160774 25.64032745 25.66289902 25.66385269 25.72636604 25.64070129 25.63872337 25.64242935 25.6394577 25.64119911 25.64086342 25.65931511 25.64876175 25.63919258 25.6415062 25.64269829 25.64750862 25.65327835 25.64809227 25.64170265 25.71215439 25.64109421 25.63877869  25.641819 25.64717865 25.64349174 25.65357399 25.85218239 25.65153885 25.66931152 25.64418793 25.65073013 25.64920044 25.65323448 25.66009521 25.64991188 25.64475632 25.64433861 

-------
======================
selected experts : 25, 29, 30, 46, 53, 55, 
layer21_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df09a2f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.203484 0.325646 -0.08617490.263837 -0.197649 -0.211468 -0.165355 0.027559 -0.218294]

layer21_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df0999b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.06998 -0.606365 0.2109930.666768 -0.258835 -0.545592 0.284594 0.0645224 -0.186811]

layer22_wq's input 
<N9nntrainer6TensorE at 0x5682df0d9be0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52088 -0.661526 0.2176970.727424 -0.272531 -0.641366 0.290025 0.065481 -0.206965]
==============================
layer22_wq's output 
<N9nntrainer6TensorE at 0x5682df099860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.437703 1.93202 -0.130586-1.09558 -0.350645 2.35805 0.589283 0.483181 -1.41336]
============================
layer22_wk's input 
<N9nntrainer6TensorE at 0x5682df0db940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52088 -0.661526 0.2176970.727424 -0.272531 -0.641366 0.290025 0.065481 -0.206965]
==============================
layer22_wk's output 
<N9nntrainer6TensorE at 0x5682df0db6b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.46632 2.72871 1.06410.640243 -2.17135 -0.228131 0.0903081 -0.916295 0.0818679]
============================
layer22_wv's input 
<N9nntrainer6TensorE at 0x5682df0dc730>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52088 -0.661526 0.2176970.727424 -0.272531 -0.641366 0.290025 0.065481 -0.206965]
==============================
layer22_wv's output 
<N9nntrainer6TensorE at 0x5682df0dc4c0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.220364 1.69392 0.3736711.04747 0.378844 0.398043 -0.296168 -0.251376 -0.942125]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.97682 0.128316 -0.80130.758457 0.759042 -2.25991 -0.738716 -0.18713 2.0414]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a30bad78
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer22_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0debe0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer22_attention_out's output 
<N9nntrainer6TensorE at 0x5682df0deb40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer22_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0dfc60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.06998 -0.606365 0.2109930.666768 -0.258835 -0.545592 0.284594 0.0645224 -0.186811]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.17076 -0.846138 0.2872880.919148 -0.343673 -0.798248 0.404351 0.0883993 -0.248042]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8047953844 -0.01834646985 -0.3145961165 -0.1551435143 -0.1897218674 -0.6782951951 -0.001238539815 -0.1476960182 0.8379756808 -0.3640313745 0.08346153051 -0.7165501118 -0.9255920649 0.1504372358 -0.8932706118 -0.4338618517 0.1948764473 0.2700033784 -1.274457693 -0.1353416145 0.4278050363 -0.8345499039 -0.1699510664 0.9164355397 -1.557055831 0.668407321 -0.7479814291 -0.5342580676 -1.330482841 -0.1022242233 -1.963770986 -1.084569573 -1.34240365 -0.1084434316 -0.565561533 -0.5060130954 -1.144616723 1.264299154 -0.1902586669 0.02174477838 -1.254423261 -0.9504104853 -0.8645780683 -0.1366228163 -0.144697085 -0.5823468566 -1.647065759 -0.5357928872 -0.8950794339 0.5012350082 -1.256810546 1.121241927 -0.6218414307 -0.2271721363 -0.5474994183 -0.4918791652 0.3645601869 -0.9830704927 2.122302771 -0.6177154779 -0.6622462273 -0.9478222728 -0.01968348585 1.327158451 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007012990303 0.01539762318 0.01144970022 0.01342899539 0.01297258027 0.007958691567 0.01566331089 0.01352938171 0.0362534821 0.01089744549 0.01704780012 0.007659981493 0.006215011235 0.01822869293 0.006419171114 0.01016243175 0.01905703172 0.0205438789 0.004384615924 0.0136975646 0.02405552752 0.00680739712 0.01323161181 0.03921248391 0.003305223072 0.03059899248 0.007422963623 0.009191705845 0.004145721905 0.01415878907 0.002200728748 0.005301501136 0.004096594639 0.01407100353 0.008908431046 0.009455027059 0.004992530216 0.05552641675 0.01296561677 0.01602747478 0.004473344889 0.006062662695 0.006606022362 0.01368002594 0.01357001439 0.008760148659 0.0030207159 0.009177611209 0.006407571491 0.02588839456 0.004462679382 0.04812499508 0.00842091348 0.01249573752 0.009070798755 0.009589612484 0.02258124948 0.005867854692 0.1309561431 0.008455728181 0.008087449707 0.006078375038 0.01537704933 0.05912880227 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.01239395 27.02077866 27.0149231 27.01737976 27.01882935 27.00809479 27.01961327 27.01747894 27.04211044 27.01580048 27.02290535 27.01304054 27.01159477 27.02313232 27.00893784 27.01601982 27.02443695 27.02640152 27.01024246 27.01287842 27.0280056 27.01218796 27.01908875 27.03887177 27.0091629 27.03598022 27.01328087 27.01314163 27.00905037 27.02001572 27.00758171 27.00925255 27.00661659 27.01992798 27.00427628 27.01245117 27.0056057 27.05518532 27.01262474 27.01950073 27.00985336 27.01001358 27.01198578 27.01906013 27.01942825 27.01271057 27.00887871 27.01360512 27.01226425 27.03174591 27.01032066 27.05207443 27.00855637 27.01835251 27.01445198 27.01449394 27.02843857 27.00790977 27.13681412 27.01383591 27.01156044 27.01193619 27.02075768 27.06498718 

-------
======================
selected experts : 8, 23, 37, 51, 58, 63, 
layer22_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df0e2e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.459906 -0.801032 -0.4119380.196134 -0.324941 0.14068 0.0877142 0.237325 -0.955242]

layer22_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dde69cd0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52989 -1.4074 -0.2009450.862902 -0.583776 -0.404912 0.372308 0.301847 -1.14205]

layer23_wq's input 
<N9nntrainer6TensorE at 0x5682de368560>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.32152 -1.33011 -0.1922740.768143 -0.565455 -0.404908 0.344564 0.266333 -1.05695]
==============================
layer23_wq's output 
<N9nntrainer6TensorE at 0x5682de2bfbc0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60922 2.58156 -3.89571.96592 1.101 3.35278 -1.33262 2.75291 -3.83909]
============================
layer23_wk's input 
<N9nntrainer6TensorE at 0x5682de266760>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.32152 -1.33011 -0.1922740.768143 -0.565455 -0.404908 0.344564 0.266333 -1.05695]
==============================
layer23_wk's output 
<N9nntrainer6TensorE at 0x5682de82d610>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.06271 3.21187 -2.23235-2.24058 -2.63303 2.30116 -0.501631 -1.88495 2.02967]
============================
layer23_wv's input 
<N9nntrainer6TensorE at 0x5682de40ebf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.32152 -1.33011 -0.1922740.768143 -0.565455 -0.404908 0.344564 0.266333 -1.05695]
==============================
layer23_wv's output 
<N9nntrainer6TensorE at 0x5682de7736d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.178801 -0.967032 0.719379-1.08272 -0.607393 -0.18185 -0.818278 -0.941207 -0.217915]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.49932 -2.72868 3.901991.95341 -0.495504 -3.49396 0.0371306 -3.05827 3.58456]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a32bfd88
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer23_attention_out's input 
<N9nntrainer6TensorE at 0x5682ddf81aa0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer23_attention_out's output 
<N9nntrainer6TensorE at 0x5682de55e330>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer23_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0fe910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52989 -1.4074 -0.2009450.862902 -0.583776 -0.404912 0.372308 0.301847 -1.14205]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.07552 -1.95378 -0.2758031.18436 -0.796674 -0.587513 0.534366 0.414296 -1.54959]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4839372635 -0.9653638005 -0.2139574289 -0.4169965982 -0.9937536716 -2.169672012 -0.2422578484 -1.502996802 -0.8820543885 -1.586862683 -2.791267872 0.3879947662 0.2185072303 0.8950022459 -0.311399132 0.2695389986 -0.6820523143 -0.01871247217 0.1456014663 -0.4945863783 0.7300466895 -0.5971394777 -0.5344864726 -0.5229815245 -1.184855461 -1.106283307 -0.7813099623 -0.5901976228 0.5363240242 0.7315717936 -1.264652252 -0.4504970312 0.6880748272 0.6829567552 -0.008895480074 -1.164098144 0.3065220416 -0.6324129105 -1.468803048 0.1183366179 -1.34001267 -0.1585486531 -1.519421697 -1.86741221 0.5924387574 -0.7581304312 -1.252984047 -0.6759970188 -1.148257971 0.4346925616 0.1837275922 2.585729837 0.6428440213 -0.5275315046 -0.9693915844 -0.2661961317 -0.9315228462 0.7165947556 0.05729415268 0.2847727537 -0.4847031832 -0.06007727981 -0.8921365738 0.2510969937 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009283553809 0.00573632028 0.01216087956 0.009926272556 0.005575756542 0.001720319386 0.01182154752 0.003350752639 0.006234680768 0.003081199247 0.0009239601204 0.02220186964 0.01874053851 0.03686210141 0.01103180554 0.01972172596 0.007615071256 0.01478287205 0.01742286049 0.00918521639 0.03125653416 0.008289935067 0.008825941011 0.008928070776 0.004605845548 0.004982333165 0.006895519327 0.008347684518 0.02575183101 0.03130424023 0.004252595361 0.009599248879 0.02997178771 0.02981878258 0.01492871158 0.004702450242 0.02046475001 0.008002618328 0.003467308125 0.01695424691 0.003943895455 0.01285371929 0.003296165727 0.002327441005 0.02723819949 0.007057221606 0.004302506335 0.007661323529 0.004777530674 0.02326323837 0.01809995063 0.1999188513 0.02864634059 0.008887539618 0.00571326213 0.01154192071 0.005933764856 0.03083888628 0.01595027186 0.02002445795 0.009276445955 0.01418385748 0.006172136869 0.01936134696 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.92597198 26.92147064 26.92885017 26.92613792 26.92035675 26.91793251 26.92708015 26.91956329 26.9224472 26.91976929 26.91761208 26.9355526 26.93495178 26.95164299 26.92724419 26.93450356 26.9171505 26.93099403 26.93172836 26.92206001 26.9474678 26.92450142 26.92551422 26.92561722 26.92129517 26.9202404 26.9211998 26.92503738 26.94244003 26.94703865 26.91998863 26.92390442 26.94332314 26.94317055 26.93018723 26.92043686 26.93715286 26.92373848 26.91967964 26.92982864 26.91777229 26.9290657 26.91998482 26.91806221 26.94297409 26.92326927 26.91765404 26.91958237 26.92098999 26.93756866 26.93478966 27.11613083 26.94533539 26.92414665 26.91858673 26.92632294 26.92119217 26.94085121 26.93216324 26.9357605 26.92596626 26.92848778 26.9228611 26.9346199 

-------
======================
selected experts : 13, 20, 29, 32, 51, 57, 
layer23_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee1eb60>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.906188 -0.93121 -0.0112482-0.0990461 0.00702408 -1.02714 -0.165144 0.382759 0.00785814]

layer23_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de7806d0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.6237 -2.33861 -0.2121930.763855 -0.576752 -1.43206 0.207164 0.684606 -1.1342]

layer24_wq's input 
<N9nntrainer6TensorE at 0x5682de5e9620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.23194 -1.76072 -0.16460.548961 -0.457261 -1.08635 0.150064 0.474435 -0.847459]
==============================
layer24_wq's output 
<N9nntrainer6TensorE at 0x5682de23a580>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00566128 0.0150758 0.4445990.272002 0.00526445 0.243909 0.0761507 0.0756884 0.0855249]
============================
layer24_wk's input 
<N9nntrainer6TensorE at 0x5682de680bc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.23194 -1.76072 -0.16460.548961 -0.457261 -1.08635 0.150064 0.474435 -0.847459]
==============================
layer24_wk's output 
<N9nntrainer6TensorE at 0x5682de1e9fa0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.20187 1.80715 1.48120.76211 -0.307243 1.50088 -0.724443 0.979726 -0.9136]
============================
layer24_wv's input 
<N9nntrainer6TensorE at 0x5682de7cdb70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.23194 -1.76072 -0.16460.548961 -0.457261 -1.08635 0.150064 0.474435 -0.847459]
==============================
layer24_wv's output 
<N9nntrainer6TensorE at 0x5682de067420>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.0577 -0.642175 2.07097-2.49102 -1.41601 2.35112 -0.627438 2.78031 -2.84199]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0160624 -0.00115232 -0.0469788-0.519082 0.0376233 -0.241047 -0.101089 -0.0361763 -0.431197]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a36c9da8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer24_attention_out's input 
<N9nntrainer6TensorE at 0x5682de40b530>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer24_attention_out's output 
<N9nntrainer6TensorE at 0x5682de646540>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer24_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de7c4940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.6237 -2.33861 -0.2121930.763855 -0.576752 -1.43206 0.207164 0.684606 -1.1342]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.6207 -2.6811 -0.2396380.871366 -0.64477 -1.70713 0.246956 0.780963 -1.27442]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.074664474 -0.8922616839 -0.102407448 0.07062817365 -0.1484004259 -0.2287002653 0.5861350894 0.1625005603 -0.2460435629 -0.3501291871 -1.06761992 -0.003797911108 1.444381356 -0.2615830898 -0.7064641118 -0.7513090372 -0.7412349582 -0.6171593666 -0.3239291012 0.02110742219 -0.7781904936 0.538713336 -0.255209446 -1.102991581 1.804532766 0.3891856074 -0.1016360149 -0.2039393783 -1.245521784 -0.1747154146 -1.308147907 1.133462429 -0.7939858437 -1.383263707 0.3777789772 -0.802591145 -1.066303134 0.01695022546 0.304941386 -1.007137418 -0.5375985503 -0.9835063219 -0.8290171027 -0.7907453775 0.5081122518 -0.939088285 -0.6026405692 -0.6043896675 -1.491520166 -0.5610138774 -0.09709006548 -0.3465279341 0.1509504467 -0.8219507337 -0.6634860635 -0.9424288273 -0.1440306008 -0.1431129873 -0.3499019742 -0.9935693741 -0.1177032068 -0.7337630987 -0.95454216 -0.2616923749 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005998932756 0.007199303247 0.01586060785 0.01885681041 0.01514765248 0.01397885382 0.03157548606 0.02067130618 0.01373850647 0.01238042768 0.00604134053 0.01750432514 0.07448720187 0.01352666412 0.008669246919 0.008289061487 0.008372988552 0.009479073808 0.0127090821 0.01794575155 0.008069209754 0.03011306934 0.01361315325 0.0058313841 0.1067808643 0.02593080327 0.01587284729 0.01432930212 0.005056750961 0.01475424133 0.004749778658 0.05458222702 0.007942754775 0.00440606568 0.02563670091 0.007874698378 0.006049302407 0.01787130348 0.02383576892 0.006418012083 0.01026404835 0.006571482867 0.007669326849 0.007968532853 0.02920553274 0.006869955454 0.009617701173 0.009600894526 0.003953992389 0.01002650429 0.01594517007 0.01242509391 0.02043392323 0.007723713294 0.009049955755 0.006847044453 0.01521398965 0.0152279567 0.01238324121 0.006505685858 0.01561985258 0.008435786702 0.006764604244 0.01352518704 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.83670807 28.83695602 28.84657097 28.84336662 28.84538078 28.8432579 28.86276245 28.85185814 28.84444809 28.84309006 28.83388901 28.84869003 28.90567398 28.84042168 28.83842659 28.83947563 28.83860588 28.83589745 28.84008026 28.84913254 28.83925629 28.85557747 28.84146309 28.83701706 28.9379673 28.8571167 28.8451519 28.8455162 28.83624268 28.8454628 28.83593559 28.88481522 28.83912849 28.8346386 28.85682297 28.83906174 28.83771324 28.84905815 28.84882355 28.83760452 28.83763504 28.83775711 28.83885574 28.83677101 28.85848427 28.83757973 28.84080315 28.83935738 28.83227921 28.83930588 28.84617805 28.84361076 28.85066605 28.8370018 28.84023666 28.83612633 28.84640121 28.84641457 28.84404564 28.83769226 28.84680557 28.83676147 28.83795166 28.84423447 

-------
======================
selected experts : 6, 12, 21, 24, 31, 44, 
layer24_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df21d1f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628785 0.184833 -0.112852-0.955649 0.0126883 -0.311257 -0.82243 -0.778489 0.780474]

layer24_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de2b2790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25249 -2.15377 -0.325045-0.191793 -0.564064 -1.74331 -0.615266 -0.0938824 -0.353721]

layer25_wq's input 
<N9nntrainer6TensorE at 0x5682ddf10a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.871 -1.26846 -0.211436-0.109585 -0.366913 -0.996073 -0.370473 -0.0557046 -0.236307]
==============================
layer25_wq's output 
<N9nntrainer6TensorE at 0x5682de7d58a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.72197 4.42588 -4.597341.49702 -2.261 4.52404 -2.91168 -0.674019 -2.79383]
============================
layer25_wk's input 
<N9nntrainer6TensorE at 0x5682de480fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.871 -1.26846 -0.211436-0.109585 -0.366913 -0.996073 -0.370473 -0.0557046 -0.236307]
==============================
layer25_wk's output 
<N9nntrainer6TensorE at 0x5682de0aef30>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.34389 1.4774 -0.535676-0.850426 -0.684613 -0.76615 0.418316 -1.17355 0.647725]
============================
layer25_wv's input 
<N9nntrainer6TensorE at 0x5682ddd64050>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.871 -1.26846 -0.211436-0.109585 -0.366913 -0.996073 -0.370473 -0.0557046 -0.236307]
==============================
layer25_wv's output 
<N9nntrainer6TensorE at 0x5682de58dbd0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.854036 0.851605 -3.935430.344204 -0.228041 -2.01824 -1.358 0.834995 -4.27294]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[5.58353 -3.27256 3.944322.79625 3.01987 -4.05702 2.92226 -0.626544 4.23945]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a38cedb8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer25_attention_out's input 
<N9nntrainer6TensorE at 0x5682df211490>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer25_attention_out's output 
<N9nntrainer6TensorE at 0x5682dddde7f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer25_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0184b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25249 -2.15377 -0.325045-0.191793 -0.564064 -1.74331 -0.615266 -0.0938824 -0.353721]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.881 -2.12042 -0.314296-0.187137 -0.540453 -1.77761 -0.616553 -0.0916031 -0.338914]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4517963231 -0.09050495923 -0.8284288645 -0.4897360504 -0.2275577635 -1.753577471 -1.147008538 1.391741633 -0.6251775622 -0.3415489197 0.6419427395 -0.5139391422 -1.198913932 -0.6744518876 -0.06356103718 0.0596325025 -0.9952005744 0.1956784427 0.7104929686 -1.46526897 -0.3979146183 -0.3888883293 -1.125691056 -0.0878001377 -1.128727078 -0.6170650721 -0.02985788137 -0.358745873 0.193454355 -1.149133563 -1.199773073 -0.5610435009 -1.269292355 1.229914904 -0.7043933868 -0.6024431586 -1.094941974 1.197730541 0.2244047076 -0.9261249304 -1.127594829 0.5340222716 -0.5747808814 -0.4632236958 -1.321432948 0.2379128188 -0.06032478064 -0.4061294496 0.6326365471 -0.4532514513 -0.1660106778 -0.599544704 -0.3058767021 -0.8097100258 -0.871348083 0.2680715322 -0.2872420549 0.7725386024 -0.3412109613 1.382186532 -0.1154797748 1.190463305 -0.2778798938 -0.3134531379 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01020949334 0.01465247478 0.007005429361 0.009829403833 0.01277584769 0.002777460264 0.00509421574 0.06451230496 0.008584315889 0.01139945351 0.03047958203 0.009594357572 0.004836543929 0.008171580732 0.01505263709 0.01702608913 0.005929345265 0.01950737834 0.03264224529 0.003705600509 0.01077468786 0.0108723836 0.005203977693 0.01469216216 0.00518820202 0.008654238656 0.01556860562 0.01120509207 0.01946404018 0.005083402153 0.004832390696 0.009152900428 0.004507856909 0.05487342551 0.007930537686 0.00878171064 0.005366480444 0.05313547701 0.02007587813 0.006353395525 0.005194080062 0.0273614917 0.009028023109 0.01009348966 0.004278837703 0.02034890465 0.01510143094 0.01068653818 0.03019724973 0.01019464806 0.01358686574 0.008807200938 0.01181343663 0.007137796842 0.006711123046 0.02097195014 0.01203564089 0.03473170474 0.01140330639 0.0638988167 0.01429106481 0.05275073275 0.01214884967 0.01172427181 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.69834518 28.70564842 28.69561768 28.70130157 28.70377159 28.69377327 28.6960907 28.75360107 28.69958115 28.70144272 28.72195244 28.70106697 28.69678688 28.69821358 28.70223427 28.70516205 28.69740295 28.70668793 28.72363853 28.69517899 28.69890976 28.69900703 28.69619942 28.70616531  28.696661 28.69917297 28.70704079 28.70267868 28.70521545 28.69083405 28.69582939 28.70062637 28.69598007 28.74634552 28.69892693 28.70025444 28.69636345 28.74460793 28.71107292 28.69639587 28.69428253 28.71788025 28.70050049 28.70061302 28.69575119 28.71182251 28.70466614 28.69929886 28.72119331 28.70119095 28.70172119 28.69932747 28.69899559 28.69813347 28.69770813 28.70958328 28.70207787 28.72620392 28.70287704 28.75489426 28.7009964 28.74374771 28.70362091 28.70319748 

-------
======================
selected experts : 7, 33, 37, 57, 59, 61, 
layer25_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df270060>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.181181 1.97758 1.990520.33743 0.29224 -0.657881 0.751527 -0.182415 1.26058]

layer25_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddfd81b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.43367 -0.176199 1.665470.145637 -0.271824 -2.40119 0.136262 -0.276298 0.906856]

layer26_wq's input 
<N9nntrainer6TensorE at 0x5682de245ed0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.6407 -0.117968 1.076610.0874191 -0.190357 -1.54295 0.0823158 -0.166911 0.575747]
==============================
layer26_wq's output 
<N9nntrainer6TensorE at 0x5682de21e590>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-5.11612 4.31771 1.10957-0.466114 -5.50468 5.45947 2.49852 1.2956 -1.05644]
============================
layer26_wk's input 
<N9nntrainer6TensorE at 0x5682de23ab70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.6407 -0.117968 1.076610.0874191 -0.190357 -1.54295 0.0823158 -0.166911 0.575747]
==============================
layer26_wk's output 
<N9nntrainer6TensorE at 0x5682de320f60>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.00795 -1.36418 0.3074020.544895 -1.04127 -0.565749 -0.416073 0.374108 0.161235]
============================
layer26_wv's input 
<N9nntrainer6TensorE at 0x5682dde7eae0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.6407 -0.117968 1.076610.0874191 -0.190357 -1.54295 0.0823158 -0.166911 0.575747]
==============================
layer26_wv's output 
<N9nntrainer6TensorE at 0x5682ddeee690>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.85801 -1.24985 -3.019780.374335 -0.668769 1.9824 -2.17322 1.1992 -4.69897]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.68911 6.13074 -1.03607-0.612345 6.37738 -4.40866 -2.81224 -0.111668 1.47173]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a116d480
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer26_attention_out's input 
<N9nntrainer6TensorE at 0x5682df278ee0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer26_attention_out's output 
<N9nntrainer6TensorE at 0x5682df278e40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer26_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df27a260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.43367 -0.176199 1.665470.145637 -0.271824 -2.40119 0.136262 -0.276298 0.906856]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.1444 -0.158646 1.499560.131689 -0.237423 -2.24514 0.12426 -0.246646 0.806046]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7976108193 -1.237690926 0.3693436384 -1.320588946 0.4601677656 -1.316403985 0.3657962978 1.585767984 0.7315429449 -0.1187434494 -0.7654778361 -2.125173807 0.1955475211 -1.207199097 2.000904083 -0.7493480444 1.018078804 -0.07063479722 -0.3333452046 -0.7209935188 -0.02316588908 0.04870539159 0.1151986048 -0.7828495502 0.01025529951 1.13081646 -0.690267086 0.3549180925 -0.9964004755 -0.4106429815 -1.097838998 -1.076774597 -0.07724364102 -1.294981956 -0.7529384494 -0.9240140319 0.2047221065 -0.4458819628 -0.08619339764 -0.601223588 -0.3765991032 -0.6582266092 -0.8708590269 -0.2210022956 -1.058641672 -0.8108075857 0.9971785545 -1.19317472 -0.669097662 0.03125523776 -0.10601601 -0.1617669761 -0.7126160264 -0.3440948129 -0.2707051635 0.7163293362 0.3726058006 -0.2156991065 -0.7929415107 0.1992799789 0.1424860656 -1.363229513 -0.7534536123 -0.4182652831 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006906083319 0.004447412677 0.02218368277 0.004093598109 0.02429282852 0.004110766575 0.02210512944 0.07487210631 0.03186653554 0.01361633185 0.007131599355 0.001830958994 0.01864468306 0.004585111048 0.1133995578 0.00724756252 0.04244003817 0.01428740844 0.0109865116 0.007456006017 0.01498196926 0.01609838195 0.01720520668 0.007008781657 0.01549114659 0.04750476032 0.007688658312 0.02186596952 0.005661070812 0.01016926859 0.005114985164 0.005223871674 0.01419329736 0.004199777264 0.007221587934 0.006086050533 0.01881652698 0.009817156941 0.01406683773 0.008404689841 0.01052143238 0.007938996889 0.006418306381 0.01229276787 0.005319459364 0.006815542933 0.04156223312 0.004649866838 0.007853157818 0.01581989974 0.01379074156 0.01304293238 0.007518731523 0.01086904295 0.01169671677 0.0313853994 0.02225616761 0.01235813089 0.006938404404 0.01871440373 0.01768115722 0.003922714386 0.007217868231 0.01009205077 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.06643677 33.06493378 33.08457565 33.06553268 33.08573151 33.06459808 33.08354568 33.12963486 33.09044647 33.07123947 33.06952667 33.06422424 33.08008575 33.06697845 33.17483902 33.06868744 33.10387802 33.07572556 33.07147217 33.06412888 33.07641983 33.07753754 33.07578278 33.06844711 33.07597733 33.10894394 33.06817627 33.07758331 33.06614685 33.07256317 33.0675087 33.06666183 33.07086563 33.0656395 33.06675339 33.06847763 33.08025742 33.07030487 33.07646179 33.06507492 33.0700531 33.0693779 33.06785965 33.07373047 33.06771088 33.06921005 33.10300064 33.0670433 33.07024765 33.07630539 33.0733223 33.07543564 33.06895828 33.07326126 33.07027435 33.0937767 33.08369446 33.07189178 33.06837845 33.08015442 33.08007431 33.06345367 33.06674957 33.07057953 

-------
======================
selected experts : 7, 8, 14, 16, 25, 46, 
layer26_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df27d4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-2.04064 -0.314795 -1.400310.827417 1.52577 -2.1098 -1.85683 1.97067 0.542728]

layer26_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddd52130>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.393023 -0.490994 0.2651620.973054 1.25395 -4.51099 -1.72057 1.69437 1.44958]

layer27_wq's input 
<N9nntrainer6TensorE at 0x5682de328070>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349417 -0.31544 0.1772360.634612 0.874767 -3.0591 -1.11655 1.13253 0.978322]
==============================
layer27_wq's output 
<N9nntrainer6TensorE at 0x5682ddefef30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.47915 2.14073 0.8226340.55384 1.33991 0.998374 -1.32992 1.91716 -1.1047]
============================
layer27_wk's input 
<N9nntrainer6TensorE at 0x5682de1e5e50>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349417 -0.31544 0.1772360.634612 0.874767 -3.0591 -1.11655 1.13253 0.978322]
==============================
layer27_wk's output 
<N9nntrainer6TensorE at 0x5682ddfc8350>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.56288 2.69319 1.58043-0.311879 0.972928 0.535231 -0.916197 0.858185 0.225043]
============================
layer27_wv's input 
<N9nntrainer6TensorE at 0x5682de7969c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349417 -0.31544 0.1772360.634612 0.874767 -3.0591 -1.11655 1.13253 0.978322]
==============================
layer27_wv's output 
<N9nntrainer6TensorE at 0x5682de46fef0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.39497 -3.06129 2.057072.83891 -0.841989 -0.0350844 -3.97103 0.705508 2.87695]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.63322 2.02563 -0.0463497-0.990615 -1.1439 -1.21803 0.38967 -2.3005 -0.384345]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a054f420
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer27_attention_out's input 
<N9nntrainer6TensorE at 0x5682de426170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer27_attention_out's output 
<N9nntrainer6TensorE at 0x5682de0d2950>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer27_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de6e6390>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.393023 -0.490994 0.2651620.973054 1.25395 -4.51099 -1.72057 1.69437 1.44958]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.326462 -0.396689 0.2116510.776689 1.03751 -3.74703 -1.40127 1.35244 1.15235]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4075613916 -1.537694812 -1.079890847 -1.658623457 -0.7141698599 -0.2288180739 -0.1915958375 -0.421092689 -0.3735206723 -1.561541319 -1.216026425 -0.9826565981 -0.783592999 0.02853864431 0.3969347179 -0.001903982367 1.232006073 -0.5751284957 -2.305074215 -1.735985398 1.168386698 -1.215337038 -1.044820428 -1.323595166 -1.625537992 -1.10840559 1.333244324 -0.7492160201 -0.4535664916 -1.268533945 -0.9302008152 1.042670369 -0.133242324 -0.2272001654 -0.9168794751 2.142210484 0.3906172514 0.3940891325 -0.1735385656 -0.6589808464 -1.141647696 -1.435662866 -0.8268273473 0.4714540839 -1.632031679 -0.6181524992 -0.7313773632 -0.7323353291 -0.3073841035 -1.545512915 0.5358894467 0.81878829 1.656416535 -0.4525648057 -0.9500568509 -0.5141102672 -0.7638406754 -0.1650416851 0.7898381948 -0.04235753417 0.6157683134 -1.09482491 -0.0324466154 0.3313139081 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.02213611454 0.003164370079 0.005001602229 0.00280393986 0.007210072596 0.01171453949 0.01215879992 0.009665436111 0.01013635378 0.003089804202 0.0043650195 0.005512358155 0.006726507097 0.01515283622 0.02190212719 0.01469849329 0.05048392713 0.008285610937 0.001468989532 0.002595200436 0.04737220705 0.004368029069 0.005180122331 0.003919851966 0.00289826165 0.004860996269 0.05586250126 0.006961764302 0.009356603958 0.004141735844 0.00580923073 0.04177588969 0.01288941782 0.01173350867 0.005887135863 0.125443995 0.02176419646 0.02183989063 0.01238034666 0.007619175594 0.004702062346 0.003504283959 0.006441887934 0.02359661087 0.002879502019 0.007936690003 0.007087067235 0.007080281153 0.010829404 0.003139727516 0.02516711876 0.03339603916 0.07717422396 0.009365982376 0.005695020314 0.00880692713 0.006860691588 0.0124859903 0.0324430801 0.01411575451 0.0272599142 0.004927462433 0.01425634976 0.02051103115 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
31.51359177 31.49461937 31.49645615 31.49473572 31.49723434 31.50126266 31.5045681 31.50064278 31.50111389 31.49502182 31.49629784 31.4955368 31.49675179 31.50708389 31.51288033 31.5047226 31.54193878 31.49640274 31.49340057 31.48356056 31.53930473 31.49629974 31.49711227 31.49203682 31.49340057 31.49631691 31.5473175 31.49603271 31.50128937 31.49225807 31.4977417 31.5327549 31.50434494 31.50318909 31.49543571 31.61689949 31.50845146 31.50804901 31.50478935 31.49907494 31.49663353 31.49543571 31.49694252 31.51552773 31.49528885 31.49891472 31.48805237 31.49853516 31.50323868 31.49507141 31.51709938 31.52485085 31.56863022 31.49938965 31.49715042 31.49740028 31.49879265 31.50298691 31.52437592 31.5060482 31.51919174 31.49638176 31.50618744 31.51196671 

-------
======================
selected experts : 16, 20, 26, 31, 35, 52, 
layer27_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df2fed10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-4.31966 -0.122392 6.770020.867754 -0.695816 2.88133 1.86454 -0.848765 -0.0286945]

layer27_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de4dbd00>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-3.92664 -0.613386 7.035181.84081 0.55813 -1.62966 0.143973 0.845604 1.42089]

(269) layer0_wq's input 
<N9nntrainer6TensorE at 0x5682dde663b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00533584 -0.00181849 0.03675270.05615 -0.0456777 -0.00173874 -0.0301168 -0.0278517 0.0253552]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5682de7965e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.340285 -1.96606 1.93697-0.305517 1.33136 1.26645 -0.936659 -1.37615 1.32085]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5682ddd56d10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00533584 -0.00181849 0.03675270.05615 -0.0456777 -0.00173874 -0.0301168 -0.0278517 0.0253552]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5682de0a36b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.36719 -0.829909 0.716176-1.44964 1.40511 -0.75517 -2.5288 0.252318 1.2568]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5682e0a65b00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00533584 -0.00181849 0.03675270.05615 -0.0456777 -0.00173874 -0.0301168 -0.0278517 0.0253552]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5682dde490d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.077627 -0.0288866 -0.01865970.0186231 -0.0536395 0.0625538 0.0203159 -0.044671 0.0258807]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.87608 -1.79267 0.0370078-1.96056 0.0544465 -1.8367 0.791822 1.46429 -1.08988]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a259f920
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer0_attention_out's input 
<N9nntrainer6TensorE at 0x5682e0a64030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer0_attention_out's output 
<N9nntrainer6TensorE at 0x5682e0a638e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer0_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dde13420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0038867 -0.00129557 0.03109360.0414581 -0.029798 -0.00129557 -0.0207291 -0.0233202 0.0220246]

layer0_ffn_gate's input 
<N9nntrainer6TensorE at 0x5682ddfb82c0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0238318 -0.00788014 0.1860610.239914 -0.180509 -0.00730588 -0.126082 -0.140694 0.129624]
==============================
layer0_ffn_gate's output 
<N9nntrainer6TensorE at 0x5682dde852c0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.0094283 -0.0215598 -0.05527670.0783745 -0.00284603 0.0299465 0.149653 0.102264 0.0322584]
============================
layer0_ffn_up's input 
<N9nntrainer6TensorE at 0x5682de34f990>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0238318 -0.00788014 0.1860610.239914 -0.180509 -0.00730588 -0.126082 -0.140694 0.129624]
==============================
layer0_ffn_up's output 
<N9nntrainer6TensorE at 0x5682dde690c0>
data addr: 0x7fc0a7fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.0954491 0.0131496 -0.09047790.163799 -0.131224 -0.0671627 -0.091035 -0.367695 0.0737123]
============================
layer0_ffn_down's input 
<N9nntrainer6TensorE at 0x5682dc3e1140>
data addr: 0x7fc0aafd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[0.00044784 -0.000140224 0.002431570.00667022 0.000186468 -0.0010207 -0.00732061 -0.0197615 0.00120809]
==============================
layer0_ffn_down's output 
<N9nntrainer6TensorE at 0x5682dc3e0770>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.530313 -0.039013 0.00509636-0.0215666 0.0196059 -0.013654 -0.0333485 0.135026 -0.0696264]
============================
layer0_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3e1bb0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.5342 -0.0403086 0.036190.0198915 -0.0101922 -0.0149496 -0.0540776 0.111705 -0.0476018]

layer1_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e48b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.770854 -0.0559952 0.04267420.0306314 -0.0110854 -0.0144084 -0.0710461 0.123901 -0.0758662]
==============================
layer1_wq's output 
<N9nntrainer6TensorE at 0x5682dc3e2330>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.05036 0.665655 0.332401-0.370155 1.02647 0.764256 -1.18285 2.57484 0.0606972]
============================
layer1_wk's input 
<N9nntrainer6TensorE at 0x5682dc3e6610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.770854 -0.0559952 0.04267420.0306314 -0.0110854 -0.0144084 -0.0710461 0.123901 -0.0758662]
==============================
layer1_wk's output 
<N9nntrainer6TensorE at 0x5682dc3e6380>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.24526 1.03814 0.9174490.701469 1.23946 1.46682 -2.86744 -0.60461 1.33113]
============================
layer1_wv's input 
<N9nntrainer6TensorE at 0x5682dc3e7400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.770854 -0.0559952 0.04267420.0306314 -0.0110854 -0.0144084 -0.0710461 0.123901 -0.0758662]
==============================
layer1_wv's output 
<N9nntrainer6TensorE at 0x5682dc3e7190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.204227 0.0149028 0.0230723-0.0187487 0.161088 0.184685 0.0454985 -0.0533836 0.0407351]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.822528 0.932628 -0.306505-0.391868 -0.116011 -1.27447 1.43862 -2.44117 0.523384]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a34c5198
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer1_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ea340>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer1_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ea2a0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer1_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3eb440>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.5342 -0.0403086 0.036190.0198915 -0.0101922 -0.0149496 -0.0540776 0.111705 -0.0476018]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.716204 -0.16842 0.1441960.0981063 -0.041488 -0.076952 -0.269044 0.52688 -0.153783]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4938856959 0.2744270563 -0.8380575776 2.652425766 0.3581895828 -0.3603386879 3.49582696 1.066620708 -0.07572924346 -1.366705418 -0.1647537351 -0.2697153091 -0.2739833891 -0.2273011953 -0.28377226 0.4387896359 0.1971707344 -0.6836133599 0.8687351942 -0.1118115112 -0.08855776489 -0.276751399 0.3082902133 0.1831746846 -0.3872572482 0.157389462 -0.6663765907 1.623328567 -0.928239882 0.9732655883 -0.4263276458 0.08605601639 -0.7634534836 -0.237398982 -0.7045798898 0.2429447472 0.01626846194 -0.9829031825 -0.3773329854 -0.6508309245 -0.7802859545 -0.2845839858 -0.4929048717 -0.319824338 0.4986183345 0.105902642 1.925558448 -0.3053503633 -0.413780421 -0.5639892817 -0.4926785231 -0.9096289873 -0.9575096369 0.2258247584 -0.4971837699 0.3114612699 0.9630727768 -0.1422177702 -0.2463431656 0.2854246497 -0.7421780825 -0.7862241864 -0.3267106712 -0.7311197519 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005316769239 0.01146362349 0.003768563503 0.1236156747 0.01246520597 0.006076402962 0.2873148322 0.02531437017 0.0080770161 0.002221196424 0.007389040664 0.006652789656 0.006624455098 0.00694103213 0.006559926085 0.01351150032 0.01061133016 0.004397948273 0.02076952346 0.007790774107 0.007974061184 0.006606145296 0.01185846422 0.01046384685 0.005915016402 0.01019748393 0.004474411253 0.04417151585 0.003443579888 0.0230581034 0.005688371137 0.009495400824 0.004060468171 0.006871296093 0.004306698218 0.01110834163 0.008855334483 0.003260395024 0.005974011496 0.0045445133 0.00399269117 0.006554603111 0.005321986508 0.006327638868 0.01434454881 0.00968573615 0.05975841358 0.006419891957 0.005760194268 0.004956808873 0.00532319257 0.003508268157 0.003344248049 0.01091978699 0.005299263634 0.01189612597 0.02282426693 0.007557449397 0.006810111459 0.01159039047 0.004147780593 0.003969052806 0.006284215022 0.004193902947 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
62.86138916 62.86658096 62.85984039 62.97777939 62.86663055 62.86119461 63.14243317 62.88043213 62.86319351 62.85733795 62.86250687 62.86177063 62.86174393 62.86206055 62.86167908 62.86672211 62.86573029 62.85951614 62.87588882 62.86290741 62.86309052 62.86172485 62.86220932 62.86653519 62.86103439 62.86531448 62.85959244 62.90024185 62.85665512 62.87722397 62.86175919 62.86461258 62.86013031 62.86198807 62.86037827 62.8662262 62.86397171 62.85647202 62.86109161 62.8596611 62.85911179 62.86262512 62.85853195 62.86144638 62.86946106 62.86480331 62.91296768 62.86153793 62.85992432 62.86007309 62.8604393 62.85862732 62.85846329 62.86603928 62.86041641 62.86605835 62.87698746 62.86267471 62.86192703 62.86670685 62.85926437 62.85908508 62.8614006 62.85931015 

-------
======================
selected experts : 3, 6, 7, 27, 29, 46, 
layer1_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e0a3ef10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.121317 -0.0599546 0.0436244-0.0415144 -0.0689801 -0.0147215 0.0202303 0.024195 -0.0197212]

layer1_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3ee080>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.655517 -0.100263 0.0798143-0.0216228 -0.0791723 -0.0296711 -0.0338473 0.1359 -0.067323]

layer2_wq's input 
<N9nntrainer6TensorE at 0x5682dc3ee2c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.50176 -0.286059 0.204058-0.0689026 -0.180415 -0.0945488 -0.100959 0.385217 -0.1821]
==============================
layer2_wq's output 
<N9nntrainer6TensorE at 0x5682dc3ee260>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0462497 0.124748 -0.389427-0.181901 0.158622 0.0341469 -0.150277 0.784759 -0.579801]
============================
layer2_wk's input 
<N9nntrainer6TensorE at 0x5682dc3edf00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.50176 -0.286059 0.204058-0.0689026 -0.180415 -0.0945488 -0.100959 0.385217 -0.1821]
==============================
layer2_wk's output 
<N9nntrainer6TensorE at 0x5682dc3ede70>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.66199 -0.380247 1.43585-1.95493 -2.02044 -0.628309 -0.453666 1.36711 -1.76648]
============================
layer2_wv's input 
<N9nntrainer6TensorE at 0x5682dc3ee380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.50176 -0.286059 0.204058-0.0689026 -0.180415 -0.0945488 -0.100959 0.385217 -0.1821]
==============================
layer2_wv's output 
<N9nntrainer6TensorE at 0x5682dc3ee3b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.16022 -0.046587 -0.08186970.00729331 -0.0579034 -0.106257 0.0585689 0.194708 -0.107775]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00955108 0.132702 -0.2470360.351731 -0.0804448 -0.14091 0.229321 -0.765403 0.307492]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0857038
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer2_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ee500>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer2_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ee620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer2_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3fefb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.655517 -0.100263 0.0798143-0.0216228 -0.0791723 -0.0296711 -0.0338473 0.1359 -0.067323]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.11729 -0.397511 0.30313-0.0929383 -0.305092 -0.12973 -0.144227 0.571532 -0.230743]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.0007239356637 0.3967224956 0.7473183274 -0.3814888 0.7392625213 2.840141058 -0.4369773269 -0.6523282528 -0.7334950566 -0.2333211303 -0.191916123 -0.6012032032 0.9653558731 -0.3224940598 -0.4581566751 0.1935741156 -0.4096742272 -0.1640245169 -0.3989120722 -0.2542994618 -0.9824817777 -0.9129154682 0.01834851131 -0.004838172346 0.2320720404 0.01329177432 2.106049538 0.08493182063 -1.030921578 -0.05433372408 -0.05983022228 0.237671569 -0.1196894795 -0.01123329997 -0.4972101152 -0.2299947292 -0.4662125707 -0.7897862792 0.09493773431 -0.4111535251 -0.7961652279 -0.4509711862 -0.003034375608 0.7694603801 0.5840034485 0.7430487871 -0.3115803897 -0.389572531 -0.2015502304 0.1198345572 -0.7311477661 -0.4564379752 0.1348663867 1.469751716 0.6477128863 0.1367376447 0.4490277767 -0.4847815335 0.4408440888 -0.5562569499 -1.426332355 -0.4745022058 -0.273398757 -0.3905330002 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01132527925 0.01685224101 0.02392871864 0.007738999091 0.02373673022 0.1940085441 0.007321269251 0.005902835634 0.005442650523 0.008974973112 0.009354382753 0.006212466396 0.02975856699 0.008209295571 0.007167841308 0.01375407632 0.007523918059 0.009618964046 0.007605327293 0.008788655512 0.004243037663 0.004548719153 0.01154335123 0.01127877831 0.01429390535 0.01148512773 0.09311270714 0.01233811118 0.004042403307 0.01073411945 0.01067528129 0.01437416859 0.01005501579 0.01120687928 0.006893307902 0.009004876949 0.007110329345 0.005144739989 0.01246218476 0.007512794808 0.005112026352 0.007219531108 0.01129914168 0.02446446382 0.02032322995 0.02382677607 0.008299378678 0.007676690351 0.009264694527 0.01277634967 0.005455440376 0.00718016969 0.01296985243 0.04927973077 0.0216601491 0.01299414318 0.01775716059 0.006979516242 0.01761243492 0.006498062517 0.002722168807 0.007051630411 0.008622392081 0.007669321261 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
53.42508698 53.43061447 53.43769073 53.42150116 53.43749619 53.60586166 53.42108154 53.41966248 53.41920471 53.42273712 53.42311478 53.41711426 53.44351959 53.42197037 53.42092896 53.42751694 53.42033005 53.42338181 53.42136765 53.42159653 53.41800308 53.41640091 53.42530441 53.42408752 53.42805481 53.42524719 53.50592041 53.42609787 53.41780472 53.4244957 53.42443466 53.42813492 53.42381668 53.42496872 53.4206543 53.42276764 53.42087173 53.41795349 53.42622375 53.42127228 53.41887283 53.42098236 53.42506027 53.43822479 53.43408585 53.43758774 53.42206192 53.42143631 53.42016602 53.42653656 53.41921616 53.41903305 53.42673111 53.4630394 53.43446732  53.426754 53.43151855 53.42074203 53.43041992 53.42025757 53.41553116 53.41986084 53.42238235 53.42142868 

-------
======================
selected experts : 2, 5, 12, 26, 43, 53, 
layer2_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e09f8dd0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.108269 0.067201 0.00380213-0.0592974 -0.0135828 0.000535565 -0.0324741 0.0812852 -0.0584557]

layer2_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc401970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.763786 -0.0330622 0.0836164-0.0809202 -0.0927551 -0.0291355 -0.0663213 0.217186 -0.125779]

layer3_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e86c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.46605 -0.0902244 0.21921-0.200976 -0.213305 -0.0674484 -0.160651 0.52609 -0.383736]
==============================
layer3_wq's output 
<N9nntrainer6TensorE at 0x5682dc409160>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.707984 0.0854658 1.18397-0.202544 -0.690064 0.887325 -0.748177 -0.459255 0.0479311]
============================
layer3_wk's input 
<N9nntrainer6TensorE at 0x5682dc41f6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.46605 -0.0902244 0.21921-0.200976 -0.213305 -0.0674484 -0.160651 0.52609 -0.383736]
==============================
layer3_wk's output 
<N9nntrainer6TensorE at 0x5682dc41f440>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.97 -0.264283 1.824420.813446 -1.20373 0.686917 -0.606336 1.37327 0.799509]
============================
layer3_wv's input 
<N9nntrainer6TensorE at 0x5682dc4204c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.46605 -0.0902244 0.21921-0.200976 -0.213305 -0.0674484 -0.160651 0.52609 -0.383736]
==============================
layer3_wv's output 
<N9nntrainer6TensorE at 0x5682dc420250>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.081883 -0.2498 -0.0316294-0.00160729 0.140572 -0.270699 -0.00854238 0.0444744 -0.062748]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.703666 -0.11576 0.00706534-1.20115 1.12133 -0.078388 0.697583 0.532975 -0.634666]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a167a0a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer3_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc422910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer3_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc422870>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer3_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc423990>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.763786 -0.0330622 0.0836164-0.0809202 -0.0927551 -0.0291355 -0.0663213 0.217186 -0.125779]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.31148 -0.12013 0.29228-0.31511 -0.327068 -0.11435 -0.255211 0.809113 -0.399162]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.1962377876 -0.103987515 0.4357120097 -0.2954514623 0.2231798172 -0.8020195365 -0.6774917245 1.119437695 -0.9338757396 -0.6962167621 1.503954053 0.1658852398 0.7134883404 -0.01098105684 -0.6858609319 -0.7453010082 -0.1625581384 -0.6343906522 -1.371559501 0.3677153885 -0.8660032153 -0.2938483655 1.433504224 -0.2337851226 -0.5885555148 -0.6060359478 -0.2926838398 0.1693664789 -0.3851058781 -0.1493725628 1.251326323 -0.4069331884 -0.1012405455 -0.1888886988 1.836473346 -0.4836421609 0.4375371933 -0.6476139426 0.1758795381 0.1851105392 -0.6089960337 -0.9272542596 0.03914502636 -0.680539012 0.02375158295 -0.6262216568 0.02406140417 0.4593750536 -0.180501461 -0.2702381611 -0.5046441555 -0.7031311989 -1.169670343 -0.161546275 -0.02932170779 -0.1969992369 -0.2860062122 -0.623481214 -0.6204127073 0.712192893 1.42602241 -0.7648400664 -0.6141082644 -0.7594501376 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01130137499 0.01239352953 0.02126099169 0.01023394894 0.01719024219 0.006166568957 0.00698433863 0.04212324694 0.005404794123 0.006854773965 0.06187498942 0.01623301767 0.02806856856 0.01360151265 0.006926128641 0.006526436657 0.01168848109 0.007291952148 0.003488956019 0.01986337081 0.005784366746 0.01025036909 0.05766591802 0.01088490617 0.007633958943 0.00750167435 0.01026231423 0.01628962718 0.009356358089 0.01184362173 0.04806183279 0.009154347703 0.01242762152 0.01138473488 0.08628324419 0.008478383534 0.02129983343 0.007196164224 0.0163960699 0.01654812135 0.007479500491 0.005440699868 0.01430067979 0.006963088177 0.0140822297 0.007351764012 0.01408659294 0.02177009173 0.01148062106 0.01049526315 0.008302179165 0.006807539612 0.004269479308 0.01170031633 0.0133543266 0.01129277237 0.01033107098 0.007371940184 0.007394595072 0.02803223021 0.05723607913 0.006400153972 0.007441361435 0.006434743758 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
42.54652405 42.54380035 42.55648041 42.54545593 42.55145645 42.54138947 42.53839111 42.57829666 42.54062653 42.54302979 42.59614182 42.55145264 42.56042862 42.54882431 42.54214859 42.54174805 42.54690933 42.54156113 42.53966522 42.55317688 42.54100418 42.54642487 42.59384155 42.54610443 42.54285431 42.54272461 42.54548264 42.55150986 42.54457855 42.54706573 42.58328247 42.54437637 42.54478836 42.54660416 42.62150574 42.54370117 42.55652237 42.54241562 42.55161667 42.55176926 42.54270172 42.54066086 42.55047607 42.54218292 42.54739761 42.54257202 42.54930878 42.55699158 42.54765701 42.54571533 42.54447556 42.54203033 42.53853607 42.54692078 42.54857635 42.54555893 42.5455513 42.54354858 42.54166031 42.5594368 42.59245682 42.54162216 42.54266357 42.54165649 

-------
======================
selected experts : 7, 10, 22, 30, 34, 60, 
layer3_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc426710>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141647 -0.00445617 0.00815817-0.0470299 0.0815447 -0.00950901 -0.0401189 -0.0316625 0.0468293]

layer3_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc426050>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.905433 -0.0375184 0.0917746-0.12795 -0.0112103 -0.0386445 -0.10644 0.185523 -0.0789494]

layer4_wq's input 
<N9nntrainer6TensorE at 0x5682dc44b9a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25242 -0.106134 0.255702-0.381958 -0.028047 -0.116461 -0.308668 0.556463 -0.233436]
==============================
layer4_wq's output 
<N9nntrainer6TensorE at 0x5682dc492890>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.030635 1.00211 -0.774273-0.0781808 0.867989 0.037558 0.177326 0.147243 -0.0249077]
============================
layer4_wk's input 
<N9nntrainer6TensorE at 0x5682dc44d700>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25242 -0.106134 0.255702-0.381958 -0.028047 -0.116461 -0.308668 0.556463 -0.233436]
==============================
layer4_wk's output 
<N9nntrainer6TensorE at 0x5682dc44d470>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.249979 -0.474866 0.5057910.318708 -0.907339 -0.236762 -0.611483 -0.579829 0.15471]
============================
layer4_wv's input 
<N9nntrainer6TensorE at 0x5682dc44e4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25242 -0.106134 0.255702-0.381958 -0.028047 -0.116461 -0.308668 0.556463 -0.233436]
==============================
layer4_wv's output 
<N9nntrainer6TensorE at 0x5682dc44e280>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.39199 -0.576836 -0.292241-0.205637 0.461115 -0.0912468 -0.0864808 0.0981705 -0.163482]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.309421 0.95364 -0.2120290.748768 -0.551373 -0.671419 -0.161429 -0.164516 -0.248376]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1e8e0e8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer4_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc450940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer4_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4508a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer4_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4519c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.905433 -0.0375184 0.0917746-0.12795 -0.0112103 -0.0386445 -0.10644 0.185523 -0.0789494]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.63462 -0.1408 0.330064-0.509277 -0.0420705 -0.156013 -0.432741 0.717336 -0.268227]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.9344680309 -0.1224616915 0.7122747302 -0.879663825 -1.050984979 -0.7712023854 -0.3001823127 0.3099183738 0.6146305799 -0.2456123233 0.09972074628 -0.1390371174 -1.008883476 0.470620662 -1.563606739 -0.5021421313 1.683896899 -0.5823207498 -0.7483549118 -0.7811715007 -0.09415169805 -0.3758384883 -0.3066797853 -0.7935734987 -0.3613235056 -0.182633847 0.3211717308 -0.1839020997 -1.400904298 -0.5521258712 -0.7814593315 -0.6820674539 0.07244253904 -0.554870069 0.3046645224 0.4763628244 -0.2898865044 -0.5237286091 -0.3867425323 -1.036280394 -0.3734202087 -0.272709161 -0.9219664931 -0.1225607991 -0.6516411304 0.2383146882 -0.6645326018 -0.1037149951 -0.7804605365 0.3365232646 -0.5520038009 0.4484129548 3.885401487 0.1329425722 -0.8620144725 -0.3145994842 1.132389545 -0.4294472635 -0.005604511127 -0.1885679513 0.178714633 -0.5649235845 -1.028280616 -0.8051867485 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003731110599 0.008404039778 0.01936464198 0.003941298928 0.003320744028 0.004392821342 0.00703566242 0.01294995565 0.01756317541 0.007430265658 0.01049495582 0.008265887387 0.003463536967 0.01520758867 0.001988871722 0.005749033764 0.05116577074 0.005306078587 0.004494340159 0.00434924569 0.008645355701 0.006523007061 0.006990094204 0.004295639228 0.006618378684 0.007913264446 0.0130965095 0.007903233171 0.002340277657 0.005468740594 0.004347995389 0.004802354611 0.01021254156 0.005453753751 0.01288209856 0.01529516745 0.007108471822 0.005626262631 0.00645226799 0.003369935555 0.006538802292 0.007231632713 0.003778048558 0.008403205313 0.004950718954 0.01205511019 0.004887307528 0.008563072421 0.004352339078 0.01329911221 0.005469407886 0.0148735866 0.462467134 0.01084947493 0.004011476878 0.006934956182 0.02947562188 0.00618252391 0.009445792995 0.007866444066 0.0113576157 0.005399198271 0.003397002816 0.004246043041 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.82138824 40.82606125 40.8360672 40.82255173 40.82193375 40.82300568 40.82564545 40.82965469 40.83140564 40.82604218 40.8281517 40.82687759 40.82207489 40.83286667 40.8205986 40.82435989 40.86787033 40.82201004 40.82310486 40.8229599 40.82630157 40.82513428 40.82273865 40.82099915 40.82427597 40.82652283 40.82884598 40.82460785 40.82094955 40.82408142 40.8229599 40.82341385 40.82882309 40.82406616 40.83149338 40.83200073 40.8228569 40.8213768 40.8250618 40.82007217 40.82419586 40.82584381 40.8223877 40.82606125 40.82356262 40.82685089 40.82349777 40.82622147 40.82201004 40.82427979 40.82312775 40.83062363 41.28107834 40.82850647 40.82167053 40.82554626 40.84808731 40.82479477 40.82519531 40.82647705 40.8299675 40.82400894 40.82201004 40.8228569 

-------
======================
selected experts : 2, 8, 16, 35, 52, 56, 
layer4_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc454a40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.120465 -0.0358364 -0.05859290.166895 0.0969606 0.00967123 -0.031883 -0.0466452 0.0645548]

layer4_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc454380>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.0259 -0.0733548 0.03318170.0389447 0.0857503 -0.0289733 -0.138323 0.138878 -0.0143946]

layer5_wq's input 
<N9nntrainer6TensorE at 0x5682dc4a0910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.91652 -0.18809 0.0753580.0946279 0.174852 -0.0746445 -0.342854 0.364577 -0.0351518]
==============================
layer5_wq's output 
<N9nntrainer6TensorE at 0x5682dc454560>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.663014 -1.19488 -0.8537191.46899 -1.12072 -0.569173 1.06715 0.145476 -1.55287]
============================
layer5_wk's input 
<N9nntrainer6TensorE at 0x5682dc4a2670>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.91652 -0.18809 0.0753580.0946279 0.174852 -0.0746445 -0.342854 0.364577 -0.0351518]
==============================
layer5_wk's output 
<N9nntrainer6TensorE at 0x5682dc4a23e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.19873 0.192916 -1.6543-0.510519 0.482255 -1.19605 0.612818 0.82119 -1.07766]
============================
layer5_wv's input 
<N9nntrainer6TensorE at 0x5682dc4a3460>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.91652 -0.18809 0.0753580.0946279 0.174852 -0.0746445 -0.342854 0.364577 -0.0351518]
==============================
layer5_wv's output 
<N9nntrainer6TensorE at 0x5682dc4a31f0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.155008 0.274099 0.359369-0.512762 -0.0739251 -0.105005 0.0591907 0.0220726 0.146967]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.302737 -1.33255 1.297571.09685 0.324193 1.21445 -1.04682 -0.253269 0.975519]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1c890d8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer5_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc4a58b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer5_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4a5810>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer5_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a6930>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.0259 -0.0733548 0.03318170.0389447 0.0857503 -0.0289733 -0.138323 0.138878 -0.0143946]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.77873 -0.254369 0.1102010.143606 0.282694 -0.10613 -0.506681 0.498538 -0.0456973]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3291094005 -1.067005634 -0.2928633988 -0.1757128835 -1.373118639 0.4114755392 0.2584048212 -0.2752860188 -1.167376161 -1.057608366 -0.8374167085 0.9554618001 -0.2741447389 0.1757035106 -0.9989030957 -0.576164782 -0.8192147017 2.311264992 -1.016098022 -1.270412564 1.849908113 -1.933212638 -2.491990566 -0.2602374554 -0.3482982516 -0.05025612563 -0.3480886519 -0.7141461372 -1.404352665 -1.230741978 -0.6166434288 -0.3129088879 0.2098553181 -1.20407033 -0.556591928 -0.04374771565 -1.015693903 -0.8262186646 -0.04862868041 0.3627088964 -0.01372391731 -0.4134725928 -0.2538684905 -0.03223772347 0.5227943659 -0.1476397663 -0.6841863394 -1.285633087 -1.073455691 -0.1691674292 -1.354353428 -1.352234244 0.2500188053 -0.3856589496 0.6190481186 1.555152297 -1.104683876 -1.076963305 -0.0127296634 -0.9971109629 -0.788003087 -0.2736488283 -0.186482653 -0.8268713355 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01124760229 0.005377688911 0.01166276168 0.01311231125 0.003959611058 0.02358804271 0.02024016716 0.01186957583 0.004864132497 0.005428462755 0.006765577942 0.04063891247 0.01188312937 0.01863362826 0.005756682716 0.008785473183 0.006889851298 0.1576739699 0.005658542272 0.004387905356 0.09940202534 0.002261552727 0.001293399138 0.01204954553 0.01103383023 0.01486498397 0.01103614364 0.007653156761 0.003837847617 0.004565474112 0.008436950855 0.01143130288 0.01928099059 0.004688881338 0.008959123865 0.01496204641 0.0056608296 0.006841765717 0.01488919556 0.02246533148 0.01541807503 0.01033764146 0.01212653238 0.01513525192 0.02636556327 0.01348562911 0.007885912433 0.004321624059 0.005343114026 0.01319841668 0.004034615587 0.004043173976 0.02007114515 0.01062920503 0.02902949974 0.07402602583 0.00517883664 0.005324405152 0.01543341111 0.005767008755 0.007108287886 0.01188902464 0.01297185197 0.006837300025 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.24911499 33.24515533 33.25334549 33.25479507 33.24373627 33.26145554 33.26192474 33.24687958 33.24559402 33.24711227 33.24749756 33.28136826 33.25356674 33.25745773 33.24744034 33.25046921 33.2485733 33.39077377 33.24734116 33.24607086 33.3315506 33.24394608 33.24297714 33.25373459 33.24794769 33.25654984 33.25271988 33.24933624 33.24552155 33.24529648 33.25012207 33.25120926 33.25524139 33.24637222 33.25064468 33.25569153 33.24734497 33.24852753 33.25275803 33.26128769 33.25710297 33.25202179 33.25285721 33.25682068 33.2661438 33.25516891 33.24956894 33.24505234 33.24607468 33.25488281 33.24381256 33.24572754 33.2579422 33.25135803 33.26785278 33.31189346 33.24686432 33.24224091 33.25711823 33.24745178 33.24879074  33.248806 33.25274658 33.24184418 

-------
======================
selected experts : 11, 17, 20, 44, 54, 55, 
layer5_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc4a9a10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.147336 -0.141224 0.01327730.0567547 0.0745959 0.013839 0.0319384 -0.0718612 -0.0475456]

layer5_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a9350>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.17323 -0.214579 0.0464590.0956994 0.160346 -0.0151342 -0.106385 0.0670166 -0.0619403]

layer6_wq's input 
<N9nntrainer6TensorE at 0x5682dc4e8620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.77169 -0.724071 0.1546520.329472 0.46064 -0.0486533 -0.332302 0.20322 -0.189239]
==============================
layer6_wq's output 
<N9nntrainer6TensorE at 0x5682dc4a9530>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0864339 -0.612978 -0.835630.900747 -0.667181 -0.993839 0.76025 0.722293 -1.56412]
============================
layer6_wk's input 
<N9nntrainer6TensorE at 0x5682dc4ea380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.77169 -0.724071 0.1546520.329472 0.46064 -0.0486533 -0.332302 0.20322 -0.189239]
==============================
layer6_wk's output 
<N9nntrainer6TensorE at 0x5682dc4ea0f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.11929 -0.10324 -0.009236750.557981 0.238305 -1.40537 0.128687 -0.405944 0.023759]
============================
layer6_wv's input 
<N9nntrainer6TensorE at 0x5682dc4eb170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.77169 -0.724071 0.1546520.329472 0.46064 -0.0486533 -0.332302 0.20322 -0.189239]
==============================
layer6_wv's output 
<N9nntrainer6TensorE at 0x5682dc4eaf00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.271435 -0.148165 0.352868-0.367987 0.232461 -0.637829 -0.47838 -0.252549 0.428962]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0882841 -0.612714 0.7411920.979927 -0.294755 1.16016 -0.682837 -0.795877 1.24284]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1a840c8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer6_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc41beb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer6_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc41be10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer6_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc41cf30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.17323 -0.214579 0.0464590.0956994 0.160346 -0.0151342 -0.106385 0.0670166 -0.0619403]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.88585 -0.74364 0.1557110.344746 0.533758 -0.0555545 -0.390516 0.239891 -0.199125]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4638691545 -0.7094838023 0.1943017393 -0.2551833391 -0.4816714525 0.08862743527 -1.246662021 -0.6691928506 -0.4370101988 -0.5953332186 -0.5229797363 0.4946106672 -1.15014708 0.185185194 0.7983567119 -0.8995850682 -0.8456157446 -1.121740341 -0.3646734655 -0.4495363235 -0.2456588447 0.5531499386 -1.047222018 -0.5409777164 -0.8014068604 -0.2398983538 -0.4034435749 -0.6143152714 -1.069929123 -0.6744322777 0.4236513376 2.86834383 -0.04825428128 0.4091398716 -0.129275769 -0.394715786 0.06413892657 -0.7999017835 -1.228420734 -0.2379585207 -1.191629887 -0.4292249382 -0.2913487256 0.1080761105 0.006064817309 -0.5773868561 0.6052529216 -1.192215562 -0.08549895883 -0.3021603227 -0.3416296244 -0.9069536924 -1.036425352 -1.180878758 -1.012220144 0.3234274983 -0.7495288253 -0.5062260628 0.5414540172 0.2662356794 -0.7921816111 1.482537866 0.05718161911 0.3893421292 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.02210799232 0.006838622037 0.01688409224 0.01077131834 0.008588282391 0.01519091334 0.003996456042 0.0071197832 0.008980538696 0.007665555924 0.008240742609 0.02279818431 0.004401402082 0.01673086733 0.0308898259 0.005654688459 0.005968253128 0.004528223537 0.009654235095 0.008868749253 0.01087439805 0.02417260781 0.004878549371 0.008093751967 0.006238022354 0.01093722042 0.009287101217 0.00752141932 0.004769020714 0.007082577329 0.02123649791 0.2447932363 0.01324759237 0.02093055286 0.01221658289 0.009368512779 0.01482342929 0.006247418467 0.004070025869 0.01095845923 0.004222554155 0.009050727822 0.01038872823 0.01548924856 0.01398709323 0.007804365829 0.02546546049 0.004220082425 0.01276326459 0.01027701516 0.009879290126 0.005613173824 0.004931507632 0.004268196877 0.005052331835 0.01921127737 0.006570179947 0.008379967883 0.02389153279 0.0181433782 0.006295836996 0.06122820452 0.01472065598 0.02052024938 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.14548874 40.13022232 40.13263702 40.13415527 40.13196945 40.13857269 40.12833405 40.13050079 40.13236237 40.1310463 40.13162231 40.14331818 40.12778473 40.13916016 40.15427399 40.12903595 40.12935257 40.12791061 40.13303757 40.13225174 40.13425827 40.1475563 40.12826157 40.13147736 40.1296196 40.13431931 40.13362503 40.13090515 40.12815094 40.13046646 40.14175797 40.36722183 40.13663101 40.14431381 40.13560104 40.13275146 40.13820648 40.12963104 40.12745285 40.13434219 40.12760544 40.13243484 40.13281631 40.13887024 40.13737106 40.13214111 40.14789581 40.12760162 40.13519287 40.13365936 40.13326263 40.12899399 40.12831497 40.12765121 40.1255722 40.14259338 40.1289978 40.13176346 40.14536667 40.14152527 40.12967682 40.18175125 40.13810349 40.14390182 

-------
======================
selected experts : 14, 21, 31, 46, 58, 61, 
layer6_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc47b4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0381875 0.16281 -0.0595574-0.0959639 -0.0746384 -0.10199 0.129345 0.000853485 -0.0417668]

layer6_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc47ae20>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21142 -0.0517691 -0.0130984-0.000264518 0.0857079 -0.117124 0.0229602 0.0678701 -0.103707]

layer7_wq's input 
<N9nntrainer6TensorE at 0x5682dc5555c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.06715 -0.156838 -0.037982-0.000744136 0.224419 -0.319354 0.0645911 0.178447 -0.305212]
==============================
layer7_wq's output 
<N9nntrainer6TensorE at 0x5682dc47b000>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.903018 0.200069 1.34658-0.212974 0.689655 0.979595 0.824704 0.675663 0.359885]
============================
layer7_wk's input 
<N9nntrainer6TensorE at 0x5682dc557b30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.06715 -0.156838 -0.037982-0.000744136 0.224419 -0.319354 0.0645911 0.178447 -0.305212]
==============================
layer7_wk's output 
<N9nntrainer6TensorE at 0x5682dc5578a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.66909 -0.428646 0.909704-0.847044 -0.0576201 0.999694 0.516561 1.05539 -0.210069]
============================
layer7_wv's input 
<N9nntrainer6TensorE at 0x5682dc558920>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.06715 -0.156838 -0.037982-0.000744136 0.224419 -0.319354 0.0645911 0.178447 -0.305212]
==============================
layer7_wv's output 
<N9nntrainer6TensorE at 0x5682dc5586b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.139538 0.504087 -0.0269906-0.0404803 -0.30488 0.0463377 0.531681 -0.183999 -0.504003]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.922953 -0.0602173 0.0251578-1.36309 0.269147 -1.16739 -0.7517 -0.756045 0.165293]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a187f0b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer7_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc55ad70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer7_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc55acd0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer7_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55bdf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21142 -0.0517691 -0.0130984-0.000264518 0.0857079 -0.117124 0.0229602 0.0678701 -0.103707]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.93991 -0.183725 -0.0447848-0.000973101 0.293043 -0.430874 0.0864527 0.243804 -0.345607]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.3026745021 -1.071165562 -0.3273747563 -0.3650847971 -0.2735459805 -0.6784827709 1.032438159 2.836415529 1.677007675 -1.012084246 -0.1210446581 0.1496284902 -1.072111249 -0.857732594 -0.7717418671 0.05227683112 -0.5959703326 -1.45846653 -0.6093594432 0.867061615 -1.10264802 -0.7392890453 0.1881039739 0.110251382 0.2924830019 -0.08666624129 -0.6546859741 -0.9960862994 0.6259451509 0.3693005443 0.2066856623 -0.7935817838 -0.7881087065 -0.8844150305 1.500858426 -0.2022871673 0.4411149323 -0.07829384506 -1.144552827 -0.7370305061 -0.7500447631 -0.7711327076 -0.4614872336 -0.4749506414 -1.833411813 -0.8816303015 -0.2007179558 -0.6693396568 0.4736348987 -0.004009608179 -0.3746697903 1.359379292 -1.315992475 -0.5028767586 -1.085083485 -0.9007630944 -1.366281986 -0.6700772643 -0.801158905 -0.9570243955 -1.029290915 -1.147143722 -2.838216066 -1.361460567 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01824202761 0.004617659841 0.009715076536 0.009355541319 0.01025235746 0.006838516798 0.0378447324 0.2298597097 0.07210052013 0.004898698069 0.01194137242 0.01565330476 0.004613294732 0.005716296379 0.006229598075 0.01420125738 0.007426712196 0.003134869039 0.007327937521 0.03207623214 0.004474549089 0.006435082294 0.01626730897 0.01504890248 0.0180570595 0.01235903427 0.0070032035 0.004977696575 0.02520390041 0.01949882694 0.0165724121 0.006095019169 0.006128469482 0.005565788597 0.06045577303 0.01100958697 0.02095062658 0.01246294565 0.004290917888 0.006449632347 0.006366238929 0.00623339368 0.0084957527 0.008382138796 0.002154678805 0.005581310019 0.01102687791 0.006901328918 0.02164314128 0.01342399698 0.009266297333 0.05248004198 0.003614888526 0.008151295595 0.004553837236 0.005475538317 0.003437592648 0.006896240171 0.006049010903 0.005175983068 0.004815128632 0.004279816058 0.0007888631662 0.003454208141 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
35.94260406 35.93374634 35.93789291 35.93466949 35.93747711 35.93597031 35.94981003 36.1570816 36.00027847 35.93307495 35.94107056 35.94478226 35.93374252 35.93293762 35.93535995  35.942379 35.93655777 35.93226624 35.93455124 35.96025467 35.93265152 35.93461227 35.9425354 35.94227219 35.93669891 35.93958282 35.93613434 35.93315506 35.94193649 35.94863129 35.94474792 35.93427277 35.9343071 35.9346962 35.98958588 35.9353714 35.9491272 35.93968582 35.93246841 35.93462753 35.93263626 35.93345642 35.93571854 35.93751144 35.93128586 35.93089676 35.93920517 35.93603134 35.94982147 35.9377861 35.93744278 35.97684097 35.93274689 35.93632889 35.9336853 35.9326973 35.93161392 35.93602753 35.93518066 35.9343071 35.93203735 35.93341064 35.9299202 35.93162918 

-------
======================
selected experts : 6, 7, 8, 19, 34, 51, 
layer7_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5969b0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00565025 0.0566365 0.0758908-0.164418 0.0241856 0.0410004 0.0588157 -0.00652726 0.0165999]

layer7_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55e510>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21707 0.0048674 0.0627924-0.164683 0.109893 -0.0761241 0.0817759 0.0613428 -0.0871072]

layer8_wq's input 
<N9nntrainer6TensorE at 0x5682dc59a250>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.71025 0.0132039 0.158897-0.433402 0.265852 -0.194175 0.206936 0.152125 -0.22748]
==============================
layer8_wq's output 
<N9nntrainer6TensorE at 0x5682dc5d3620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.113811 0.124451 -0.4443170.0557785 -0.156237 -0.0434516 0.0620928 0.0876601 -0.309255]
============================
layer8_wk's input 
<N9nntrainer6TensorE at 0x5682dc59bfb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.71025 0.0132039 0.158897-0.433402 0.265852 -0.194175 0.206936 0.152125 -0.22748]
==============================
layer8_wk's output 
<N9nntrainer6TensorE at 0x5682dc59bd20>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.407766 -1.14437 1.048860.735342 -0.108753 -0.838916 0.525454 -1.19989 0.509964]
============================
layer8_wv's input 
<N9nntrainer6TensorE at 0x5682dc59cda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.71025 0.0132039 0.158897-0.433402 0.265852 -0.194175 0.206936 0.152125 -0.22748]
==============================
layer8_wv's output 
<N9nntrainer6TensorE at 0x5682dc59cb30>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.155474 -0.0211943 -0.246304-0.226146 -0.513429 -0.183102 -0.704311 -0.585059 0.931872]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0745046 0.151294 -0.02257320.447235 0.071924 0.145344 -0.0528542 -0.0935214 0.308064]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1475098
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer8_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc59f1f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer8_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc59f150>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer8_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a0270>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21707 0.0048674 0.0627924-0.164683 0.109893 -0.0761241 0.0817759 0.0613428 -0.0871072]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.00805 0.017441 0.211016-0.620099 0.37375 -0.28818 0.30792 0.222288 -0.290963]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.008404136 -0.4691090584 -0.9366872311 -0.7921546102 -1.274636269 0.006863810122 2.454214811 -1.383565426 -0.8426497579 0.05605497584 -1.409932137 0.1777789742 -1.179196596 -1.211033463 -1.666357994 1.034234285 -0.3294745088 -1.14750886 0.9802370667 1.069889188 -0.03552164137 -0.7446625829 -0.1001953781 -0.6484101415 -1.137970924 -1.197386622 0.05350415409 -0.1711198688 -0.7221972346 0.2002630532 -0.9857591391 -1.11968112 0.1529440433 -0.9305140972 0.003514394164 0.2896854579 -0.1185809597 -0.4627895951 -1.680969238 0.3894585669 -0.7379513383 -0.4079317153 -0.6289588809 -0.6414070129 -2.64396143 0.7762132287 -1.07730329 -0.1143154651 -0.9056591392 -1.619636178 -0.8199756145 -1.296906233 -0.08220855147 -1.223901033 -0.2582148612 -0.9574040771 -1.854082346 -1.161227226 -0.7291987538 -1.523873329 0.2886013985 -0.07492308319 1.134797335 1.669533372 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005677468609 0.009735708125 0.006099594291 0.007048077881 0.004350423347 0.01567039452 0.1811135709 0.0039014332 0.006701019593 0.01646051556 0.003799909726 0.01859120093 0.004786085337 0.004636111204 0.002940416336 0.0437785387 0.01119463891 0.00494017452 0.04147730768 0.04536761716 0.01502007525 0.007390880957 0.01407941896 0.008137633093 0.004987518769 0.004699814133 0.01641858183 0.01311543211 0.007558797952 0.01901394129 0.00580750173 0.005079578608 0.01813517697 0.006137364078 0.01561799366 0.0207925532 0.01382292435 0.009797427803 0.002897765487 0.02297411487 0.007440649439 0.01034990791 0.008297468536 0.008194821887 0.001106219366 0.03382237628 0.005299467128 0.01388201211 0.006291819271 0.003081058385 0.006854694802 0.004254610278 0.01433495339 0.00457683811 0.01202147361 0.005974529311 0.002437144518 0.004872865975 0.007506060414 0.003390699159 0.02077002451 0.01443977375 0.04841001704 0.08263579011 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.07800674 34.08301926 34.07843018 34.08033371 34.07667923 34.08895493 34.25439835 34.07718658 34.0790329 34.08879089 34.07708359 34.08615494 34.0742569 34.07791901 34.07622528 34.11515427 34.08352661 34.07822418 34.0871048 34.11102295 34.08734894 34.07971954 34.0873642 34.08046722 34.07731628 34.07703018 34.08970261 34.0854454 34.08084106 34.09134293 34.07909012 34.07836533 34.09046555 34.07847214 34.0822258 34.09217072 34.08710861 34.08212662 34.07522964 34.09435272 34.07977295 34.08363342 34.08062744 34.0786171 34.07439041 34.10710526 34.07858276 34.08621216 34.07862091 34.07636642 34.08013916 34.07658386 34.08571243 34.07786179 34.08053589 34.07925797 34.07572174 34.07720184 34.0798378 34.07667542 34.09405518 34.0867691 34.11597061 34.14256668 

-------
======================
selected experts : 6, 15, 18, 19, 62, 63, 
layer8_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5a3350>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.152072 0.210309 0.0329533-0.00769576 0.160583 0.0579157 0.109306 0.0401298 0.0594724]

layer8_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a2c90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.36914 0.215177 0.0957457-0.172378 0.270477 -0.0182084 0.191082 0.101473 -0.0276348]

layer9_wq's input 
<N9nntrainer6TensorE at 0x5682dc5e1750>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.68563 0.619512 0.26179-0.521262 0.719953 -0.0514344 0.53284 0.279286 -0.0840663]
==============================
layer9_wq's output 
<N9nntrainer6TensorE at 0x5682dc5a2e70>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.591752 -0.374015 0.415191-0.627025 0.363317 0.275043 0.417152 0.358708 0.439543]
============================
layer9_wk's input 
<N9nntrainer6TensorE at 0x5682dc5e3c80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.68563 0.619512 0.26179-0.521262 0.719953 -0.0514344 0.53284 0.279286 -0.0840663]
==============================
layer9_wk's output 
<N9nntrainer6TensorE at 0x5682dc5e39f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.461237 -0.0227207 -0.3632830.355216 -0.12193 -0.141143 -0.366343 -0.083101 -0.283239]
============================
layer9_wv's input 
<N9nntrainer6TensorE at 0x5682dc5e4a70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.68563 0.619512 0.26179-0.521262 0.719953 -0.0514344 0.53284 0.279286 -0.0840663]
==============================
layer9_wv's output 
<N9nntrainer6TensorE at 0x5682dc5e4800>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.194997 0.478782 0.0529553-0.439892 -0.131646 0.0185741 0.000719097 0.660515 0.598036]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.463677 -0.524463 -0.544997-0.518191 -0.0376847 -0.454123 -0.378502 -0.399279 -0.677586]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1270088
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer9_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc5e6ec0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer9_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc5e6e20>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer9_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5e7f40>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.36914 0.215177 0.0957457-0.172378 0.270477 -0.0182084 0.191082 0.101473 -0.0276348]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.14448 0.728608 0.306867-0.611781 0.866882 -0.0649524 0.68162 0.345433 -0.087569]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7255349159 -0.5672965646 -0.7764482498 -0.6477704048 -0.03378194571 -0.7673395872 0.1534353197 -1.082969308 -0.07606554031 0.767480731 -0.2667455077 -0.748966217 -1.318661094 -1.149337053 -1.112321019 -0.1356878877 -1.085234404 -1.697420955 0.1044918671 -0.4385250807 2.16889739 -1.998455286 -1.768396854 -1.40848434 -1.780827403 -2.222319603 -2.025152922 -3.420464516 -0.6627473831 -0.01339121908 0.4632426202 -1.924889922 -0.2594430447 -0.2274001539 -1.100752831 2.526510239 0.1277280599 -0.03995922208 0.839887917 -0.6934179664 0.2299685776 -1.154621005 0.8696126342 1.671569228 -1.055778384 -1.093514442 -1.236648202 0.5946958661 -0.2920380831 -1.948354721 -0.1334101111 -1.829491615 -1.338919282 -1.027295113 -0.6525812745 -1.12422967 -1.035017014 -0.9695008993 -0.1200153977 0.3410769403 0.1406766176 -1.76957798 -1.523997784 -1.030200601 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007330521941 0.008587306365 0.00696664257 0.007923327386 0.01464061718 0.007030388806 0.01765496284 0.005127470475 0.01403446496 0.03262446076 0.01159803942 0.007160754874 0.004050824791 0.004798217677 0.00497915782 0.01322215516 0.005115868989 0.002773640212 0.01681167632 0.009767460637 0.1324862838 0.002052639611 0.002583602676 0.003702829126 0.002551685553 0.001640928211 0.001998563064 0.0004951558076 0.007805544417 0.01494221482 0.02406658046 0.0022093351 0.01168304496 0.01206346601 0.005037091672 0.1894437075 0.01720688678 0.01455045864 0.03507433087 0.007569777314 0.01905920543 0.004772930872 0.03613255918 0.08057197928 0.005268802866 0.005073684268 0.004397048615 0.02744756453 0.01130837668 0.002158097224 0.01325230394 0.002430483 0.003969588783 0.005421033595 0.007885301486 0.004920213483 0.005379334558 0.005743568297 0.01343101077 0.02129896544 0.01743113808 0.002580552828 0.003298882861 0.00540530635 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.4592247 34.46047974 34.45313644 34.4588623 34.46557999 34.45892334 34.44761276 34.45701981 34.46592712 34.48356247 34.46348953 34.45905304 34.45594406 34.45669174 34.45687103 34.46511459 34.45605469 34.45466614 34.46775055 34.46165848 34.57865524 34.45394516 34.45352173 34.45368958 34.45444489 34.45353317 34.45389175 34.45238876 34.44920731 34.46683502 34.47595978 34.45410156 34.4626236 34.46300125 34.45692825 34.63275528 34.46337891 34.46548843 34.48696899 34.45946121 34.44710922 34.45666504 34.48325729 34.5315094 34.45716095 34.4569664 34.4562912 34.47457123 34.46129227 34.45405197 34.46037674 34.45432281 34.45586395 34.45731354 34.45691681 34.45490646 34.45441055 34.45668411 34.46341705 34.47223663 34.46741486 34.45447159 34.45519257 34.45539093 

-------
======================
selected experts : 9, 20, 35, 38, 42, 43, 
layer9_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5eb020>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0103548 -0.0827766 -0.0817536-0.102075 0.068178 0.173603 -0.188488 -0.0705576 0.106281]

layer9_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5ea960>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.3795 0.1324 0.0139921-0.274454 0.338655 0.155395 0.00259337 0.0309151 0.0786466]

layer10_wq's input 
<N9nntrainer6TensorE at 0x5682ded33210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.45415 0.362037 0.0377992-0.777595 0.814453 0.432593 0.00709134 0.0763867 0.199506]
==============================
layer10_wq's output 
<N9nntrainer6TensorE at 0x5682dc5eab40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.38492 -1.21453 1.34427-0.00452872 -1.3604 1.30168 -0.661107 -1.8578 -1.70101]
============================
layer10_wk's input 
<N9nntrainer6TensorE at 0x5682ded34f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.45415 0.362037 0.0377992-0.777595 0.814453 0.432593 0.00709134 0.0763867 0.199506]
==============================
layer10_wk's output 
<N9nntrainer6TensorE at 0x5682ded34ce0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.873695 -0.283103 0.4851621.0017 0.0310412 -0.544273 1.10511 -0.63873 -0.25015]
============================
layer10_wv's input 
<N9nntrainer6TensorE at 0x5682ded35d60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.45415 0.362037 0.0377992-0.777595 0.814453 0.432593 0.00709134 0.0763867 0.199506]
==============================
layer10_wv's output 
<N9nntrainer6TensorE at 0x5682ded35af0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.13422 -0.16506 0.07610980.152348 -0.368472 -0.381889 0.432319 -0.0450181 0.801782]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.708948 -1.0586 0.230006-1.32446 1.8773 0.144222 0.468708 1.91541 1.29996]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a106b078
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer10_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded38210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer10_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded38170>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer10_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded39290>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.3795 0.1324 0.0139921-0.274454 0.338655 0.155395 0.00259337 0.0309151 0.0786466]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.96559 0.427465 0.0424089-0.931306 1.02643 0.529862 0.00897098 0.100321 0.23578]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.075698853 -2.146638155 -1.572076797 -1.239016533 -0.6601934433 -1.058405876 -0.8171054125 -0.5537326932 0.8124222159 -1.65486455 -1.263222814 -0.2799122632 -0.5027951002 -0.9667331576 1.368038416 -0.9534963369 -1.396287799 -0.8885353208 -0.773917675 -0.5835622549 -0.1159888133 -0.5864533782 -1.190278411 1.46242857 -0.7600318193 0.1094364524 -0.527754426 -1.326165557 -1.424989223 -0.2970946431 -0.1208939254 -1.036193252 -0.2115094513 -0.1717701852 -1.760190725 -0.5123511553 -0.834112525 -1.510728478 0.2634393275 -0.08949471265 0.3920693099 -0.2159163058 -0.9869779348 -0.1603210419 -0.5909483433 -0.3569854796 -1.103301883 -1.43753016 1.086938024 0.04133091494 -0.6025595069 -0.9155442715 -0.1440999508 -0.4863758683 -1.130069971 -0.870148778 -0.9056789875 1.548809886 -0.2099162936 -1.09917748 -1.344641328 -0.5869354606 -1.286455154 -1.634610772 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006908041891 0.002367292996 0.004205143079 0.005867147353 0.01046662498 0.007028541528 0.008946655318 0.01164238621 0.04564104602 0.003871030407 0.005726831034 0.01530949119 0.01225078478 0.007703325246 0.07955300808 0.007805970032 0.005013315007 0.008329886012 0.009341505356 0.01130022854 0.01803647913 0.01126760617 0.006160184741 0.08742783219 0.009472126141 0.02259709872 0.01194879878 0.005377478898 0.004871470388 0.01504868269 0.01794822514 0.007186411414 0.01639334857 0.01705792546 0.003484047018 0.01213427354 0.008795784786 0.004471199121 0.0263593886 0.01852072589 0.02997772209 0.01632126607 0.007548940834 0.01725434884 0.01121707261 0.01417386346 0.00671996735 0.004810759798 0.06005874649 0.02110935003 0.01108758152 0.008107917383 0.01753651351 0.01245359331 0.006542474031 0.008484461345 0.008188299835 0.09531574696 0.01641948894 0.006747740787 0.005279037636 0.01126217563 0.005595316179 0.00395023264 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.10935593 33.10577011 33.10760498 33.10926819 33.11386871 33.10089111 33.11234665 33.11504364 33.14713669 33.1072731 33.10912704 33.11775589 33.11565018 33.10538101 33.17913818 33.11120605 33.1084137 33.11077881 33.10606766 33.11183929 33.1204834 33.1146698 33.10956192 33.18510818 33.11001205 33.12123108 33.11439514 33.10877991 33.10731888 33.11845016 33.12039566 33.11058807 33.11979294 33.12046051  33.106884 33.11362839 33.11029053 33.10787201 33.12976074 33.12192154 33.11525726 33.10065079 33.11095047 33.12065506 33.11461639 33.11566925 33.10916901 33.10821152 33.15869141 33.12451172 33.11067581 33.11150742 33.12093735 33.11394882 33.10994339 33.11188507 33.10968399 33.19394684 33.11791229 33.10919571 33.10868073 33.11275482 33.10899734 33.10735321 

-------
======================
selected experts : 8, 14, 23, 40, 48, 57, 
layer10_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded3c110>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.100843 -0.160853 -0.002693580.1557 -0.206979 -0.0521097 0.0486964 -0.0564466 0.0430339]

layer10_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded3bb90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.48034 -0.0284524 0.0112985-0.118753 0.131675 0.103285 0.0512898 -0.0255316 0.12168]

layer11_wq's input 
<N9nntrainer6TensorE at 0x5682ded7c3b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.82488 -0.0757713 0.0285557-0.338408 0.321627 0.287321 0.136589 -0.0614967 0.319918]
==============================
layer11_wq's output 
<N9nntrainer6TensorE at 0x5682ded3ba40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.711116 -0.0312718 0.6831160.309559 0.223987 -1.01384 0.898509 0.212579 -1.42737]
============================
layer11_wk's input 
<N9nntrainer6TensorE at 0x5682ded7e110>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.82488 -0.0757713 0.0285557-0.338408 0.321627 0.287321 0.136589 -0.0614967 0.319918]
==============================
layer11_wk's output 
<N9nntrainer6TensorE at 0x5682ded7de80>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.919881 0.605903 -1.4669-0.890419 -1.10398 0.894191 -0.587251 0.00590786 1.58978]
============================
layer11_wv's input 
<N9nntrainer6TensorE at 0x5682ded7ef00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.82488 -0.0757713 0.0285557-0.338408 0.321627 0.287321 0.136589 -0.0614967 0.319918]
==============================
layer11_wv's output 
<N9nntrainer6TensorE at 0x5682ded7ec90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.272071 0.685627 -0.546734-0.0507568 0.0982439 -0.692871 -0.549821 0.199806 -0.310142]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.691531 0.168671 0.423961-0.618653 -0.904458 0.509895 -0.872226 -0.30287 1.42886]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0e66068
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer11_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded813b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer11_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded81310>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer11_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded82430>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.48034 -0.0284524 0.0112985-0.118753 0.131675 0.103285 0.0512898 -0.0255316 0.12168]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.14691 -0.0994196 0.0364134-0.433081 0.431069 0.38543 0.191399 -0.0883474 0.390093]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.288918138 -0.845023632 -0.4500235617 0.09027478844 -0.02849121951 0.4326645136 0.861541748 -2.127013445 -1.683238268 -0.9644001126 -0.7943502069 -1.822052717 -0.2006771863 -1.047119379 -0.4974162877 0.2427326739 -0.09994769096 -0.3965860903 0.2931783795 -0.9949479103 -2.787274361 -0.0202193968 0.06953013688 -0.5222980976 0.183985889 0.3801911771 -0.7795951962 0.9515047073 -0.2640305758 -1.946425319 -0.3005286753 -0.3565134406 -0.8987566829 -1.200834036 -0.6032832861 -0.7825671434 0.3121511042 -1.317822576 -1.634918094 -2.074688435 -0.6773531437 -1.798682928 -0.8446490765 1.976724267 -0.8513905406 -1.06051755 1.735411763 -0.9552757144 -0.468685925 -0.08455939591 -0.4899786115 -1.069809794 -0.06575390697 -1.333945274 -1.214619875 -2.006838083 -0.262242198 -1.690782309 -0.7679491043 -0.9080834985 -1.099174023 -0.9894859791 -0.2361604422 -1.029676914 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.00526396744 0.008205294609 0.01217980962 0.02090687305 0.01856562868 0.02944333665 0.0452112034 0.002276842482 0.003548641223 0.007281980943 0.008631798439 0.003088699887 0.01562896371 0.006703861058 0.01161603816 0.02435009554 0.01728527993 0.01284837071 0.0256099645 0.007062897086 0.001176482299 0.01871983521 0.02047763392 0.01133057568 0.02296081185 0.0279381834 0.008760104887 0.04946710169 0.01466953009 0.002727479208 0.01414377335 0.01337369531 0.00777603453 0.005748672411 0.0104491422 0.008734109811 0.0261004921 0.005113993306 0.003724322887 0.002399150748 0.009703142568 0.00316173234 0.008208367042 0.1378998011 0.008153217845 0.006614640355 0.1083335504 0.007348729763 0.01195461117 0.01755333133 0.0117027564 0.00655346131 0.01788655482 0.005032203626 0.005669965874 0.002567582764 0.0146957878 0.003521970706 0.008862723596 0.007703845389 0.006363822613 0.007101578172 0.01508412324 0.006821820047 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.54701042 28.55090523 28.55535698 28.55216217 28.55602074 28.55926895 28.58028221 28.54593086 28.54481888 28.54712105 28.55228615 28.54674149 28.55403709 28.54988098 28.5547924 28.56037331 28.56046104 28.55602455 28.56115723 28.54594803 28.54483032 28.55951309 28.56365395 28.5454464 28.56327629 28.56777763 28.54764557 28.58119965 28.55212402 28.54590416 28.55350494 28.55559731 28.55095291 28.5489254 28.55314827 28.54618835 28.56927681 28.54542923 28.54547119 28.5455761 28.55287933 28.54490852 28.55138588 28.67392349 28.54942322 28.54788399 28.64864922 28.55052567 28.55560875 28.55548477 28.55440331 28.54686928 28.56058693 28.54820824 28.5488472 28.54526711 28.55739594 28.54669952 28.54727173 28.55088043 28.54906273 28.54980087 28.55778313 28.5495224 

-------
======================
selected experts : 5, 6, 25, 27, 43, 46, 
layer11_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded85530>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.333288 -0.129826 0.0946371-0.126506 0.0569822 -0.0248454 0.022742 -0.0304357 -0.0313503]

layer11_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded84d30>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.81363 -0.158279 0.105936-0.245259 0.188657 0.0784395 0.0740318 -0.0559673 0.0903302]

layer12_wq's input 
<N9nntrainer6TensorE at 0x5682dedc4470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.89637 -0.441801 0.292464-0.725737 0.48631 0.226125 0.217936 -0.14683 0.24387]
==============================
layer12_wq's output 
<N9nntrainer6TensorE at 0x5682ded84be0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.348987 0.440544 0.5327880.103167 -0.98111 -0.391637 0.483843 -0.561279 0.615396]
============================
layer12_wk's input 
<N9nntrainer6TensorE at 0x5682dedc61d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.89637 -0.441801 0.292464-0.725737 0.48631 0.226125 0.217936 -0.14683 0.24387]
==============================
layer12_wk's output 
<N9nntrainer6TensorE at 0x5682dedc5f40>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.94753 2.73744 -1.06041-0.612855 -0.205349 -1.58668 1.13056 1.90304 -0.65085]
============================
layer12_wv's input 
<N9nntrainer6TensorE at 0x5682dedc6fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.89637 -0.441801 0.292464-0.725737 0.48631 0.226125 0.217936 -0.14683 0.24387]
==============================
layer12_wv's output 
<N9nntrainer6TensorE at 0x5682dedc6d50>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.51248 -0.402007 0.1068260.234327 -0.535508 -0.147109 -0.676383 -0.230129 1.07105]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.458182 0.325485 0.194514-0.506627 0.36321 0.991986 -0.538425 0.509153 -0.613134]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0c61058
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer12_attention_out's input 
<N9nntrainer6TensorE at 0x5682dedc9470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer12_attention_out's output 
<N9nntrainer6TensorE at 0x5682dedc93d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer12_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dedca4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.81363 -0.158279 0.105936-0.245259 0.188657 0.0784395 0.0740318 -0.0559673 0.0903302]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.24071 -0.499742 0.300544-0.811778 0.546739 0.266804 0.251812 -0.173294 0.260404]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.293932796 -0.3431039155 -2.383466959 -1.621967912 -0.7980388999 -0.5974785686 0.1122665331 -0.1272202879 -1.179748893 -1.615149617 -0.006524482276 1.812610626 -0.6442659497 -0.4597440958 -1.410847545 -0.171241641 0.3463445008 -0.6412830353 -0.8454797268 -1.184060097 0.4546080232 -0.3660334647 -0.001814156771 -0.4574493468 -1.220888734 1.647700906 -1.07535696 -1.064948797 -0.2735287845 -1.309849143 -0.6186333895 -0.214939326 -0.0545353815 0.04064106569 -1.461414933 2.050419092 -0.3244403005 -0.6647894382 -0.5618572235 0.7115014791 -1.880402684 2.990878344 -0.04464754835 -0.509827733 -1.141849995 -2.116267204 0.530513227 -0.2795463204 -0.5140702128 -1.890625715 -0.4986811876 -0.3700327575 -0.9741646647 -1.60545063 -0.9082166553 0.1884768605 -1.114508629 0.2282897979 -1.38516736 -0.4846554399 -0.957275033 0.7046700716 0.6681559682 -1.846594334 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003478836035 0.009002718143 0.001170186908 0.002505936194 0.005712127313 0.006980718113 0.01419510134 0.01117199287 0.003899629926 0.002523080911 0.01260515582 0.07772998512 0.006661632098 0.008011565544 0.003094984917 0.01069085672 0.01793896034 0.006681532599 0.005447466858 0.003882854478 0.01999012567 0.008798637427 0.01266467106 0.008029971272 0.003742454108 0.06591271609 0.00432872586 0.004374016076 0.00965138711 0.003423903836 0.006834593136 0.01023374964 0.01201426983 0.01321392972 0.002942370018 0.09859785438 0.009172319435 0.00652630534 0.007233863231 0.02584537677 0.00193523278 0.2525246143 0.01213365421 0.007620199583 0.004050256219 0.001528617111 0.0215665549 0.009593484923 0.007587940432 0.001915549859 0.007705613505 0.008763519116 0.004789690487 0.002547672251 0.005116208922 0.01531920396 0.004162525758 0.01594141312 0.003175493563 0.007814453915 0.004871272948 0.02566942573 0.02474903129 0.002001778223 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
30.80781364 30.81381416 30.80550575 30.80636406 30.80909348 30.80940819 30.81900597 30.81550598 30.80489731 30.8073349 30.81741714 30.87825012 30.81147385 30.81091499 30.80599976 30.81502533 30.82275009 30.81053925 30.81025887 30.80774117 30.8209877 30.81361008 30.81747627 30.81236458 30.8085537 30.87072372 30.80818558 30.80918503 30.81255531 30.80680466 30.81116867 30.8150444 30.81587219 30.81325722 30.80727768 30.89959526 30.81350708 30.81038475 30.81156921 30.83017921 30.8062706 31.05733681 30.81408501 30.8119545 30.80838585 30.80586243 30.82494736 30.80582237 30.81049156 30.80672646 30.81204224 30.81071472 30.80912399 30.80449867 30.80992699 30.8201313 30.80849648 30.81884575 30.80751038 30.81214905 30.80968285 30.83048058 30.81811714 30.80538368 

-------
======================
selected experts : 11, 25, 35, 39, 41, 61, 
layer12_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dedcd730>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.112173 -0.131077 0.02260420.128528 0.194601 0.0424895 0.20247 0.0769971 0.138645]

layer12_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dedccdf0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.9258 -0.289355 0.12854-0.116731 0.383258 0.120929 0.276502 0.0210298 0.228975]

layer13_wq's input 
<N9nntrainer6TensorE at 0x5682dee397f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.16659 -0.748282 0.326644-0.340257 0.865079 0.368764 0.781172 0.0493541 0.55791]
==============================
layer13_wq's output 
<N9nntrainer6TensorE at 0x5682dedccca0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.146461 -0.826287 0.551154-0.545832 0.223024 -1.19836 0.793292 0.190072 -0.0831282]
============================
layer13_wk's input 
<N9nntrainer6TensorE at 0x5682dc471a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.16659 -0.748282 0.326644-0.340257 0.865079 0.368764 0.781172 0.0493541 0.55791]
==============================
layer13_wk's output 
<N9nntrainer6TensorE at 0x5682dc4717a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.402265 0.759593 -0.07713470.614578 0.107329 0.575085 -0.997259 0.0339192 0.130419]
============================
layer13_wv's input 
<N9nntrainer6TensorE at 0x5682dc472820>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.16659 -0.748282 0.326644-0.340257 0.865079 0.368764 0.781172 0.0493541 0.55791]
==============================
layer13_wv's output 
<N9nntrainer6TensorE at 0x5682dc4725b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.566453 -0.334422 0.3136370.445715 -0.460067 0.359764 0.332423 0.159887 -0.479781]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0902499 -0.8343 -0.441334-0.637909 -1.04122 0.633769 -0.769844 -0.269778 0.378037]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0a5c048
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer13_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc474cd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer13_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc474c30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer13_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc475da0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.9258 -0.289355 0.12854-0.116731 0.383258 0.120929 0.276502 0.0210298 0.228975]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.34616 -0.91697 0.365072-0.389114 1.09424 0.417571 0.9341 0.065072 0.653747]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7220129371 -0.05478731543 0.6278259754 -0.9891938567 1.762662411 -1.380978107 1.996001959 -0.8052836061 -0.9301933646 -1.203303814 0.8459310532 2.089992046 -0.199139744 -1.273727894 0.3800617158 -1.414164662 1.100451708 -0.2400038391 2.241235256 -2.743719339 -1.01332128 -0.2049026638 -0.4105205238 -0.9677480459 -1.712805986 -0.8239360452 -0.2945116162 -0.7590095401 -1.885005236 -1.946353197 -1.634285212 0.4477111399 -1.928819418 0.2596154809 -1.967078924 0.3224657178 -1.111128688 -0.7384868264 -1.687330604 0.1799392998 -0.6839897633 -0.3906354308 -1.360973239 -0.6651363373 -0.4168076515 -0.9761619568 -0.7915734649 -0.1483076811 -0.4143925905 0.6110135317 0.3685078025 -1.747005105 0.08016446978 -0.8501906395 -0.5594712496 -0.5311316848 -1.084499002 0.2401874214 -0.3063743711 -0.02832869813 0.33382985 -0.3051034212 -0.5633391738 -0.5100511909 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006589851342 0.01284245402 0.02541576885 0.005044758786 0.07905992866 0.003409500234 0.09983768314 0.006063336506 0.005351358093 0.004072430544 0.03161004186 0.1096765697 0.01111620478 0.003795498982 0.01983812451 0.003298207885 0.04077199474 0.01067110803 0.127584517 0.0008726891829 0.004924498498 0.01105232816 0.00899818819 0.005154115614 0.002446694067 0.005951288622 0.0101050185 0.006350503769 0.002059654566 0.001937096706 0.002646554494 0.02122659422 0.001971361926 0.0175869856 0.001897363109 0.01872780733 0.004465650767 0.006482180674 0.002509825164 0.01624009199 0.006845243275 0.00917890761 0.003478393191 0.006975524127 0.008941792883 0.005110932048 0.006147037726 0.01169587206 0.008963414468 0.02499203756 0.01961023547 0.002364434302 0.01469795313 0.005797072779 0.007752943784 0.007975799963 0.004586168099 0.01724860258 0.009985852987 0.01318678353 0.01894184761 0.009998554364 0.007723012473 0.008145718835 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.72858047 28.73578644 28.74788284 28.7279892 28.80057335 28.72540092 28.82230568 28.72805405 28.72877312 28.72749329 28.75074005 28.82451439 28.73215294 28.72578621 28.74087524 28.7267189 28.76371574 28.72932434 28.85100555 28.72429466 28.7273922   28.73209 28.73098946 28.72809792 28.72634506 28.72889519 28.73018837 28.72881699 28.7250042 28.72392845 28.72511482 28.74417114 28.72491646 28.74053192 28.7200737  28.740242 28.72740936 28.72704315 28.72593117 28.73918343 28.73026657 28.73212242 28.72356224 28.72991943 28.72950172 28.72757912 28.72909164 28.72939491 28.73143005 28.74841309 28.74303055 28.72530937 28.73764229 28.72874069 28.73069763 28.73139763 28.72705269 28.7387619 28.73245239 28.73470116 28.74188614 28.73246574 28.73114395 28.73156738 

-------
======================
selected experts : 4, 6, 10, 11, 16, 18, 
layer13_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee45420>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.155227 -0.00390031 0.166556-0.0488616 0.0151408 -0.1858 0.310591 -0.101189 0.0405358]

layer13_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc478790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.08103 -0.293256 0.295096-0.165592 0.398399 -0.0648707 0.587092 -0.0801589 0.269511]

layer14_wq's input 
<N9nntrainer6TensorE at 0x5682dee98c10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04213 -0.643039 0.616261-0.404169 0.847593 -0.17188 1.41762 -0.160076 0.587455]
==============================
layer14_wq's output 
<N9nntrainer6TensorE at 0x5682dc478730>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.58019 0.258 -0.471951-0.137936 0.0589217 -0.443345 -1.4416 -2.72168 -0.39271]
============================
layer14_wk's input 
<N9nntrainer6TensorE at 0x5682dee9aab0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04213 -0.643039 0.616261-0.404169 0.847593 -0.17188 1.41762 -0.160076 0.587455]
==============================
layer14_wk's output 
<N9nntrainer6TensorE at 0x5682dee9a7d0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.12019 0.159095 1.60696-0.118079 1.05921 1.02661 0.26934 0.833747 0.0833444]
============================
layer14_wv's input 
<N9nntrainer6TensorE at 0x5682dee9b8a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04213 -0.643039 0.616261-0.404169 0.847593 -0.17188 1.41762 -0.160076 0.587455]
==============================
layer14_wv's output 
<N9nntrainer6TensorE at 0x5682dee9b630>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.13295 -0.965879 -0.733511-0.177862 0.0406729 0.341231 -0.450788 0.578666 0.315487]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.58934 -0.193806 -0.2181380.440659 -0.369466 0.252035 1.15728 2.8542 0.483594]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2eb6168
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer14_attention_out's input 
<N9nntrainer6TensorE at 0x5682dee9dda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer14_attention_out's output 
<N9nntrainer6TensorE at 0x5682dee9dd00>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer14_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dee9ee70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.08103 -0.293256 0.295096-0.165592 0.398399 -0.0648707 0.587092 -0.0801589 0.269511]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.33592 -0.857385 0.754919-0.501429 1.02959 -0.206595 1.80842 -0.223897 0.696504]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.890654683 -0.677886188 -0.8622816205 -0.8444775343 -0.6838998199 -0.4321343005 -0.6509006023 -0.5058846474 1.295049429 -0.8424673676 -1.344491839 -1.465663314 0.8016123176 0.7685012817 -0.516190052 -0.9302549362 -1.699092507 0.3788572848 -3.006859779 -1.006314635 -1.602183938 -1.416317463 -0.9968240261 -1.496439219 -0.5641298294 -1.308431149 -0.3583960533 -0.7280638814 -1.764087915 -0.2883976698 -1.896824598 -1.733500719 1.287511587 -0.8243377209 -0.4451369345 -1.575756311 -0.472317487 -0.8194108605 -0.1870341748 -1.031679988 -0.5676518083 0.06790029258 -0.8494802117 -0.09206518531 -0.4842657745 -0.2350678742 -1.721546173 -0.3043273389 -1.466235518 1.14675498 -1.694718361 -0.5937050581 -0.3306755126 -0.7036556602 -0.9399239421 1.586244106 0.6639513373 0.7030807137 0.4497053325 -0.159288466 -1.697398186 -0.0456347391 -0.105351761 0.3423116803 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1113802493 0.00853699632 0.007099424489 0.007226955611 0.008485811763 0.01091525145 0.008770506829 0.0101392176 0.06139600277 0.007241496816 0.004383307416 0.00388309313 0.0374837555 0.03626295179 0.01003526524 0.006632889621 0.003074686043 0.02456082404 0.0008314664592 0.006147101987 0.003387565026 0.004079514649 0.006205718499 0.003765407018 0.00956552662 0.004544257652 0.01175054256 0.008119198494 0.002881201217 0.01260253135 0.0025230553 0.002970690606 0.06093495339 0.007373979315 0.01077424362 0.003478283528 0.01048533712 0.007410400081 0.01394695323 0.005993139464 0.009531894699 0.01799683087 0.007190891076 0.01533641573 0.01036080252 0.0132928649 0.003006418003 0.01240336709 0.003880871926 0.05293423682 0.003088165075 0.009286765009 0.01208082959 0.008319811895 0.006569064688 0.08214939386 0.03266312182 0.03396654502 0.02636403404 0.01433934085 0.003079900518 0.01606528275 0.0151339937 0.02367943898 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.27173233 27.16936684 27.16697502 27.16519547 27.16693115 27.17126846 27.16959953 27.16906166 27.22222519 27.16807175 27.16378212 27.16280556 27.1987896 27.19137001 27.1656189 27.16603279 27.16295052 27.1844368 27.16213799 27.16363907 27.16374016 27.16490936 27.16703606 27.15934944 27.1703949 27.16489601 27.17258072 27.16894913 27.16371155 27.17390823 27.16239929 27.16284561 27.22176361 27.16724968 27.17112732 27.16287804 27.16893005 27.16728592 27.17477608 27.1663456 27.17036057 27.17835045 27.16563606 27.17473602 27.17119026 27.17364502 27.16383553 27.1689415 27.16328049 27.21376419 27.16248703 27.16868591 27.17243385 27.1691494 27.16739845 27.24202538 27.19349289 27.19431877 27.18147087 27.17421532 27.16343307 27.17737198 27.16595078 27.18450928 

-------
======================
selected experts : 0, 8, 12, 32, 49, 55, 
layer14_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deea2ef0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0442295 0.142497 -0.183646-0.151549 0.0582103 0.0591179 -0.199296 0.0431362 -0.149447]

layer14_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deea2970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.12526 -0.150758 0.11145-0.317141 0.456609 -0.00575276 0.387797 -0.0370227 0.120064]

layer15_wq's input 
<N9nntrainer6TensorE at 0x5682deedb770>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.77349 -0.33165 0.211932-0.764679 0.868282 -0.0155153 0.910942 -0.0713222 0.244728]
==============================
layer15_wq's output 
<N9nntrainer6TensorE at 0x5682deea2820>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00260178 0.611024 -0.150906-0.25107 0.966889 -0.0170978 -0.14178 -0.448184 -0.40272]
============================
layer15_wk's input 
<N9nntrainer6TensorE at 0x5682deedd610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.77349 -0.33165 0.211932-0.764679 0.868282 -0.0155153 0.910942 -0.0713222 0.244728]
==============================
layer15_wk's output 
<N9nntrainer6TensorE at 0x5682deedd330>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.591653 -1.26591 0.07956451.14947 -0.494893 0.228183 1.02436 0.556575 0.497839]
============================
layer15_wv's input 
<N9nntrainer6TensorE at 0x5682deede400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.77349 -0.33165 0.211932-0.764679 0.868282 -0.0155153 0.910942 -0.0713222 0.244728]
==============================
layer15_wv's output 
<N9nntrainer6TensorE at 0x5682deede190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.461074 0.0829068 -0.469892-0.137902 -0.0689102 -0.205022 -0.708806 -0.3385 -0.00434557]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.173228 0.58596 -0.2735420.104801 -0.658083 -0.708585 0.0954566 0.460281 0.748041]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2bae950
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer15_attention_out's input 
<N9nntrainer6TensorE at 0x5682deee0900>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer15_attention_out's output 
<N9nntrainer6TensorE at 0x5682deee0860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer15_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682deee19d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.12526 -0.150758 0.11145-0.317141 0.456609 -0.00575276 0.387797 -0.0370227 0.120064]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.46972 -0.436579 0.277035-0.942053 1.15203 -0.0179463 1.16157 -0.099391 0.301433]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2218439579 -0.6005067229 -0.007580773905 -0.7548547983 0.0933939144 -0.8238271475 -0.3696285486 -1.379104376 -1.4727844 -1.010642409 0.03440863639 -0.8138206601 -0.7815232277 -0.4850285351 -1.464040756 1.524754405 -0.9279221892 -0.5366939902 -1.547908783 -0.245569557 -1.846567154 -0.4650019109 2.035564899 -1.926776528 -0.1271660626 -0.9479135871 0.1389866769 -0.8522074223 -1.067058682 0.2254901528 -0.4206766188 -0.4966990054 -1.859713674 -0.08688179404 0.07939142734 -0.3981376886 -0.7420488 0.1732515693 1.48654604 0.07724988461 -1.073909998 -0.9899170399 -0.7569380999 -2.455502748 -1.836840987 -0.6345955729 -0.5112048984 -1.380798697 0.3201414645 0.5749521255 0.1245499775 -0.6584037542 -0.3076282442 -0.5475282669 -1.27268219 -1.233708143 1.157920361 -1.180791736 0.08818650246 -1.08333075 -0.1766496301 0.6963065863 -1.426909804 -1.258859158 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01397671271 0.009570924565 0.01731643081 0.008202031255 0.01915627718 0.007655384485 0.01205655094 0.004393525887 0.004000630695 0.006350883748 0.01805901714 0.007732374128 0.007986186072 0.01074250136 0.004035764374 0.08015730232 0.006898571271 0.01020157803 0.003711097874 0.01364901103 0.002752939938 0.01095980778 0.1335934699 0.002540752059 0.01536466647 0.006762028206 0.02004988119 0.007441177499 0.006002511829 0.02186148986 0.01145652961 0.01061785966 0.002716985298 0.01599625498 0.01888991147 0.01171768177 0.008307741024 0.02074879594 0.07715238631 0.01884950139 0.005961526185 0.006483882666 0.008184961975 0.001497404883 0.002779845614 0.009250160307 0.01046494953 0.00438608788 0.02403180115 0.03100624494 0.01976250671 0.00903253071 0.01282771863 0.01009164937 0.004886881448 0.005081103183 0.05554296449 0.005357217509 0.01905678213 0.00590562867 0.01462287363 0.03500682861 0.004188432824 0.00495490199 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.90499115 25.90058517 25.89974785 25.89826202 25.90873909 25.8948555 25.90354729 25.89588356 25.89596748 25.89545822 25.91002655 25.89445496 25.89900017 25.90175629 25.89600372 25.9706955 25.89886665 25.90217018 25.89615631 25.90466309 25.89424324 25.90006638 26.02269936 25.89403152 25.90399551 25.89872932 25.91154099 25.89940834 25.89606285 25.91144562 25.90294838 25.90115547  25.894207 25.90701103 25.91085815 25.90177727 25.89836884 25.91271591 25.96912003 25.89555931 25.89793015 25.89320564 25.89967537 25.89441872 25.89474678 25.90074158 25.90100288 25.88777161 25.91552353 25.92297363 25.91077614 25.89575577 25.90336418 25.90205956 25.89542389 25.89704895 25.94751167 25.89446449 25.90816307 25.89453506 25.90659142 25.92649841 25.89329529 25.88690948 

-------
======================
selected experts : 15, 22, 38, 49, 56, 61, 
layer15_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deee4f80>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.211953 0.234548 -0.2150810.176693 -0.00234827 0.111494 -0.40818 0.163585 0.0598682]

layer15_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deee44b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.33721 0.0837894 -0.103631-0.140448 0.454261 0.105741 -0.0203833 0.126562 0.179933]

layer16_wq's input 
<N9nntrainer6TensorE at 0x5682def24710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.31761 0.218152 -0.219981-0.375548 0.953619 0.319948 -0.0516351 0.268658 0.409382]
==============================
layer16_wq's output 
<N9nntrainer6TensorE at 0x5682deee4360>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.618402 -0.131074 -0.5364070.337663 -0.519812 -0.376648 1.02457 0.418604 -0.127396]
============================
layer16_wk's input 
<N9nntrainer6TensorE at 0x5682def26470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.31761 0.218152 -0.219981-0.375548 0.953619 0.319948 -0.0516351 0.268658 0.409382]
==============================
layer16_wk's output 
<N9nntrainer6TensorE at 0x5682def261e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.42494 0.0491374 0.692216-1.36299 1.31172 0.350764 -1.39053 -0.210663 1.22936]
============================
layer16_wv's input 
<N9nntrainer6TensorE at 0x5682def27260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.31761 0.218152 -0.219981-0.375548 0.953619 0.319948 -0.0516351 0.268658 0.409382]
==============================
layer16_wv's output 
<N9nntrainer6TensorE at 0x5682def26ff0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.317676 0.0349983 -0.5024191.1096 -0.649026 -0.662572 0.484461 -0.665229 -0.147114]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.630395 0.0469376 0.2389280.58708 0.066477 0.638474 -0.976677 -0.520649 0.469994]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a20930f8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer16_attention_out's input 
<N9nntrainer6TensorE at 0x5682def29710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer16_attention_out's output 
<N9nntrainer6TensorE at 0x5682def29670>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer16_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def2a790>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.33721 0.0837894 -0.103631-0.140448 0.454261 0.105741 -0.0203833 0.126562 0.179933]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.97402 0.23977 -0.261304-0.41508 1.14541 0.329869 -0.0595238 0.333967 0.453696]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.363337874 -1.736756444 -0.4215849638 1.753603697 -0.6389190555 -1.77861166 -0.2765093744 0.7122148871 -0.5134734511 -0.3759033382 -1.253976345 1.214964628 -0.7106405497 -0.3341830969 0.9082656503 -0.1438941211 -0.8174051046 -0.6503274441 -0.85016644 -0.2432413399 -0.9850304127 -2.22254467 -0.9448741674 0.2155602872 -1.159727931 -0.6424306035 -1.199065208 -0.3694017529 -0.7249289751 -2.222334862 -1.334394097 0.4562349319 -0.2326183468 -1.090725303 -0.700260818 -0.9060382843 -1.269330025 -2.373129845 -1.232488871 -0.5860313177 0.6837432384 -1.275163651 -2.348347187 -0.650632441 -0.553194344 -1.861816406 -0.8980414271 0.5922238827 -0.8130593896 -0.6252757907 -1.020447969 -0.6618753672 -0.5517811775 -0.8442652822 -2.194777489 -0.3334437609 -0.532897532 -0.5412735343 -0.8869378567 -0.002399519086 -0.6179801226 -0.02949033678 -0.2771101594 -1.085317016 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005518888123 0.003799074795 0.01415303815 0.1246011481 0.01138839684 0.003643345786 0.01636270806 0.04397974163 0.01291049644 0.01481456496 0.00615668064 0.07270998508 0.01060020551 0.01544570737 0.05350525305 0.01868311316 0.009526803158 0.01125921216 0.009219747037 0.01691621915 0.008056536317 0.002337236889 0.008386641741 0.02676444873 0.006765163038 0.01134847756 0.006504205056 0.01491119713 0.01044982299 0.002337727463 0.005680958275 0.03404724225 0.0170968771 0.007248459384 0.01071080659 0.008718749508 0.006062875036 0.002010501223 0.00629040366 0.01200691797 0.04274522141 0.006027609576 0.002060950501 0.0112557793 0.0124077322 0.003352471162 0.008788751438 0.03900688142 0.009568292648 0.01154483669 0.007776187733 0.011129939 0.01242527831 0.009274316952 0.00240304484 0.01545712817 0.01266214345 0.01255652681 0.008886882104 0.02152283676 0.01162937097 0.0209475942 0.01635288075 0.00728776725 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
23.53619194 23.52541542 23.54482651 23.65527534 23.53157425 23.53479385 23.54751396 23.56702614 23.53786469 23.54596519 23.53492546 23.60290718 23.54127502 23.54373741 23.57369041 23.54029846 23.53924751 23.53955078 23.53894043 23.54711342 23.53253365 23.53348732 23.53906059 23.55696106 23.53743935 23.53487206 23.53622437 23.54606247 23.54112434 23.53110695 23.53635406 23.56424522 23.54634285 23.53744507 23.54043198 23.53939247 23.53340149  23.533638 23.53744125 23.54172707 23.57294273 23.53336525 23.53225899 23.54145241 23.54117584 23.5325985 23.53946304 23.56920433 23.54024315 23.54079056 23.53463745 23.5422802 23.5397625 23.53184319 23.53355408 23.54708481 23.54333687 23.53846359 23.53860664 23.55171967 23.54230309 23.55066872 23.54750443 23.53891563 

-------
======================
selected experts : 3, 7, 11, 14, 40, 47, 
layer16_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def2d9d0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.06765 0.135349 0.03424350.176277 0.000973045 0.105585 0.174205 0.0174802 -0.465571]

layer16_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def2d090>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.40486 0.219138 -0.06938780.0358294 0.455234 0.211325 0.153822 0.144042 -0.285638]

layer17_wq's input 
<N9nntrainer6TensorE at 0x5682def6d870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8694 0.49753 -0.1226780.0816931 0.752081 0.563501 0.358153 0.244927 -0.532607]
==============================
layer17_wq's output 
<N9nntrainer6TensorE at 0x5682def2cf40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0256799 0.0705974 0.1823790.217593 0.266656 -0.00630807 -0.365624 -0.29495 -0.195453]
============================
layer17_wk's input 
<N9nntrainer6TensorE at 0x5682def6f5d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8694 0.49753 -0.1226780.0816931 0.752081 0.563501 0.358153 0.244927 -0.532607]
==============================
layer17_wk's output 
<N9nntrainer6TensorE at 0x5682def6f340>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.17511 -0.059102 1.942110.653518 0.191876 0.562744 -1.34005 -0.450133 0.671633]
============================
layer17_wv's input 
<N9nntrainer6TensorE at 0x5682def703c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8694 0.49753 -0.1226780.0816931 0.752081 0.563501 0.358153 0.244927 -0.532607]
==============================
layer17_wv's output 
<N9nntrainer6TensorE at 0x5682def70150>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.94471 -1.1771 0.439853-0.419611 0.35281 -0.0350813 -0.527458 -0.84754 -1.3832]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0443831 0.0606101 0.246068-0.141632 -0.182677 -0.194356 0.333726 0.33061 0.0632592]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2298108
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer17_attention_out's input 
<N9nntrainer6TensorE at 0x5682def72870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer17_attention_out's output 
<N9nntrainer6TensorE at 0x5682def727d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer17_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def738f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.40486 0.219138 -0.06938780.0358294 0.455234 0.211325 0.153822 0.144042 -0.285638]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.91587 0.550459 -0.1555270.0906932 1.02477 0.567585 0.389361 0.34095 -0.634713]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.02730626427 -1.069718957 -1.153170466 1.221750617 -2.066622972 -0.6677621007 -0.7245548368 -0.7949968576 -0.4414895177 -1.43932271 -1.94204855 -0.9670998454 0.1795118153 -0.2821341157 -0.05507342517 -0.2822469175 0.2484291792 -1.22727263 -0.05082730949 -1.032768846 -1.087264657 -1.23376894 -1.694174886 0.5322695971 -1.270576835 -0.889942646 -0.7890108824 -1.251397491 1.160098314 -0.435328722 -1.485999465 -0.008478671312 -1.682764173 -2.35131669 -0.5163273811 -0.3666296601 -0.8657974005 -1.863427281 -1.073807955 -0.5735812187 -1.754856706 -0.1780351698 -1.234422684 0.2845253944 -2.078668356 -0.7848764062 0.08920755982 -0.5364621878 -1.624352455 -0.9305257797 -1.41782701 -1.152937055 -0.9347455502 -0.1895541549 1.260882735 0.2797592282 -0.7419340014 -0.0863994956 -0.2757208943 -1.148961782 -1.375760078 0.1735088974 -0.2640367746 -0.1926818788 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0220124498 0.007761654444 0.007140222937 0.07675857842 0.002864207374 0.0116017079 0.0109611759 0.01021561678 0.01454758272 0.005363366567 0.003244190244 0.008600451984 0.02707000449 0.01706074737 0.0214096345 0.01705882326 0.02900138684 0.006630245596 0.02150073647 0.00805381313 0.007626658771 0.006587312091 0.004156775307 0.03852025047 0.006349256262 0.00929030776 0.0102769509 0.006472205743 0.07216915488 0.01463748515 0.005118774716 0.02243081853 0.004204478581 0.002154584508 0.01349861547 0.01567841321 0.009517355822 0.003509547794 0.007729982957 0.01274747588 0.003912035376 0.01893248782 0.006583007518 0.03006735072 0.002829913748 0.01031952724 0.02473259531 0.01322954148 0.004457383417 0.008920826018 0.005479903426 0.007141890004 0.008883263916 0.01871565729 0.07982184738 0.02992438525 0.01077232696 0.02074935101 0.01717051305 0.007170338184 0.005715342704 0.02690799162 0.01737231202 0.01865720935 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
22.12599373 22.11984825 22.12065887 22.18264771 22.11352158 22.11892128 22.12447929 22.12373352 22.12758827 22.11888123 22.11485481 22.12164116 22.13248062 22.12962532 22.13445091 22.13105392  22.142519 22.12062454 22.12119102 22.12109566 22.11733055 22.11533737 22.11528969 22.14917755 22.11939049 22.11851692 22.12427139 22.1199894 22.17710304 22.12672424 22.11816025 22.13547134 22.11676788 22.11567307 22.12701607 22.1206131 22.12255859 22.11655045 22.11791039 22.12578773 22.11742973 22.12482071 22.12010002 22.13977051 22.10824203 22.12431335 22.13491249 22.12674713 22.11320686 22.12243843 22.11899757 22.12018204 22.1033268 22.12412643 22.18761826 22.14010429 22.1247673 22.13045311 22.12878036 22.11591911 22.11875534 22.1399498 22.13136673 22.12979126 

-------
======================
selected experts : 3, 23, 28, 43, 54, 55, 
layer17_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def76b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.253826 -0.0186747 0.03773680.0680806 -0.473988 0.129516 -0.478414 0.0785916 -0.034919]

layer17_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def761f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.65869 0.200463 -0.03165090.10391 -0.0187538 0.340841 -0.324593 0.222634 -0.320557]

layer18_wq's input 
<N9nntrainer6TensorE at 0x5682defb6420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.10791 0.463276 -0.06257080.239174 -0.0339414 0.879432 -0.750142 0.394667 -0.64561]
==============================
layer18_wq's output 
<N9nntrainer6TensorE at 0x5682def760a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.10673 -0.153221 0.5897311.9506 1.29427 -2.68213 1.67582 1.40147 -1.31853]
============================
layer18_wk's input 
<N9nntrainer6TensorE at 0x5682defb8180>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.10791 0.463276 -0.06257080.239174 -0.0339414 0.879432 -0.750142 0.394667 -0.64561]
==============================
layer18_wk's output 
<N9nntrainer6TensorE at 0x5682defb7ef0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.28275 1.297 -0.2089410.677472 1.33644 0.660171 -0.293485 1.65407 -1.16858]
============================
layer18_wv's input 
<N9nntrainer6TensorE at 0x5682defb8f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.10791 0.463276 -0.06257080.239174 -0.0339414 0.879432 -0.750142 0.394667 -0.64561]
==============================
layer18_wv's output 
<N9nntrainer6TensorE at 0x5682defb8d00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.591238 0.102822 -0.5731520.478514 0.657506 -1.73205 0.866751 -0.900636 0.185941]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.98001 -0.73577 2.02356-0.240473 -2.86112 0.826408 -1.52457 -1.56466 0.154365]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a249d118
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer18_attention_out's input 
<N9nntrainer6TensorE at 0x5682defbb420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer18_attention_out's output 
<N9nntrainer6TensorE at 0x5682defbb380>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer18_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682defbc4a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.65869 0.200463 -0.03165090.10391 -0.0187538 0.340841 -0.324593 0.222634 -0.320557]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.45462 0.491184 -0.07108980.258463 -0.0421222 0.885759 -0.807382 0.516579 -0.711064]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.062613368 -0.3103205264 -0.813877821 -0.05949025229 -1.83977294 -2.380988598 -1.19530642 0.3794342577 0.3779788911 -2.770207644 0.5257703662 -2.53913641 -0.9748841524 -1.182571411 -2.624329329 -1.193560004 0.9496892095 0.1868463457 -0.9716626406 -0.2941969931 -0.9582231045 0.3939257562 -1.022436738 -0.07888153195 -1.747231841 -0.07336111367 -0.8625987768 0.2567335069 -2.161632538 0.2967662215 -0.8609887362 1.667371035 0.07463056594 -0.2470603138 -0.6184720993 -0.4640968144 -1.307123542 -0.8273018599 -1.310783267 -0.7721133828 0.4477494657 -1.912881017 -0.8133640289 1.033631086 -0.767663002 0.2045336962 -0.9569313526 -1.185732603 1.950773239 -0.01261408255 -1.979505777 -1.264241338 0.571731925 -0.2704636157 -0.9788761139 0.2174901217 -0.8327384591 -1.441499591 -1.883395791 -1.240181923 0.1753808558 -0.3174679875 -0.3530494571 0.9615533352 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005993448198 0.01271725539 0.00768601615 0.01634284481 0.002755248221 0.001603665296 0.005248666741 0.02534837648 0.02531151287 0.00108662108 0.02934290655 0.001369086909 0.006543003954 0.005315935705 0.001257280237 0.005257840268 0.04483412579 0.02090789378 0.006564116571 0.01292396523 0.006652929354 0.02571838722 0.006239148788 0.01602898911 0.003022391582 0.01611771993 0.007320521399 0.02242135629 0.001997003565 0.02333715372 0.007332318462 0.09189544618 0.01868855022 0.0135477446 0.009344690479 0.01090458781 0.004693397786 0.00758352736 0.004676252604 0.00801381655 0.02714057639 0.002561004367 0.007689965889 0.0487600565 0.008049559779 0.02128098905 0.006661529187 0.005299157463 0.12200398 0.01712717302 0.002395937452 0.004899039865 0.03072302416 0.01323436294 0.006516935769 0.02155850641 0.007542411797 0.004103255458 0.002637640573 0.005018336698 0.02066954225 0.0126266852 0.01218530722 0.04536921531 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
24.21902084 24.21716309 24.21976089 24.22603226 24.21578407 24.21510887 24.21827698 24.23885345 24.2373867 24.21459198 24.23855591 24.21392059 24.21766281 24.21691322 24.21476173 24.21828651 24.2502327 24.2325058 24.21863747 24.22547531 24.2134819 24.23207092 24.21926689 24.22858047 24.21557426 24.22771454 24.21939468 24.22829628 24.19928932 24.23636436 24.21892929 24.30540085 24.23028564 24.21846962 24.22237206 24.22345543 24.21819878 24.20630646 24.2167511 24.22008896 24.23969078 24.21558952 24.21976471 24.26131058 24.2215538 24.23001671 24.2168293 24.21689606 24.33503151 24.22920227 24.21542358 24.21840477 24.23469162 24.22626305 24.2200222 24.23124886 24.22056961 24.21713066 24.21566582 24.21804619 24.23083687 24.22470093 24.22473717 24.25839806 

-------
======================
selected experts : 16, 31, 43, 48, 52, 63, 
layer18_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682defbf6e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.560586 0.0277587 -0.1215660.0890109 -0.0883643 -0.106343 -0.0221612 0.0365498 -0.135021]

layer18_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682defbeda0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.21927 0.228222 -0.1532170.192921 -0.107118 0.234498 -0.346754 0.259184 -0.455578]

layer19_wq's input 
<N9nntrainer6TensorE at 0x5682deffefd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.33037 0.452046 -0.2608050.377646 -0.173219 0.522538 -0.68146 0.419121 -0.835404]
==============================
layer19_wq's output 
<N9nntrainer6TensorE at 0x5682defbec50>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0782116 -0.28653 -0.0172082-0.619468 -0.0762679 -0.593608 0.282658 -0.80718 -0.135468]
============================
layer19_wk's input 
<N9nntrainer6TensorE at 0x5682df001130>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.33037 0.452046 -0.2608050.377646 -0.173219 0.522538 -0.68146 0.419121 -0.835404]
==============================
layer19_wk's output 
<N9nntrainer6TensorE at 0x5682df001100>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.05797 -0.676246 0.9896371.00173 0.42944 -0.338087 0.795811 1.07648 -0.594723]
============================
layer19_wv's input 
<N9nntrainer6TensorE at 0x5682df002000>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.33037 0.452046 -0.2608050.377646 -0.173219 0.522538 -0.68146 0.419121 -0.835404]
==============================
layer19_wv's output 
<N9nntrainer6TensorE at 0x5682df001d90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.917758 -0.238449 -0.2498290.0371437 1.04362 0.315361 0.489691 0.719257 0.336181]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.155157 -0.253264 -0.612974-0.0911018 -0.391127 0.452998 -0.363296 0.774242 0.359188]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a28a7138
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer19_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0044b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer19_attention_out's output 
<N9nntrainer6TensorE at 0x5682df004410>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer19_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df005580>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.21927 0.228222 -0.1532170.192921 -0.107118 0.234498 -0.346754 0.259184 -0.455578]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.9355 0.480299 -0.3034820.411978 -0.209686 0.522538 -0.756582 0.517384 -0.891803]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2560965121 0.5607023835 1.380713105 -1.156835437 -1.137527227 -0.9903067946 -1.374790668 -1.243409276 -1.533348918 -1.82641983 -0.8730707169 0.501588583 -1.044003844 -0.9129401445 -1.779503822 -2.349038363 -1.573071957 0.2331105024 -1.77170682 -1.189740181 -0.1851579547 -0.1333834082 0.828663528 -0.5412015915 -0.8152538538 -1.159140587 -1.81690979 -0.7082381845 0.1524386406 -0.7536927462 -0.3860671818 -0.6523693204 -0.5111266375 -1.121736884 -0.5304392576 -0.4721988142 0.4311973155 -0.5876043439 1.234532952 -0.3707628846 -1.116874456 -0.5162636638 -1.205090284 -0.6366769671 -1.703146935 -0.2628949583 -1.272262096 -0.930413425 -0.8881460428 -0.6206386685 -0.490003556 -0.1590138078 -0.4007500708 -0.7877420187 -1.791340947 -0.6367516518 -0.6509783864 -1.25172472 -0.5542578101 -0.6510242224 0.4458911121 1.347165823 -1.530253649 -2.132788897 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01686263829 0.03816425428 0.08665286005 0.006850772537 0.006984333508 0.008092115633 0.005509127863 0.006282622926 0.004701341968 0.003507056739 0.00909865275 0.03597360477 0.007669052109 0.008743029088 0.003675514599 0.00207956438 0.0045182514 0.02750333957 0.003704283852 0.006629019044 0.01810229942 0.01906422339 0.04989198968 0.01267961133 0.009640211239 0.006834999658 0.003540568054 0.01072908845 0.02537173033 0.01025232114 0.01480743941 0.01134557184 0.01306674257 0.007095494773 0.01281681098 0.0135854315 0.03352844343 0.01210468449 0.07486824691 0.01503579877 0.007130078971 0.01299979072 0.006528038532 0.01152501628 0.003967158496 0.01674838737 0.006103943102 0.008591587655 0.00896251481 0.01171134692 0.01334568765 0.01858180761 0.01459161192 0.009909112938 0.00363226328 0.01152415574 0.01136136334 0.00623059785 0.01251513977 0.0113608446 0.03402474523 0.08379410952 0.004715915769 0.002581596142 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.26359749 26.27917671 26.32623482 26.25310898 26.25419617 26.24576759 26.25081253 26.25301743 26.25143623 26.25024223 26.25011063 26.28175545 26.25297356 26.25547791 26.25041008 26.24929047 26.25125313 26.27137756 26.24996185 26.25288773 26.2653141 26.26532173 26.29138184 26.25798416 26.2568512 26.25357056 26.25027466 26.25698662 26.27162933 26.25460243 26.2620182 26.25855637 26.2602787 26.25430679 26.25764465 26.25936699 26.27835655 26.25645447 26.32160378 26.25366402 26.25386429 26.25973511 26.25326347 26.2553978 26.24450302 26.26348305 26.25283813 26.25532532 26.25474358 26.25415421 26.2596035 26.26436234  26.260849 26.2528286 26.23701477 26.25873566 26.25761986 26.25344276 26.25972748 26.25332642 26.28123665 26.32814407 26.25144958 26.24836159 

-------
======================
selected experts : 1, 2, 11, 22, 38, 61, 
layer19_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df008b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.302106 0.0097258 -0.285841-0.0748007 -0.230624 -0.0890906 -0.0904621 -0.372348 0.37356]

layer19_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df008060>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.52138 0.237948 -0.4390580.11812 -0.337743 0.145408 -0.437216 -0.113164 -0.082018]

layer20_wq's input 
<N9nntrainer6TensorE at 0x5682df047b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60653 0.37066 -0.6731660.17748 -0.470188 0.233641 -0.678386 -0.149907 -0.118205]
==============================
layer20_wq's output 
<N9nntrainer6TensorE at 0x5682df007f10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.07461 -0.517926 -0.684738-0.743797 1.84935 0.4878 1.43956 -0.376304 1.23786]
============================
layer20_wk's input 
<N9nntrainer6TensorE at 0x5682df0498e0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60653 0.37066 -0.6731660.17748 -0.470188 0.233641 -0.678386 -0.149907 -0.118205]
==============================
layer20_wk's output 
<N9nntrainer6TensorE at 0x5682df049650>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.186323 -1.42675 1.10225-1.13125 -0.496273 0.775429 0.251476 0.979608 0.500795]
============================
layer20_wv's input 
<N9nntrainer6TensorE at 0x5682df04a6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60653 0.37066 -0.6731660.17748 -0.470188 0.233641 -0.678386 -0.149907 -0.118205]
==============================
layer20_wv's output 
<N9nntrainer6TensorE at 0x5682df04a460>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.877532 -0.0883245 0.607350.314175 0.0202026 0.753049 -1.47165 -0.321368 0.507924]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.17653 -0.197035 -0.8518260.544511 -0.871111 -1.70271 -1.47037 0.227924 -0.396864]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2cb1158
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer20_attention_out's input 
<N9nntrainer6TensorE at 0x5682df04cb80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer20_attention_out's output 
<N9nntrainer6TensorE at 0x5682df04cae0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer20_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df04dc00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.52138 0.237948 -0.4390580.11812 -0.337743 0.145408 -0.437216 -0.113164 -0.082018]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.95207 0.41152 -0.7270190.205732 -0.546827 0.263961 -0.782959 -0.187384 -0.133798]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4138334095 -0.7941479683 -0.9165152907 -2.569709539 -1.421836019 -0.1668744236 -0.9031383395 -2.294758081 -1.237062454 -0.1760980487 -0.3693721592 -0.1580355465 -1.632927299 0.4013758898 -1.187618256 -0.1161043495 -0.6882314682 -0.03248381615 -0.8780407906 -0.3582237363 0.6017161012 -2.62579751 -0.9137005806 -0.3008619547 -1.031279802 -0.5180200934 -0.8078605533 0.3422093987 -1.578213811 -0.4726060033 -0.7385864258 -0.6835306287 -0.1002677679 -1.033990622 0.3952358961 -1.323274851 0.8766098619 1.240920305 -0.342014432 -0.6332079172 -1.222097993 -0.6673287749 -1.852769852 -1.920262098 -0.04423336685 -0.7442017794 -1.4834162 0.1318867505 1.003386855 0.03271181881 -0.3037775457 -2.032606363 -1.716417551 0.04686329514 -0.2210749388 -1.228260994 -0.8499057293 -0.2385745198 -0.2812626958 -0.5164778829 -0.6176597476 -0.6172142625 -0.09065865725 -1.061925769 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01473560743 0.01007394399 0.008913659491 0.00170640822 0.005377717782 0.01886344329 0.009033697657 0.002246429678 0.006469104905 0.01869025268 0.01540555339 0.01903091371 0.004354340024 0.03329729289 0.006797004491 0.01984586939 0.01119949669 0.02157675289 0.009263291024 0.01557826251 0.04068324715 0.001613333821 0.008938784711 0.01649798453 0.007947205566 0.01327762194 0.00993674621 0.03138435632 0.004599218257 0.01389451697 0.0106495088 0.01125226822 0.02016266063 0.007925692014 0.03309347481 0.005934752524 0.053555049 0.07709362358 0.01583283208   0.011833 0.006566638593 0.01143605821 0.00349498936 0.003266888903 0.02132471837 0.01058987528 0.005056547001 0.02543145977 0.06079375744 0.0230303295 0.01644995436 0.002919737948 0.004005557392 0.0233585611 0.01786824688 0.006526293699 0.009527615272 0.01755828224 0.01682452485 0.01329811662 0.0120184198 0.01202377584 0.02035734057 0.007707351353 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.40888786 25.40517998 25.40592575 25.39919662 25.40143585 25.41635323 25.40127754 25.39925957 25.40348244 25.40950394 25.41194153 25.41318321 25.40136719 25.42983246 25.4038105 25.41542816 25.40249062 25.41286659 25.40436935 25.41163635 25.43769646 25.39862633 25.40070534 25.41208076 25.40162277 25.41028976 25.40218163 25.42791939 25.39588928 25.41090775 25.40766144  25.408741 25.41622162 25.40398407 25.43010712 25.40247154 25.45056725 25.46504593 25.40855408 25.40693855 25.40357971 25.40701866 25.39859962 25.40075684 25.41690636 25.40807915 25.40206909 25.42244339 25.4573288 25.41956711 25.41107941 25.39993286 25.38671303 25.42037201 25.41392708 25.40258598 25.40701675 25.4112339 25.41145325 25.40697289 25.4076004 25.40760612 25.41260147 25.39995193 

-------
======================
selected experts : 13, 20, 34, 36, 37, 48, 
layer20_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df050e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.27992 -0.123736 0.109519-0.0913493 0.248634 0.13094 0.216233 -0.0920996 0.00966147]

layer20_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df050500>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.24146 0.114212 -0.3295390.026771 -0.0891088 0.276347 -0.220983 -0.205264 -0.0723565]

layer21_wq's input 
<N9nntrainer6TensorE at 0x5682df091030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.96238 0.168701 -0.4394620.0374619 -0.117234 0.439588 -0.314518 -0.266368 -0.100819]
==============================
layer21_wq's output 
<N9nntrainer6TensorE at 0x5682df0503b0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.15064 0.0532157 -0.042246-0.203928 0.30255 -0.100603 -0.534653 -0.137248 0.0665243]
============================
layer21_wk's input 
<N9nntrainer6TensorE at 0x5682df092d90>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.96238 0.168701 -0.4394620.0374619 -0.117234 0.439588 -0.314518 -0.266368 -0.100819]
==============================
layer21_wk's output 
<N9nntrainer6TensorE at 0x5682df092b00>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0929967 -0.866341 0.09207010.728006 0.901695 1.11479 1.49877 -0.121993 -0.628814]
============================
layer21_wv's input 
<N9nntrainer6TensorE at 0x5682df093b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.96238 0.168701 -0.4394620.0374619 -0.117234 0.439588 -0.314518 -0.266368 -0.100819]
==============================
layer21_wv's output 
<N9nntrainer6TensorE at 0x5682df093910>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.24552 -1.54342 0.110974-0.205941 -1.38733 0.791705 -0.401286 -0.701056 -0.336938]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.12977 0.0931872 -0.2081710.00602979 -0.276852 -0.158147 0.517919 0.190919 -0.316258]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1f908f0
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer21_attention_out's input 
<N9nntrainer6TensorE at 0x5682df096030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer21_attention_out's output 
<N9nntrainer6TensorE at 0x5682df095f90>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer21_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0970b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.24146 0.114212 -0.3295390.026771 -0.0891088 0.276347 -0.220983 -0.205264 -0.0723565]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.79932 0.206266 -0.5754390.0486684 -0.15347 0.528828 -0.417595 -0.360885 -0.124618]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1783123165 -0.29889974 -0.5538125634 0.3373761773 -0.472266376 -0.7141254544 -1.454328179 0.2542715371 -0.7339566946 -1.226141095 -1.311332822 -0.9130453467 -0.2845664322 0.2438750714 -0.8389728665 -1.112065434 -0.823212266 -0.7511786819 -0.5577736497 -0.945778966 -2.06117177 -0.1704679281 -0.1381780356 -1.486085892 -0.07875689864 -0.2048711777 0.07434412837 -0.4823636711 -0.7482740283 -2.119517803 -0.8294374347 -1.46167469 -1.50707984 -0.399132967 -0.5167472959 -1.082633853 -0.6440500021 0.2263461798 -1.25105834 2.997587919 -0.533398509 -0.1614771187 -0.9952273965 -1.202630043 -0.3438590467 -1.079587579 -0.7780657411 -1.948967695 -0.2780954838 -0.7075446844 -0.2848754823 -1.309324741 -0.4318304956 -1.394148946 -0.9812729359 1.677747846 -0.4324631393 -0.1824264973 -0.516405642 0.2792288959 -0.6079953313 0.2241086811 -0.6234211326 -0.5771641731 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01918534376 0.01190471742 0.009225965478 0.02249314077 0.01000983268 0.007859389298 0.003749063471 0.02069942281 0.007705063559 0.004710024688 0.004325386137 0.006441676989 0.0120765781 0.02048533782 0.006936945021 0.005279169418 0.007047140971 0.007573502138 0.009189493023 0.006234230939 0.00204349705 0.01353618503 0.01398039889 0.003631872125 0.01483630948 0.01307841484 0.01729086787 0.0099092694 0.007595532574 0.001927679172 0.00700340746 0.003721621353 0.003556420328 0.01076931972 0.009574345313 0.005436854437 0.008429896086 0.02012938447 0.004594114609 0.3216365874 0.009416241199 0.01365843415 0.005933457054 0.004822073504 0.01138134208 0.005453440361 0.007372586988 0.002286144067 0.01215497777 0.00791128166 0.01207284816 0.004334082361 0.01042288635 0.003981606103 0.006016835105 0.0859342292 0.01041629259 0.01337527577 0.009577617049 0.02122252807 0.008739378303 0.02008439414 0.008605599403 0.009013019502 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.65747643 25.65019608 25.64703941 25.66030693 25.64639282 25.64567375 25.64204025 25.65660477 25.64551926 25.64204597 25.63164902 25.63567162 25.64655304 25.65639114 25.64522743 25.64309311 25.64533806 25.64586449 25.64461899 25.64452553 25.63985634 25.65182686 25.65179443 25.64049149 25.65312576 25.65041542 25.65510368 25.64676857 25.64588547 25.64021873 25.64529419 25.64058113 25.64089394 25.64858246 25.64643478 25.64277267 25.64672089 25.65794373 25.64050102 25.95897293 25.64770699 25.65194893 25.64279366 25.64263535 25.64538002 25.64326668 25.64566231 25.64010048 25.64520073 25.64334106 25.65036392 25.6388092 25.64060783 25.64227295 25.64430809 25.72231674 25.64346123 25.6511879 25.63976097 25.65903664 25.64559937 25.65789795 25.64498901 25.64634895 

-------
======================
selected experts : 3, 7, 13, 39, 55, 59, 
layer21_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df09a2f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.643184 0.222712 -0.7929290.183264 0.747842 0.786664 0.0493223 0.199264 -0.0933151]

layer21_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df0999b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.88464 0.336924 -1.122470.210035 0.658733 1.06301 -0.171661 -0.00599937 -0.165672]

layer22_wq's input 
<N9nntrainer6TensorE at 0x5682df0d9be0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.15133 0.400246 -1.261070.249509 0.755238 1.36069 -0.190486 -0.00662968 -0.19986]
==============================
layer22_wq's output 
<N9nntrainer6TensorE at 0x5682df099860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.546149 1.16361 0.626299-1.24008 -0.672939 1.76016 -0.502856 -0.075978 -2.78427]
============================
layer22_wk's input 
<N9nntrainer6TensorE at 0x5682df0db940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.15133 0.400246 -1.261070.249509 0.755238 1.36069 -0.190486 -0.00662968 -0.19986]
==============================
layer22_wk's output 
<N9nntrainer6TensorE at 0x5682df0db6b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.747404 2.64771 1.071541.4648 -1.04922 -0.578845 1.52732 -0.831963 -0.0360067]
============================
layer22_wv's input 
<N9nntrainer6TensorE at 0x5682df0dc730>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.15133 0.400246 -1.261070.249509 0.755238 1.36069 -0.190486 -0.00662968 -0.19986]
==============================
layer22_wv's output 
<N9nntrainer6TensorE at 0x5682df0dc4c0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.654865 0.853878 0.4372470.199922 -0.88083 0.138692 0.835335 -0.370026 0.868068]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.849527 0.964661 -1.11183-0.832991 1.75987 -0.673718 0.49252 0.126733 3.19489]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a30bb178
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer22_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0debe0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer22_attention_out's output 
<N9nntrainer6TensorE at 0x5682df0deb40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer22_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0dfc60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.88464 0.336924 -1.122470.210035 0.658733 1.06301 -0.171661 -0.00599937 -0.165672]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.43586 0.511943 -1.66420.315271 0.952389 1.69352 -0.265574 -0.00895006 -0.239526]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7397916913 -0.4645708799 -1.015678048 -0.1586270481 2.572156906 -1.184009671 0.1542642117 -0.7809244394 1.002029419 -0.7511141896 -0.4391508102 -0.6108403206 -0.4246154726 -1.049105287 -0.07224667072 -0.260074079 -1.30487287 0.001101973467 -1.751760244 -0.5972699523 0.02286567539 2.529406548 -1.568264842 0.06576365978 -2.270291805 -1.031431913 -0.950517118 -0.2471860498 -0.7377126217 -1.35686934 -1.336291909 -1.579776406 -0.5386202931 -0.6078422666 -0.1715735197 -2.634065151 -0.8631902933 0.9276689887 1.088684678 -0.5127094984 0.7183439732 -0.5988658071 0.1742632091 -0.2389595211 -0.3931342363 -0.6965096593 -1.324651122 -0.9061495662 -1.457275152 -0.810759604 -0.3742614985 -1.45335412 -0.3097060919 -0.9273035526 -1.475761294 -0.845074892 -1.814042211 -0.7738408446 -0.5757521391 0.7166854739 -0.4288810194 -0.4447434545 0.2580054104 -1.245664835 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006957845762 0.009162238799 0.005280303769 0.01244146097 0.1909131259 0.004462245386 0.01701211557 0.006677457131 0.03971349075 0.006879509892 0.009398129769 0.007915486582 0.00953573361 0.00510671502 0.01356394216 0.01124121994 0.003954240587 0.01459623408 0.002529195044 0.008023634553 0.01491738483 0.1829235107 0.003038599156 0.01557123382 0.001505868393 0.005197769962 0.005635829642 0.01138703711 0.006972326431 0.003753888886 0.003831934649 0.003003821475 0.008508292958 0.007939253934 0.01228142437 0.001046651974 0.006150119007 0.0368675068 0.04330838472 0.008731628768 0.0299043972 0.008010840975 0.01735576615 0.01148109697 0.009840706363 0.007265607361 0.003876801115 0.005891507491 0.003395279869 0.006481176242 0.01002819091 0.003408620367 0.01069691405 0.00576818781 0.00333309127 0.006262545008 0.0023764777 0.006724923849 0.008198156022 0.02985484339 0.00949514471 0.009345716797 0.01887176558 0.004195433576 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.01233864 27.01454353 27.00875282 27.01639175 27.19676971 27.00459862 27.02096176 27.01062775 27.04557037 27.0117836 27.01525497 27.01329613 27.01491547 27.01000977 27.01608276 27.01709938 27.00933456 27.02045441 27.00838661 27.00720596 27.01886749 27.1883049 27.00889587 27.01523018 27.00736427 27.01057816 27.01149368 27.01533699 27.01187706 27.00961113 27.00921249 27.00695419 27.01102829 27.01379585 27.00764847 27.00404358 27.00676155 27.03652573 27.04296684 27.01220512 27.03528595 27.01196098 27.0227356 27.01686096 27.01569748 27.01121521 27.00973511 27.01031876 27.00925255 27.01233864 27.01588631 27.00735855 27.01083183 27.01162529 27.00871277 27.01116562 27.00823402 27.00876808 27.01405525 27.03523636 27.01296806 27.01520348 27.02425194 27.01005363 

-------
======================
selected experts : 4, 8, 21, 37, 38, 40, 
layer22_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df0e2e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.488194 0.377901 0.466394-0.0167934 -0.273322 0.297149 -0.392417 -0.31235 -0.740184]

layer22_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dde69cd0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.39645 0.714826 -0.6560750.193241 0.385411 1.36016 -0.564077 -0.318349 -0.905855]

layer23_wq's input 
<N9nntrainer6TensorE at 0x5682de368560>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88793 0.625983 -0.5816860.159394 0.345913 1.2603 -0.483722 -0.260274 -0.776812]
==============================
layer23_wq's output 
<N9nntrainer6TensorE at 0x5682de2bfbc0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.81287 2.46712 -3.204050.161744 -0.160598 2.96982 -1.30325 1.66376 -2.68029]
============================
layer23_wk's input 
<N9nntrainer6TensorE at 0x5682de266760>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88793 0.625983 -0.5816860.159394 0.345913 1.2603 -0.483722 -0.260274 -0.776812]
==============================
layer23_wk's output 
<N9nntrainer6TensorE at 0x5682de82d610>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.31819 1.55241 -2.13453-1.49608 -1.32869 1.37024 -0.700615 -1.14271 -0.10444]
============================
layer23_wv's input 
<N9nntrainer6TensorE at 0x5682de40ebf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88793 0.625983 -0.5816860.159394 0.345913 1.2603 -0.483722 -0.260274 -0.776812]
==============================
layer23_wv's output 
<N9nntrainer6TensorE at 0x5682de7736d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0659388 0.12311 0.4507320.32833 -1.39694 -0.600461 -0.907153 -1.79537 1.35136]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.43001 1.86231 -0.3995783.18314 2.31868 -1.86262 1.46572 -1.52257 3.26035]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a32c0188
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer23_attention_out's input 
<N9nntrainer6TensorE at 0x5682ddf81aa0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer23_attention_out's output 
<N9nntrainer6TensorE at 0x5682de55e330>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer23_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0fe910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.39645 0.714826 -0.6560750.193241 0.385411 1.36016 -0.564077 -0.318349 -0.905855]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.82589 0.919493 -0.8343850.245761 0.487359 1.82868 -0.750179 -0.404871 -1.13889]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.872992158 0.2064440399 -1.035467386 -0.640977025 -0.1961841881 -0.1090170741 -0.34689942 -1.025684476 -0.8059713244 -1.519582868 -1.232269287 -0.7925223112 -0.03936348855 0.9528845549 -0.4500332177 1.322859287 0.7175119519 0.7044981122 1.78325367 -0.5533096194 -0.7680734396 -0.7863910198 -1.033133268 -0.03407310322 -1.032354474 -0.9097954631 -0.4200244546 -0.2161732614 -0.6270029545 -0.3525469303 -0.06292621791 0.7336152792 -0.673283577 0.5641796589 -0.1569390148 -0.8231748343 -0.2828865051 -0.728974402 -0.8087525368 -0.003392666578 -2.537916422 -1.832093239 0.2140242308 -2.572942972 -0.5260803699 -0.7155008912 -1.603597641 -0.6312178969 0.1997449249 -0.2652683854 -2.51944685 -1.796715975 2.482131004 -0.3266799748 -0.3935008347 -1.422336698 -0.2271452546 -0.5259958506 -0.9059403539 0.8565720916 -0.8876277208 -1.621199846 -0.04766143113 -1.352401018 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.002359084319 0.01887257025 0.005450995173 0.008087249473 0.01261745673 0.01376664173 0.01085218042 0.00550458394 0.006857165601 0.003359132679 0.004477193113 0.00695001008 0.01475972496 0.03981127217 0.00978873577 0.05763470009 0.03146190196 0.03105511516 0.0913336426 0.008828241378 0.007122023962 0.006992754061 0.005463732872 0.01483801473 0.005467990413 0.006180937402 0.01008693594 0.01236775145 0.008201053366 0.01079106703 0.01441600733 0.03197265044 0.007830152288 0.02698942646 0.01312247664 0.006740206853 0.01156957727 0.00740600517 0.006838120986 0.01530030556 0.001213306561 0.002457568189 0.01901617274 0.001171544311 0.009071931243 0.007506465539 0.003088445636 0.008166558109 0.01874656416 0.01177521888 0.00123592373 0.002546067117 0.1837169975 0.01107383985 0.01035805792 0.003702206304 0.0122327935 0.009072699584 0.006204812787 0.03615581244 0.006319486536 0.003034558613 0.01463775244 0.003970390651 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.91904831 26.93460846 26.92214012 26.92429924 26.92739868 26.92997932 26.92611122 26.92171669  26.923069 26.92004776 26.92116547 26.92030144 26.93097115 26.95459366 26.9260006 26.97241592 26.94099808 26.94726753 27.00563812 26.92170334 26.92333412 26.92320442 26.92215347 26.93152618 26.92215729 26.92144012 26.92439079 26.92905617 26.92489052 26.92652702 26.93015099 26.94627762 26.92118073 26.94034004 26.92838097 26.92247581 26.9282589 26.92314148 26.92304993 26.92817497 26.91504097 26.91866875 26.93570518 26.91690636 26.92480659 26.92371941 26.91643906 26.92008781 26.93495941 26.9260807 26.91792488 26.91875839 27.10040665 26.92633247 26.92323303 26.91848373 26.92749214 26.91908646 26.92241669 26.95189095 26.92300797 26.91733932 26.93132591 26.91922951 

-------
======================
selected experts : 13, 15, 18, 31, 52, 59, 
layer23_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee1eb60>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.506976 0.458975 -0.696784-1.91816 -0.823732 0.977666 0.0765063 1.047 0.0117463]

layer23_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de7806d0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.90343 1.1738 -1.35286-1.72492 -0.43832 2.33783 -0.487571 0.728649 -0.894109]

layer24_wq's input 
<N9nntrainer6TensorE at 0x5682de5e9620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.51394 0.90817 -1.07843-1.27391 -0.357113 1.82248 -0.362945 0.518912 -0.686532]
==============================
layer24_wq's output 
<N9nntrainer6TensorE at 0x5682de23a580>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.47825 -0.488654 0.184464-0.519587 0.487288 -0.0527524 -0.216239 0.226775 -0.161041]
============================
layer24_wk's input 
<N9nntrainer6TensorE at 0x5682de680bc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.51394 0.90817 -1.07843-1.27391 -0.357113 1.82248 -0.362945 0.518912 -0.686532]
==============================
layer24_wk's output 
<N9nntrainer6TensorE at 0x5682de1e9fa0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00326021 1.4771 1.20550.866987 -0.189965 0.885759 -0.672452 0.556131 0.303197]
============================
layer24_wv's input 
<N9nntrainer6TensorE at 0x5682de7cdb70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.51394 0.90817 -1.07843-1.27391 -0.357113 1.82248 -0.362945 0.518912 -0.686532]
==============================
layer24_wv's output 
<N9nntrainer6TensorE at 0x5682de067420>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.291303 3.60319 -1.58111-0.0753707 2.08941 -3.37433 2.6696 -1.44074 0.555183]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.322664 -0.602821 -0.479449-0.272262 -0.364524 -0.327651 0.238185 -0.203604 -0.0955155]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a36ca1a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer24_attention_out's input 
<N9nntrainer6TensorE at 0x5682de40b530>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer24_attention_out's output 
<N9nntrainer6TensorE at 0x5682de646540>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer24_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de7c4940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.90343 1.1738 -1.35286-1.72492 -0.43832 2.33783 -0.487571 0.728649 -0.894109]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.0039 1.3829 -1.57006-2.02208 -0.503555 2.8639 -0.597287 0.854176 -1.03242]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.369717717 0.4141850471 -0.1664281189 0.3237210214 -0.750937283 -0.8741667867 -0.1055953726 -1.083861828 -0.4515500367 -0.7865809202 -1.144575119 -0.08553080261 -0.3235462606 -0.9011095762 -0.8509297967 0.184768945 -0.1499087811 -0.6074998379 -0.9416130185 -0.3370392323 -0.6768990755 -0.3038922846 -0.9472158551 -0.4724726975 -0.1225259677 0.7403610349 -0.8168305159 -1.12814188 -0.7372927666 -0.6504989862 -0.9537336826 -0.6664224863 -0.2640016377 0.5276591778 -0.6773705482 -0.5016269684 -0.7963917255 0.2570232451 -0.4677351713 -0.005658693612 -0.9181857705 0.3472033143 -0.233420372 -1.923967242 -0.7331756353 0.5005047917 -1.65133512 -0.4732036889 -0.7726078033 -0.7602410913 -0.958774209 0.01471002214 -1.592873096 -0.923161149 0.342824012 -0.5423586369 -0.1020421833 -0.0777990818 -0.727165103 -1.42258203 -0.2568499744 -1.058764815 -0.324097693 0.5694395304 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.08025097102 0.03086510301 0.01727072708 0.02819549479 0.00962634664 0.008510274813 0.018353967 0.006900400389 0.01298624929 0.00928927213 0.006493918132 0.01872595213 0.01475961693 0.008284046315 0.008710343391 0.0245376844 0.01755839773 0.01111106295 0.007955217734 0.01456180308 0.01036611199 0.01505257189 0.007910770364 0.01271736529 0.01804584078 0.04276851192 0.00901248306 0.006601516157 0.009758595377 0.01064342353 0.007859376259 0.01047528442 0.01566516608 0.03457394242 0.01036122721 0.01235195249 0.009198580869 0.02637626044 0.0127777569 0.02028298564 0.008143787272 0.02886542305 0.01615162566 0.002978660865 0.009798854589 0.0336477384 0.003912223969 0.01270807255 0.009419984184 0.009537200443 0.007819862105 0.02070036158 0.004147758707 0.008103369735 0.02873928659 0.01185894478 0.01841929741 0.0188712962 0.00985792838 0.004917789251 0.0157775972 0.007075770292 0.01475147903 0.0360490568 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.91096115 28.8606205 28.8479805 28.85270691 28.83985901 28.83778954 28.84954071 28.83808708 28.84369659 28.83999825 28.83434296 28.84991264 28.84594536 28.83517838 28.83846855 28.85572433 28.84779167 28.83752823 28.83532715 28.8457489 28.84155273 28.84051704 28.83576202 28.8439045 28.84923172 28.87395477 28.83829117 28.83778763 28.84094429 28.84135246 28.83904648 28.84070778 28.84685135 28.86480713 28.84154701 28.84353828 28.84086227 28.85756302 28.83776474 28.85146904 28.83551598 28.86005211 28.84733772 28.83178139  28.839077 28.86435699 28.83509827 28.84246445 28.83774567 28.83881569 28.83805275 28.85188675 28.8343811 28.83738136 28.85992622 28.84113884 28.84960556 28.8500576 28.84152031 28.83610344 28.84696388 28.83540154 28.84593773 28.86675835 

-------
======================
selected experts : 0, 1, 25, 33, 45, 63, 
layer24_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df21d1f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.605617 -0.646749 0.3423190.583574 -0.679776 -0.100882 -0.309929 0.861299 0.362823]

layer24_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de2b2790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.29781 0.527051 -1.01054-1.14134 -1.1181 2.23694 -0.7975 1.58995 -0.531286]

layer25_wq's input 
<N9nntrainer6TensorE at 0x5682ddf10a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.7088 0.347731 -0.73638-0.730544 -0.814756 1.43181 -0.537945 1.05683 -0.397611]
==============================
layer25_wq's output 
<N9nntrainer6TensorE at 0x5682de7d58a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.83559 3.91835 -4.080750.0644075 -3.05639 2.98326 -3.06824 -0.246444 -1.04628]
============================
layer25_wk's input 
<N9nntrainer6TensorE at 0x5682de480fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.7088 0.347731 -0.73638-0.730544 -0.814756 1.43181 -0.537945 1.05683 -0.397611]
==============================
layer25_wk's output 
<N9nntrainer6TensorE at 0x5682de0aef30>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.475826 0.562091 -0.47697-0.568508 -0.792714 -0.737048 -0.359451 -0.803374 -0.195476]
============================
layer25_wv's input 
<N9nntrainer6TensorE at 0x5682ddd64050>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.7088 0.347731 -0.73638-0.730544 -0.814756 1.43181 -0.537945 1.05683 -0.397611]
==============================
layer25_wv's output 
<N9nntrainer6TensorE at 0x5682de58dbd0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.840023 -4.61997 -2.585693.21929 -0.908869 1.03073 -2.44439 0.160528 -3.1034]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.77767 2.69056 -0.6483364.02944 4.26148 0.284766 3.02726 0.557258 2.64859]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a38cf1b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer25_attention_out's input 
<N9nntrainer6TensorE at 0x5682df211490>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer25_attention_out's output 
<N9nntrainer6TensorE at 0x5682dddde7f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer25_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0184b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.29781 0.527051 -1.01054-1.14134 -1.1181 2.23694 -0.7975 1.58995 -0.531286]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.08507 0.581282 -1.09462-1.24754 -1.20011 2.55523 -0.895266 1.73789 -0.570258]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3521238267 0.7037926912 -0.8344409466 -0.2512977123 -0.403291285 -1.932332873 -0.543863833 0.06713044643 -0.4288933575 -0.004103213549 -0.8570634127 -1.144786596 -0.09808783978 -0.003877218813 -0.6428384185 -0.8870458603 -0.6276754737 -0.985355854 -0.3978602886 0.09748359025 -0.8429579735 0.2512204945 -0.4472000003 -1.10507071 1.46047616 -0.5447825789 -1.209560871 -0.8008135557 -0.2794691622 -0.915550828 -1.310251117 -0.01395785809 -0.7888618708 0.691167593 -0.7541944385 0.01394310407 -0.9679329395 0.4135997593 0.5579542518 -0.3448362052 -0.94643116 0.2649400532 1.001892567 -0.8317495584 -1.023207664 -0.8339598775 -0.7867859006 -0.05729614943 0.08660242707 -0.7493286729 0.1543898433 -0.2039871514 -0.7524009943 -0.5948024392 -0.2189787924 -1.112606168 -0.4913251698 -0.4672349393 -0.7243953347 -0.7608498931 -0.421402812 -0.4930419922 -0.4981641471 -0.9012343884 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0139128631 0.03999403864 0.008589124307 0.01538879983 0.01321888436 0.002865104936 0.01148536801 0.0211590603 0.01288475003 0.01970425434 0.008396997117 0.006297489628 0.01793671958 0.01970870793 0.01040305197 0.008148972876 0.01056199521 0.007385967299 0.01329087093 0.02181115001 0.008516280912 0.02543581463 0.01265101787 0.006552632432 0.08523514867 0.01147481985 0.005902505014 0.008882866241 0.01496132556 0.007919964381 0.005337122362 0.01951102912 0.008989665657 0.03949228302 0.009306780063 0.02006307058 0.007515779696 0.02992030978 0.03456674144 0.01401462499 0.007679132279 0.02578718588 0.05388382077 0.008612271398 0.007111619692 0.008593257517 0.009008348919 0.01868351549 0.02157510631 0.00935217645 0.02308833599 0.01613434963 0.009323486127 0.01091497112 0.01589427516 0.006503441371 0.01210492663 0.01240007859 0.009588289075 0.009245045483 0.01298162527 0.01208416373 0.01202242356 0.00803416688 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.70204735 28.73098946 28.69720078 28.7068615  28.704216 28.69386101 28.70248222 28.71024704 28.70388031 28.70974731 28.69986916 28.69777107 28.70988655 28.70975113 28.69758415 28.69628334 28.7020359 28.69456673 28.70428658 28.71328354 28.69665146 28.71357155 28.70364761 28.69802475 28.7767086 28.70199394 28.69737625 28.70035553 28.7007122 28.69367027 28.69633293 28.71098328 28.70046234 28.73096466 28.70030212 28.71153641 28.69851112 28.72139359 28.72556305 28.70405769 28.69676781 28.71630669 28.74535751 28.69913101 28.69858551 28.70006561 28.69857407 28.70729637 28.7125721 28.7003479 28.7112236 28.70665359 28.69650459 28.70191193 28.70689011 28.69511604 28.70214653 28.70387268 28.70106125 28.70024109 28.69968605 28.70308113 28.70349503 28.69950676 

-------
======================
selected experts : 1, 24, 33, 37, 38, 42, 
layer25_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df270060>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.929537 0.615093 0.4607850.747286 1.42073 -1.73008 0.312851 -0.646419 -0.217662]

layer25_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddfd81b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.22735 1.14214 -0.549755-0.394058 0.302637 0.50686 -0.484649 0.943529 -0.748947]

layer26_wq's input 
<N9nntrainer6TensorE at 0x5682de245ed0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.35866 0.893325 -0.415162-0.276328 0.24759 0.380491 -0.342032 0.665878 -0.555488]
==============================
layer26_wq's output 
<N9nntrainer6TensorE at 0x5682de21e590>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-4.69165 2.99857 0.631250.0792068 -5.66683 2.75762 3.25285 2.31526 -2.07136]
============================
layer26_wk's input 
<N9nntrainer6TensorE at 0x5682de23ab70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.35866 0.893325 -0.415162-0.276328 0.24759 0.380491 -0.342032 0.665878 -0.555488]
==============================
layer26_wk's output 
<N9nntrainer6TensorE at 0x5682de320f60>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.52201 -0.0364019 1.006851.02954 -0.914028 -0.0709108 -0.168282 0.383635 0.519894]
============================
layer26_wv's input 
<N9nntrainer6TensorE at 0x5682dde7eae0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.35866 0.893325 -0.415162-0.276328 0.24759 0.380491 -0.342032 0.665878 -0.555488]
==============================
layer26_wv's output 
<N9nntrainer6TensorE at 0x5682ddeee690>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-3.73006 -3.97706 -7.653534.56543 1.57953 2.92632 3.35135 -1.13161 0.936454]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-3.66694 4.19005 0.188094-0.607759 5.8358 2.37924 -3.00048 -2.63412 2.50099]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a116d880
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer26_attention_out's input 
<N9nntrainer6TensorE at 0x5682df278ee0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer26_attention_out's output 
<N9nntrainer6TensorE at 0x5682df278e40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer26_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df27a260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.22735 1.14214 -0.549755-0.394058 0.302637 0.50686 -0.484649 0.943529 -0.748947]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.35154 1.20137 -0.578262-0.416263 0.308807 0.553649 -0.516316 0.983972 -0.777683]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.2759172022 -0.1387059689 -0.7067614198 -1.268479586 -0.3612571657 1.021911383 -0.2966087461 -0.26906389 -0.1048665121 0.0133791212 -1.354461908 -1.306173325 -0.02691921592 0.2491696626 0.3892656267 -1.124330401 -0.1418023109 -0.3649367988 -0.5551408529 -0.3173350692 -0.7594336271 0.4147895873 -0.08907012641 -0.3768146932 -0.1962184012 -0.3255196214 -0.07426039129 0.01923182607 -0.04550541565 -0.9463357925 -0.6037111282 -0.5362623334 -0.813598752 -0.7713258266 -1.054637551 -1.169281721 -1.212759495 -0.35141325 0.1003354192 1.251168966 -0.6620184779 -0.4314883053 -0.9407871962 -0.7866211534 -0.9597117305 -1.313242674 -0.192396909 -0.334353596 -0.5201273561 -0.7273904085 0.04272904992 -0.5805600882 -0.5623420477 0.1588353813 0.4589306712 -0.6584821939 -1.201208353 -0.9459183812 0.04744794592 -0.6764290333 -0.6047253013 0.1458210498 -0.9528331757 -0.4144361615 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.02648847364 0.01749799959 0.009914824739 0.005653715692 0.01400669292 0.05585191771 0.0149421161 0.01535941381 0.01810025424 0.02037220635 0.005187908188 0.005444572307 0.01956756413 0.02578936704 0.02966767736 0.006530360784 0.01744390279 0.01395524852 0.01153806597 0.01463560667 0.009406105615 0.03043466061 0.01838844456 0.01379047055 0.01652003825 0.01451631077 0.01866279915 0.02049179003 0.01920723729 0.007802597713 0.01099105086 0.01175795775 0.008910172619 0.009294907562 0.007001713384 0.0062433118 0.005977682769 0.01414525602 0.02222300135 0.07024306059 0.01036851667 0.01305673737 0.007846012712 0.009153821506 0.007698924746 0.005406218581 0.01658329181 0.01438863948 0.01194921136 0.009712387808 0.02097899094 0.01124847401 0.01145527698 0.02356182784 0.03180817142 0.01040524896 0.006047131959 0.007805855479 0.02107822336 0.01022017282 0.01097990945 0.0232571736 0.007752065547 0.01328129135 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.08602142 33.07798386 33.07230759 33.0670929 33.07544708 33.11633682 33.07638168 33.07012177 33.07667923 33.0779953 33.06758118 33.06783676 33.08100891 33.08818436 33.09110641 33.06797028 33.07888412 33.07539368 33.0720253 33.07130814 33.07084656 33.09187317 33.07696533 33.07522964 33.07700729 33.07595444 33.07914734 33.07621002 33.07969284 33.07019424 33.07338333 33.07319641 33.06558228 33.07073593 33.06653214 33.06863785 33.06741714 33.07463074 33.08461761 33.12691498 33.06990051 33.07449722 33.06928635 33.07059479 33.07009125 33.06779861  33.078022 33.07678223 33.07434082 33.07019806  33.080513 33.07364273 33.07289505 33.08595657 33.09038544 33.07279968 33.06748581 33.06733704 33.08251953 33.07165909 33.07337189 33.08279037 33.06728363 33.07376862 

-------
======================
selected experts : 0, 5, 14, 21, 39, 54, 
layer26_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df27d4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-3.32686 1.13824 2.549562.01513 -2.48562 -0.516023 -2.50276 -2.9583 0.0558259]

layer26_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddd52130>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.900489 2.28039 1.99981.62107 -2.18298 -0.00916255 -2.98741 -2.01477 -0.693121]

layer27_wq's input 
<N9nntrainer6TensorE at 0x5682de328070>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.777849 1.42344 1.298731.02722 -1.47964 -0.0060371 -1.88361 -1.30845 -0.454505]
==============================
layer27_wq's output 
<N9nntrainer6TensorE at 0x5682ddefef30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.73188 1.85899 0.7583631.4781 1.7505 1.43621 -1.66906 1.5717 -0.972143]
============================
layer27_wk's input 
<N9nntrainer6TensorE at 0x5682de1e5e50>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.777849 1.42344 1.298731.02722 -1.47964 -0.0060371 -1.88361 -1.30845 -0.454505]
==============================
layer27_wk's output 
<N9nntrainer6TensorE at 0x5682ddfc8350>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.743974 1.18005 0.6682281.29277 0.611509 0.311492 -0.605846 0.68516 0.0157546]
============================
layer27_wv's input 
<N9nntrainer6TensorE at 0x5682de7969c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.777849 1.42344 1.298731.02722 -1.47964 -0.0060371 -1.88361 -1.30845 -0.454505]
==============================
layer27_wv's output 
<N9nntrainer6TensorE at 0x5682de46fef0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.19192 2.79636 -1.47562-2.0129 -0.243943 0.46185 0.810476 2.93607 -2.04597]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.14347 2.26887 1.58772-0.488932 -0.0988942 -2.26212 1.82028 -1.39378 -0.146282]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a054f820
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer27_attention_out's input 
<N9nntrainer6TensorE at 0x5682de426170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer27_attention_out's output 
<N9nntrainer6TensorE at 0x5682de0d2950>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer27_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de6e6390>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.900489 2.28039 1.99981.62107 -2.18298 -0.00916255 -2.98741 -2.01477 -0.693121]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.726749 1.79009 1.550921.25719 -1.75492 -0.00739473 -2.36393 -1.56252 -0.535355]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5099403262 -1.220533609 -0.0565347448 -0.2577859163 -0.2888199985 -0.2733395696 -0.3190815151 -0.1558616161 0.7160744667 -0.7994988561 -0.4760230482 -1.204645514 -0.2987708151 0.2233734429 -0.08029260486 -1.236840963 -1.258179665 -0.3760178685 -0.8201752305 -1.427593231 0.6406546235 -0.3322273195 -0.5550384521 -1.472351193 -1.734372973 -0.6209437847 -0.126408428 0.6248345971 -0.194844991 -0.5386272669 0.632547617 -0.9789749384 0.249084428 0.1696014851 -0.2190168798 -0.4187732339 -0.5208759308 -0.8158570528 0.09890311211 0.1262154281 -1.107846975 -0.1528904587 -0.8031591177 0.1494600177 -0.8999056816 -0.1750700027 0.5058190823 0.3375385106 -0.01996741071 -1.69429338 0.4086866975 -0.1200674474 -0.7148858905 -0.694650948 -0.348574698 -0.5709431767 -1.013030648 -0.2335567027 0.4432167411 0.1251413524 -0.1332988739 0.1675446182 -1.052818179 1.052858591 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01116948295 0.005488154478 0.01757699437 0.01437283214 0.01393363532 0.01415101252 0.01351829711 0.01591503248 0.03806138411 0.008361408487 0.01155481953 0.005576048046 0.01379567198 0.02325451188 0.01716432534 0.005399383605 0.005285388324 0.01277011819 0.008190300316 0.004461711738 0.03529637679 0.01334175188 0.01067695022 0.00426641712 0.003282984253 0.009995969012 0.01639075018 0.03474238142 0.01530654822 0.01085361745 0.03501138464 0.006987694185 0.02386016026 0.02203709632 0.01494099572 0.01223563403 0.01104800403 0.008225743659 0.02053290792 0.02110143751 0.006142788101 0.01596238837 0.008330859244 0.02159767598 0.007562637795 0.0156122474 0.03084407747 0.02606684528 0.01823163591 0.003417237429 0.02798902243 0.01649501547 0.009099684656 0.009285693057 0.01312542334 0.01050848048 0.006753730122 0.01472532749 0.02897236496 0.02107878588 0.01627820171 0.02199181356 0.006490292493 0.05330255628 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
31.50262451 31.49694252 31.5090313 31.50630569 31.50395775 31.50369835 31.50592613 31.50689316 31.52903938 31.50029373 31.50348663 31.49559975 31.50382042 31.51518631 31.50814247 31.49542427 31.49674034 31.50088692 31.50012207 31.48542595 31.5272274 31.50527382 31.50260925 31.49238396 31.49378395 31.50145149 31.50784492 31.52381325 31.50723839 31.49897003 31.52694321 31.49796677 31.51531601 31.51349258 31.50448799 31.50369072 31.49773407 31.49443626 31.51294136 31.51255608 31.49807549 31.50789452 31.4988327 31.51352882 31.49997139 31.50658989 31.5118084 31.51752281 31.5106411 31.49534988 31.51992035 31.50794983 31.50055504 31.49930954 31.50458145 31.49910164 31.49868584 31.50522614 31.52090454 31.51301003 31.50820923 31.51344681 31.49842262 31.54475784 

-------
======================
selected experts : 8, 20, 27, 30, 46, 63, 
layer27_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df2fed10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.78379 -4.10973 0.174737-0.765252 2.4391 -2.11893 -2.19582 -0.143156 2.99934]

layer27_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de4dbd00>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.883297 -1.82934 2.174540.855816 0.256112 -2.1281 -5.18323 -2.15792 2.30621]

(93919)layer0_wq's input 
<N9nntrainer6TensorE at 0x5682dde663b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5682de7965e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.13528 -2.40334 2.68629-0.919085 2.00659 2.0107 -1.72146 -1.10937 2.11685]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5682ddd56d10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5682de0a36b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.89838 -1.3551 1.40273-1.31928 1.80822 0.0189238 -3.15912 0.501596 1.80267]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5682e0a65b00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5682dde490d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0171632 -0.00860554 -0.02487710.023363 0.0279423 0.00942741 0.0125607 0.108111 -0.0271058]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.723069 -2.55775 1.74136-2.24244 1.87146 -2.13705 0.713519 1.91964 -2.11055]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a259fd20
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer0_attention_out's input 
<N9nntrainer6TensorE at 0x5682e0a64030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer0_attention_out's output 
<N9nntrainer6TensorE at 0x5682e0a638e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer0_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dde13420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00261426 -0.0209141 0.0150320.00392139 -0.0209141 -0.00326782 -0.0169927 0.00326782 0.00718921]

layer0_ffn_gate's input 
<N9nntrainer6TensorE at 0x5682ddfb82c0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.016856 -0.133765 0.09458650.0238624 -0.133223 -0.0193776 -0.108684 0.0207315 0.0444924]
==============================
layer0_ffn_gate's output 
<N9nntrainer6TensorE at 0x5682dde852c0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.0745774 -0.045048 -0.104621-0.0199713 -0.0449096 0.327996 0.0860863 0.095988 -0.0662891]
============================
layer0_ffn_up's input 
<N9nntrainer6TensorE at 0x5682de34f990>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.016856 -0.133765 0.09458650.0238624 -0.133223 -0.0193776 -0.108684 0.0207315 0.0444924]
==============================
layer0_ffn_up's output 
<N9nntrainer6TensorE at 0x5682dde690c0>
data addr: 0x7fc0a7fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.107725 -0.084519 -0.0651140.108516 -0.371791 -0.215119 -0.0580026 -0.266965 0.0745787]
============================
layer0_ffn_down's input 
<N9nntrainer6TensorE at 0x5682dc3e1140>
data addr: 0x7fc0aafd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[0.0038672 0.00186083 0.00322812-0.00107278 0.00816106 -0.0410134 -0.00260401 -0.0134272 -0.00238998]
==============================
layer0_ffn_down's output 
<N9nntrainer6TensorE at 0x5682dc3e0770>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.019992 -0.0625515 0.0377594-0.0686288 -0.133513 -0.0569278 -0.00148558 0.141268 0.0288674]
============================
layer0_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3e1bb0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0173777 -0.0834656 0.0527914-0.0647074 -0.154427 -0.0601957 -0.0184783 0.144535 0.0360566]

layer1_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e48b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wq's output 
<N9nntrainer6TensorE at 0x5682dc3e2330>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.796753 0.125337 -0.343608-0.150926 0.507089 0.41414 -0.255773 -0.0929489 0.288512]
============================
layer1_wk's input 
<N9nntrainer6TensorE at 0x5682dc3e6610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wk's output 
<N9nntrainer6TensorE at 0x5682dc3e6380>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.57238 0.950343 0.763138-0.230196 1.08302 0.869608 -0.770607 0.449956 1.26046]
============================
layer1_wv's input 
<N9nntrainer6TensorE at 0x5682dc3e7400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wv's output 
<N9nntrainer6TensorE at 0x5682dc3e7190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.181 0.0291937 0.03531750.0125654 -0.00638554 0.189028 -0.105657 -0.2298 0.067497]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.683019 -0.428964 -0.3700730.0623815 0.379165 -0.533747 0.149083 0.22767 -0.28288]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a34c5598
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer1_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ea340>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer1_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ea2a0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer1_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3eb440>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0173777 -0.0834656 0.0527914-0.0647074 -0.154427 -0.0601957 -0.0184783 0.144535 0.0360566]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00849878 -0.127214 0.076729-0.116416 -0.229304 -0.113028 -0.033535 0.248681 0.0424914]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.1702160239 -0.2239896655 -0.1769756079 0.04392522946 0.2368980944 0.6970673203 -0.3592808545 0.1850829422 0.05595271289 -0.5391097665 -0.4449483454 -0.1334935427 -0.4149801433 -0.1864147633 -0.1508485675 1.056051373 -0.3195793629 0.2847701907 -0.2090599388 0.2084010988 0.0856358707 -0.2458385676 0.4397518933 -0.2768904567 -0.3535001278 -0.3292910159 -0.614720583 -0.2910648882 -0.5341821313 1.065764666 -0.4363492429 -0.01145206578 -0.3598379493 0.01293567009 -0.4634871483 0.6671438813 0.07331451029 4.606241703 -0.1133288145 -0.4652608633 -0.276211381 -0.27166453 0.3908366859 -0.07471401989 -0.2063711286 -0.08803310245 0.8862541914 0.1459055394 0.1584375054 -0.7652307153 -0.911662221 -0.3270534873 -0.7755787373 -0.1130612567 -0.363222748 -0.1517439485 1.124939442 0.2087254822 -0.1229620501 0.2299077511 -0.002020265907 -0.2369497269 -0.2072182894 0.03846488521 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005106037483 0.004838720895 0.005071639083 0.006325348746 0.0076716966 0.0121545922 0.00422643451 0.007284310181 0.00640188437 0.003530820133 0.003879443277 0.005297030788 0.003997462802 0.005023993552 0.005205893889 0.01740384474 0.004397606011 0.008047888987 0.004911503755 0.007456163876 0.006594760343 0.004734145477 0.009397014044 0.004589401186 0.004250939004 0.004355106037 0.003273693845 0.004524807911 0.003548261477 0.01757371798 0.003912945744 0.005984588526 0.004224081524 0.006132334471 0.003808184993 0.01179627329 0.006514005363 0.6060009599 0.005404926836 0.003801435698 0.004592518788 0.004613446537 0.008948416449 0.005617718678 0.004924725275 0.005543392152 0.01468599215 0.007004447747 0.007092781365 0.002816258464 0.002432641573 0.00436486071 0.002787265228 0.005406372715 0.00420980854 0.005201234482 0.01864502393 0.007458582055 0.005353110842 0.007618254982 0.00604130188 0.004776413552 0.004920556676 0.006290904246 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
62.86117935 62.85995483 62.8611412 62.86048889 62.86183548 62.86727142 62.85934448 62.86240387 62.86151886 62.85865021 62.85899734 62.86041641 62.8591156 62.86014175 62.86032486 62.8706131 62.85951614 62.86316681 62.86003113 62.86257553 62.86171341 62.85985184 62.85974503 62.86066055 62.85936737 62.85947418 62.85839081 62.8605957 62.85675812 62.87173843 62.85998535 62.86110306 62.86029434 62.86125183 62.85987854 62.86691284 62.8616333 63.45921326 62.86052322 62.85892105 62.85971069 62.86068344 62.86215973 62.86073685 62.86004257 62.86066055 62.86789703 62.86212158 62.86125565 62.85793304 62.85755157 62.85948181 62.85790634 62.86052322 62.85932922 62.85936356 62.87281036 62.86257553 62.86046982 62.86273575 62.86116028 62.8598938 62.86003876 62.86140823 

-------
======================
selected experts : 5, 15, 29, 37, 46, 56, 
layer1_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e0a3ef10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00353315 -0.0549329 0.126958-0.123369 0.276545 -0.191098 0.106235 0.309095 -0.178975]

layer1_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3ee080>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0209109 -0.138399 0.179749-0.188076 0.122118 -0.251294 0.0877565 0.45363 -0.142918]

layer2_wq's input 
<N9nntrainer6TensorE at 0x5682dc3ee2c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wq's output 
<N9nntrainer6TensorE at 0x5682dc3ee260>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.311247 0.115223 -0.416898-0.165847 -0.237754 -0.201397 0.366615 0.127884 -0.336297]
============================
layer2_wk's input 
<N9nntrainer6TensorE at 0x5682dc3edf00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wk's output 
<N9nntrainer6TensorE at 0x5682dc3ede70>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0170464 -0.00491821 -0.00816116-0.0380695 0.0298006 -0.00619471 0.0300897 0.0291104 -0.00756178]
============================
layer2_wv's input 
<N9nntrainer6TensorE at 0x5682dc3ee380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wv's output 
<N9nntrainer6TensorE at 0x5682dc3ee3b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0488053 0.00885962 0.00802386-0.00675694 -0.00410349 -0.01637 0.00385213 -0.0244586 -0.011974]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.310349 -0.117618 -0.439530.0901253 -0.184983 0.250737 -0.216892 -0.322054 0.327289]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0857438
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer2_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ee500>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer2_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ee620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer2_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3fefb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0209109 -0.138399 0.179749-0.188076 0.122118 -0.251294 0.0877565 0.45363 -0.142918]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00114894 -0.0176881 0.0220069-0.0260591 0.0151698 -0.0354185 0.0120544 0.0614986 -0.0157906]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2300609797 -0.0573739633 -0.0792670846 -0.07990511507 -0.02465081401 0.3291009963 -0.0433845073 0.0155646475 -0.0844059214 0.0009286757559 0.03862661868 -0.08860354871 -0.003646862693 -0.01065728627 0.02001750097 0.02708270214 0.04012955353 0.008215387352 -0.02356889471 -0.008847231045 -0.1422992498 2.097109318 -0.2351353914 0.4799684286 -0.5973323584 0.03877436742 0.04228200763 0.03647579625 -0.1728328317 0.0651492998 0.9051232338 0.01538673695 -0.1603259444 -0.3426310718 0.1016679481 0.5145780444 -0.05423829705 -0.0345232375 -0.1464090049 0.08176235855 -0.0002122647129 -0.1026671231 0.08935724944 0.1386951506 0.009488531388 0.03291593865 -0.3518608809 -0.01619542576 0.1929396689 -0.04016084224 0.006257107947 0.08056685328 -0.2241435498 -0.1660892814 0.1276066601 0.09963126481 -0.1244759187 0.005371605046 -0.127043888 -0.3551532924 -0.3419806063 -0.0312563628 -0.01512844954 -0.1615694612 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01110433694 0.01319743972 0.01291164756 0.0129034128 0.01363644563 0.01942377351 0.01338336244 0.01419601869 0.01284546684 0.01398975775 0.01452721003 0.01279165968 0.01392589416 0.01382860821 0.01425937004 0.01436047349 0.01454906166 0.01409207098 0.01365120709 0.01385366265 0.01212291792 0.1138072386 0.01104813442 0.02258679084 0.007691104431 0.0145293558 0.01458041091 0.01449599955 0.01175835636 0.01491766516 0.03455388919 0.01419349387 0.01190633792 0.009922111407 0.01547250804 0.02338219807 0.0132388873 0.01350248232 0.01207319647 0.01516756415 0.01397380698 0.01261302177 0.01528319623 0.0160561502 0.01411002409 0.01444448438 0.009830952622 0.01375223417 0.01695116423 0.01342657488 0.01406450011 0.01514944155 0.01117024291 0.01183791552 0.01587909646 0.0154410284 0.01234092377 0.01405205205 0.01230927277 0.009798639454 0.009928567335 0.0135466652 0.01376691833 0.01189154293 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
53.42486572 53.42695999 53.42667389 53.42666626 53.42739868 53.43127823 53.4271431 53.42795563 53.42660522 53.42774963 53.42828751 53.4236908 53.4276886 53.42758942 53.42802048 53.42812347 53.42735672 53.42785263 53.42741394 53.42666245 53.42588425 53.52566147 53.4248085 53.43539429 53.42145157 53.42829132 53.42738724 53.42825699 53.42551804 53.42868042 53.44831467 53.42795563 53.42566681 53.42368317 53.42923355 53.43714523 53.42699814 53.42631149 53.42583466 53.42892838 53.42773438 53.42637253 53.42904282 53.4298172 53.4278717 53.4282074 53.42359161 53.42751312 53.42785263 53.42718887 53.42782593 53.42700195 53.42493057 53.42559814 53.42868805 53.42920303 53.42610168 53.42781448 53.42511749 53.4235611 53.42273712 53.42635345 53.42752838 53.42565155 

-------
======================
selected experts : 5, 21, 23, 30, 35, 48, 
layer2_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e09f8dd0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00287643 0.0675208 -0.00951222-0.0402701 -0.0273482 0.0245452 0.04068 0.00865384 -0.00745776]

layer2_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc401970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0180344 -0.0708777 0.170237-0.228346 0.0947696 -0.226748 0.128437 0.462284 -0.150376]

layer3_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e86c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wq's output 
<N9nntrainer6TensorE at 0x5682dc409160>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.367673 -0.164716 0.417190.0188933 -0.448419 0.281779 -0.241015 -0.0599261 0.228738]
============================
layer3_wk's input 
<N9nntrainer6TensorE at 0x5682dc41f6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wk's output 
<N9nntrainer6TensorE at 0x5682dc41f440>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0494961 -0.00890612 -0.00339991-0.0380567 -0.012209 -0.0539861 0.0167038 0.0355852 0.0534441]
============================
layer3_wv's input 
<N9nntrainer6TensorE at 0x5682dc4204c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wv's output 
<N9nntrainer6TensorE at 0x5682dc420250>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00987394 -0.0372493 0.01608040.0108743 -0.00258411 -0.0155564 0.00276103 0.00223089 -0.00269894]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.385406 0.117377 0.359134-0.213137 0.311245 0.428492 0.157054 0.192389 -0.243779]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a167a4a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer3_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc422910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer3_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc422870>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer3_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc423990>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0180344 -0.0708777 0.170237-0.228346 0.0947696 -0.226748 0.128437 0.462284 -0.150376]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00117001 -0.00973031 0.0224832-0.0335967 0.012626 -0.0336243 0.0186737 0.0650705 -0.0180309]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.7030926943 0.730641067 0.9185103774 1.089624643 0.6388058662 0.8775565028 0.3533841074 0.9655683041 0.9445055723 0.9198542237 0.6780980229 1.313909769 1.142851233 1.079918623 0.7256379724 0.9863049984 0.9989354014 0.95402354 0.8960082531 0.8800563216 0.8590018153 0.3948054016 1.023362279 0.8607522845 1.028882027 1.132201791 0.9340718389 1.035694122 1.269880891 1.17101717 1.161755562 0.8632258773 7.094688416 0.9837840796 1.429793835 0.3792514503 1.048365355 0.4638099968 1.291579366 0.9866654277 1.075057983 0.7833786011 0.8463903069 0.3343887925 1.796683669 1.537041783 0.5512750745 1.040719032 0.6032510996 0.8395021558 0.1258548796 0.3762799203 0.7514244914 1.113770843 0.7281199098 1.025203586 0.4975908697 0.7822400331 1.484714389 1.298515081 0.8620041013 0.9687132239 0.9522148371 0.9354790449 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001474627294 0.0015158155 0.001829098328 0.002170455642 0.001382811344 0.001755702426 0.001039455179 0.001917229616 0.001877269591 0.001831557835 0.001438226667 0.002716168528 0.002289112192 0.002149492037 0.001508250833 0.001957401866 0.001982280519 0.001895222114 0.001788399648 0.001760097337 0.001723426278 0.001083415002 0.002031297656 0.001726445742 0.00204254128 0.002264863113 0.001857784577 0.002056502737 0.002599173458 0.002354503609 0.00233279774 0.001730722026 0.8800697327 0.001952473191 0.003049893072 0.001066694036 0.002082727384 0.001160815358 0.002656187862 0.001958106412 0.00213906914 0.00159790169 0.001701827976 0.001019896823 0.004401725251 0.003395171836 0.00126691896 0.002066862537 0.001334509347 0.001690146164 0.0008279253379 0.001063528936 0.001547649037 0.002223502612 0.00151199894 0.002035042038 0.001200698782 0.001596083166 0.00322208018 0.002674675314 0.001728608971 0.001923268428 0.001891797525 0.001860400545 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
42.53669739 42.53292084 42.53704834 42.53739166 42.53564835 42.53697586  42.532444 42.53809357 42.53709793 42.53800583 42.53570557 42.53793716 42.5346489 42.53736877 42.53672791 42.53717804 42.53720474 42.53616333 42.53796387 42.53507233 42.53694534 42.53725815 42.53820419 42.53694916 42.53726196 42.53748703 42.53707886 42.53727722 42.53781891 42.53757477 42.53755569 42.53695297 43.41242981 42.53717422 42.53827286 42.53628922 42.53730392 42.53638077 42.53787613 42.53717804 42.53736115 42.53681946 42.53787613 42.53623962 42.53771591 42.53861618 42.53648758 42.53728867 42.53750992 42.53691101 42.53700256 42.5362854 42.53581619 42.53744507 42.53673172 42.53630066 42.53642273 42.53776932 42.53749084 42.53408051 42.53694916 42.53714371 42.53711319 42.53708267 

-------
======================
selected experts : 11, 32, 34, 44, 45, 58, 
layer3_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc426710>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.40804 -0.163766 -0.0283651-0.0258024 0.375191 -0.636849 0.150238 0.480676 -0.0173886]

layer3_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc426050>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.426075 -0.234644 0.141872-0.254149 0.469961 -0.863597 0.278674 0.942961 -0.167765]

layer4_wq's input 
<N9nntrainer6TensorE at 0x5682dc44b9a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wq's output 
<N9nntrainer6TensorE at 0x5682dc492890>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0362699 0.0761985 -0.162530.0108048 0.133773 0.0730457 0.019711 0.0756074 0.0487248]
============================
layer4_wk's input 
<N9nntrainer6TensorE at 0x5682dc44d700>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wk's output 
<N9nntrainer6TensorE at 0x5682dc44d470>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00265456 0.0108227 0.006283270.0177541 -0.0206112 0.00339958 -0.00927054 0.0110561 -0.0341779]
============================
layer4_wv's input 
<N9nntrainer6TensorE at 0x5682dc44e4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wv's output 
<N9nntrainer6TensorE at 0x5682dc44e280>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00723192 0.0269832 0.01238150.00259692 -0.0625021 0.0233134 -0.0178625 -0.0133778 -0.0104791]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0774053 0.0336174 -0.1299440.0982205 0.0639007 -0.138375 0.0295214 -0.0723428 -0.0534846]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1e8e4e8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer4_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc450940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer4_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4508a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer4_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4519c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.426075 -0.234644 0.141872-0.254149 0.469961 -0.863597 0.278674 0.942961 -0.167765]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0182407 -0.0208817 0.0120996-0.0239882 0.0418232 -0.0826764 0.0268667 0.0864598 -0.0135161]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4858219922 -0.6959101558 -1.212872982 -0.5218012333 -0.3581064343 -0.6095018983 -0.9364464879 -0.09696792811 0.1423784941 -0.6651900411 -0.3415829241 -0.6328966618 -0.448492974 0.1721494049 -0.6025950313 -0.3689320683 0.2208227664 -0.4570725858 -0.2653499246 -0.5709964633 -0.5247528553 -0.8439400792 -0.7144295573 -0.4792812765 -0.2926749885 -0.719201386 5.035842419 -0.5945936441 -0.8254883885 -0.2731153667 -0.396169126 -0.2761000395 -0.4569109082 -0.4405405819 -0.4258541465 -0.9477441907 -0.5268508196 -0.8339192271 -0.6794077754 -0.0201159101 -0.3519995511 -0.3451288044 -0.7215133309 -0.1839890182 -0.3048131168 -0.4804430902 -0.3798335195 -0.1730620563 -0.3575777709 -0.1691406071 -0.5078726411 -0.7150136232 -0.4467060566 -0.5603669286 -0.3437692225 -0.2371052802 -0.9603158832 -0.3850839734 -0.2239291668 -0.5798804164 -0.4820096195 -0.009696807712 -0.3213909268 -0.4072785378 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003149774857 0.002552933758 0.001522388076 0.003038462717 0.003578868229 0.002783339238 0.002007131465 0.004646830726 0.005903418176 0.002632576274 0.003638495924 0.002718978561 0.003269575769 0.006081810221 0.002802630188 0.00354033336 0.006385156885 0.003241643542 0.003926715348 0.002892603399 0.003029507585 0.002201662865 0.002506090095 0.003170444164 0.003820870072 0.002494159155 0.7876041532 0.002825144911 0.002242664341 0.003896341659 0.003445207141 0.003884728299 0.003242167644 0.003295679577 0.003344439203 0.001984582981 0.003023159457 0.002223837189 0.002595413011 0.005018029362 0.003600790864 0.003625615733 0.002488400089 0.004259552807 0.003774773097 0.00316676381 0.003501948435 0.004306353163 0.003580761142 0.004323271569 0.003081081435 0.002504626755 0.003275422612 0.002923513297 0.00363054988 0.004039204679 0.001959790243 0.003483609762 0.004092779011 0.002867019502 0.003161807079 0.005070585292 0.003712710226 0.003407144919 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.82080841 40.8202095 40.81822586 40.82165146 40.82218933 40.82139587 40.82061768 40.8213501 40.81974792 40.82124329 40.82129669 40.82133102 40.82188034 40.8237381 40.82141495 40.82215118 40.8230896 40.81994629 40.82253647 40.82150269 40.82068634 40.82081223 40.81825638 40.81987381 40.8214798 40.82110596 41.60335541 40.81953049 40.82085419 40.82250595 40.82205582 40.82249451 40.82185364 40.82190704 40.82195663 40.81868744 40.81877518 40.81797409 40.82120514 40.82172012 40.82125854 40.82223511 40.82109833 40.82191849 40.8223877 40.81796265 40.82211304 40.82196426 40.82123947 40.8153038 40.82073975 40.81825638 40.82188797 40.82057953 40.82128906 40.82265091 40.8205719 40.82209396 40.81984329 40.8214798 40.82177353 40.82368088 40.82232285 40.82201767 

-------
======================
selected experts : 8, 13, 16, 26, 39, 61, 
layer4_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc454a40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0859682 -0.410187 -0.0549648-0.0186526 0.0215153 0.136957 0.138183 0.141585 -0.052018]

layer4_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc454380>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.512043 -0.644831 0.0869074-0.272801 0.491476 -0.72664 0.416858 1.08455 -0.219783]

layer5_wq's input 
<N9nntrainer6TensorE at 0x5682dc4a0910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wq's output 
<N9nntrainer6TensorE at 0x5682dc454560>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.275413 -0.275119 -0.4205730.130582 -0.153064 -0.171391 0.250294 0.344814 -0.237526]
============================
layer5_wk's input 
<N9nntrainer6TensorE at 0x5682dc4a2670>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wk's output 
<N9nntrainer6TensorE at 0x5682dc4a23e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0251711 0.00994586 -0.00368810.0447051 -0.0208935 -0.0184831 -0.00454087 0.00173929 -5.86053e-05]
============================
layer5_wv's input 
<N9nntrainer6TensorE at 0x5682dc4a3460>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wv's output 
<N9nntrainer6TensorE at 0x5682dc4a31f0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00785 0.000318006 -0.00348613-0.00889498 -0.0160193 0.010875 -0.0116615 -0.00481091 -0.00860701]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.388384 -0.0264699 -0.2799370.339953 -0.160729 0.164224 0.00621608 -0.426034 0.225681]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1c894d8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer5_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc4a58b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer5_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4a5810>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer5_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a6930>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.512043 -0.644831 0.0869074-0.272801 0.491476 -0.72664 0.416858 1.08455 -0.219783]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0104662 -0.0263608 0.00340267-0.011859 0.0191012 -0.0313787 0.0180013 0.0458975 -0.00822548]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.07918033749 -0.2179847509 -0.1854854673 -0.02147212252 -0.2435834855 -0.04457190633 -0.05281364918 0.02368463762 -0.7193178535 -0.03581977263 1.976906419 -0.0489499718 -0.1354791224 0.1448095441 -0.05553285405 -0.09898391366 -0.3166708648 -0.1941818893 -0.1947810501 -0.2095515877 -0.3199042678 -0.01641224325 -0.1026784554 -0.07198929787 -0.6075111628 -0.3197972476 -0.03667161986 -0.07751637697 0.02160535939 -0.2651851773 -0.04437225312 -0.3091673255 -0.003033100627 -0.08875891566 -0.05681180954 0.985704422 -0.1130490974 -0.03929310292 -0.3192313612 0.09553340077 -0.003807086032 -0.145200029 -0.2841767073 -0.1278078854 2.390167236 -0.05618714541 -0.1036904231 -0.02516179718 0.9318757057 -0.4884956181 -0.7425076962 -1.161397815 -0.01418332662 0.03714296594 1.100428462 -0.02066170983 -0.01740192436 -0.5280942917 -0.0759184286 -1.118462682 -0.1128986701 -0.281962961 -0.1339662522 0.06412689388 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01403941866 0.01043018512 0.01077472791 0.01269510575 0.0101665752 0.0124052139 0.0123033952 0.01328151859 0.006317798514 0.01251426246 0.09365288168 0.0123510221 0.01132723037 0.01499172207 0.01226998307 0.01174825523 0.009450029582 0.01068143174 0.01067503355 0.01051851641 0.00941952318 0.01275950484 0.01170493197 0.01206971519 0.00706517417 0.009420530871 0.01250360627 0.01200318988 0.01325392816 0.009949313477 0.01240768936 0.009521204047 0.01293136273 0.01186899748 0.01225430053 0.03475742415 0.01158417203 0.01247087214 0.009425864555 0.01427089516 0.01292135939 0.01121765375 0.009762142785 0.01141445898 0.1415787339 0.01226195786 0.01169309299 0.01264835335 0.03293593973 0.007958122529 0.006172975991 0.004060437903 0.01278797723 0.0134614734 0.03898267075 0.01270540152 0.01274688449 0.007649149746 0.01202238444 0.00423857104 0.01158591546 0.009783779271 0.01134438068 0.01382966246 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.25190735 33.25020599 33.25246048 33.25437927 33.24994278 33.25027466 33.25398636 33.24829102 33.24704742 33.25419998 33.33438492 33.25308228 33.2530098 33.2538147 33.25395584 33.25343323 33.25113297 33.24378204 33.25235748 33.25220108 33.2415657 33.25444412 33.25338745 33.25375366 33.24398041 33.25110626 33.25418854 33.25368881 33.25493622 33.25067902 33.25409317 33.2492981 33.24889374 33.25355148 33.25393677 33.27548599 33.2532692 33.25415421 33.24729538 33.25309372 33.25460434 33.25290298 33.2504921 33.25309753 33.38135529 33.2539444 33.25337601 33.25337982 33.27366638 33.24964142 33.24594879 33.2457428 33.25065613 33.25419235 33.27780533 33.25057602 33.25443268 33.24456406 33.25370789 33.24592209 33.2532692 33.24670029 33.25112152 33.24883652 

-------
======================
selected experts : 10, 13, 35, 44, 48, 54, 
layer5_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc4a9a10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.230467 0.147142 0.06459260.0019409 -0.181316 0.0733079 0.0421877 0.0761149 -0.146847]

layer5_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a9350>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.74251 -0.497689 0.1515-0.27086 0.310161 -0.653332 0.459045 1.16066 -0.36663]

layer6_wq's input 
<N9nntrainer6TensorE at 0x5682dc4e8620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wq's output 
<N9nntrainer6TensorE at 0x5682dc4a9530>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.695634 -0.228144 -0.5810460.323757 -0.197663 -0.540155 0.504746 0.847593 -0.763714]
============================
layer6_wk's input 
<N9nntrainer6TensorE at 0x5682dc4ea380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wk's output 
<N9nntrainer6TensorE at 0x5682dc4ea0f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0214494 -0.00297009 0.00338558-0.00782245 0.00143022 0.00439973 0.00877311 -0.0147463 -0.046852]
============================
layer6_wv's input 
<N9nntrainer6TensorE at 0x5682dc4eb170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wv's output 
<N9nntrainer6TensorE at 0x5682dc4eaf00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0156485 0.0104525 0.01945610.00157869 0.0098697 0.000841773 -0.0121287 0.00979754 -0.00119108]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.674328 0.285024 -0.3080870.589505 -0.525667 0.233477 0.103752 -0.981029 0.735522]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1a844c8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer6_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc41beb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer6_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc41be10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer6_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc41cf30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.74251 -0.497689 0.1515-0.27086 0.310161 -0.653332 0.459045 1.16066 -0.36663]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0147305 -0.0212876 0.00626695-0.0120428 0.0127428 -0.0295996 0.0207973 0.051278 -0.014547]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.04598842189 0.871989727 0.1590040326 -0.8808486462 -0.7566508055 -0.0392893441 0.2642817199 0.3292520642 0.2644926012 0.08304589987 0.0166921448 -0.2166069597 1.023880839 -0.08878401667 -0.2583498955 0.2684820294 0.1323997676 -0.9021778703 0.135657087 0.2334127873 0.1226155683 0.1617766619 0.007764321752 1.611345887 0.2760307789 -0.5341758728 -0.6800649762 0.1462279111 0.2474199682 -0.1545801759 -0.6242238879 -0.3659591973 0.0122226933 -0.2061981857 -0.1350325495 -0.7296162844 1.269290686 -0.002525131684 0.3083646595 -0.1382303983 0.2969625592 0.06327658892 0.1928350031 0.676184237 0.2964215279 0.01302839536 0.08529359847 0.2071783841 -0.05202829838 -0.6404911876 -0.05744434148 0.4427712262 0.3092009425 0.38174209 -0.3089568913 0.2807747126 0.3261196911 0.22609815 -0.1027657315 0.3057509661 0.296938926 0.3073717356 0.02158760652 -0.1024745256 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01360130031 0.03106763959 0.01522868965 0.005383443553 0.006095350254 0.01248949207 0.01691936329 0.01805511862 0.01692293212 0.01411478501 0.01320861373 0.01046012156 0.03616377339 0.01188637782 0.01003247313 0.01699057966 0.01482888218 0.005269835237 0.01487726346 0.01640505902 0.01468450017 0.01527097076 0.013091214 0.06507385522 0.01711932197 0.007614096161 0.006580508314 0.01503536291 0.01663646474 0.0111294724 0.006958425511 0.009008944035 0.01314970851 0.01056956686 0.01134916861 0.006262382492 0.04622254521 0.01295720413 0.01768190227 0.01131293271 0.01748143882 0.01383848768 0.01575270295 0.02554294653 0.01747198217 0.01316030882 0.0141465487 0.01598027907 0.0123313982 0.006846146192 0.01226479094 0.02022558078 0.01769669354 0.01902814396 0.009537393227 0.01720072888 0.01799864694 0.01628550142 0.01172134187 0.01763574779 0.01748102345 0.01766435429 0.01327343471 0.01172475517 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.13698196 40.15444946 40.13098145 40.12876511 40.12947845 40.13587189 40.14125443 40.14143753 40.14030457 40.13749695 40.13659286 40.13098145 40.1595459 40.13431549 40.13341522 40.14037323 40.1382103 40.12865067 40.13825989 40.13978577 40.13806534 40.1386528 40.13647461 40.18845749 40.14050293 40.1309967 40.1309166 40.13841629 40.14001846 40.13451385 40.12747955 40.13143921 40.13653183 40.13395309 40.13473129 40.1296463 40.16960526 40.13634109 40.14106369 40.13469696 40.14086533 40.13722229 40.13817978 40.14892578 40.14085388 40.13749695 40.13657379 40.13936234 40.13476181 40.13022995 40.13564682 40.14360809 40.14107895 40.14241028 40.13005829 40.14058304 40.14042664 40.13966751 40.13319778 40.14101791 40.14086533 40.13818741 40.13665771 40.13510895 

-------
======================
selected experts : 1, 12, 23, 36, 43, 51, 
layer6_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc47b4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0510724 -0.0072978 0.002230830.066627 0.0371369 -0.00985265 -0.0324661 0.0408974 0.107894]

layer6_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc47ae20>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.793582 -0.504987 0.153731-0.204233 0.347298 -0.663184 0.426579 1.20156 -0.258736]

layer7_wq's input 
<N9nntrainer6TensorE at 0x5682dc5555c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wq's output 
<N9nntrainer6TensorE at 0x5682dc47b000>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.657963 0.508159 0.759416-0.493352 0.0679253 0.91612 0.356312 0.745763 0.297703]
============================
layer7_wk's input 
<N9nntrainer6TensorE at 0x5682dc557b30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wk's output 
<N9nntrainer6TensorE at 0x5682dc5578a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00883845 -0.00656046 -0.02105710.0099999 0.028946 0.0126508 0.00832559 -0.0132098 -0.0295955]
============================
layer7_wv's input 
<N9nntrainer6TensorE at 0x5682dc558920>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wv's output 
<N9nntrainer6TensorE at 0x5682dc5586b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0188292 0.010387 -0.0138226-0.0142297 0.00276319 0.00587439 0.00344935 -0.0125941 0.00343755]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.162186 0.815375 0.364137-0.829164 0.909493 -0.129271 0.161576 -0.810564 -0.262049]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a187f4b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer7_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc55ad70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer7_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc55acd0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer7_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55bdf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.793582 -0.504987 0.153731-0.204233 0.347298 -0.663184 0.426579 1.20156 -0.258736]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0163221 -0.0230185 0.00675105-0.00965002 0.0152515 -0.0313355 0.0206301 0.0554378 -0.0110747]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.168024302 0.6618694067 -0.4694300592 -0.07413705438 0.7391534448 -0.06975306571 0.1814451218 0.4088294804 0.2756572068 -0.01008156221 0.5435899496 0.4069769084 -0.6550350189 0.07319442928 -0.56976825 0.3659587801 0.6475477815 0.04731979966 0.2641719878 0.295361042 0.4828495979 0.6668714285 -0.2184385061 -0.2693095505 -0.4303425848 0.4009917974 0.5435461998 -0.2240395248 0.3005890548 0.2294455171 0.1688566357 1.472923517 0.4575823247 0.5258388519 0.4786459804 -0.03981018811 0.3397579789 -0.005647979677 0.05844898149 0.6566990614 -0.944694221 0.03326295689 1.298671484 1.307865739 0.6658383608 0.252460748 0.4188720584 0.521461308 0.061222516 0.3877601027 0.6422598958 0.1709300727 0.5699272752 -0.7041506171 -0.5168834329 -0.1764284968 -0.09934764355 0.5614067316 0.6186754107 0.6668535471 0.02402624302 1.682482243 0.5926005244 -0.3600988984 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03339649364 0.02013170719 0.006494766567 0.009643552825 0.02174926735 0.009685923345 0.01245188154 0.01563099958 0.01368203759 0.01028148923 0.01788596809 0.01560206991 0.005394563079 0.01117435098 0.005874720402 0.01497504953 0.01984544285 0.01088892762 0.01352579426 0.0139542995 0.01683190651 0.02023265883 0.008347717114 0.007933680899 0.006753655616 0.01550896745 0.01788518578 0.00830109138 0.01402744371 0.01306415349 0.01229611319 0.04530195147 0.01641193777 0.01757127605 0.01676130109 0.009980333038 0.01458778512 0.0103271734 0.01101079024 0.02002788708 0.00403793063 0.01073693391 0.03805749863 0.03840902448 0.02021176741 0.01336831506 0.01578876749 0.0174945239 0.01104137115 0.01530511118 0.01974077895 0.01232163515 0.01836329512 0.005136006977 0.006193765905 0.008705874905 0.009403472766 0.01820749603 0.01928065158 0.02023229748 0.01063821744 0.05586336926 0.01878440939 0.007245117333 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
35.95775986 35.94926071 35.93467331 35.93495941 35.94897079 35.93881607 35.92441559 35.94285583 35.9418602 35.93845749 35.94701767 35.94473267 35.93452454 35.93839645 35.93500519 35.94315338 35.94897461 35.9400177 35.94075012 35.94213104 35.94500732 35.94841003 35.93461609 35.93515778 35.92539215 35.94273376 35.94701385 35.93647766 35.93075943 35.94219589 35.94047165 35.97348022 35.94458771 35.94670105 35.94589233 35.93434143 35.94276428 35.93754959 35.9391861 35.94820404 35.9303093 35.93796158 35.96528244 35.96754074 35.94934082 35.93868256 35.94396591 35.94662476 35.93921661 35.93966675 35.94791794 35.93668365 35.94749451 35.93331146 35.93532562 35.93592834 35.93758011 35.9473381 35.94841003 35.94936371 35.9378624 35.98499298 35.94791412 35.93542099 

-------
======================
selected experts : 0, 4, 31, 42, 43, 61, 
layer7_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5969b0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0358682 0.0494057 -0.02676070.00325278 -0.0567075 -0.0131402 0.0472899 0.0318014 0.108935]

layer7_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55e510>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.757714 -0.455581 0.12697-0.20098 0.29059 -0.676324 0.473869 1.23336 -0.149801]

layer8_wq's input 
<N9nntrainer6TensorE at 0x5682dc59a250>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wq's output 
<N9nntrainer6TensorE at 0x5682dc5d3620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.17101 -0.653928 0.222739-0.618268 0.202001 -0.518507 -0.352742 -0.371231 0.40923]
============================
layer8_wk's input 
<N9nntrainer6TensorE at 0x5682dc59bfb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wk's output 
<N9nntrainer6TensorE at 0x5682dc59bd20>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0122512 -0.0240249 0.0049726-0.00696511 -0.00671129 0.0076463 -0.00612936 0.00283497 -0.00945466]
============================
layer8_wv's input 
<N9nntrainer6TensorE at 0x5682dc59cda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wv's output 
<N9nntrainer6TensorE at 0x5682dc59cb30>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0125965 -0.00244861 0.007529460.00303611 0.0145719 0.00140784 -0.0154647 -0.0179054 0.00261313]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.300697 -0.605349 -0.153066-0.639093 -0.530898 -0.166738 0.0599771 0.508568 -0.407451]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1475498
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer8_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc59f1f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer8_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc59f150>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer8_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a0270>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.757714 -0.455581 0.12697-0.20098 0.29059 -0.676324 0.473869 1.23336 -0.149801]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0170022 -0.0222015 0.005803-0.0102922 0.013441 -0.0348208 0.0242669 0.0607834 -0.0068052]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.04677072912 0.0153601896 0.2453148216 0.3004711866 -0.3885725439 0.05983536318 -0.01540975925 0.05687586218 0.2940652668  0.1836714 -0.01984599419 0.4423549771 0.2803600132 0.05182646215 0.1945592016 0.2888280451 0.1189836785 0.1493378282 -0.5161525607 0.266795069 -0.8293113112 0.2661831379 0.08042082191 0.07239897549 0.05997288972 0.3686698079 -1.536476731 -0.3078627288 -0.7882967591 0.24841474 0.2563607693 -0.04476862773 0.5374804139 -0.3126162291 4.726294041 0.2904126942 -0.4587142169 0.1429113746 0.2790945172 -0.3088897169 0.3767482638 0.1019092426 0.2512847781 0.5570003986 0.134382531 -0.3317438364 0.1961397231 -0.2455921173 -0.03754698113 0.2989471853 0.1975146532 0.2983741462 0.5875585675 0.003402953502 0.7836763859 -0.401131928 0.07859761268 0.2543839812 0.2182640433 0.1351471692 0.2176695615 0.1511563063 0.435500294 0.8533852696 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005646863021 0.005472250748 0.006887059659 0.007277598605 0.003653760534 0.005721122492 0.005306432024 0.005704214796 0.007231128402 0.006475340109 0.005282944534 0.008387016132 0.007132700179 0.005675485358 0.00654622633 0.007193353958 0.006069725845 0.006256790832 0.003216125071 0.007036597934 0.002351417439 0.007032294292 0.005840115249 0.005793454591 0.005721908063 0.007791236974 0.001159342472 0.003960882314 0.002449864987 0.006908441894 0.006963555235 0.005152905826 0.009224010631 0.003942098934 0.6082729101 0.007204764523 0.003406262491 0.00621671183 0.007123679388 0.003956816625 0.007854430005 0.005966967437 0.006928298157 0.009405835532 0.006163916085 0.003867413383 0.006556582171 0.004215370398 0.005190253723 0.007266516332 0.006565601565 0.007262352388 0.009697696194 0.005407207645 0.01179889683 0.003608158557 0.005829476751 0.006949805655 0.006703258492 0.006168629508 0.006699273828 0.006268180441 0.008329719305 0.01265072823 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.07797623 34.07875824  34.079216 34.08056259 34.07598495 34.0790062 34.07859039 34.07898712 34.07956314 34.07880402 34.0785675 34.07595062 34.07660294 34.07896042 34.07983017 34.07857132 34.07839966 34.07954025 34.04884338 34.07269287 34.07468033 34.07936096 34.07912445  34.078125 34.07805252 34.08012009 34.07444382 34.07629013 34.07573318 34.07923889 34.08024597 34.07843781 34.08155441 34.07627487 34.67488098 34.07858276 34.07669067 34.07854843 34.07945251 34.07533264 34.08018494 34.07925034 34.07925797 34.07983017 34.0794487 34.07715225 34.07984161 34.07654572 34.07752228 34.08055115 34.07984924 34.07959366 34.08107376 34.07868958 34.08031464 34.07689285 34.07911301 34.07928085 34.0790329 34.07945251 34.07998276 34.07859802 34.0758934 34.07258224 

-------
======================
selected experts : 32, 34, 43, 52, 54, 63, 
layer8_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5a3350>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0681935 -0.0987799 -0.1255480.266272 -0.427989 -0.0341151 -0.182963 0.2666 0.19531]

layer8_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a2c90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.68952 -0.554361 0.00142260.0652915 -0.137399 -0.71044 0.290906 1.49996 0.0455094]

layer9_wq's input 
<N9nntrainer6TensorE at 0x5682dc5e1750>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wq's output 
<N9nntrainer6TensorE at 0x5682dc5a2e70>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141972 0.0167292 -0.2640250.310849 -0.154788 0.0734234 -0.210784 -0.00362809 -0.189374]
============================
layer9_wk's input 
<N9nntrainer6TensorE at 0x5682dc5e3c80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wk's output 
<N9nntrainer6TensorE at 0x5682dc5e39f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00161957 -0.00211483 -0.01375779.81252e-05 -0.00883225 0.00970442 -0.0232949 -0.00734125 -0.0170646]
============================
layer9_wv's input 
<N9nntrainer6TensorE at 0x5682dc5e4a70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wv's output 
<N9nntrainer6TensorE at 0x5682dc5e4800>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.011892 -0.000943265 -0.006786920.0114438 -0.0217582 0.0152061 -0.00763955 -0.0135636 0.0142479]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0960421 0.105886 -0.05014460.40475 0.0836486 0.14951 0.166583 0.129202 0.182844]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1270488
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer9_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc5e6ec0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer9_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc5e6e20>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer9_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5e7f40>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.68952 -0.554361 0.00142260.0652915 -0.137399 -0.71044 0.290906 1.49996 0.0455094]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0163705 -0.0284533 6.91121e-050.00351246 -0.00667504 -0.0384142 0.0157296 0.0773991 0.00218593]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3258353472 0.183533296 -0.09342952073 -1.036007285 2.088111162 0.008346061222 -0.7364020944 -1.349478364 0.3679609299 0.1264469326 1.101921201 0.259608686 0.4678474665 -1.35572803 0.4126421809 -0.07927054912 0.1937977076 0.3577730358 -0.3610570133 -0.1297360808 0.3895307481 1.095702529 0.1365136802 0.2798104882 0.4129787385 0.1292768866 0.1402641833 -0.1215476245 -0.04986479506 -0.7106806636 0.4740997851 0.4535753131 -0.2847249806 1.092014313 -1.758917809 -0.2847560942 -0.2298212647 -0.6525506973 -0.1235622168 0.4583579898 -0.7284759879 0.4226437807 1.040506482 0.5733621716 0.317548275 -0.7666806579 -0.6158863902 -0.1706359237 -0.3159227073 0.4458977878 -0.1455331892 -0.06074886769 0.1500902325 -0.07550656796 -0.2112460881 -0.4560808241 -0.04254198447 -0.6656578779 -0.3927685916 -0.1671101898 -0.002543612383 0.1304136366 0.551289022 -0.1643009335 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009224582464 0.01535192225 0.01163802482 0.004534433596 0.1031122804 0.01288486551 0.006118428428 0.003314241767 0.01846114546 0.01450008154 0.0384603776 0.01656539738 0.02040040493 0.003293594345 0.01930471882 0.01180397905 0.01551031135 0.0182740204 0.008905332536 0.01122306567 0.01886367425 0.03822194785 0.0146467872 0.01690345071 0.01931121573 0.01454117335 0.01470182277 0.0113153439 0.01215623971 0.00627784431 0.02052835561 0.02011131682 0.009611711837 0.03808123246 0.002200730843 0.009611411951 0.01015418675 0.006653590593 0.01129257306 0.02020773478 0.006167116109 0.01949876361 0.03616941348 0.02267061174 0.01755353995 0.005935947411 0.006902066525 0.01077330578 0.009316476993 0.01995750144 0.01104716957 0.01202464849 0.01484699547 0.01184849534 0.01034456585 0.008098075166 0.01224558335 0.006566950586 0.008627361618 0.01081135683 0.01274531428 0.01455771364 0.02217568457 0.01084177103 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.46111679 34.46724319 34.45780945 34.45547485 34.55405045 34.4647789 34.43607712 34.45520782 34.47035217 34.46543884 34.49035263 34.46846008 34.47229385 34.45518494 34.47119904 34.46369553 34.46644974 34.47016525 34.45984268 34.46311569 34.46503448 34.49011612 34.46558762 34.46688843 34.47120285 34.46643448 34.4665947 34.46320724 34.45355988 34.45817184 34.47241974 34.47200394 34.46055222 34.4890213 34.45409393 34.45292282 34.45632553 34.45759201 34.46318436 34.4720993 34.43421936 34.47138977 34.48329544 34.47360992 34.46944809 34.45782852 34.45879364 34.45789719 34.45930099 34.47185135 34.45817184 34.46391678 34.46673965 34.4637413 34.45937729 34.45808411 34.46127701 34.45750427 34.45861435 34.46175003 34.46273041 34.46644974 34.47406769 34.46082687 

-------
======================
selected experts : 4, 10, 21, 33, 42, 43, 
layer9_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5eb020>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.104579 -0.000398263 -0.07572780.115588 0.014312 0.0643511 0.122948 -0.0377023 0.091618]

layer9_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5ea960>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.584942 -0.554759 -0.07430520.18088 -0.123087 -0.646088 0.413854 1.46226 0.137127]

layer10_wq's input 
<N9nntrainer6TensorE at 0x5682ded33210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wq's output 
<N9nntrainer6TensorE at 0x5682dc5eab40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37707 -0.407332 -0.004689360.264799 -0.450686 0.237675 0.354465 0.042499 -0.208016]
============================
layer10_wk's input 
<N9nntrainer6TensorE at 0x5682ded34f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wk's output 
<N9nntrainer6TensorE at 0x5682ded34ce0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0208244 0.0187902 -0.0183501-5.44079e-05 0.00482989 0.0189981 -0.00186447 -0.0230889 0.00503917]
============================
layer10_wv's input 
<N9nntrainer6TensorE at 0x5682ded35d60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wv's output 
<N9nntrainer6TensorE at 0x5682ded35af0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0224915 0.00636522 0.0154213-0.00975636 0.0199064 0.0167431 -0.0279089 -0.0151201 0.023924]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.551885 -0.0593583 0.1413870.223942 0.267393 0.433714 -0.258326 -0.246413 0.212482]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a106b478
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer10_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded38210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer10_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded38170>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer10_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded39290>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.584942 -0.554759 -0.07430520.18088 -0.123087 -0.646088 0.413854 1.46226 0.137127]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.01385 -0.0297634 -0.003742470.0101995 -0.00619941 -0.0366087 0.0237897 0.0788518 0.00683152]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.2405900508 0.2403998226 0.002393446397 0.09837586433 1.045801878 -0.8216309547 -1.209175825 0.3056552112 -0.2752718031 0.3853158951 -1.040553689 -0.4904887974 0.2650624514 -0.7685959339 -0.8298601508 -1.237736106 0.03745195642 -0.165141806 -0.4367792606 -0.7191370726 -0.961849153 0.3766517937 -0.4394464791 0.6722314358 -0.05634330213 0.07336346805 0.2354294658 -0.00606180029 -1.113972902 0.9323561192 -0.3637063205 0.3454566598 0.2466523647 0.2701610923 0.3343005478 -0.5620473027 -1.098581672 0.1022080481 -0.1563752741 0.02149196714 0.1330704093 -1.023319602 -0.3335804641 -0.1875314862 0.009166814387 -0.7846198082 0.1157286912 -0.9036570191 -0.8283277154 1.769645333 -0.7296331525 -0.4721302688 -0.02899205871 0.1692908704 0.2316015065 1.04218781 -0.1277344823 0.7623437047 -0.3691411912 0.1704837829 -0.1390079856 0.9013450146 0.08754011244 0.1399177164 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01815791614 0.01815446094 0.01430930384 0.01575081982 0.0406223461 0.006276959088 0.004260303918 0.01937864535 0.01084001828 0.02098551393 0.005042806268 0.008741025813 0.01860776357 0.006618842017 0.006225516088 0.004140350502 0.01481986418 0.01210204791 0.009223339148 0.006954433862 0.00545573514 0.02080447786 0.00919877179 0.02795924433 0.01349302847 0.01536173839 0.01806444861 0.01418882515 0.004685831722 0.03626570851 0.009922552854 0.0201654993 0.01826832816 0.01870287955 0.01994178072 0.008137387224 0.004758510739 0.01581129432 0.01220860705 0.01458521653 0.01630687527 0.005130467936 0.01022602711 0.01183409803 0.01440655533 0.006513629574 0.01602652669 0.005782634486 0.006235063076 0.08377727866 0.006881820504 0.008902981877 0.01386717334 0.01690834761 0.01799543202 0.04047580063 0.0125633264 0.03059572168 0.009868769906 0.01692852937 0.01242249086 0.03515832499 0.01558106858 0.0164189171 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.12060547 33.12155533 33.11771011 33.11915207 33.1440239 33.10013962 33.1076622 33.12277985 33.11233521 33.12438583 33.10844421 33.11118698 33.12200928 33.10429764 33.10581207 33.10754013 33.11822128 33.11454773 33.1059494 33.10749435 33.10790253 33.12420654 33.11259842 33.12563705 33.11403275 33.1139946 33.1205101 33.11759186 33.10713196 33.13966751 33.11236954 33.12356567 33.12166977 33.12210464 33.12334442 33.10963058 33.10625076 33.1192131 33.11560822 33.11798477 33.1015892 33.08945847 33.11362839 33.11523438 33.1178093 33.10800934 33.11847305 33.10918427 33.10486603 33.18717957 33.1064682 33.11230469 33.11726761 33.11840057 33.12139511 33.14387512 33.11405563 33.12922668 33.11136246 33.11937714 33.11582184 33.1366539 33.11898041 33.11981964 

-------
======================
selected experts : 4, 29, 49, 55, 57, 61, 
layer10_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded3c110>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00871513 -0.0179093 -0.129039-0.00419578 -0.0721665 -0.0473022 0.0376891 -0.0830591 0.0259834]

layer10_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded3bb90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.576227 -0.572668 -0.2033450.176684 -0.195253 -0.693391 0.451544 1.3792 0.163111]

layer11_wq's input 
<N9nntrainer6TensorE at 0x5682ded7c3b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wq's output 
<N9nntrainer6TensorE at 0x5682ded3ba40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.574647 -0.344996 -0.3160790.0666121 0.327954 0.336796 -0.180087 0.539557 0.764458]
============================
layer11_wk's input 
<N9nntrainer6TensorE at 0x5682ded7e110>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wk's output 
<N9nntrainer6TensorE at 0x5682ded7de80>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0108217 0.0526808 0.006898240.0209765 0.0171261 0.0374855 -0.0384892 0.0369667 0.0138322]
============================
layer11_wv's input 
<N9nntrainer6TensorE at 0x5682ded7ef00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wv's output 
<N9nntrainer6TensorE at 0x5682ded7ec90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00918804 0.00942161 0.0280262-0.0530578 0.0101649 0.00276343 0.00300308 0.0247157 0.0975801]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.659885 0.117442 -0.2276850.229134 0.314021 -0.349823 0.467471 -0.324074 -0.732947]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0e66468
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer11_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded813b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer11_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded81310>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer11_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded82430>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.576227 -0.572668 -0.2033450.176684 -0.195253 -0.693391 0.451544 1.3792 0.163111]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0134085 -0.0321063 -0.01051490.0103385 -0.0102559 -0.0415165 0.027036 0.0765732 0.00839005]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8536322117 -0.350666672 -0.2271159291 -0.814027369 -0.24312675 -0.4555317461 -0.1419058442 2.084069014 -0.5543870926 0.160293147 -0.3175723851 -1.9721241 -0.2567070723 -1.214590073 -0.7125858068 0.09249140322 -0.09203302115 -0.7283654809 1.177680373 -0.4151083827 -0.1389609128 0.09961105138 -1.649830222 -0.6365466118 -0.4705213308 -0.9583889842 -0.7093999982 -1.075470805 -0.6670421362 -0.1231312156 -0.5486690998 -0.05667171255 0.2446939349 -0.4024503827 -0.2572669983 -0.4099058807 -0.1073041111 -1.158459306 -0.703230381 -0.5467608571 -0.07921869308 -0.1965308785 -2.247526884 -0.1062458828 -0.2751447856 -1.356668234 -0.3595725298 -0.07924947888 -1.645887733 -0.6230176091 -1.833443165 -0.3092767894 -0.6894958615 -0.2229477465 -0.4004736543 0.674198091 -0.08846428245 -0.1153771728 -0.8708809018 -1.661915421 -0.03361873329 0.5712429285 -1.02976048 -0.3162067533 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007948376238 0.01314357575 0.0148720555 0.00826948788 0.01463583857 0.01183508057 0.01619486138 0.1500050426 0.01072108932 0.02190889977 0.01358583197 0.002597307786 0.0144384224 0.005540084559 0.009152381681 0.02047267929 0.01702302694 0.009009093046 0.06059911102 0.0123232957 0.01624262705 0.0206189584 0.003585040569 0.009875463322 0.01165900286 0.007157857995 0.009181586094 0.006367004942 0.009578852914 0.01650178619 0.01078256872 0.01763575152 0.02383830771 0.01248027664 0.01443033852 0.01238757465 0.01676503941 0.005859945901 0.009238407016 0.01080316398 0.01724256761 0.01533394586 0.001972048776 0.01678278856 0.01417464856 0.004806319252 0.01302704029 0.01724203676 0.00359920226 0.01000997704 0.002983677667 0.0136990035 0.009366167709 0.01493417192 0.01250497065 0.0366274491 0.01708388515 0.01663023792 0.007812452968 0.003541974584 0.01804703102 0.03304409236 0.006664795801 0.01360439882 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.54969406 28.55584335 28.55804825 28.53952599 28.55208969 28.54166031 28.55126572 28.69365883 28.55199051 28.5617485 28.55723953 28.5462513 28.55284691 28.5487175 28.55232811 28.55649757 28.56019974 28.55218506 28.59614563 28.5512085 28.55989647 28.5614109 28.54676247  28.543993 28.55197525 28.54699707 28.54806709 28.53809929 28.54703331 28.55967903 28.5501442 28.55985832 28.56701469 28.55565643 28.55713081 28.54984283 28.55994225  28.546175 28.55098534 28.55397987 28.56041908 28.55707932 28.54514885 28.55280685 28.55544472 28.54607582 28.55334282 28.56041908 28.54725266 28.54794121 28.54568291 28.55401421 28.5520668 28.55811119 28.55568123 28.57932663 28.55978394 28.55980682 28.54622078 28.5467186 28.56074715 28.57574463 28.54936409 28.55630493 

-------
======================
selected experts : 7, 9, 18, 32, 55, 61, 
layer11_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded85530>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.333239 -0.0966277 0.0164065-0.155013 -0.154962 0.0912206 0.0206473 0.0287376 0.173099]

layer11_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded84d30>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.242987 -0.669296 -0.1869380.0216705 -0.350215 -0.60217 0.472191 1.40794 0.336209]

layer12_wq's input 
<N9nntrainer6TensorE at 0x5682dedc4470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wq's output 
<N9nntrainer6TensorE at 0x5682ded84be0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.242823 0.417797 0.07170260.586705 0.501475 0.360597 0.460942 0.30801 0.72607]
============================
layer12_wk's input 
<N9nntrainer6TensorE at 0x5682dedc61d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wk's output 
<N9nntrainer6TensorE at 0x5682dedc5f40>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0059719 0.0473741 0.01258060.0277794 0.0201364 0.0578011 0.0204722 0.00987752 -0.0366265]
============================
layer12_wv's input 
<N9nntrainer6TensorE at 0x5682dedc6fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wv's output 
<N9nntrainer6TensorE at 0x5682dedc6d50>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00766343 -0.0528842 0.0304772-0.00113746 -0.0263957 0.00103918 0.00807294 -0.021785 0.00503729]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0914224 0.474509 0.3818950.451132 0.32612 -0.524551 -0.184484 -0.522783 -0.728535]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0c61458
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer12_attention_out's input 
<N9nntrainer6TensorE at 0x5682dedc9470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer12_attention_out's output 
<N9nntrainer6TensorE at 0x5682dedc93d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer12_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dedca4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.242987 -0.669296 -0.1869380.0216705 -0.350215 -0.60217 0.472191 1.40794 0.336209]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00532087 -0.0374544 -0.009399940.00127128 -0.0179888 -0.0363026 0.0284667 0.0772668 0.0171785]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.515114903 0.1988955289 -0.9148083925 0.4729863703 0.09639342874 -0.6808546782 0.1147310883 -0.4401502907 -0.1680116206 -0.3849343359 0.007665990852 0.2398532033 -0.804179132 -1.055164337 -0.8419640064 0.1758016348 -0.00687226234 -0.1439996511 -1.990939736 0.1290771216 0.2109279782 -1.326081753 0.06457764655 -1.200477242 -0.4049041867 -0.09832254797 -0.5622937083 -0.5176398158 -0.5233002305 -1.259488463 -1.66703105 -1.807760835 -1.113789678 -1.614046335 0.0009765264113 1.904020071 -0.4413326979 -0.8838368654 -0.04244723171 0.2512405515 -0.04221006855 -0.5307527184 -0.7680432796 -1.219922185 -0.0778702423 -1.0996387 -0.5135358572 -0.5197799802 -0.987991631 -0.5169560909 0.6045063138 -0.9295527935 -0.9713642001 -0.537006259 0.2595245838 0.04104918987 -0.4304583073 -1.368692636 0.4785416722 -0.1011550277 -0.1014918387 2.315051079 -0.7431070209 -0.141637668 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003567925189 0.01980618946 0.00650317641 0.02605176158 0.01787659712 0.008217320777 0.01820743643 0.01045362372 0.01372319274 0.0110470634 0.01635878161 0.02063424699 0.007263921667 0.005651577841 0.006994576193 0.01935403235 0.01612267829 0.01405670401 0.002217009896 0.01847052574 0.02004594728 0.004310342018 0.01731679216 0.004887211602 0.01082864497 0.01471366175 0.009251681156 0.009674167261 0.009619562887 0.004607154522 0.003065062687 0.002662693616 0.005329777021 0.003231843235 0.01624971814 0.1089750677 0.01044126973 0.006707741413 0.01555919368 0.02087055892 0.01556288544 0.009548139758 0.007531210314 0.004793098196 0.01501769014 0.005405734293 0.009713950567 0.009653486311 0.006044249982 0.009680784307 0.02971361391 0.006407993846 0.006145589985 0.009488614276 0.02104417048 0.01691411063 0.01055543404 0.004130532965 0.02619688772 0.0146720456 0.01466710307 0.1643749475 0.007721371017 0.0140899457 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
30.80790329 30.82461739 30.8108387 30.82991028 30.82125664 30.81064415 30.82301903 30.81478882 30.81472015 30.81585884 30.82117081 30.82115364 30.81207466 30.8085556 30.80989838 30.82368851 30.8209343 30.81791496 30.80702782 30.82232857 30.82104301 30.80912209 30.8221283 30.80922127 30.8156395 30.81952477 30.81311035 30.81448555 30.81252289 30.80798721 30.80739975 30.80747414 30.80918694 30.80327415 30.82058525 30.90997124 30.81477547 30.81056595 30.81989288 30.82520485 30.8198967 30.81435966 30.80948257 30.80912781 30.8193531 30.80974007 30.81309509 30.8058815 30.80894852 30.81449318 30.83404922 30.80835915 30.81048012 30.81143951 30.82585526 30.82172585 30.81488991 30.80703545 30.83053207 30.81900597 30.81947899 30.96918678 30.80108833 30.81747055 

-------
======================
selected experts : 3, 35, 50, 54, 58, 61, 
layer12_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dedcd730>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.261759 0.0260365 0.00151380.0209557 -0.246369 0.0859744 -0.00723364 -0.109461 0.183084]

layer12_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dedccdf0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0187714 -0.64326 -0.1854240.0426262 -0.596584 -0.516196 0.464957 1.29847 0.519293]

layer13_wq's input 
<N9nntrainer6TensorE at 0x5682dee397f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wq's output 
<N9nntrainer6TensorE at 0x5682dedccca0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.544315 0.211178 0.4857970.142756 0.287921 -0.0756668 -0.190495 0.334301 0.515609]
============================
layer13_wk's input 
<N9nntrainer6TensorE at 0x5682dc471a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wk's output 
<N9nntrainer6TensorE at 0x5682dc4717a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00536536 0.0270588 0.0105784-0.0175378 -0.0381201 -0.00524855 -0.0441706 0.0075387 0.00437258]
============================
layer13_wv's input 
<N9nntrainer6TensorE at 0x5682dc472820>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wv's output 
<N9nntrainer6TensorE at 0x5682dc4725b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0538234 0.00921317 -0.00105804-0.0519059 -0.0114752 0.000672776 0.0390768 0.0122256 -0.005239]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.271619 0.516815 0.484458-0.147237 -0.0948241 -0.282192 0.352819 -0.153506 -0.493536]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0a5c448
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer13_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc474cd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer13_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc474c30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer13_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc475da0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0187714 -0.64326 -0.1854240.0426262 -0.596584 -0.516196 0.464957 1.29847 0.519293]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.000411249 -0.0366582 -0.009470430.00255523 -0.0306305 -0.0320535 0.0282469 0.0722525 0.0266621]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8210696578 0.01764702797 0.1705377102 -1.32864821 -0.6457030773 0.2107856125 -0.5317567587 0.4186590016 0.1665709466 -0.09206339717 -0.7631891966 0.5217927694 -0.4000129104 -0.0318245478 -0.6582522988 -0.6459796429 -0.1373912543 -0.6905651093 -0.9183356166 -0.1151067689 -1.146143317 -1.225360155 -0.8136463761 -1.787121296 -0.08054890484 0.2638849914 0.1978272647 -1.86265564 -0.3499395549 -1.720562339 -0.5657072663 -1.050999761 -0.5782107711 0.1856319308 -0.4710305333 0.3538194895 -0.02123886347 0.2299393564 -0.5446910262 -0.2708410919 0.1396059841 -0.009761870839 -0.4558828175 -0.8684517741 -1.109177709 -1.336254835 -0.4432338178 -0.7737660408 0.2498282343 3.344063044 0.06941227615 0.2823231816 -0.2373957634 -0.1085118875 0.5851342678 -0.1705833822 -0.638215065 -0.5434451699 0.4397984147 -0.7761206031 -0.911747992 -1.731405616 -0.6584652066 -1.277460694 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.00578087708 0.01337345783 0.01558271982 0.003479806008 0.00688897213 0.01622268371 0.007720416412 0.01997105218 0.01552102901 0.01198386867 0.006125349551 0.02214070037 0.008807573467 0.01272794977 0.006803059019 0.006887066178 0.01145279221 0.006586750038 0.005245073233 0.0117108766 0.004176533781 0.003858446609 0.005823947955 0.002200101269 0.01212265249 0.01710737869 0.01601382345 0.002040040214 0.009259826504 0.002351521747 0.007462702692 0.004593420774 0.007369973231 0.01581971347 0.008203774691 0.01871722937 0.01286340132 0.01653640531 0.007621199358 0.01002201065 0.01510809734 0.01301188301 0.008328989148 0.005513353739 0.004333809949 0.003453437472 0.008435011841 0.006060902029 0.01686858758 0.3722955287 0.01408396848 0.01742573269 0.01036286913 0.0117883645 0.02358849533 0.01107888855 0.00694074994 0.007630701177 0.02039772272 0.00604665 0.005279738922 0.002326161368 0.006801612675 0.003662566189 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.72777176 28.73631859 28.73805046 28.72642326 28.72840309 28.73821259 28.73018837 28.74196243 28.73894119 28.73540497 28.72525406 28.73697853 28.72984505 28.73471832 28.72784042 28.73030853 28.73439789 28.7252388 28.72866631 28.73513222 28.72664452 28.72489548 28.72781372 28.72514343 28.73602104 28.74005127 28.73609734 28.72450829 28.73220444 28.72434235 28.72993088 28.72753716 28.73031425 28.73876381 28.72637939 28.74023056 28.73580742 28.73709679 28.73104286 28.73296547 28.73852921 28.73595619 28.72841263 28.7284584 28.72489357 28.72592163 28.73137856 28.7237606 28.73933601 29.09571648 28.73750496 28.7403698 28.73330688 28.73473167 28.74653244 28.73450089 28.72940826 28.72914505 28.74286461 28.72756004 28.7282238 28.72479439 28.7302227 28.72708321 

-------
======================
selected experts : 7, 11, 35, 49, 54, 58, 
layer13_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee45420>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.337035 -0.127108 -0.2176710.144968 -0.150565 0.148819 0.00124518 -0.257126 0.256935]

layer13_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc478790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.355807 -0.770368 -0.4030950.187594 -0.747149 -0.367376 0.466202 1.04135 0.776228]

layer14_wq's input 
<N9nntrainer6TensorE at 0x5682dee98c10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wq's output 
<N9nntrainer6TensorE at 0x5682dc478730>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.310121 0.128975 0.07752420.61004 -0.194837 0.0533598 0.711713 0.43598 -0.135811]
============================
layer14_wk's input 
<N9nntrainer6TensorE at 0x5682dee9aab0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wk's output 
<N9nntrainer6TensorE at 0x5682dee9a7d0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00563616 -0.0128344 0.0348296-0.0478778 0.0302346 0.0681164 0.063781 -0.00346803 -0.0459049]
============================
layer14_wv's input 
<N9nntrainer6TensorE at 0x5682dee9b8a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wv's output 
<N9nntrainer6TensorE at 0x5682dee9b630>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0533198 0.0518202 0.0305033-0.0279568 0.0927579 0.00337922 0.0188315 0.0349787 0.00499831]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.149066 0.30098 0.3995670.467446 0.0663188 0.190816 -0.308579 -0.775496 0.144568]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2eb6568
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer14_attention_out's input 
<N9nntrainer6TensorE at 0x5682dee9dda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer14_attention_out's output 
<N9nntrainer6TensorE at 0x5682dee9dd00>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer14_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dee9ee70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.355807 -0.770368 -0.4030950.187594 -0.747149 -0.367376 0.466202 1.04135 0.776228]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.00819254 -0.0462011 -0.02115290.0116523 -0.0396076 -0.0239998 0.0294573 0.0596645 0.0411491]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3146974742 -0.7524214983 -0.5073871613 1.047515512 -1.900506973 -0.5483075976 -0.8108694553 -1.170781374 -0.3059524596 -2.787629366 -0.9951738119 -0.8819032907 -0.03284237161 -1.08283782 -1.844440937 -0.9865199924 -0.8003217578 -1.080387592 0.4031157792 -1.560947061 -0.3382537067 -0.08784183115 0.1755543947 -0.5047937036 -1.889325738 -0.3198569417 -0.09724221379 -0.5367322564 -0.489025116 -0.007524366491 -2.364694357 -2.770090342 -0.593550086 -1.921137214 -0.9594412446 -0.5471981168 -0.2572587132 -1.150555253 -0.003611662425 -0.3223264217 -0.2941896915 0.8458377719 0.2309077829 -1.740465164 -0.182038337 0.1403097957 -0.5310169458 -2.140178204 -1.20871079 0.02241208963 -1.441024542 -1.899502873 -1.541872621 0.405549556 -0.9199211597 1.239122152 -0.1296442747 -0.2416889817 -0.3628253043 -0.6105259061 -1.894799471 2.003627777 -1.867062569 -0.0566174984 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01456574071 0.00940224342 0.01201291662 0.05687666684 0.002982800826 0.01153126452 0.00886845123 0.006187853869 0.01469367556 0.001228434499 0.007375736721 0.008260346018 0.01930814981 0.006756681949 0.003154811682 0.007439842448 0.008962488733 0.006773257162 0.02985897474 0.004188835621 0.01422663592 0.01827489026 0.02378188446 0.01204411406 0.003016339615 0.01449078415 0.01810390316 0.01166552026 0.01223553717 0.01980323717 0.001875124522 0.001250170055 0.0110211866 0.002921894891 0.007644057274 0.01154406741 0.01542687323 0.006314285565 0.01988087222 0.01445504278 0.01486753579 0.04648862034 0.02513540722 0.003500495572 0.01663204841 0.02295829915 0.01173238363 0.002347125672 0.005957548507 0.02040503547 0.004722532351 0.00298579759 0.004269502126 0.02993173338 0.007952199318 0.06888867915 0.01752669737 0.01566894539 0.01388132386 0.01083567459 0.002999873599 0.1479682177 0.003084245836 0.01885451004 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.17491913 27.17023087 27.17188835 27.21484566 27.16142845 27.17188454 27.16969872 27.16510963 27.17552376 27.16205788 27.16677475 27.16718292 27.18061447 27.16186333 27.15873909 27.1668396 27.1688385 27.16664886 27.19116592 27.16168022 27.17457962 27.17910385 27.18461227 27.16762924 27.16384506 27.17484283 27.1789341 27.17249489 27.17306519 27.18111038 27.16175079 27.16112518 27.1718502 27.16279793 27.16799736 27.17094231 27.17387199 27.1661911 27.18070984 27.1748085 27.17569733 27.20684052 27.1835804 27.16289902 27.17746162 27.18331146 27.17256165 27.15888596 27.16535568 27.18123436 27.16412163 27.16238403 27.16462135 27.19076157 27.16878128 27.22876549 27.17835617 27.17602158 27.16898918 27.17071152 27.16335297 27.30927467 27.15390015 27.17968369 

-------
======================
selected experts : 3, 18, 41, 53, 55, 61, 
layer14_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deea2ef0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.415789 0.0136436 -0.07160960.00549867 -0.0739112 0.0502533 -0.0109407 -0.342321 0.111997]

layer14_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deea2970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.771596 -0.756724 -0.4747040.193093 -0.82106 -0.317123 0.455262 0.699027 0.888225]

layer15_wq's input 
<N9nntrainer6TensorE at 0x5682deedb770>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wq's output 
<N9nntrainer6TensorE at 0x5682deea2820>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.246993 -0.0980489 0.2560660.161456 0.156527 -0.0754717 0.249379 -0.286325 0.0365459]
============================
layer15_wk's input 
<N9nntrainer6TensorE at 0x5682deedd610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wk's output 
<N9nntrainer6TensorE at 0x5682deedd330>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0280981 0.0160434 -0.020244-0.0687225 -0.0147608 0.0326301 -0.00132725 -0.034869 -0.0117971]
============================
layer15_wv's input 
<N9nntrainer6TensorE at 0x5682deede400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wv's output 
<N9nntrainer6TensorE at 0x5682deede190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.027509 -0.0128741 -0.01039650.00837937 0.0063715 0.011103 0.00334155 -0.0227479 -0.0511434]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.121792 -0.236191 0.302667-0.0055404 -0.085809 -0.151107 -0.371216 0.0798136 -0.022984]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2baed50
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer15_attention_out's input 
<N9nntrainer6TensorE at 0x5682deee0900>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer15_attention_out's output 
<N9nntrainer6TensorE at 0x5682deee0860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer15_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682deee19d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.771596 -0.756724 -0.4747040.193093 -0.82106 -0.317123 0.455262 0.699027 0.888225]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0191901 -0.0468997 -0.0252540.0122755 -0.0443351 -0.0211728 0.0291847 0.0401629 0.0477256]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-2.068495512 0.06064449251 -0.2854043543 -2.37253499 -0.5997478962 -1.363569617 -0.4294730723 0.3454683125 -2.21794486 -0.3285040855 -1.38233602 -0.9914281368 -1.088238001 -0.1005136892 0.2885901928 -0.3372989893 0.335038662 0.4939994216 -0.1296791434 -1.760103464 -1.571818233 -0.3351227045 0.3463970125 -1.455619454 4.249740124 -1.797733426 -0.3779758513 0.04171392322 -2.804435015 -1.001756907 -0.419159323 -0.5463706255 -1.305555463 -0.07715242356 0.08199023455 -0.2658957541 -1.742617965 -0.8322230577 0.1008040458 0.6929460168 0.6067660451 -1.113214135 -0.4716964066 0.1628283262 -0.9055261016 -3.344549894 -1.85081017 -1.61446631 -0.8867996931 -0.2743210196 -1.716823936 0.4269520342 -1.464987159 -0.145443514 -2.872466326 -0.7048119903 0.2177646607 -0.8569467664 -1.120281219 -0.7068556547 0.1902229339 -0.1809620261 -2.570884466 -1.580011606 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001140439766 0.009588398971 0.006783580873 0.0008414522745 0.004953830503 0.002307903487 0.005873415619 0.01274804026 0.0009821263375 0.006497419905 0.002264996292 0.003348395927 0.003039433155 0.008161237463 0.01204319112 0.006440527271 0.01261577383 0.01478937082 0.00792664662 0.001552405418 0.001874029636 0.006454559043 0.01275988482 0.002104946179 0.6324805021 0.001495074364 0.00618380215 0.009408589453 0.00054633338 0.003313987516 0.005934304558 0.005225438625 0.002445755294 0.008354138583 0.009795268998 0.006917216349 0.001579788863 0.003926256206 0.009981297888 0.01804475859 0.01655478589 0.002964461222 0.005630582571 0.0106199868 0.00364874443 0.0003183383669 0.001417789841 0.001795786549 0.003717715852 0.00685918238 0.00162106799 0.01383029483 0.002085319255 0.007802668959 0.0005104016745 0.004459770396 0.01121973339 0.00383037352 0.002943584695 0.004450664856 0.0109149348 0.007530393079 0.0006900612498 0.001858737436 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.89215469 25.90060234 25.88921547 25.89090157 25.89453697 25.88950729 25.89736366 25.90423965 25.89295006 25.89560509 25.8942337 25.89007187 25.89405441 25.89917564 25.90401077 25.89697838 25.90458298 25.90675735 25.90037155 25.89256668 25.89336586 25.89556122 25.90186691 25.89359665 26.52111053 25.89346313 25.89767456 25.90137672 25.89060593 25.89289665 25.8974247 25.8957634 25.89393616 25.89936829 25.90176392 25.89697838 25.89163971 25.8958931 25.90194893 25.89475441 25.90852165 25.88968658 25.89712143 25.90354156 25.89561653 25.89180946 25.89195442 25.88518143 25.89520836 25.8988266 25.89263535 25.90055275 25.89262199 25.89977074 25.89104843 25.89642715 25.9031868 25.89293671 25.89204979 25.89307976 25.90288353 25.89902115 25.88979721 25.88381386 

-------
======================
selected experts : 17, 22, 24, 39, 40, 51, 
layer15_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deee4f80>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.420765 0.217941 0.222422-0.14563 -0.174842 -0.00262449 -0.196889 0.0361661 0.230033]

layer15_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deee44b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.19236 -0.538783 -0.2522820.0474629 -0.995903 -0.319747 0.258373 0.735193 1.11826]

layer16_wq's input 
<N9nntrainer6TensorE at 0x5682def24710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wq's output 
<N9nntrainer6TensorE at 0x5682deee4360>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.355268 0.197313 -0.389867-0.372069 -0.160161 -0.638674 0.37698 0.298585 0.319134]
============================
layer16_wk's input 
<N9nntrainer6TensorE at 0x5682def26470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wk's output 
<N9nntrainer6TensorE at 0x5682def261e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0315604 -0.0124703 -0.07055450.0248561 0.0810568 -0.00435547 0.0442637 0.0670922 -0.00547626]
============================
layer16_wv's input 
<N9nntrainer6TensorE at 0x5682def27260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wv's output 
<N9nntrainer6TensorE at 0x5682def26ff0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.037477 0.0743753 0.0621462-0.163479 0.00509745 -0.0277609 -0.0101428 -0.0310047 -0.0741977]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.39747 -0.0846521 -0.530096-0.0971073 -0.626482 0.202673 -0.122911 -0.46493 -0.307356]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a20934f8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer16_attention_out's input 
<N9nntrainer6TensorE at 0x5682def29710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer16_attention_out's output 
<N9nntrainer6TensorE at 0x5682def29670>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer16_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def2a790>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.19236 -0.538783 -0.2522820.0474629 -0.995903 -0.319747 0.258373 0.735193 1.11826]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0341949 -0.0347478 -0.01433670.00316139 -0.0565951 -0.0224808 0.0170047 0.0437227 0.0635483]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.05211476982 -0.6416469216 -2.025191069 -0.1436697394 -0.6531259418 -0.6036865711 0.08149973303 0.3208004832 -3.047298193 -1.111545444 -1.02949369 -3.965992212 -1.467410803 -1.43652916 -1.315266013 -1.292850018 -1.682392359 -2.04670763 -1.666963696 0.1243281886 -0.3349597156 0.08837586641 -1.756295681 -0.1972560436 -0.1667171866 -0.7029651999 -1.273959517 -0.3595299125 -1.542718649 -0.3003361225 -0.304392606 -0.9442470074 -1.322111726 -0.8383237123 -1.063028097 -0.2437692136 0.8430628181 -0.2073403895 -1.313209176 -0.1361294836 2.023962736 -1.132570505 0.9384945631 -2.073050261 -0.5370718837 -2.903338671 -0.1327673644 -1.958109021 -3.113909483 -1.157161355 -1.999120355 -0.06422943622 -0.9717085361 -1.779744625 -0.4174019694 0.0480931066 -1.076514125 -2.244340897 -0.8149682879 -0.7359886765 -0.1602908522 -0.7065141797 0.3943091333 2.630728483 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01854330115 0.009265955538 0.002322868444 0.01524610445 0.009160199203 0.009624456055 0.01909628138 0.02425916307 0.0008358515333 0.005791831296 0.006287102588 0.0003335380461 0.004057565238 0.004184823018 0.004724340513 0.004831436556 0.003272654954 0.002273422666 0.003323538462 0.01993191056 0.0125916535 0.01922804117 0.003039516509 0.01445062645 0.01489873882 0.008714850992 0.004923572764 0.01228604373 0.003763220971 0.01303525735 0.01298248675 0.006846563891 0.00469210837 0.007611574605 0.006079763174 0.01379387639 0.04089700431 0.01430563349 0.004734066781 0.01536150184 0.1332139671 0.005671328399 0.0449921675 0.002214316046 0.01028742176 0.0009652726003 0.01541323401 0.002484036377 0.0007819882012 0.005533565767 0.002384223277 0.01650666818 0.00666110497 0.0029690722 0.01159520727 0.01846887544 0.005998322275 0.001865730737 0.007791439071 0.0084317578 0.01499479171 0.00868397858 0.02610959671 0.2443795055 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
23.54921722 23.53088188 23.53299713 23.54591942 23.52934647 23.5407753 23.55024719 23.54730606 23.52578926 23.53694344 23.53505516 23.53053093 23.53473091 23.53247643 23.52490997 23.5264473 23.53299332 23.53056526 23.53304291 23.55012894 23.53706932 23.5503788 23.53371429 23.54464722 23.54557228 23.53223801 23.53464317 23.54343605 23.53443718 23.54180336 23.5436573 23.53704453 23.53393745 23.53780937 23.53580093 23.54446793 23.5682354 23.54593277 23.53588486 23.54508209 23.66341019 23.53300858 23.57518959 23.53241158 23.53905678 23.53021049 23.54608727 23.53268051 23.53145599 23.53477859 23.52924538 23.54765701 23.53399849 23.5255394 23.54274559 23.55009651 23.53667259 23.5277729 23.53751183 23.53862953 23.54566956 23.53840446 23.55726051 23.7760067 

-------
======================
selected experts : 7, 36, 40, 42, 62, 63, 
layer16_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def2d9d0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.431278 -0.0191207 -0.0520095-0.191345 -0.0821877 0.0657345 0.0929842 -0.17835 0.119429]

layer16_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def2d090>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.62364 -0.557904 -0.304292-0.143882 -1.07809 -0.254013 0.351357 0.556844 1.23769]

layer17_wq's input 
<N9nntrainer6TensorE at 0x5682def6d870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wq's output 
<N9nntrainer6TensorE at 0x5682def2cf40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0986049 0.941314 -0.409761-0.228745 -0.439152 -0.517336 0.20517 0.411878 0.786435]
============================
layer17_wk's input 
<N9nntrainer6TensorE at 0x5682def6f5d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wk's output 
<N9nntrainer6TensorE at 0x5682def6f340>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0270154 -0.012093 0.0181588-0.0148033 -0.0128511 0.0329365 -0.048675 0.0630503 0.0434794]
============================
layer17_wv's input 
<N9nntrainer6TensorE at 0x5682def703c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wv's output 
<N9nntrainer6TensorE at 0x5682def70150>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.274216 -0.0489666 0.0310645-0.0363662 -0.0251874 -0.0699952 -0.236286 -0.151216 0.111659]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.544092 0.774441 -0.4680790.0336274 -0.486689 0.47289 0.0825257 -0.452689 -0.732778]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2298508
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer17_attention_out's input 
<N9nntrainer6TensorE at 0x5682def72870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer17_attention_out's output 
<N9nntrainer6TensorE at 0x5682def727d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer17_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def738f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.62364 -0.557904 -0.304292-0.143882 -1.07809 -0.254013 0.351357 0.556844 1.23769]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0535453 -0.0381172 -0.018551-0.00990592 -0.0660084 -0.0185562 0.0241901 0.0358498 0.0748043]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.447009921 -1.251222968 0.4436779618 1.208736181 0.4357713461 -1.42989099 0.6122367978 0.2530575395 0.4667769969 0.4646663964 -2.264201641 -0.3218255341 -1.396860361 -0.2306746393 -0.1178826988 0.7724598646 0.2812962234 0.5701763034 -0.05667025223 -0.4016815722 0.5942981243 -0.2179611325 -1.151953578 1.020982146 0.1786067039 -0.5935477614 0.4067239463 0.5758956671 -0.2033901215 -1.378864169 0.6396024823 -0.2597191632 0.6028248668 -0.01780005358 -0.4718881547 -1.254062057 -0.4256217182 0.6643728614 -0.9968361259 0.7363439798 0.7514398098 0.1557527333 0.05587822571 -0.2031203806 0.02681217901 0.5725940466 1.238481522 0.2346255332 -0.7182914615 -0.5017694831 0.2432640791 -0.7048752308 5.43648386 -0.1543168426 -0.4374468923 0.8873459697 -0.7013961077 -0.7799318433 -0.2013331503 0.02283242717 -2.182951212 -0.4535562098 0.4822836518 -1.40295589 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01393856574 0.00093840505 0.005110653583 0.01098340377 0.005070406478 0.0007848665118 0.006048960611 0.004223680589 0.005230078474 0.00521905208 0.000340768398 0.00237696385 0.0008112239884 0.002603807254 0.002914699493 0.007100104354 0.004344652407 0.00579981273 0.003098689485 0.002194530331 0.005941415206 0.002637122059 0.001036340487 0.009103251621 0.003920644056 0.001811402966 0.00492524216 0.005833080504 0.002675829455 0.000825955125 0.006216780283 0.002529268386 0.005992292892 0.003221508116 0.002045743633 0.0009357446106 0.002142617013 0.006372694392 0.001210233429 0.006848250981 0.006952414755 0.003832058283 0.003467825241 0.002676551463 0.003368479898 0.005813853815 0.01131501887 0.0041465424 0.001598967589 0.001985518262 0.004182518926 0.001620563678 0.753051281 0.002810416045 0.002117428463 0.007964508608 0.00162621215 0.001503382344 0.002681339392 0.003355100984 0.0003696118365 0.002083592117 0.005311812274 0.000806294207 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
22.11791992 22.11302567 22.11862755 22.11687088 22.11572647 22.1081028 22.11956596 22.11774063 22.11827087 22.11873627 22.11195183 22.11541748 22.10622215 22.11516762 22.11595535 22.12109375 22.1178627 22.11979485 22.10278893 22.11523628 22.11564445 22.11138725 22.11216927 22.11976051 22.11696243 22.11103821 22.11891937 22.11935043 22.1076107 22.11291313 22.11925697 22.11557007 22.11855698 22.11673927 22.11556435 22.1058712 22.11518288 22.11941338 22.11139107 22.11988831 22.12047005 22.10972023 22.11698532 22.11237907 22.10877991 22.1198082 22.12149429 22.11766434 22.11034775 22.11550331 22.11770058 22.11466217 22.84749603 22.10822105 22.10991287 22.11814499 22.11562157 22.11120605 22.11429214 22.11210442 22.11341095 22.11512375 22.11930656 22.11194038 

-------
======================
selected experts : 0, 3, 23, 46, 52, 55, 
layer17_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def76b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.34535 0.153269 -0.0514444-0.155825 0.00398532 -0.280045 -0.110691 -0.0676852 -0.0705817]

layer17_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def761f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.96899 -0.404635 -0.355736-0.299706 -1.07411 -0.534058 0.240666 0.489158 1.16711]

layer18_wq's input 
<N9nntrainer6TensorE at 0x5682defb6420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wq's output 
<N9nntrainer6TensorE at 0x5682def760a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.892632 0.785006 0.2843590.732417 0.502672 0.0353727 -0.273241 0.803194 -0.858658]
============================
layer18_wk's input 
<N9nntrainer6TensorE at 0x5682defb8180>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wk's output 
<N9nntrainer6TensorE at 0x5682defb7ef0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0625939 0.0209839 -0.02201980.140951 0.13563 0.073881 -0.0576498 0.0120187 -0.0372709]
============================
layer18_wv's input 
<N9nntrainer6TensorE at 0x5682defb8f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wv's output 
<N9nntrainer6TensorE at 0x5682defb8d00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0673743 0.132851 -0.8126420.0689228 0.0105354 -0.0484212 -0.0431445 0.0169316 0.0487522]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.157219 1.17826 0.6396320.456251 0.00154872 -0.503912 0.700018 -0.47933 0.833858]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a249d518
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer18_attention_out's input 
<N9nntrainer6TensorE at 0x5682defbb420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer18_attention_out's output 
<N9nntrainer6TensorE at 0x5682defbb380>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer18_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682defbc4a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.96899 -0.404635 -0.355736-0.299706 -1.07411 -0.534058 0.240666 0.489158 1.16711]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0721664 -0.027966 -0.0225376-0.0210278 -0.0680496 -0.039148 0.0168854 0.032015 0.073025]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7184080482 -1.151590586 -1.859447241 -0.977907002 -1.203753948 0.2016505301 0.3415195346 0.1751564294 -0.9603215456 0.07764619589 -0.7337498069 0.7458074093 -0.4427110255 -2.942986965 -1.691908717 -1.262107611 -1.842625141 3.898965359 -0.4046615362 0.1811235845 0.07861576974 0.7561917901 -2.544876337 -0.3593176007 -1.128900528 -0.5133380294 -0.7166668773 -1.134882569 -0.3825878203 -0.8983453512 -1.73834765 0.4515714049 -2.509013414 0.3447127342 -1.726599813 -1.201112628 0.3410312831 -1.635834694 -0.9594169855 -1.42271924 -0.5482043624 -0.2436633706 -0.3327748179 -0.1896322966 -0.08608092368 -0.4912527204 0.02922016196 0.4147014618 0.102746658 -1.13919425 -0.06142451242 -0.05008335412 0.8983634114 -0.6112719774 0.4918267131 -0.466303587 -0.5821825266 0.1258903295 -0.5778212547 0.5221877098 -2.873530388 -0.7968274951 -1.698697209 0.7144367695 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005024361424 0.003258007113 0.001605217811 0.003875982948 0.003092415631 0.01260832138 0.01450112276 0.0122786602 0.003944747616 0.01113788877 0.004947867244 0.02172609232 0.006619339809 0.00054319849 0.001897994196 0.00291712652 0.001632448984 0.508605063 0.006876053289 0.01235214714 0.01114869118 0.02195287496 0.0008088270552 0.007195016835 0.003332777182 0.006167961285 0.005033118185 0.003312900197 0.007029520813 0.004196962342 0.001811869093 0.01618812606 0.0008383603999 0.01454750076 0.001833280083 0.00310059404 0.01449404284 0.002007463016 0.003948317841 0.002484290162 0.005956612993 0.008077182807 0.007388552651 0.008525605313 0.009455773048 0.006305697374 0.01061137579 0.01560213789 0.01142099407 0.003298647236 0.009691816755 0.009802358225 0.0253067147 0.00559254596 0.01685307547 0.006465000566 0.005757619161 0.01168839727 0.005782783963 0.01737259701 0.000582268287 0.004645407666 0.001885153819 0.0210551098 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
24.21805191 24.20770264 24.21368027 24.21356583 24.21611977 24.22611237 24.22752953 24.2257843 24.21601868 24.2246418 24.21416092 24.23427773 24.21773911 24.21214104 24.2154026 24.21594429 24.20703125 24.7202034 24.21895027 24.22490311 24.21797752 24.22830582 24.21383667 24.21974564 24.21588326 24.21776581 24.21710777 24.20918846 24.20432091 24.21722412 24.21340942 24.22969246 24.21243668 24.21946907 24.21486092 24.21565247 24.22799873 24.20072937 24.21602249 24.21455765 24.21850777 24.22110558 24.21946335 24.22107697 24.22296143 24.21504211 24.22077751 24.22719955 24.22444916 24.21537209 24.22271919 24.22330666 24.22927475 24.2186203 24.23035812 24.21615601 24.21878624 24.22471619 24.21881104 24.23040009 24.21074867 24.21672058 24.21443558 24.23408318 

-------
======================
selected experts : 11, 17, 21, 52, 59, 63, 
layer18_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682defbf6e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.57986 0.0943264 -0.0378901-0.0561241 -0.00075978 -0.0367193 -0.33725 -0.0977015 -0.0766937]

layer18_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682defbeda0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.54885 -0.310308 -0.393626-0.35583 -1.07486 -0.570777 -0.0965837 0.391457 1.09041]

layer19_wq's input 
<N9nntrainer6TensorE at 0x5682deffefd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wq's output 
<N9nntrainer6TensorE at 0x5682defbec50>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.361323 -0.227422 0.290729-0.417 -0.367518 -0.121355 0.565305 -0.199414 0.142538]
============================
layer19_wk's input 
<N9nntrainer6TensorE at 0x5682df001130>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wk's output 
<N9nntrainer6TensorE at 0x5682df001100>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00226154 -0.0396273 0.06855920.0128666 0.0418959 -0.0108973 0.0969948 -0.022773 -0.0303774]
============================
layer19_wv's input 
<N9nntrainer6TensorE at 0x5682df002000>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wv's output 
<N9nntrainer6TensorE at 0x5682df001d90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0179469 0.0446899 0.0160040.00136719 0.031549 0.0285391 -0.0551306 0.0632468 -0.0651789]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.122989 -0.408838 0.0142189-0.508144 -0.0964097 0.374836 -0.572076 -0.179065 -0.152692]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a28a7538
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer19_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0044b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer19_attention_out's output 
<N9nntrainer6TensorE at 0x5682df004410>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer19_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df005580>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.54885 -0.310308 -0.393626-0.35583 -1.07486 -0.570777 -0.0965837 0.391457 1.09041]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.104808 -0.0219663 -0.0262252-0.0255591 -0.0707731 -0.0427812 -0.00708838 0.0262844 0.0717968]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.870427072 -0.4297446311 0.3893831074 -2.882740974 -1.749268174 -1.140577197 -1.86351347 -2.083424807 -0.1198053062 -1.283785939 -3.595624924 -1.68920207 -0.931278646 1.751794577 -0.9549500942 -2.474923849 -0.3612092137 -2.245876074 0.4594415128 -1.703000188 -0.006122693419 -0.2473336458 -0.1874592602 -1.355520844 -1.34108603 -4.318873405 -0.1267712563 -3.603009701 0.3241306543 -2.305549383 -0.7661187053 -1.171770692 -0.2226484567 -1.774108052 -3.001091003 -2.214206457 -0.9160502553 -1.340917349 -0.1638941765 0.6700047255 -0.1463842988 -0.7276086211 -0.6233993769 -0.04615239799 -1.428402066 -0.2105231136 -1.808840513 -0.7044687271 -3.060681105 -1.606765389 -5.207351685 -3.351971865 -2.702824354 -1.067015171 -1.12849617 -0.5040866733 -2.808013678 -1.055145264 -0.2338203192 -3.263477802 -0.8612078428 0.8286098838 -0.3876197636 -1.732399702 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01169053651 0.01816437021 0.0412062481 0.001562778838 0.004854657222 0.008922977373 0.004330544267 0.003475651378 0.02476425841 0.00773241045 0.0007661184645 0.005155193619 0.01100036036 0.1609351188 0.01074302476 0.002349688904 0.01945292763 0.002954503521 0.04419661686 0.005084549543 0.02774578705 0.02179919556 0.02314427681 0.007197155152 0.007301797625 0.000371700502 0.02459235303 0.0007604820421 0.03860328719 0.002783356002 0.01297582407 0.008648932911 0.02234400995 0.004735553171 0.001388349221 0.003049568972 0.01116916165 0.00730303023 0.02369614877 0.05455511436 0.02411472239 0.01348527148 0.01496639382 0.0266570691 0.00669127563 0.02261658758 0.004573899787 0.01380095724 0.001308034523 0.005598178133 0.0001528733992 0.0009774920763 0.001870830311 0.009604114108 0.009031428955 0.01686296798 0.001684035524 0.009718793444 0.02209577523 0.001067937468 0.01179881394 0.06393178552 0.01894588955 0.004937242717 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.25842476 26.25917625 26.28078842 26.2478199 26.25206566 26.24659729 26.24963379 26.25020981 26.27149963 26.25446701 26.24177933 26.25093651 26.25630379 26.40766907 26.25747681 26.24956131 26.26618767 26.24682808 26.29045486 26.25134277 26.27495766 26.26805687 26.26463318 26.25250053 26.25451279 26.24710655 26.27132607 26.24701881 26.28486061 26.24713326 26.26018715 26.25586128 26.26955605 26.2519474 26.24621582 26.2488308 26.2559967 26.25165367 26.27043152 26.29318428 26.27084923 26.26021957 26.26170158 26.2705307 26.24722672 26.26935196 26.25130844 26.26053619 26.24708939 26.24804115 26.24641037 26.24675751 26.24812889 26.25252342 26.24241447 26.26407433 26.24794197 26.2569294 26.26930809 26.24303436 26.25901031 26.30828285 26.26568031 26.25071907 

-------
======================
selected experts : 2, 13, 18, 28, 39, 61, 
layer19_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df008b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.291141 -0.0548041 0.1960420.0124939 0.0760055 -0.388228 -0.0445634 -0.0385717 0.00012557]

layer19_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df008060>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.83999 -0.365113 -0.197585-0.343336 -0.998859 -0.959005 -0.141147 0.352885 1.09054]

layer20_wq's input 
<N9nntrainer6TensorE at 0x5682df047b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wq's output 
<N9nntrainer6TensorE at 0x5682df007f10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.443588 -0.365536 0.0309314-0.373895 1.03147 -0.199066 0.619521 -0.0463079 0.570942]
============================
layer20_wk's input 
<N9nntrainer6TensorE at 0x5682df0498e0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wk's output 
<N9nntrainer6TensorE at 0x5682df049650>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.061873 -0.0443794 0.0643148-0.0113864 0.0207143 0.00327355 0.052702 0.0385123 0.0354851]
============================
layer20_wv's input 
<N9nntrainer6TensorE at 0x5682df04a6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wv's output 
<N9nntrainer6TensorE at 0x5682df04a460>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00685912 -0.00390602 -0.02020850.0231271 -0.0199988 0.0483193 -0.0235687 0.0313001 0.0278894]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0942695 -0.56701 -0.179315-0.329545 -0.267858 -1.01578 -0.523745 -0.334129 -0.547937]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2cb1558
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer20_attention_out's input 
<N9nntrainer6TensorE at 0x5682df04cb80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer20_attention_out's output 
<N9nntrainer6TensorE at 0x5682df04cae0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer20_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df04dc00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.83999 -0.365113 -0.197585-0.343336 -0.998859 -0.959005 -0.141147 0.352885 1.09054]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.134808 -0.0267069 -0.0138377-0.0252921 -0.0684 -0.0736309 -0.0106906 0.0247141 0.0752436]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.07704258 -2.381285906 -0.1274219602 0.474237591 -1.869292617 0.430000782 -0.9043648243 -0.4669285119 0.2660955489 -1.392124534 -0.8622024655  0.1724381 0.3264771998 0.9078991413 0.1739273667 -0.3697404861 -0.88002038 0.2017908543 0.6609428525 -2.082634687 0.03842191026 -1.76477313 -0.5597907901 -2.003566265 -0.2413147092 -0.1986148357 0.2799862325 -0.3508349657 -0.9200164676 0.4224737883 0.5498284101 0.2064149082 1.088294625 -1.623036504 -0.8739697933 -0.8394398689 0.6316232085 5.037063122 -0.5610482693 -2.034821033 -0.7283396125 -0.5939122438 -4.271018505 0.4074138105 0.9174279571 -0.8665634394 -1.88837862 -2.123327732 0.770165205 -1.222227216 0.05432872102 -0.7720525861 -1.608665943 -0.2474517077 0.5766109824 -1.176881194 -1.034535289 -0.09248919785 -1.464740157 -2.865098953 -1.450525284 -0.5726585388 0.5862969756 -0.6457912326 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001647277153 0.0004470343119 0.004257765133 0.007771037985 0.0007459277986 0.007434765808 0.001957760425 0.00303204637 0.006310796365 0.001202065847 0.002042069333 0.005746577401 0.006703590509 0.01198991202 0.005755141377 0.003341520205 0.002006005961 0.00591775449 0.009366217069 0.0006026201881 0.005025818478 0.0008281121845 0.002763161901 0.0006522025797 0.003799431259 0.003965181299 0.006399069447 0.003405294614 0.001927357749 0.007379014976 0.008381230757 0.005945181008 0.01436020341 0.0009542113403 0.002018181141 0.002089085523 0.009095588699 0.7448846698 0.002759689698 0.0006321334513 0.002334567253 0.002670469228 6.755236245e-05 0.007268719841 0.01210470591 0.002033183817 0.0007318261196 0.0005785898538 0.01044717059 0.001424668473 0.005106402561 0.002234714571 0.0009680227959 0.003776186146 0.008608734235 0.001490758266 0.001718807616 0.004409128334 0.001117871027 0.0002755647292 0.00113387499 0.002727833577 0.008692523465 0.002535460284 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.39579964 25.39555168 25.40126991 25.40526009 25.39680481 25.40492439 25.39420128 25.40004539 25.40332413 25.39201546 25.39857864 25.39989853 25.40371704 25.40852547 25.40276718 25.39892387 25.3932972 25.39720917 25.40447235 25.39666176 25.40203857 25.3978405 25.39453125 25.39623451 25.39747429 25.40097809 25.39864349 25.39994049 25.39321709 25.40439224 25.4053936 25.40343475 25.41041946 25.39701271 25.39903069 25.39862442 25.40610886 26.1328373 25.39548111 25.39573669 25.39934731 25.39825249 25.39517212 25.40475845 25.40768623 25.39952278 25.39774513 25.39759064 25.40698242 25.39796066 25.3997345 25.39924812 25.38367653 25.40078926 25.4046669 25.39755058 25.39920807 25.39808464 25.39574623 25.39394951 25.39671516 25.39830971 25.40093613 25.39477921 

-------
======================
selected experts : 13, 18, 32, 37, 44, 48, 
layer20_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df050e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0120884 -0.209664 0.05369820.136559 0.0140424 -0.212215 -0.0268751 0.245811 -0.552276]

layer20_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df050500>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8279 -0.574777 -0.143887-0.206777 -0.984817 -1.17122 -0.168022 0.598696 0.538261]

layer21_wq's input 
<N9nntrainer6TensorE at 0x5682df091030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wq's output 
<N9nntrainer6TensorE at 0x5682df0503b0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.332466 -0.309924 0.2384420.07408 0.479344 -0.182912 -0.21657 -0.208468 -0.599435]
============================
layer21_wk's input 
<N9nntrainer6TensorE at 0x5682df092d90>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wk's output 
<N9nntrainer6TensorE at 0x5682df092b00>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0128925 -0.14536 -0.03713740.107526 -0.0377128 0.0351184 0.0651516 -0.0369747 -0.00649811]
============================
layer21_wv's input 
<N9nntrainer6TensorE at 0x5682df093b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wv's output 
<N9nntrainer6TensorE at 0x5682df093910>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0628524 0.476884 -0.03043020.0533559 0.0167144 -0.0309751 -0.0983312 -0.00852327 0.00372253]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0470308 -0.452078 0.239986-0.0689144 -0.214677 -0.465983 0.0484801 0.296667 0.525807]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1f90cf0
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer21_attention_out's input 
<N9nntrainer6TensorE at 0x5682df096030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer21_attention_out's output 
<N9nntrainer6TensorE at 0x5682df095f90>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer21_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0970b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8279 -0.574777 -0.143887-0.206777 -0.984817 -1.17122 -0.168022 0.598696 0.538261]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.144591 -0.045282 -0.0109603-0.0163982 -0.073989 -0.0977705 -0.0138507 0.0459169 0.0404394]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.06304276 -0.6021475196 -2.169597626 -1.313102484 -2.742123365 -0.4679281712 0.3970277607 -2.853251934 -0.06517066061 -1.92474246 -4.035582066 0.06261336058 -2.236532211 -2.247601271 -0.04237207025 -1.586821675 -1.129099131 -0.2283283621 -2.213349104 -0.2064970732 -3.909958363 -0.2399390191 -1.702290535 -2.80487442 -1.139941931 -2.144385815 0.2781732678 -0.2992320657 -0.5869427323 -0.1516870111 -1.931723356 -3.424999952 -0.7316350341 -2.441805601 -2.182060957 -1.475407958 0.5334613919 -1.330709934 -1.049032211 3.90513134 0.4757867754 0.219257772 -2.52214694 -0.5174241662 0.6447601318 -0.966193676 0.1037304252 -1.640603065 -1.418705821 -1.239153266 -0.990398109 -3.344450474 -2.827080965 -0.2736230493 -0.09573896229 -0.2715366781 -0.3317405581 -0.1800187677 -1.254295468 0.3095138967 -0.3546442688 -3.898478985 -2.363801718 -1.45413053 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.004216297995 0.006684909109 0.001394314109 0.003283458995 0.0007865307853 0.007645156235 0.01815648749 0.0007038065814 0.01143672224 0.001781146857 0.0002157614508 0.0129956333 0.001304041129 0.001289685839 0.01170045976 0.00249722111 0.003946784884 0.009715008549 0.001334625646 0.009929428808 0.0002446422877 0.009602860548 0.002224894706 0.0007386920042 0.00390421995 0.001429914031 0.01612181589 0.009050031193 0.006787329447 0.01048885286 0.001768756192 0.0003973252606 0.005872997455 0.001062042895 0.00137704378 0.002791536273 0.02081057988 0.003226152388 0.004275786225 0.6061524749 0.01964429393 0.01519943215 0.0009800546104 0.007275962271 0.02326058596 0.004645070527 0.01354111452 0.002366464585 0.002954395954 0.003535471857 0.004533989821 0.0004306539777 0.0007224691217 0.009284785949 0.01109241135 0.009304176085 0.008760559373 0.01019585505 0.003482341068 0.01663508452 0.008562188596 0.0002474668145 0.001148203155 0.002851569559 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.64250755 25.64497566 25.63920784 25.64109612 25.63716888 25.64545822 25.65644646 25.63661003 25.64925003 25.63911819 25.62753868 25.64222527 25.63578033 25.63719559 25.64999008 25.64031029 25.64223671 25.64800453 25.63676453 25.64822006 25.63805771 25.64789391 25.64003754 25.63759804 25.64219475 25.63876724 25.65393448 25.64591026 25.64507866 25.64877892 25.64005852 25.63725662 25.64320946 25.63887596  25.638237 25.64012909 25.65910149 25.64103889 25.6401825 26.24348831 25.65793419 25.65349007 25.63784027 25.6450901 25.65725899 25.64245796 25.65183067 25.64018059 25.63599968 25.63896561 25.64282417 25.63490677 25.63090706 25.64757538 25.64938354 25.6456871 25.64180565 25.64801025 25.63366699 25.65444946 25.64542198 25.63806152 25.63753128 25.64018822 

-------
======================
selected experts : 6, 36, 39, 40, 44, 59, 
layer21_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df09a2f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.215912 0.0337436 -0.14080.25848 -0.380119 0.226237 0.102527 -0.408488 0.198852]

layer21_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df0999b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04381 -0.541033 -0.2846860.0517024 -1.36494 -0.944982 -0.0654953 0.190208 0.737113]

layer22_wq's input 
<N9nntrainer6TensorE at 0x5682df0d9be0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wq's output 
<N9nntrainer6TensorE at 0x5682df099860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0645966 2.94181 1.97864-1.35017 -2.31954 0.353108 -0.301218 -1.04382 -2.49729]
============================
layer22_wk's input 
<N9nntrainer6TensorE at 0x5682df0db940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wk's output 
<N9nntrainer6TensorE at 0x5682df0db6b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0181593 0.194621 0.1058130.081483 -0.104169 -0.00915633 0.00530279 0.0582135 -0.174956]
============================
layer22_wv's input 
<N9nntrainer6TensorE at 0x5682df0dc730>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wv's output 
<N9nntrainer6TensorE at 0x5682df0dc4c0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.305374 -0.118744 0.1250070.0234811 0.348752 0.0440496 -0.268004 -0.125917 0.012953]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.98143 2.1754 0.913218-2.2145 0.508021 2.2906 -0.384277 1.01619 2.49512]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a30bb578
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer22_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0debe0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer22_attention_out's output 
<N9nntrainer6TensorE at 0x5682df0deb40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer22_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0dfc60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04381 -0.541033 -0.2846860.0517024 -1.36494 -0.944982 -0.0654953 0.190208 0.737113]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.197024 -0.0466002 -0.02392610.00439924 -0.111864 -0.0853393 -0.0057438 0.0160851 0.0604106]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.199773863 -1.673453927 -1.750790596 -1.891195297 -0.7850407362 -0.5988141298 0.3508761823 0.4396923184 -0.5164562464 -0.1288634688 -0.439224124 -0.1732848287 -0.6426890492 0.3127274215 -1.910321116 -0.2244655788 0.03051177971 -1.879820585 0.03443358094 0.8580367565 -1.790165305 0.5585227013 -0.4073811471 -1.642910004 0.4139422178 -0.3693930805 -0.7692814469 -0.3295662105 -2.578949928 -0.6650422812 -2.566251755 -2.248004675 -0.9758638144 0.04356760532 0.9725430608 -2.060469627 -0.793438375 0.1285246015 0.4450246394 -1.208471537 -0.1679882407 0.3906342387 -1.493481159 -0.03915252537 -0.4554958344 -0.8757504225 0.291896075 -2.210798025 -0.09234327823 -0.6468251944 0.1034733579 -1.954865456 4.743592262 -3.236852884 -0.3848002851 -3.316403866 -0.5754801035 -1.129412532 0.2965017557 -0.4800824225 0.2253926992 -1.031445861 -1.540406108 -0.7616586685 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007627194747 0.001171743148 0.001084539806 0.0009424721356 0.002848821692 0.00343196257 0.008871312253 0.009695276618 0.003726577386 0.005490849726 0.004025793634 0.00525227515 0.003284640145 0.008539254777 0.0009246177506 0.004990224726 0.006439546589 0.0009532533586 0.006464849226 0.01473142672 0.00104266603 0.01091861352 0.004156050738 0.001208084868 0.009448808618 0.004316968843 0.002894073259 0.00449236948 0.00047378405 0.003212032374 0.0004798386362 0.0006596416351 0.002353920834 0.00652417168 0.01651863754 0.0007957077469 0.002824998694 0.007102672476 0.009747110307 0.00186539907 0.005280168727 0.009231120348 0.00140279287 0.006006208714 0.003960817587 0.002601779765 0.008363208733 0.0006846469478 0.005695081782 0.003271082649 0.006926949136 0.000884335197 0.7173318863 0.0002453900233 0.004250964615 0.0002266253578 0.003512985772 0.00201886124 0.008401816711 0.003864621744 0.007825120352 0.002226654906 0.001338487375 0.002916218247 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.01300812 27.00655174 27.00455856 27.00489235 27.00870705 27.00356674 27.0128212 27.01364517 27.00958443 27.01039505 27.00988388 27.01063347 27.00866508 27.01344299 27.00344467 27.01084709 27.01181984 27.00681114 27.01232147 27.01391411 27.00499344 27.01629829 27.01001358 27.00086594 27.01530647 27.00969696 27.00875092 27.00844193 27.00537682 27.00906944 27.00586128 27.00461006 27.00487328 27.01238251 27.0118866 27.00379181 27.00343704 27.00676155 27.00940514 27.00533867 27.01066017 27.01318169 27.00678253 27.01138687 27.00981903 27.00655174 27.01422119 27.00511169 27.01155281 27.00912857 27.01278496 27.00483513 27.71746826 27.00610352 27.00963211 27.00513077 27.0093708 27.00406075 27.01425934 27.00924492 27.01129913 27.00808334 27.00671959 27.0087738 

-------
======================
selected experts : 7, 19, 21, 34, 38, 52, 
layer22_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df0e2e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0903192 0.42473 0.3125610.306603 0.951165 1.31895 0.790386 1.13406 0.257965]

layer22_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dde69cd0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.9535 -0.116303 0.02787510.358305 -0.413771 0.373971 0.724891 1.32427 0.995078]

layer23_wq's input 
<N9nntrainer6TensorE at 0x5682de368560>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wq's output 
<N9nntrainer6TensorE at 0x5682de2bfbc0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88475 1.19701 -2.95799-0.774949 -0.550968 3.72149 -2.80755 0.835098 0.0767813]
============================
layer23_wk's input 
<N9nntrainer6TensorE at 0x5682de266760>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wk's output 
<N9nntrainer6TensorE at 0x5682de82d610>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.16132 0.101492 -0.1736-0.0632329 0.00180998 0.100202 -0.12567 -0.0723858 0.0486436]
============================
layer23_wv's input 
<N9nntrainer6TensorE at 0x5682de40ebf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wv's output 
<N9nntrainer6TensorE at 0x5682de7736d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.133239 0.0820239 -0.446299-0.364692 0.117455 0.266068 0.109828 0.368292 0.705527]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.3884 2.79767 -2.898090.975338 3.75008 0.299903 2.74814 1.01363 0.111418]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a32c0588
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer23_attention_out's input 
<N9nntrainer6TensorE at 0x5682ddf81aa0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer23_attention_out's output 
<N9nntrainer6TensorE at 0x5682de55e330>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer23_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0fe910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.9535 -0.116303 0.02787510.358305 -0.413771 0.373971 0.724891 1.32427 0.995078]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.248394 -0.0111696 0.002646840.0340224 -0.0390645 0.037539 0.0719775 0.125744 0.0934063]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4227033556 -0.08820123225 -1.093985319 -1.440326333 0.1767097861 -0.6456956863 -1.188692927 -2.515872002 -0.1630707234 0.6196206212 0.6059263349 -1.085564375 -0.3715315461 0.8512659073 0.2090708166 0.6669648886 1.468102455 -1.003164649 4.688289642 -1.688715458 -1.784513116 -0.9512995481 0.2725952566 -1.258306623 0.1121827066 -1.115008235 -1.628750801 -2.018517733 0.472153604 -0.4246005118 -0.5433605313 -0.1163094714 0.03554884717 -1.526789784 -1.247554541 -1.311082482 0.3014304638 -2.34950757 0.6530562043 -0.4077222347 -0.4513951242 -0.467533648 -1.078356385 0.04713717103 0.2013515085 -1.248224258 -0.7126752138 -1.343229294 -2.383528709 -0.6903945208 0.5946252346 -0.4792165756 0.7827592492 -0.3523043096 -1.912632704 -0.1119556129 -0.1083869934 0.8989235163 -1.450334668 0.4656749964 0.7065121531 -0.6281039715 0.8132551908 0.9489036798 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009099072777 0.005459014326 0.001996675739 0.001412191894 0.007114813197 0.003126060357 0.001816254109 0.0004817149311 0.005065225065 0.01107942872 0.010928737 0.002013560617 0.004112116061 0.01396752708 0.007348821498 0.01161659043 0.02588262036 0.002186505357 0.6479145885 0.001101589063 0.001000956749 0.002302900888 0.007830799557 0.001694118953 0.00667021377 0.001955138287 0.001169666299 0.0007921153447 0.009560336359 0.003899579169 0.003462907393 0.005307705607 0.006178144366 0.00129521871 0.001712431898 0.001607028535 0.008059890009 0.0005689071259 0.01145613473 0.003965955228 0.003796479665 0.003735701554 0.002028127434 0.006250156555 0.007292313501 0.001711285789 0.002923537046 0.001556189149 0.0005498776445 0.002989406232 0.01080592722 0.003692311235 0.01304269768 0.004191944841 0.0008805895341 0.005330865271 0.005349923857 0.01464930177 0.00139812869 0.009498597123 0.01208519842 0.00318153901 0.01344657689 0.01540008187 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.92578888 26.92119408 26.91868591 26.91762352 26.92189598 26.91933823 26.9170742 26.91669464  26.921278 26.92776871 26.92761803 26.91536522 26.92032433 26.92874908 26.9235611 26.92639732 26.93541908 26.9183979 27.56221962 26.91397667 26.91721344 26.91851425 26.92452049 26.91838264 26.92335892 26.91721344 26.91547394 26.91748047 26.92624855 26.91963577 26.91919899 26.91961288 26.91952896 26.91464615 26.91697121 26.91734314 26.92474937 26.91630363 26.92766762 26.9168396 26.91762352 26.91994858 26.91871643 26.92198563 26.92302704 26.91792297 26.91627502 26.91347694 26.9167614 26.91729355 26.92749405 26.91990471 26.92973137 26.91945076 26.91375542 26.92011261 26.92060852 26.92466164 26.91761017 26.92523384 26.92877388 26.91748619 26.93013573 26.93065834 

-------
======================
selected experts : 13, 16, 18, 57, 62, 63, 
layer23_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee1eb60>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0869226 -0.195127 -0.00683361-0.561033 0.658098 0.719169 0.109476 -0.258927 -0.228366]

layer23_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de7806d0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.86657 -0.31143 0.0210415-0.202728 0.244327 1.09314 0.834367 1.06534 0.766711]

layer24_wq's input 
<N9nntrainer6TensorE at 0x5682de5e9620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wq's output 
<N9nntrainer6TensorE at 0x5682de23a580>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.336158 -0.169375 -0.425678-0.648299 -0.123858 -0.259336 0.708369 -0.032059 -0.618515]
============================
layer24_wk's input 
<N9nntrainer6TensorE at 0x5682de680bc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wk's output 
<N9nntrainer6TensorE at 0x5682de1e9fa0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0118696 -0.0472703 0.113450.103728 0.0296149 -0.0224001 -0.0348054 0.0611872 -0.0188398]
============================
layer24_wv's input 
<N9nntrainer6TensorE at 0x5682de7cdb70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wv's output 
<N9nntrainer6TensorE at 0x5682de067420>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0733123 0.0836663 -0.00333526-0.468789 0.0173092 0.0456101 -0.047658 0.045135 -0.0803263]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.364707 0.093159 -0.711614-0.308381 -0.250436 0.140988 -0.58634 -0.398772 0.574346]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a36ca5a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer24_attention_out's input 
<N9nntrainer6TensorE at 0x5682de40b530>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer24_attention_out's output 
<N9nntrainer6TensorE at 0x5682de646540>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer24_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de7c4940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.86657 -0.31143 0.0210415-0.202728 0.244327 1.09314 0.834367 1.06534 0.766711]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.272563 -0.0340113 0.00226365-0.0220298 0.0260193 0.124133 0.094748 0.115767 0.0820663]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.929450631 -1.128785849 -0.6543552279 -0.8471324444 -1.39042747 -0.55434829 -0.02498121932 -0.4676400721 -2.470920801 -1.70237565 -0.9748182893 -1.800919175 -0.2439994067 -1.728101611 -1.238625407 -0.255404681 -0.2346673757 -1.047284842 -2.222267866 -0.4669069946 -0.6821814775 0.1248121113 -1.806736708 -0.9977571964 -0.1882074773 -1.306464791 -1.56954062 -1.755864024 -0.8727980852 -1.033334374 -1.979539037 5.464857101 -1.646643162 -0.4878594875 0.3052386045 -0.8554965258 -0.3183939159 -0.9714736342 1.016834497 -2.717564344 -1.23928678 -0.06641087681 0.3262445629 -1.273775458 -1.078132153 0.4311248064 0.4545654655 -2.53660512 -1.765888453 -1.713524938 -1.485613465 -1.774708033 -1.024132609 -1.954378843 0.06704782695 -0.327961266 0.04493098333 -2.279580355 0.0472863242 -0.5062567592 -1.145820975 -1.043580055 -1.944802403 -2.451274872 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0005397897912 0.001202122658 0.001931931009 0.001593196415 0.0009253784083 0.002135128016 0.003625144018 0.002328525297 0.0003140994813 0.0006773952045 0.001402220107 0.0006138258614 0.002912103198 0.0006601905916 0.001077075489 0.002879079431 0.002939406782 0.001304200152 0.0004027686082 0.002330232412 0.001878913492 0.004210945219 0.0006102650659 0.001370421145 0.003079192713 0.001006430946 0.0007736269617 0.0006421142025 0.001552826958 0.001322522294 0.0005134185776 0.8780751228 0.0007162198308 0.002281915629 0.00504356809 0.001579926931 0.002703321865 0.001406917698 0.01027495414 0.0002454432251 0.001076363376 0.003478022991 0.005150632001 0.001039873925 0.001264583552 0.005720176734 0.005855846219 0.0002941310522 0.00063570973 0.0006698846119 0.0008413577452 0.0006301276735 0.001334747649 0.0005264999345 0.003974594176 0.002677580575 0.003887654282 0.0003803341533 0.003896822687 0.002240319503 0.001181818079 0.001309041283 0.0005315663293 0.0003203311935 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.83124924 28.83095741 28.8326416 28.82610321 28.83115768 28.83141327 28.83481216 28.83351517 28.83102417 28.83138657 28.82925034 28.83180046 28.83409882 28.8275547 28.83083534 28.83406448 28.83317184 28.82772255 28.82777405 28.83351707 28.83306503 28.82967567 28.82846069 28.83255577 28.83426476 28.83219337 28.83005333 28.83182907 28.83273888 28.83203125 28.83169937 29.70830727 28.83190346 28.83251381 28.83622932 28.83276558 28.83436584 28.83259392 28.8352623 28.83143234 28.82844734 28.83466339 28.83633614 28.82984161 28.83054352 28.8364296 28.83704185 28.83004951 28.82896042 28.82994843 28.83107376 28.83181572 28.83156776 28.82980537 28.83516121 28.83195686 28.83507347 28.83156586 28.83555984 28.83342743 28.83236885 28.82963371 28.83171844 28.83102989 

-------
======================
selected experts : 31, 34, 38, 42, 45, 46, 
layer24_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df21d1f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.833895 -0.802753 -0.3862-2.35492 0.648108 1.42702 0.936258 -1.31322 -0.598527]

layer24_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de2b2790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.70047 -1.11418 -0.365158-2.55765 0.892435 2.52016 1.77062 -0.247877 0.168184]

layer25_wq's input 
<N9nntrainer6TensorE at 0x5682ddf10a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wq's output 
<N9nntrainer6TensorE at 0x5682de7d58a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.64346 4.6151 -3.59633-1.6699 -4.39449 -0.0783202 -2.1087 -2.86507 -0.238884]
============================
layer25_wk's input 
<N9nntrainer6TensorE at 0x5682de480fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wk's output 
<N9nntrainer6TensorE at 0x5682de0aef30>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0538789 0.0193812 -0.0043537-0.242867 0.037277 -0.198658 0.0676407 -0.0872147 0.0887407]
============================
layer25_wv's input 
<N9nntrainer6TensorE at 0x5682ddd64050>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wv's output 
<N9nntrainer6TensorE at 0x5682de58dbd0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.241149 -0.135526 -0.009660890.227738 -0.432866 0.166314 -0.223882 0.00738034 -0.38231]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.03915 5.21605 -3.922840.577459 0.216857 4.38983 -0.0284336 3.55731 0.437332]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a38cf5b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer25_attention_out's input 
<N9nntrainer6TensorE at 0x5682df211490>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer25_attention_out's output 
<N9nntrainer6TensorE at 0x5682dddde7f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer25_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0184b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.70047 -1.11418 -0.365158-2.55765 0.892435 2.52016 1.77062 -0.247877 0.168184]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.566076 -0.200941 -0.0646798-0.457149 0.156638 0.47074 0.325032 -0.0443051 0.0295192]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-2.033876419 -0.6662036777 -2.519889355 -1.634744644 -1.620467186 -1.470805049 -1.356907725 -0.6036100984 -2.662803173 -3.570815802 -0.7119606137 -2.638509989 -2.228242636 -2.593982458 -1.716693759 -1.688163757 -3.056198359 -2.286839008 -2.550026178 -0.5139263868 -0.06882531941 -1.386721492 -2.962647438 -2.006780863 -2.144985676 -2.108816862 -1.044886827 0.2158241868 1.383966804  -0.539756 -2.881628513 -1.352892756 -1.068458796 -0.9172226787 -1.361247182 -0.08626000583 -2.900213718 -2.272035122 -0.9135314226 -1.731878757 -2.158599854 -2.207988501 -1.664811611 -0.8823071718 -3.022545099 -0.1656448096 -2.413261414 -1.190886617 -0.6852507591 -0.8799331188 -2.690348148 -2.977132082 -2.799127102 -2.899184465 -2.980380535 -1.859682441 -1.973814964 -1.156326056 -1.944438696 -1.011434793 -0.5033848286 -1.838603735 -1.536196589 2.701905012 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003711364232 0.01457157079 0.002282764297 0.005531900097 0.005611447617 0.006517372094 0.007303609047 0.01551281009 0.001978765707 0.0007980854134 0.01391984802 0.002027424518 0.003055776004 0.002119740704 0.00509664556 0.00524414517 0.001335195615 0.002881864319 0.002214994747 0.01696835272 0.0264816191 0.007089074235 0.001466133283 0.003813301679 0.003321082564 0.003443400143 0.00997806713 0.03520191088 0.1132098287 0.01653567515 0.001589863212 0.007332991809 0.009745614603 0.01133679319 0.007271982264 0.02602392063 0.001560588018 0.00292484439 0.01137871668 0.00501983799 0.003276173491 0.003118299181 0.005368050653 0.01173961349 0.001380893984 0.02403789014 0.002539620269 0.008622624911 0.01429665275 0.01176751871 0.00192500453 0.001445050235 0.00172659161 0.001562194782 0.001440364053 0.004417588003 0.003941104282 0.008925837465 0.004058597609 0.01031749882 0.01714816876 0.004511693027 0.006104826927 0.4229192436 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.69184685 28.70556831 28.69089508 28.69700432 28.69660759 28.69751358 28.69829941 28.70460129 28.69297409 28.69083977 28.70539284 28.69350052 28.69500542 28.69216156 28.69227791 28.69337845 28.69280815 28.69006348 28.6932106 28.70844078 28.71461678 28.69522476 28.69246292 28.6952858 28.6947937 28.6939621 28.70145035 28.72667503 28.79896164 28.70228577 28.6925869 28.69880676 28.70121956 28.70281029 28.69826889 28.71749687 28.69255638 28.69439697 28.70237541 28.69506264 28.69236565 28.69363785 28.69684029 28.70225906 28.69285393 28.71551132 28.69210434 28.69723511 28.70529366 28.70276451 28.69005966 28.6919651 28.68890762 28.69255829 28.69243622 28.6930294 28.69398308 28.7003994 28.69553185 28.70131302 28.70385361 28.69550705 28.69757843 29.11439133 

-------
======================
selected experts : 20, 27, 28, 35, 45, 63, 
layer25_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df270060>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.44193 3.30931 -0.1478391.66089 -1.97504 -0.568949 3.54565 0.684309 -1.95359]

layer25_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddfd81b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.1424 2.19513 -0.512997-0.896758 -1.0826 1.95121 5.31627 0.436431 -1.78541]

layer26_wq's input 
<N9nntrainer6TensorE at 0x5682de245ed0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wq's output 
<N9nntrainer6TensorE at 0x5682de21e590>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-7.19763 4.21139 1.345270.336204 -5.75587 3.75966 4.87192 1.62306 1.39669]
============================
layer26_wk's input 
<N9nntrainer6TensorE at 0x5682de23ab70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wk's output 
<N9nntrainer6TensorE at 0x5682de320f60>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.146106 -0.197982 -0.1023530.20076 -0.00982388 -0.0815199 -0.115575 0.150995 -0.0874328]
============================
layer26_wv's input 
<N9nntrainer6TensorE at 0x5682dde7eae0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wv's output 
<N9nntrainer6TensorE at 0x5682ddeee690>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.787365 1.20748 2.441630.378884 -1.00658 -1.26723 0.465748 0.381196 -1.92399]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-8.19314 -1.55377 1.30912-0.45715 4.13757 5.4905 -2.92803 -4.21859 -1.33246]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a116dc80
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer26_attention_out's input 
<N9nntrainer6TensorE at 0x5682df278ee0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer26_attention_out's output 
<N9nntrainer6TensorE at 0x5682df278e40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer26_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df27a260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.1424 2.19513 -0.512997-0.896758 -1.0826 1.95121 5.31627 0.436431 -1.78541]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.23653 0.539361 -0.126048-0.221282 -0.258047 0.497869 1.323 0.106318 -0.433065]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.229813457 -0.05995209515 -2.346139908 -1.001055837 -0.8235158324 -0.05465627834 -0.1190630272 0.5707327127 0.606651783 0.7820273638 0.002560531255 -0.5726556778 -0.5510423183 -1.395941615 -0.6992129683 -0.1102071032 -0.01739729755 -1.311926961 -0.3690626919 0.4405331016 -0.3804124296 0.1966792345 -0.3727973402 -0.2154888511 0.1727482677 -0.1869333088 0.1713048369 1.859833717 -1.653277993 -1.194599271 -0.2070242614 -2.092623711 0.7438879013 -0.4336843491 -0.8664966226 -0.5564077497 -0.4844253659 -1.836260319 0.4542253315 4.332145214 0.1508646607 0.1188326254 -0.7216179967 -0.6991884112 0.1267536134 0.3779300153 -1.579019308 -0.1242448017 0.3456149697 -0.2343725562 -2.290715456 -0.7030614018 0.944742322 0.4067699015 0.230991438 -1.112182736 -0.7881058455 -1.062981129 -1.485591888 -0.741122663 -1.58641994 0.2200573087 0.5616708994 0.5927568078 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.002155417111 0.006943775341 0.000705857412 0.002709440188 0.003235818585 0.006980645005 0.006545219105 0.01304663718 0.01352377981 0.01611620188 0.007391705178 0.004158448894 0.004249306396 0.001825504005 0.003664107528 0.00660344027 0.007245643996 0.001985500567 0.005097421817 0.01145390794 0.005039894953 0.008975305595 0.005078420509 0.005943563767 0.008763066493 0.006115731318 0.008750427514 0.0473530665 0.00141131226 0.00223267125 0.005994088482 0.0009095313144 0.0155131137 0.004778436851 0.003099687397 0.004226566292 0.004542022478 0.001175316633 0.01161181554 0.5611246228 0.008573383093 0.00830311235 0.003582925536 0.003664198564 0.008369144984 0.01075883955 0.001520104008 0.006511391141 0.01041672565 0.005832380615 0.0007460833876 0.003650033148 0.01896395534 0.01107364334 0.009288612753 0.002424475737 0.003352451371 0.002546746517 0.00166896882 0.003513719188 0.001508895191 0.009187606163 0.01292894501 0.01333716605 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.06168747 33.06742859 33.06309891 33.06414795 33.06467438 33.06746674 33.06798553 33.06781006 33.07210159 33.07374191 33.06978607 33.06655121 33.06568909 33.06422043 33.06510544 33.06804276 33.06868362 33.06342316 33.06558228 33.06812668 33.06647873 33.0704155 33.06365585 33.06738281 33.0692482 33.06755447 33.06923676 33.10306931 33.06189728 33.06462479 33.06838608 33.06234741 33.07218552 33.06621933 33.06263351 33.06661987 33.06598282 33.06166077 33.07400513 33.61779404 33.06810379 33.06974411 33.06502151 33.06510544 33.07076263 33.07315063 33.06295776 33.06890488 33.07281113 33.06631851 33.06027985 33.06604385 33.08040237 33.07346725 33.06786728 33.06481934 33.06479263 33.06208038 33.06311035 33.06495285 33.06390381 33.06871796 33.07246017 33.07382202 

-------
======================
selected experts : 8, 9, 27, 32, 39, 52, 
layer26_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df27d4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.09747 -1.72508 -0.102068-3.96982 0.264923 0.310013 0.223394 0.572912 -0.468745]

layer26_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddd52130>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[8.23987 0.470053 -0.615066-4.86658 -0.817679 2.26123 5.53967 1.00934 -2.25415]

layer27_wq's input 
<N9nntrainer6TensorE at 0x5682de328070>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wq's output 
<N9nntrainer6TensorE at 0x5682ddefef30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-3.71408 1.9354 2.356543.03328 2.67895 4.20827 -1.76141 2.67573 -0.578456]
============================
layer27_wk's input 
<N9nntrainer6TensorE at 0x5682de1e5e50>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wk's output 
<N9nntrainer6TensorE at 0x5682ddfc8350>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.400105 -0.24232 0.401053-0.150454 0.0979789 0.371003 -0.358186 -0.0571382 0.698908]
============================
layer27_wv's input 
<N9nntrainer6TensorE at 0x5682de7969c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wv's output 
<N9nntrainer6TensorE at 0x5682de46fef0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.420768 -0.0722796 -0.2112940.196022 -0.195416 0.81495 0.146881 0.813715 -0.146626]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-4.07158 -0.981001 3.634541.24264 4.01894 -2.9554 3.01345 -1.08683 0.311499]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a054fc20
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer27_attention_out's input 
<N9nntrainer6TensorE at 0x5682de426170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer27_attention_out's output 
<N9nntrainer6TensorE at 0x5682de0d2950>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer27_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de6e6390>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[8.23987 0.470053 -0.615066-4.86658 -0.817679 2.26123 5.53967 1.00934 -2.25415]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.05855 0.114221 -0.147658-1.16832 -0.203481 0.564918 1.35693 0.242312 -0.538953]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.987653255 -0.7842393517 -2.230341911 -0.758665204 -1.053579092 -1.312015295 1.44309485 -0.69209975 -1.784579635 -1.067586184 -0.6883801222 -1.15128839 -0.1300299764 -0.478109628 -0.1315491945 -0.6079538465 -0.1765194386 1.365325212 -1.465485215 -1.203162909 -0.4411250651 -0.5796673298 -0.9326632023 -0.09328451753 -2.341962814 -0.3186990917 -1.199958563 2.033224821 -0.1808017492 -1.539794326 1.491401196 -1.677116752 -0.9739207029 -0.5623084307 -0.4002993405 -1.290343404 -0.2136254013 2.042429447 0.2812911868 -0.07124047726 -0.1099433899 -0.68425107 -0.9261820316 -1.498537898 -1.244819045 -0.7785608768 0.3858971894 -1.06656611 -0.2841586769 -1.134593248 -2.137027025 -0.7241751552 -2.135964632 -1.843329668 -0.5121998787 -1.465894222 -2.073708057 -0.02629480883 -0.6666491628 -2.23829031 -0.3608047664 -1.097417712 -1.685164094 -0.1254190207 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.002409837907 0.008028305136 0.001890555723 0.008236270398 0.006132691167 0.004736021161 0.07446338981 0.008803178556 0.00295244297 0.006047389004 0.008835984394 0.005561813246 0.01544341724 0.0109037105 0.01541997306 0.009575990029 0.01474189386 0.06889185309 0.004062212072 0.00528065348 0.01131452806 0.009850728326 0.006920925807 0.01602144539 0.001690881327 0.01278808154 0.005297601689 0.1343485564 0.0146788964 0.003771294607 0.078148745 0.003287396161 0.00664119469 0.01002322044 0.01178601291 0.004839781206 0.01420490444 0.1355908811 0.02330117859 0.01637854613 0.01575675793 0.008872545324 0.006965926848 0.00393013889 0.005065199919 0.00807402283 0.02587066963 0.006053561345 0.01323750429 0.005655448884 0.002075465396 0.00852529332 0.002077671699 0.002783984412 0.01053826418 0.004060550593 0.002211132087 0.01713148504 0.009030101821 0.001875588438 0.01226080861 0.005869649351 0.003261048347 0.01551478729 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
31.49386406 31.49948311 31.49334526 31.50016785 31.49615669 31.49428368 31.56687164 31.49978065 31.49393082 31.49798012 31.50076866 31.4955864 31.50546837 31.50283623 31.50639915 31.49960136 31.50619698 31.55700874 31.49599457 31.48624611 31.50324631 31.50178337 31.49885368 31.50413895 31.49219322 31.50424385 31.49675179 31.62341881 31.50661087 31.49188805 31.5700798 31.49426651 31.49809647 31.5014782 31.50133324 31.49629402 31.50089073 31.62180138 31.51571083 31.50783348 31.50768852 31.5008049 31.49746704 31.49586296 31.49747467 31.49905205 31.50683594  31.497509 31.50564575 31.4975872 31.49400711 31.49998093 31.49353218 31.4928093 31.50199318 31.4926548 31.49414253 31.50763321 31.5009613 31.49380684 31.50419235 31.49732399 31.49519348 31.50696945 

-------
======================
selected experts : 6, 17, 27, 30, 37, 46, 
layer27_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df2fed10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-2.73092 -1.75519 1.56366.56381 4.80255 3.19545 -10.1483 2.09887 -0.0882844]

layer27_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de4dbd00>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.50894 -1.28514 0.9485321.69723 3.98487 5.45668 -4.60863 3.10822 -2.34244]

(93958)Ilayer0_wq's input 
<N9nntrainer6TensorE at 0x5682dde663b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00470756 -0.0465267 -0.01080840.0123846 0.0280342 -0.012272 -0.0514805 -0.00136512 0.0315807]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5682de7965e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.166964 -1.09071 1.079920.0058572 0.676155 0.796471 -0.433137 -0.820415 0.66633]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5682ddd56d10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00470756 -0.0465267 -0.01080840.0123846 0.0280342 -0.012272 -0.0514805 -0.00136512 0.0315807]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5682de0a36b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.86394 -0.0748888 0.168426-0.845703 0.365969 -0.525742 -1.64801 0.556798 0.671278]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5682e0a65b00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00470756 -0.0465267 -0.01080840.0123846 0.0280342 -0.012272 -0.0514805 -0.00136512 0.0315807]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5682dde490d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0143575 0.0228836 0.003861170.00985081 0.0516625 0.0180623 0.0077625 -0.0177031 0.00990551]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.1034 -0.00648903 1.049190.255839 1.03875 -0.112052 -0.595744 0.711181 -0.551852]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a25a0120
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer0_attention_out's input 
<N9nntrainer6TensorE at 0x5682e0a64030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer0_attention_out's output 
<N9nntrainer6TensorE at 0x5682e0a638e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer0_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dde13420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00302124 -0.0292053 -0.008056640.00805664 0.0161133 -0.00805664 -0.0312195 -0.00100708 0.0241699]

layer0_ffn_gate's input 
<N9nntrainer6TensorE at 0x5682ddfb82c0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0210257 -0.201616 -0.05471740.052916 0.110786 -0.051565 -0.21552 -0.00689597 0.16145]
==============================
layer0_ffn_gate's output 
<N9nntrainer6TensorE at 0x5682dde852c0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[0.0710219 -0.0243796 -0.08894840.12087 0.0489584 -0.104624 0.0413304 0.0387468 -0.0774261]
============================
layer0_ffn_up's input 
<N9nntrainer6TensorE at 0x5682de34f990>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0210257 -0.201616 -0.05471740.052916 0.110786 -0.051565 -0.21552 -0.00689597 0.16145]
==============================
layer0_ffn_up's output 
<N9nntrainer6TensorE at 0x5682dde690c0>
data addr: 0x7fc0a7fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.129525 -0.047763 -0.2889950.0299654 -0.331167 -0.346303 -0.0853519 -0.0627946 -0.10754]
============================
layer0_ffn_down's input 
<N9nntrainer6TensorE at 0x5682dc3e1140>
data addr: 0x7fc0aafd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.00476281 0.000575125 0.01228160.00192028 -0.0083051 0.017169 -0.00180026 -0.00124011 0.00400212]
==============================
layer0_ffn_down's output 
<N9nntrainer6TensorE at 0x5682dc3e0770>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.000936617 0.0861878 0.002459120.0408338 -0.0465336 -0.0519033 -0.00198296 0.0126573 0.0261818]
============================
layer0_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3e1bb0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00208462 0.0569825 -0.005597520.0488904 -0.0304203 -0.0599599 -0.0332024 0.0116502 0.0503517]

layer1_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e48b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.003422 0.090049 -0.007508580.0856461 -0.0376385 -0.0657403 -0.0496224 0.0147001 0.09129]
==============================
layer1_wq's output 
<N9nntrainer6TensorE at 0x5682dc3e2330>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-2.2137 1.49018 1.76725-0.873064 2.77531 0.719708 -1.12149 1.2827 1.41735]
============================
layer1_wk's input 
<N9nntrainer6TensorE at 0x5682dc3e6610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.003422 0.090049 -0.007508580.0856461 -0.0376385 -0.0657403 -0.0496224 0.0147001 0.09129]
==============================
layer1_wk's output 
<N9nntrainer6TensorE at 0x5682dc3e6380>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.00567 1.59998 1.3431.87863 0.238808 1.73569 -2.11491 -0.212269 1.81347]
============================
layer1_wv's input 
<N9nntrainer6TensorE at 0x5682dc3e7400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.003422 0.090049 -0.007508580.0856461 -0.0376385 -0.0657403 -0.0496224 0.0147001 0.09129]
==============================
layer1_wv's output 
<N9nntrainer6TensorE at 0x5682dc3e7190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0673909 0.0620003 0.109753-0.102173 0.0435433 0.0182136 -0.0732091 -0.0083449 0.147085]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.15223 -2.40696 1.92142-0.439973 2.1543 -1.89191 1.61152 0.55325 -2.17094]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a34c5998
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer1_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ea340>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer1_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ea2a0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer1_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3eb440>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00208462 0.0569825 -0.005597520.0488904 -0.0304203 -0.0599599 -0.0332024 0.0116502 0.0503517]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0031794 0.270845 -0.02537140.274307 -0.140865 -0.351105 -0.187914 0.062511 0.185047]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4307895005 -0.1841507256 0.135800615 0.04447042197 -0.0499409847 -0.4950153232 -0.5512891412 1.30370307 1.275840998 0.5842041373 -0.3279032111 -1.648462653 -0.02648603171 -0.0264756158 -0.2227101475 2.397724152 -0.6761419773 -0.2701722682 0.5824278593 0.1082199812 0.001042265445 -0.4016340971 1.609354734 -0.5031391382 -0.5605567694 -0.6605211496 -0.1350102723 -1.336895704 -0.5455344915 2.85885191 -0.6387345195 -0.1259180605 -0.6464231014 -0.07153322548 -0.07752400637 0.3379843533 -0.1304998696 -0.5933691859 0.4696699679 -1.348541856 -0.9087414145 -1.581966996 1.002173305 1.892059326 -0.8242944479 0.5786972046 -0.6346139908 0.05505080894 -0.4305692911 -0.01128564775 -1.803298354 -0.3296391964 -0.5814422369 -0.3645513356 -0.6953773499 -0.8920446634 0.763395071 0.3901729286 -0.1331802905 -0.1245460138 1.428204656 -1.546777725 -0.6999182105 -0.2506659031 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01537049562 0.008310415782 0.01144394744 0.01044507604 0.009504062124 0.00608998118 0.005756739527 0.03679505363 0.03578401729 0.01791905425 0.00719766831 0.001921675866 0.009729616344 0.009729715995 0.007996070199 0.109879531 0.005081052426 0.007625424769 0.01788725331 0.01113263052 0.01000117604 0.006686069537 0.04994963109 0.006040709093 0.005703633651 0.005161046516 0.008728994057 0.002624170622 0.005789962132 0.1742537022 0.005274720956 0.008808720857 0.005234321579 0.009301048703 0.009245495312 0.01400822587 0.008768454194 0.005519520957 0.01597988047 0.002593786223 0.00402658619 0.002053803531 0.02721678093 0.06626883894 0.004381389357 0.01782064326 0.005296500865 0.01055617724 0.006495380308 0.009878640063 0.001646022662 0.007185184397 0.005585746374 0.006938662846 0.004984250292 0.004094382282 0.02143565007 0.01475870889 0.00874498114 0.008820815012 0.04167348519 0.00212736195 0.004961668514 0.007775629871 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
62.87144089 62.86343002 62.86751556 62.86460876 62.86366653 62.86120605 62.86087418 62.89191437 62.89090347 62.87303543 62.86231613 62.85704041 62.86484909 62.86484909 62.8631134 62.96308899 62.86019897 62.86274338 62.87300491 62.86624908 62.86511993 62.86180496 62.90029907 62.86211395 62.86082077 62.86027908 62.86384583 62.85869598 62.85900116 63.02841949 62.8613472 62.86392593 62.86130524 62.86441803 62.8653183 62.86912537 62.86388779 62.85873032 62.87109756 62.85771179 62.85914612 62.85812378 62.88042831 62.92138672 62.85950089 62.87294006 62.85850525 62.86567307 62.86066055 62.86499786 62.85676193 62.86230469 62.86070251 62.86205673 62.86010361 62.85825729 62.87559891 62.86987686 62.86386108 62.86393738 62.89678955 62.8572464 62.86008072 62.86289215 

-------
======================
selected experts : 7, 15, 22, 29, 43, 60, 
layer1_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e0a3ef10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0245953 -0.0391809 -0.02191010.0561746 -0.0766892 -0.0429587 -0.0702658 0.0359129 -0.109381]

layer1_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3ee080>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.02668 0.0178016 -0.02750760.105065 -0.10711 -0.102919 -0.103468 0.0475631 -0.0590292]

layer2_wq's input 
<N9nntrainer6TensorE at 0x5682dc3ee2c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.105586 0.0526663 -0.07292650.347169 -0.253097 -0.340076 -0.320027 0.139803 -0.165567]
==============================
layer2_wq's output 
<N9nntrainer6TensorE at 0x5682dc3ee260>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.728063 0.116087 -0.7897090.168591 -0.62339 -0.0035476 0.975437 0.2551 -0.481121]
============================
layer2_wk's input 
<N9nntrainer6TensorE at 0x5682dc3edf00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.105586 0.0526663 -0.07292650.347169 -0.253097 -0.340076 -0.320027 0.139803 -0.165567]
==============================
layer2_wk's output 
<N9nntrainer6TensorE at 0x5682dc3ede70>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.49132 0.0543507 -0.20134-2.59986 0.763209 -1.86359 -0.642021 1.05378 -0.949512]
============================
layer2_wv's input 
<N9nntrainer6TensorE at 0x5682dc3ee380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.105586 0.0526663 -0.07292650.347169 -0.253097 -0.340076 -0.320027 0.139803 -0.165567]
==============================
layer2_wv's output 
<N9nntrainer6TensorE at 0x5682dc3ee3b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.725264 -0.00604983 -0.4373230.0222086 -0.0746775 -0.442288 0.476208 0.433268 0.273971]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00891845 -0.737206 -0.807282-0.0189138 -0.353084 0.51377 -0.132648 -0.999479 0.911827]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0857838
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer2_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ee500>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer2_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ee620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer2_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3fefb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.02668 0.0178016 -0.02750760.105065 -0.10711 -0.102919 -0.103468 0.0475631 -0.0590292]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0471549 0.0731857 -0.1083330.468274 -0.428001 -0.466616 -0.457182 0.20742 -0.209794]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.0934920162 0.5232843757 -0.8450167775 -0.3234837353 -0.0336504057 2.137332201 -0.5679025054 0.006714668591 -0.3903882802 0.1523206532 0.2629042566 -0.2128079832 0.240971595 0.1091089919 -0.5416561365 -0.6098800302 1.601985097 -0.7315782309 -0.3482190669 1.016847491 -0.2046647668 0.06216091663 0.1674819887 -0.1112588271 -0.535158813 -0.2945003808 -0.5575503707 0.02658708766 -1.601998091 0.1779913604 -0.6792650819 -0.06728672981 -0.1698344648 -0.322052598 -0.0734956935 -0.309035331 -0.6906391978 -0.7844748497 0.08373695612 0.03448255733 0.4836958349 -0.1885450035 -0.5079341531 1.050334334 0.06574561447 0.2271577567 0.693333745 -0.1737065762 -0.3850834966 0.2595508099 1.380516768 0.5898442268 -0.4565664828 -0.9783053398 0.5971566439 -0.1786491424 0.2759366035 -0.8576596379 -1.095670342 0.5211244226 -0.1892276555 -0.1837007254 0.04368966445 0.7588869333 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0116348099 0.0215586666 0.005487521645 0.009244323708 0.01235231012 0.1082913876 0.007239780389 0.01286111027 0.00864607282 0.01487696543 0.01661652513 0.01032621227 0.01625604741 0.01424779743 0.007432313636 0.006942163687 0.06340093166 0.006146699656 0.009018465877 0.03531616926 0.01041064411 0.01359435264 0.01510423888 0.01142992266 0.007480761502 0.009516175836 0.007315116934 0.01311924774 0.002574088285 0.01526381262 0.006476812065 0.01194373332 0.01077963877 0.009257561527 0.01186980586 0.009378859773 0.00640356075 0.005830009468 0.01389084943 0.01322324108 0.02072186209 0.01057982072 0.007687221281 0.03651881963 0.01364316978 0.01603303291 0.0255548507 0.01073797885 0.008692059666 0.01656089723 0.05080578476 0.02304243855 0.008092412725 0.004802747164 0.02321155183 0.01068503596 0.01683449559 0.005418580491 0.004270893056 0.02151214704 0.01057260111 0.01063119527 0.01334555261 0.02728618123 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
53.42539597 53.43531799 53.41925049 53.42300415 53.42611313 53.52014542 53.42100143 53.42662048 53.42240906 53.42863846 53.43037796 53.4212265 53.43001556 53.42800903 53.42119217 53.42070389 53.47620773 53.41990662 53.42277908 53.44812393 53.42417145 53.42544937 53.42886353 53.4242363 53.42124176 53.42327881 53.42012405 53.42687988 53.41633606 53.42902374 53.42023849 53.42570496 53.42454147 53.42301941 53.42563248 53.42314148 53.42016602 53.41863632 53.42765045 53.42698288 53.43448257 53.42433929 53.42144775 53.45027924 53.4274025 53.42979431 53.4393158 53.42449951 53.41959381 53.43032074 53.46456528 53.43489456 53.42185211 53.41856384 53.4360199 53.42444611 53.4305954 53.41917801 53.41707993 53.43527222 53.42338181 53.42343903 53.42710495 53.44104767 

-------
======================
selected experts : 5, 16, 19, 43, 50, 63, 
layer2_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e09f8dd0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0519867 0.00856681 -0.0284037-0.0400309 0.0270178 0.0200372 0.0438958 -0.00988634 -0.0751584]

layer2_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc401970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0786666 0.0263684 -0.05591130.0650342 -0.0800917 -0.0828815 -0.0595725 0.0376768 -0.134188]

layer3_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e86c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.371832 0.0749493 -0.1526720.168237 -0.191842 -0.199847 -0.150303 0.0950594 -0.426412]
==============================
layer3_wq's output 
<N9nntrainer6TensorE at 0x5682dc409160>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.0692 -0.458864 1.38395-1.07684 -0.394386 1.17786 -0.148935 -0.389548 0.619026]
============================
layer3_wk's input 
<N9nntrainer6TensorE at 0x5682dc41f6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.371832 0.0749493 -0.1526720.168237 -0.191842 -0.199847 -0.150303 0.0950594 -0.426412]
==============================
layer3_wk's output 
<N9nntrainer6TensorE at 0x5682dc41f440>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[3.77456 0.805306 0.5845431.64642 -2.70246 1.18473 0.379973 0.740736 -1.26943]
============================
layer3_wv's input 
<N9nntrainer6TensorE at 0x5682dc4204c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.371832 0.0749493 -0.1526720.168237 -0.191842 -0.199847 -0.150303 0.0950594 -0.426412]
==============================
layer3_wv's output 
<N9nntrainer6TensorE at 0x5682dc420250>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.181916 -0.197801 -0.242114-0.0812725 0.0323169 -0.359375 0.0569709 0.188467 -0.595215]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.298411 1.12459 1.59574-0.726994 0.752984 0.987883 -0.304318 0.285166 -0.0294429]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a167a8a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer3_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc422910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer3_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc422870>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer3_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc423990>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0786666 0.0263684 -0.05591130.0650342 -0.0800917 -0.0828815 -0.0595725 0.0376768 -0.134188]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.140693 0.0997921 -0.2035630.263778 -0.294157 -0.338814 -0.238772 0.146199 -0.443554]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7289729714 -0.5335597396 -0.1839262992 -0.5233195424 0.3554777801 0.2119001746 1.552555442 -0.6535074711 -0.00459009409 -0.07510069758 0.5618703961 0.1054131314 0.253040731 -0.1304226369 -1.080092669 -0.1675660461 -1.218974829 -0.8078290224 -0.05679995567 -0.01361918356 0.1924585104 -0.1846369505 -0.4339244068 -0.5550991893 -0.09112460911 -0.4543816149 -0.3196879923 -0.5018143058 -0.2495882511 0.2730513811 -0.9791836739 0.1265223324 -0.4175069928 -0.1767056584 1.010258198 0.4161131382 -0.3894725144 0.1850838661 -0.7227553725 -0.01342593506 0.02664080262 -0.4128195047 -1.153370023 -0.5147992373 -0.3168607652 -0.4345905781 -0.4674172699 -0.5376713276 1.158827305 -1.018765807 1.621137977 -0.1733201444 0.3592012525 0.07649448514 0.09867663682 -0.5094680786 -0.08239448071 0.6137117743 -0.8467483521 1.075052023 1.401985168 -0.4103972316 -0.1727882624 -1.128186226 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006799882744 0.008267388679 0.01172768231 0.008352482691 0.02011279576 0.01742278039 0.06658197194 0.007332900073 0.01403126772 0.0130759906 0.02472336777 0.01566284709 0.01815451123 0.01237224694 0.004786435049 0.01192112826 0.004165780731 0.006284268107 0.01331749279 0.01390514988 0.01708732359 0.01171935163 0.009133546613 0.008091217838 0.01286813058 0.008948598057 0.01023886167 0.008534051478 0.0109823579 0.01852145605 0.00529463822 0.01599699259 0.009284732863 0.01181267016 0.0387114957 0.02137007378 0.009548707865 0.01696177572 0.006842294708 0.01390783675 0.01447639242 0.009328356944 0.004448239692 0.008423952386 0.01026785001 0.009127464145 0.008832703345 0.008233467117 0.04491203278 0.005089159124 0.07130856067 0.01185273007 0.02018782683 0.01521638595 0.01555769052 0.008468980901 0.0129809631 0.02603886276 0.00604438642 0.0413028039 0.05727496371 0.009350981563 0.01185903698 0.004561685026 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
42.54202271 42.53967285 42.54694748 42.54357529 42.55437851 42.55264282 42.59798813 42.54350662 42.54925156 42.54925156 42.55899048 42.55088425 42.55051422 42.54759216 42.54000854 42.54714203 42.53938675 42.54055023 42.54949188 42.54721832 42.55230713 42.54789352 42.54530716 42.54331207 42.54808807 42.54417038 42.54545975 42.54375458 42.54620361 42.55374146 42.5405159 42.55121994 42.54164505 42.54703522 42.57393265 42.55659103 42.54476929 42.55218124 42.54206467 42.54912949 42.54969788 42.54454803 42.54062271 42.54364395 42.54358292 42.54434967 42.54405212 42.54345322 42.58108521 42.54030991 42.60748291 42.54707336 42.5544548 42.55043793 42.55077744 42.54273605 42.54820251 42.5622139 42.54030991 42.57270813 42.59249496 42.54457092 42.54708099 42.53978348 

-------
======================
selected experts : 6, 34, 48, 50, 59, 60, 
layer3_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc426710>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.060015 -0.0205406 0.0372005-0.0560069 0.0877867 -0.00908835 -0.0705842 0.0198905 0.0873397]

layer3_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc426050>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.138682 0.00582782 -0.01871080.00902725 0.007695 -0.0919698 -0.130157 0.0575673 -0.0468479]

layer4_wq's input 
<N9nntrainer6TensorE at 0x5682dc44b9a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.350666 0.016757 -0.05298880.0273912 0.0195685 -0.28172 -0.383648 0.175507 -0.140796]
==============================
layer4_wq's output 
<N9nntrainer6TensorE at 0x5682dc492890>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.969563 0.721811 -1.201660.176894 1.05716 -0.291057 0.800175 0.638609 0.780764]
============================
layer4_wk's input 
<N9nntrainer6TensorE at 0x5682dc44d700>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.350666 0.016757 -0.05298880.0273912 0.0195685 -0.28172 -0.383648 0.175507 -0.140796]
==============================
layer4_wk's output 
<N9nntrainer6TensorE at 0x5682dc44d470>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.985035 -1.19871 1.55621-0.124086 -1.33027 0.445463 -1.51528 -0.496529 -0.296997]
============================
layer4_wv's input 
<N9nntrainer6TensorE at 0x5682dc44e4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.350666 0.016757 -0.05298880.0273912 0.0195685 -0.28172 -0.383648 0.175507 -0.140796]
==============================
layer4_wv's output 
<N9nntrainer6TensorE at 0x5682dc44e280>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.232352 0.0497875 0.2972450.215731 1.04167 0.073453 -0.145023 0.023658 -0.0093237]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.855201 0.854221 -1.20995-0.106257 0.352987 -1.03813 0.288657 -0.982231 -0.402452]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1e8e8e8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer4_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc450940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer4_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4508a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer4_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4519c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.138682 0.00582782 -0.01871080.00902725 0.007695 -0.0919698 -0.130157 0.0575673 -0.0468479]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.254483 0.0222303 -0.06839880.0365216 0.0293528 -0.377398 -0.53786 0.226246 -0.16178]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4233067334 -0.8003293872 0.6444360018 -0.4378878772 -1.36439085 -0.1103366837 -0.7561166883 0.1250419915 0.3909090459 0.02027952112 -0.2909910083 0.1024083048 -0.9229542017 -0.448563695 -1.051607847 -0.5025811195 -0.5787528753 0.1923734844 -0.9440920353 -0.5193585753 -0.08674078435 -1.059256077 -0.4905348122 -0.6434621215 -0.8703958392 1.485964775 -0.1829965711 -0.744075954 -0.7400940061 -1.118461967 -0.506603539 -0.1404953897 0.03317378461 -0.8824873567 -0.2091689259 0.6334250569 0.6675570011 -1.059693217 0.1148692369 -0.3503339589 -0.3829305768 -0.5799865723 0.864215374 -0.6390654445 -0.493824482 0.3954688013 1.241177559 -0.1369689256 0.2495298237 2.187966347 2.07179904 1.488792062 -0.8710832596 -0.5833969712 0.1309114397 0.8206555247 -0.95511657 0.3027754426 -1.015067458 -0.1963151693 0.06178678945 0.2862616777 -1.829807281 -0.1472508758 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01924641244 0.005661497824 0.02400960401 0.008134627715 0.003220791463 0.01128733344 0.005917424336 0.01428285614 0.01863286458 0.01286225859 0.009421806782 0.01396321505 0.005008136388 0.008048247546 0.004403545521 0.007625034545 0.007065791171 0.01527765673 0.004903385881 0.007498172577 0.01155683771 0.004369994625 0.007717443164 0.006623048335 0.005278395023 0.05570014566 0.01049628574 0.005989104975 0.006013001315 0.004118775483 0.007594425697 0.01095200609 0.01302918326 0.005214955658 0.01022513676 0.02374668419 0.02457119711 0.004368084949 0.01413829438 0.008878955618 0.008594199084 0.007057080045 0.0299112089 0.00665223226 0.007692097686 0.01871802099 0.04360603169 0.01099069603 0.01617630944 0.1123910472 0.1000647023 0.05585784465 0.005274767522 0.007033053786 0.01436693408 0.02863625437 0.004849625286 0.01706096902 0.004567428492 0.0103574153 0.0134073738 0.01678154245 0.002022249857 0.01087826863 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.83690262 40.82331848 40.8407135 40.82674408 40.82183075 40.82989883 40.82452774 40.83098602 40.83247375 40.8314743 40.82707977 40.83257294 40.82361984 40.82570648 40.82301331 40.82623672 40.82376862 40.83198166 40.82351303 40.82611084  40.829216 40.82298279 40.82346725 40.82332611 40.82293701 40.87430954 40.82624817 40.82269287 40.82462311 40.82273102 40.82620621 40.82956314 40.83164215 40.82382584 40.82883453 40.84045029 40.84032059 40.82011795 40.83274841 40.82558441 40.82625198 40.82566833 40.84852219 40.8243103 40.82630157 40.83351517 40.86221695 40.82864761 40.8338356 40.92337418 40.91772079 40.87160873 40.82388687 40.82469177 40.83202362 40.84724808 40.82345963 40.83567047 40.82031631 40.82896805 40.83201981  40.835392 40.82063293 40.82949066 

-------
======================
selected experts : 25, 42, 46, 49, 50, 51, 
layer4_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc454a40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0478261 -0.0202937 0.1414030.138244 0.0105741 0.0660352 -0.078456 -0.0414171 -0.0757324]

layer4_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc454380>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.186508 -0.0144659 0.1226920.147271 0.0182691 -0.0259347 -0.208613 0.0161502 -0.12258]

layer5_wq's input 
<N9nntrainer6TensorE at 0x5682dc4a0910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37183 -0.0395841 0.2973610.381879 0.0397548 -0.0713048 -0.551814 0.0452452 -0.319453]
==============================
layer5_wq's output 
<N9nntrainer6TensorE at 0x5682dc454560>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.27904 -1.01169 -0.9215611.36454 -0.72238 -0.498745 1.54375 0.659523 -1.45093]
============================
layer5_wk's input 
<N9nntrainer6TensorE at 0x5682dc4a2670>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37183 -0.0395841 0.2973610.381879 0.0397548 -0.0713048 -0.551814 0.0452452 -0.319453]
==============================
layer5_wk's output 
<N9nntrainer6TensorE at 0x5682dc4a23e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[3.24098 0.412286 -2.08267-1.41415 0.314497 -1.61792 -1.16653 0.709432 -1.39033]
============================
layer5_wv's input 
<N9nntrainer6TensorE at 0x5682dc4a3460>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37183 -0.0395841 0.2973610.381879 0.0397548 -0.0713048 -0.551814 0.0452452 -0.319453]
==============================
layer5_wv's output 
<N9nntrainer6TensorE at 0x5682dc4a31f0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.139015 0.095336 -0.0847325-0.0599647 0.125625 -0.379508 -0.338026 -0.0653292 0.0863798]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.960323 0.423272 -1.212571.11397 -0.818387 0.317524 0.0268759 -1.67851 1.48448]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1c898d8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer5_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc4a58b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer5_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4a5810>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer5_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a6930>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.186508 -0.0144659 0.1226920.147271 0.0182691 -0.0259347 -0.208613 0.0161502 -0.12258]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.345097 -0.0535328 0.4348510.579535 0.0642743 -0.101381 -0.815489 0.0618702 -0.415289]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.6644698381 0.3958806396 -0.8431923985 0.2933754027 -0.9926815033 0.3259683251 0.4573433399 -1.295527816 -0.8638315797 -0.5962546468 1.083653688 -0.5674967766 -0.2397421151 -0.5430603027 -1.03829217 -0.1272376031 -0.290961802 1.88923049 -0.6655781865 -0.4766088128 1.197840452 -0.892660141 -1.295008659 0.4723694921 -0.5369101167 -0.04444982111 -0.7701082826 -0.6128735542 -0.4972300231 -0.9362294674 0.0592253916 -0.4229903519 0.525193572 -0.3231920004 -0.5599902868 -0.8925861716 0.3094721735 -0.1731057167 0.5254550576 0.6374439001 0.4803516567 -1.244556785 -1.547644854 -0.3532342017 0.2070346922 -0.2350983173 -0.2090717554 -1.477300048 0.4622754753 -0.6229419112 0.3936619759 -1.05861032 -0.765895009 -1.137443542 -0.4172428548 0.1035719812 0.1171668693 -0.9444702864 -0.2407902479 -0.0649222061 -1.223350048 -0.465829283 -0.371851325 -0.9839936495 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03131745011 0.02394085377 0.006934529636 0.02160837501 0.005971654784 0.0223242566 0.02545848116 0.004411337432 0.006792874075 0.008876888081 0.04762506858 0.009135873988 0.012679209 0.00936187245 0.005705402233 0.01418901514 0.01204613503 0.1065842882 0.008282355964 0.01000511926 0.05338586867 0.006599840242 0.004413628019 0.02584391087 0.009419627488 0.0154136857 0.007460313383 0.008730582893 0.009800913744 0.006318463944 0.01709747873 0.01055622008 0.02724579349 0.01166407671 0.009204710834 0.006600328255 0.0219590161 0.01355289109 0.02725291811 0.03048240207 0.02605102956 0.00464201672 0.003428286873 0.01131887082 0.01982096769 0.01273822412 0.01307410747 0.003678134643 0.02558435686 0.008643120527 0.0238877926 0.005590649322 0.007491810247 0.005166843999 0.01061706711 0.01787275821 0.0181173943 0.0062666093 0.01266592741 0.01510133874 0.004741509445 0.01011355128 0.01111009717 0.006023761351 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.26918793 33.26371765 33.24861908 33.26329422 33.24574661 33.26019287 33.26714325 33.23941803 33.24752426 33.25056076 33.28835678 33.24986649 33.25436401 33.2481842 33.24739075 33.25587463 33.25373077 33.33968353 33.24996567 33.25168991 33.28553391 33.24828339 33.24609756 33.26752853 33.24633408 33.25709915 33.24914551 33.2504158 33.25148392 33.24704742 33.25878143 33.25033188 33.26320648 33.2533493 33.25088882 33.24732971 33.26364136 33.25523758 33.26512146 33.26930618 33.26773453 33.24632645 33.2441597 33.25300217 33.25959778 33.25442123 33.25475693 33.24440765 33.26631546 33.25032806 33.26366425 33.24727631 33.24536133 33.24589539 33.24943924 33.25574112 33.25979996 33.24318314 33.25434875 33.25678635 33.24642563 33.24702835 33.25088501 33.24103165 

-------
======================
selected experts : 0, 10, 17, 20, 38, 39, 
layer5_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc4a9a10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0342631 0.0553379 -0.039758-0.0504181 0.0299267 0.0941602 0.0995771 -0.124148 0.0256439]

layer5_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a9350>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.152245 0.040872 0.08293390.0968529 0.0481958 0.0682255 -0.109036 -0.107998 -0.0969364]

layer6_wq's input 
<N9nntrainer6TensorE at 0x5682dc4e8620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.481221 0.135603 0.2714360.327848 0.136133 0.21565 -0.334867 -0.321996 -0.291189]
==============================
layer6_wq's output 
<N9nntrainer6TensorE at 0x5682dc4a9530>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.08021 0.134619 -1.689510.372374 -0.432704 -1.72997 0.560465 1.13711 -2.68552]
============================
layer6_wk's input 
<N9nntrainer6TensorE at 0x5682dc4ea380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.481221 0.135603 0.2714360.327848 0.136133 0.21565 -0.334867 -0.321996 -0.291189]
==============================
layer6_wk's output 
<N9nntrainer6TensorE at 0x5682dc4ea0f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.24336 0.122814 -0.1984340.556906 0.592433 -1.41524 -0.579507 0.669371 0.388004]
============================
layer6_wv's input 
<N9nntrainer6TensorE at 0x5682dc4eb170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.481221 0.135603 0.2714360.327848 0.136133 0.21565 -0.334867 -0.321996 -0.291189]
==============================
layer6_wv's output 
<N9nntrainer6TensorE at 0x5682dc4eaf00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.270678 -0.163141 -0.07282670.287713 0.071787 -0.199607 0.473052 -0.0426461 0.254859]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.290357 1.04913 -1.72981-0.0290937 -1.67434 -0.613703 0.840788 -0.948799 2.74515]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1a848c8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer6_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc41beb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer6_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc41be10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer6_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc41cf30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.152245 0.040872 0.08293390.0968529 0.0481958 0.0682255 -0.109036 -0.107998 -0.0969364]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.24061 0.139268 0.2732950.343046 0.157741 0.246238 -0.393529 -0.380101 -0.3064]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4410547912 -1.218328714 -0.749876678 -0.9559231997 -0.1196647584 0.1754807979 -0.5955162048 -1.395718694 -1.214615464 2.168490887 0.1459833086 0.8688387871 -0.7450354695 0.1884209365 0.9173011184 0.175174281 -0.9830300212 -1.049170732 -0.6121963263 -0.0005945349112 -0.5670848489 0.2899364531 0.5462858081 -0.2541283667 0.09138106555 0.06696138531 -1.341629744 -1.249254823 -0.4981438816 -1.828889728 0.9308676124 0.9007117152 0.7550630569 0.6048219204 0.6557562947 0.1265725344 0.4342204928 -0.3482604623 -1.431741595 0.3023626208 2.698046684 -1.048008323 -0.1608816832 -0.9697629213 -0.1068262458 -0.6657227874 -0.5831062198 0.0226062946 -1.022549629 -0.3982205987 -0.1861209869 -0.4678562284 0.5408172607 -0.1379685253 -0.3198312521 -0.4305019677 -0.6436776519 -0.3965961635 -0.2285197973 -0.2880137563 -0.3232179582 0.3415495753 0.3171806037 -0.8836710453 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01893318258 0.00360215595 0.005754514132 0.004682996776 0.01080702711 0.01451731566 0.006715008989 0.003016637405 0.003615557216 0.1065220684 0.01409534365 0.02904075198 0.005782441236 0.01470639277 0.03048279695 0.0145128658 0.004557759501 0.004266059492 0.00660392968 0.01217356324 0.006908665877 0.0162777286 0.02103414759 0.009447337128 0.0133463433 0.01302437484 0.003184296191 0.003492460819 0.007401756942 0.001956136664 0.03089915961 0.02998127788 0.02591765299 0.02230215259 0.02346752398 0.0138243828 0.0188042298 0.008598613553 0.002909902483 0.0164812617 0.1808934212 0.004271020647 0.01037064847 0.004618631676 0.01094666682 0.006259738468 0.006798860617 0.01245930512 0.00438115187 0.008179579861 0.01011217758 0.00762936892 0.02091943286 0.0106110163 0.008846570738 0.007919748314 0.006399268284 0.008192877285 0.009692393243 0.009132574312 0.008816663176 0.01713993214 0.01672729664 0.005033876281 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.14231491 40.12698364 40.12150955 40.12806702 40.13418961 40.13790131 40.13105011 40.12639999 40.1269989 40.22990417 40.13747787 40.14956284 40.12916565 40.13713455 40.15386581 40.13789368 40.12794113 40.1276474 40.12998581 40.13555527 40.13029099 40.13965988 40.14441681 40.13283157 40.13673019 40.13640594 40.12752151 40.12687683 40.13078308 40.12533951 40.15142059 40.1524086 40.14929962 40.14568329 40.14685059 40.13720703 40.14218521 40.1319809 40.12629318 40.13986206 40.30427551 40.12765503 40.13280106 40.12800217 40.13433075 40.13059616 40.12922668 40.13584137 40.12680817 40.13156128 40.13349533 40.13101196 40.14430237 40.13399506 40.12936783 40.13130188 40.12882996 40.13157654 40.13116837 40.13251495 40.13219833 40.13766098 40.14011002 40.12841797 

-------
======================
selected experts : 9, 11, 14, 30, 31, 40, 
layer6_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc47b4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.116619 0.06211 0.0381594-0.153191 0.0637205 -0.0967168 0.0778489 0.131376 0.107361]

layer6_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc47ae20>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.268863 0.102982 0.121093-0.0563378 0.111916 -0.0284913 -0.0311867 0.0233776 0.010425]

layer7_wq's input 
<N9nntrainer6TensorE at 0x5682dc5555c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.644431 0.295358 0.332417-0.150038 0.27742 -0.073543 -0.0830561 0.0581881 0.029045]
==============================
layer7_wq's output 
<N9nntrainer6TensorE at 0x5682dc47b000>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.732738 0.628422 1.19-0.581977 -0.188778 0.047805 -0.324582 0.481942 0.357657]
============================
layer7_wk's input 
<N9nntrainer6TensorE at 0x5682dc557b30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.644431 0.295358 0.332417-0.150038 0.27742 -0.073543 -0.0830561 0.0581881 0.029045]
==============================
layer7_wk's output 
<N9nntrainer6TensorE at 0x5682dc5578a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.62036 0.00124264 1.4656-1.44503 -0.546472 0.551392 -0.13881 0.625616 -0.065592]
============================
layer7_wv's input 
<N9nntrainer6TensorE at 0x5682dc558920>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.644431 0.295358 0.332417-0.150038 0.27742 -0.073543 -0.0830561 0.0581881 0.029045]
==============================
layer7_wv's output 
<N9nntrainer6TensorE at 0x5682dc5586b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.152496 -0.0865679 0.2932710.462981 -0.2989 0.268249 0.458184 0.729476 0.53018]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.728348 0.633505 1.29244-0.29051 -0.0664825 0.183037 0.568889 0.118266 -0.698215]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a187f8b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer7_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc55ad70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer7_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc55acd0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer7_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55bdf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.268863 0.102982 0.121093-0.0563378 0.111916 -0.0284913 -0.0311867 0.0233776 0.010425]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.407589 0.34599 0.391955-0.196204 0.362251 -0.0992247 -0.111167 0.0794998 0.0328892]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.098373771 0.2836256325 -0.2417769879 -0.3635024428 -0.606269002 0.2527832985 1.537901521 0.4816333354 0.09163210541 -1.234294653 -1.267491341 0.1218170673 -1.077616811 -0.6664997339 -1.141363263 -1.204203129 0.3488199711 -0.7398209572 -0.5408400297 -0.4675128162 0.485101819 0.2313048244 -0.05166152492 0.2560469806 1.058061838 -0.336117357 -0.6226214767 -0.9360643625 0.6463159323 -1.137920022 -0.1322301924 -0.1359293163 -0.3121391535 -0.7324919105 -0.521625936 0.09431058168 -0.3835838437 -0.3052536845 -0.400924474 -0.5267472863 0.1987118423 -1.661210179 -0.8067662716 -0.8190937042 -0.7711262703 0.4742020965 -0.4262674153 -0.8152752519 -0.8452249765 -0.2902589738 -0.3541771472 -0.3275723457 -0.3245003223 -0.08514315635 -1.52711904 -0.1305801272 -0.6654924154 -0.6012252569 -0.7324240804 -0.9401038289 1.551528454 -0.654296875 1.070305347 0.1213589758 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005570847541 0.02218789048 0.01312008314 0.01161640882 0.009112547152 0.02151401155 0.07777520269 0.02704641409 0.01831193827 0.004862858914 0.004704077728 0.01887311041 0.005687691271 0.008579893969 0.005336435977 0.005011413712 0.02368261106 0.007973313332 0.009728706442 0.01046889275 0.0271403864 0.02105685323 0.01586728729 0.02158434317 0.04813371971 0.01193892118 0.008964744397 0.006552566774 0.03188823164 0.005354842171 0.01463902555 0.01458497252 0.0122286547 0.008031964302 0.009917442687 0.01836105064 0.01138546225 0.01231314428 0.0111897327 0.009866783395 0.02038160898 0.003173106583 0.007457012311 0.007365650497 0.00772757316 0.02684617229 0.01090971567 0.007393830456 0.007175670471 0.01249916758 0.01172524225 0.0120413769 0.01207842398 0.01534481905 0.003628436942 0.01466319896 0.008588538505 0.009158621542 0.008032510057 0.006526151206 0.07884228975 0.008685233071 0.04872666672 0.01886446774 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
35.92993164 35.95131683 35.94129562 35.93693161 35.93633652 35.95064545 35.98973846 35.95426941 35.94648743 35.93304062 35.93383408 35.94800186 35.93481827 35.93580246 35.93446732 35.93318939 35.95281219 35.93710327 35.93695068 35.93864441 35.95531845 35.94923401 35.94213867 35.94880676 35.96677399 35.93916321 35.93809509 35.93473053 35.94861984 35.93448639 35.94281769 35.94276047 35.9404068 35.93716431 35.93904877 35.94272232 35.93956375 35.93953705 35.93936539 35.9380455 35.94665146 35.93039703 35.93468094 35.93649673 35.93685913 35.9521637 35.93908691 35.93652344 35.93535233 35.93686295 35.93990326 35.93640518 35.94120789 35.94352341 35.93275833 35.9418869 35.93676376 35.93828964 35.93716431 35.9356575 36.00606537 35.93781662 35.97785568 35.94704056 

-------
======================
selected experts : 6, 20, 24, 28, 60, 62, 
layer7_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5969b0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0117731 -0.00431516 0.09412550.0485652 -0.0529214 -0.069048 -0.0954666 0.055075 0.0510467]

layer7_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55e510>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.25709 0.0986668 0.215219-0.00777257 0.0589949 -0.0975393 -0.126653 0.0784525 0.0614716]

layer8_wq's input 
<N9nntrainer6TensorE at 0x5682dc59a250>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.541513 0.253167 0.515135-0.0193481 0.134994 -0.235332 -0.30315 0.184024 0.151843]
==============================
layer8_wq's output 
<N9nntrainer6TensorE at 0x5682dc5d3620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0237115 0.0685095 -0.414937-0.247035 -0.467361 0.0607781 -0.238849 0.292587 -0.135862]
============================
layer8_wk's input 
<N9nntrainer6TensorE at 0x5682dc59bfb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.541513 0.253167 0.515135-0.0193481 0.134994 -0.235332 -0.30315 0.184024 0.151843]
==============================
layer8_wk's output 
<N9nntrainer6TensorE at 0x5682dc59bd20>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.896541 -1.61613 1.186980.590892 0.540082 -0.798445 -0.046022 -2.45929 -0.234835]
============================
layer8_wv's input 
<N9nntrainer6TensorE at 0x5682dc59cda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.541513 0.253167 0.515135-0.0193481 0.134994 -0.235332 -0.30315 0.184024 0.151843]
==============================
layer8_wv's output 
<N9nntrainer6TensorE at 0x5682dc59cb30>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.15903 -0.87771 0.1879420.172852 0.341283 -0.0373287 0.476336 0.355474 0.699468]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0643304 -0.0334273 -0.346432-0.336428 -0.212225 0.42081 0.361175 0.110491 -0.103732]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1475898
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer8_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc59f1f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer8_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc59f150>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer8_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a0270>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.25709 0.0986668 0.215219-0.00777257 0.0589949 -0.0975393 -0.126653 0.0784525 0.0614716]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.401212 0.334407 0.684099-0.0276827 0.189782 -0.349262 -0.451087 0.2689 0.194218]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5820931196 -0.2350897938 -0.4585057497 -0.3865448833 0.7096521854 0.06612271816 -0.6608039141 -0.3367446661 -0.8939000368 -0.4477111101 -1.01867187 -0.6945809126 -0.962595582 1.454297066 0.001071602106 0.02070719749 -0.7310253978 -1.269895792 0.4321978688 0.4479066133 -0.2188422233 -0.8506630659 -1.137848377 -0.3327110112 0.3433792889 0.1516014189 0.6872583628 -1.29946208 -0.8785806894 -0.856221199 -0.2928788364 -1.726149082 -0.4915761352 -0.9426625967 1.706531644 -0.5457578897 -1.037370682 -1.509035707 -0.5542669296 0.1647266001 -0.8272060752 -0.7226264477 0.09949754179 1.002302289 -0.6495707631 -0.2562497854 -0.1520896554 -0.1404538006 0.3654158711 -1.098366261 -0.5634807944 -0.00612174347 0.2465134561 -0.5623323917 -0.5518009067 -1.863395095 -0.1223517507 -0.4435008764 0.2245500088 -1.699274421 0.5346589684 -0.5374289751 0.04647413269 1.446173787 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009014371783 0.01275372691 0.01020020247 0.01096127369 0.03280449286 0.01723661833 0.008332048543 0.01152096875 0.006599627901 0.01031090599 0.005825479981 0.008055317216 0.006161484402 0.06907621026 0.01615104638 0.0164713189 0.007767030969 0.004531338345 0.02485630102 0.02524984069 0.01296263654 0.006891234312 0.005170994438 0.01156753115 0.02274380066 0.0187747851 0.03207804263 0.004399325233 0.006701508537 0.006853039376 0.01203759294 0.002871298464 0.009868394583 0.006285533309 0.08889402449 0.009347935207 0.005717563909 0.003567544976 0.00926873181 0.01902283169 0.007054793648 0.007832539268 0.01782159321 0.04395716265 0.008426170796 0.01248669345 0.01385745872 0.01401964389 0.02325055934 0.005379240494 0.009183721617 0.01603528298 0.0206440445 0.009194273502 0.009291616268 0.002503070515 0.01427573897 0.01035440993 0.02019557171 0.00294950977 0.02753815055 0.009426117875 0.0169012472 0.06851735711 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.0813446 34.08603668 34.08253098 34.08424377 34.10513687 34.09051895 34.08161545 34.08480453 34.0789299 34.0826416 34.07910919 34.07561874 34.07563019 34.14236069 34.08943558 34.08784866 34.0800972 34.07781601 34.07048416 34.09090424 34.08529282 34.07921982 34.07845688 34.08389664 34.0950737 34.09110641 34.10536194 34.07672882 34.07998657 34.07918167 34.08532333 34.07615662 34.0821991 34.07862091 34.15550232 34.08072662 34.07900238 34.07589722 34.08160019 34.0904007 34.07938385 34.08111572 34.09015274 34.11437988 34.08171082 34.08576965 34.08714294 34.08634949 34.09558105 34.07866287 34.08246613 34.08836746 34.09202194 34.08247757 34.07780838 34.07578659 34.08755875 34.08268356 34.09252548 34.07623291 34.10082245 34.08175659 34.08446503 34.12844849 

-------
======================
selected experts : 4, 13, 26, 34, 43, 63, 
layer8_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5a3350>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0659566 0.0530296 0.1635850.0778446 -0.0195666 0.0881568 0.183909 0.170824 0.0908925]

layer8_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a2c90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.191133 0.151696 0.3788040.0700721 0.0394283 -0.00938249 0.0572556 0.249276 0.152364]

layer9_wq's input 
<N9nntrainer6TensorE at 0x5682dc5e1750>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628368 0.419554 0.9949620.203553 0.100819 -0.02546 0.153375 0.659083 0.445254]
==============================
layer9_wq's output 
<N9nntrainer6TensorE at 0x5682dc5a2e70>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.990122 -0.0779878 1.01044-0.451464 -0.0806437 1.01568 0.814009 0.598821 0.507806]
============================
layer9_wk's input 
<N9nntrainer6TensorE at 0x5682dc5e3c80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628368 0.419554 0.9949620.203553 0.100819 -0.02546 0.153375 0.659083 0.445254]
==============================
layer9_wk's output 
<N9nntrainer6TensorE at 0x5682dc5e39f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.93641 -0.107036 -0.8609020.46931 0.199984 -0.895828 -0.831834 -0.632928 -0.362626]
============================
layer9_wv's input 
<N9nntrainer6TensorE at 0x5682dc5e4a70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628368 0.419554 0.9949620.203553 0.100819 -0.02546 0.153375 0.659083 0.445254]
==============================
layer9_wv's output 
<N9nntrainer6TensorE at 0x5682dc5e4800>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.249564 -0.310188 -0.025437-0.134065 -1.11543 0.202387 0.0279106 0.0432688 0.980205]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.066905 0.990933 1.08754-0.205137 0.795025 0.637211 0.246593 -0.979995 -0.28193]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1270888
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer9_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc5e6ec0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer9_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc5e6e20>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer9_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5e7f40>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.191133 0.151696 0.3788040.0700721 0.0394283 -0.00938249 0.0572556 0.249276 0.152364]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.287586 0.493438 1.166280.2389 0.121394 -0.0321514 0.1962 0.815181 0.463806]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5784392953 -2.692181826 -0.5327215791 -1.096446872 0.06641447544 -0.5960524678 0.4831649363 -0.9647579789 0.7627049088 -0.09703366458 -2.138244867 -1.655194521 -0.7575159669 -0.2602666914 -1.185462832 -1.286947131 -1.109573603 -0.4413939416 -0.1912102252 0.1474581361 2.318176985 -1.217723966 1.076936603 -1.016357303 -1.984680414 -0.8027300239 -0.8972060084 -0.9883889556 -0.08658076823 -0.681370914 -1.071043372 -0.9319506288 -0.4055244625 -1.134295821 0.2941918075 0.5751672387 -0.2030042708 0.5597757101 -1.342829466 -1.232607245 0.2436300069 1.034404755 0.596901238 2.314760923 -0.914604485 -1.468491554 -1.077005982 -0.7855711579 -1.070604563 -1.898351192 0.5030686259 -0.6025437117 -1.22859478 -0.6789172292 -1.126736045 -0.4787145555 0.06532867253 0.009236903861 0.5657193065 -0.2974469364 -0.4449689388 -1.005197048 0.08275671303 -0.4499510229 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.008367558941 0.001010676147 0.008758983575 0.004984606989 0.01594612747 0.00822146982 0.02419065125 0.005686207209 0.03199265152 0.0135416165 0.00175866764 0.002850820543 0.006995628588 0.01150215697 0.004560073372 0.004120005295 0.004919602536 0.009596587159 0.01232452411 0.01729226671 0.1515595168 0.004415306728 0.04380455986 0.005400244147 0.002050576499 0.006686371285 0.006083591841 0.005553410854 0.01368390862 0.007549115457 0.005112856161 0.005875850562 0.009947058745 0.004799470771 0.02002523467 0.02652184106 0.01218002196 0.02611675672 0.003896083683 0.004350080155 0.01903789304 0.04198053479 0.02710457519 0.1510426551 0.005978662521 0.00343600614 0.005082459655 0.006802092306 0.005115099251 0.002235467779 0.02467696182 0.008168275468 0.004367568996 0.00756766228 0.004835891072 0.009245037101 0.01592881791 0.01505993959 0.02627244778 0.01108235773 0.009562339634 0.005460849497 0.01620886102 0.009514818899 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.4602623 34.45290375 34.45492935 34.45592499 34.46688461 34.46011353 34.45414734 34.45758057 34.48388672 34.46448135 34.45365143 34.45474243 34.45888901 34.46339417 34.45645142 34.45601273 34.45586014 34.46149063 34.46326447 34.46918488 34.59772873 34.45630646 34.49474335 34.45538712 34.45394516 34.45858002 34.45797729 34.45744705 34.45508575 34.45944214 34.45700455 34.45776749 34.46088791 34.45573807 34.4719162 34.46983337 34.45835114 34.4770546 34.45578766 34.45624161 34.44709015 34.4938736 34.47422791 34.60198212 34.45787048 34.4553299 34.45697403 34.45392609 34.45510101 34.45412827 34.47180176 34.46006012 34.45626068 34.45946121 34.45386887 34.45923233 34.46496201 34.4659996 34.47625732 34.46202087 34.45954895 34.4573555 34.4681015 34.45949936 

-------
======================
selected experts : 8, 20, 22, 41, 42, 43, 
layer9_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5eb020>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0292678 -0.0956209 -0.113527-0.268267 0.0155715 -0.0378454 0.0868689 0.020848 -0.0885791]

layer9_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5ea960>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.220401 0.0560755 0.265277-0.198195 0.0549998 -0.0472279 0.144125 0.270124 0.063785]

layer10_wq's input 
<N9nntrainer6TensorE at 0x5682ded33210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.39589 0.154817 0.723569-0.566966 0.133552 -0.132746 0.397908 0.673894 0.163371]
==============================
layer10_wq's output 
<N9nntrainer6TensorE at 0x5682dc5eab40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.181234 -0.342398 1.430770.0895295 -0.553066 0.257564 0.0833396 -1.49051 -1.00958]
============================
layer10_wk's input 
<N9nntrainer6TensorE at 0x5682ded34f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.39589 0.154817 0.723569-0.566966 0.133552 -0.132746 0.397908 0.673894 0.163371]
==============================
layer10_wk's output 
<N9nntrainer6TensorE at 0x5682ded34ce0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.53692 -0.0485435 -0.1724740.715683 0.119405 -0.883975 1.76163 -0.277954 0.280245]
============================
layer10_wv's input 
<N9nntrainer6TensorE at 0x5682ded35d60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.39589 0.154817 0.723569-0.566966 0.133552 -0.132746 0.397908 0.673894 0.163371]
==============================
layer10_wv's output 
<N9nntrainer6TensorE at 0x5682ded35af0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.559905 -0.0366422 0.3549090.866707 -0.239438 -0.0393911 0.553588 0.34391 1.07834]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.365123 -0.129486 1.371120.418504 -0.097553 0.60225 -1.41137 0.486407 0.874627]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a106b878
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer10_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded38210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer10_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded38170>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer10_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded39290>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.220401 0.0560755 0.265277-0.198195 0.0549998 -0.0472279 0.144125 0.270124 0.063785]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.317078 0.182795 0.81181-0.679041 0.168312 -0.162594 0.503378 0.885047 0.193075]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.06926098466 -1.889656901 -2.135423183 -1.227051497 -0.4244788289 -0.7646638155 -0.2025152743 -0.2169721425 1.188247561 -0.662728548 -1.118843555 0.2492176294 0.9456104636 -1.251841784 -0.3659493923 -0.8920525908 -0.1320210993 -0.5265669227 0.1242789775 -1.218567133 -0.7645328045 -0.8224347234 -1.494637251 1.817089558 -0.5894706845 -0.3520736098 -0.3152672648 0.9674650431 0.737018168 0.09049356729 -0.4484396577 -1.74812007 -0.8611502647 0.1298037916 0.4455396831 0.7185868621 1.352536917 -0.9928257465 -0.9874344468 0.2044235319 0.3249462843 -0.4133012295 -1.023074627 -0.9486420751 -0.08636790514 0.4954489172 -1.477710724 -0.9838752151 -0.9046508074 -0.6560556293 -0.6540198922 -0.6196044087 -1.701559186 -0.4007335007 -1.854149699 0.3188380301 -1.211869359 0.8672431707 -1.061550379 -1.684293866 -1.357903361 -1.057067871 -0.7432658076 -1.377599716 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01834772527 0.002587229479 0.002023485489 0.005018811673 0.01119834371 0.007969174534 0.01398141962 0.01378074847 0.05617614463 0.008824360557 0.005592358299 0.02196526341 0.04407334328 0.004895923194 0.01187333651 0.00701599149 0.01500260178 0.01011154335 0.01938546821 0.005061573815 0.007970217615 0.007521834224 0.00384051865 0.105354853 0.009495083243 0.01203923579 0.01249061152 0.04504714906 0.03577548265 0.01874146052 0.01093321107 0.002980599878 0.007236186881 0.01949286275 0.02672994137 0.03512213379 0.06620669365 0.006343425252 0.00637771748 0.02100306191 0.02369326726 0.01132421568 0.00615441706 0.006629985757 0.01570339315 0.0280978661 0.003906078404 0.006400457118 0.006928157993 0.008883440867 0.008901544847 0.00921322871 0.003122661263 0.01146743447 0.002680745209 0.0235489849 0.00509558944 0.04075130448 0.005922118668 0.003177043051 0.004403242376 0.005948724225 0.008141535334 0.004317363258 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.1207962 33.10598755 33.10542297 33.10842133 33.11460114 33.10183334 33.11738205 33.11718369 33.15766907 33.11222458 33.10899353 33.12441254 33.1474762 33.10257339 33.11146164 33.11041641 33.11840439 33.11256027 33.11611176 33.10560226 33.11041641 33.11092377 33.10724258 33.20303345 33.11003494  33.110672 33.11493683 33.14844894 33.13822174 33.12214279 33.11338043 33.10638046 33.11063766 33.12289429 33.13013077 33.13661575 33.16770172 33.10974503 33.10977936 33.12440491 33.10897446 33.09565353 33.10955429 33.11003113 33.11910629 33.1295929 33.10635376 33.10980225 33.1055603 33.11228561 33.10848618 33.11261368 33.10652542 33.11296082 33.10608292 33.12694931 33.10659027 33.13938522 33.10741425 33.10562515 33.10780334 33.10744095 33.11154175 33.10771942 

-------
======================
selected experts : 8, 12, 23, 27, 36, 57, 
layer10_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded3c110>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.161962 -0.0780533 0.1249870.0509749 0.26931 0.0336457 -0.056708 0.0038211 0.0792823]

layer10_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded3bb90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.382363 -0.0219779 0.390264-0.14722 0.32431 -0.0135822 0.0874166 0.273945 0.143067]

layer11_wq's input 
<N9nntrainer6TensorE at 0x5682ded7c3b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.633897 -0.0508481 0.85691-0.364473 0.688197 -0.032825 0.202248 0.573248 0.326785]
==============================
layer11_wq's output 
<N9nntrainer6TensorE at 0x5682ded3ba40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.657842 0.365413 0.2754280.0422222 -0.275213 -0.197291 0.727014 -0.487024 -0.91165]
============================
layer11_wk's input 
<N9nntrainer6TensorE at 0x5682ded7e110>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.633897 -0.0508481 0.85691-0.364473 0.688197 -0.032825 0.202248 0.573248 0.326785]
==============================
layer11_wk's output 
<N9nntrainer6TensorE at 0x5682ded7de80>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.47571 0.339769 -0.600838-1.8889 -1.66195 2.8416 -0.0334167 -0.885505 2.48664]
============================
layer11_wv's input 
<N9nntrainer6TensorE at 0x5682ded7ef00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.633897 -0.0508481 0.85691-0.364473 0.688197 -0.032825 0.202248 0.573248 0.326785]
==============================
layer11_wv's output 
<N9nntrainer6TensorE at 0x5682ded7ec90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.427054 0.818584 0.0928597-0.0225618 0.314247 -0.0656768 -0.627374 -0.441628 -0.612546]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.265808 -0.704009 0.2581570.104871 -0.317812 0.116882 -0.725753 -0.488902 0.813759]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0e66868
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer11_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded813b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer11_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded81310>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer11_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded82430>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.382363 -0.0219779 0.390264-0.14722 0.32431 -0.0135822 0.0874166 0.273945 0.143067]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.481761 -0.0667179 1.0927-0.466439 0.922375 -0.0440336 0.283404 0.823539 0.398467]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1634536982 0.2338491082 1.390282989 -0.3676809072 -0.5225353837 0.1594894528 1.739082575 -2.323273182 -1.632861614 -0.00858733058 -1.730676174 -1.526996255 0.113975741 -0.1351315677 -2.58881259 0.814460218 -0.05961622298 -0.1475380659 0.4953226447 -0.9851433039 -1.164471626 0.004394590855 0.316722542 -0.2453278005 1.028160095 -0.268912673 -1.446122289 -0.4320624769 0.7278697491 -0.5316099524 -1.532606602 -1.846465111 -1.457428217 -0.6088111997 -0.6791196465 -0.2312903404 -1.189405918 -0.5066782236 -1.544893384 -0.2530484796 -0.3886814713 -0.8982741237 -2.302025318 2.996816397 -1.963040948 -0.8953847885 1.07270515 -2.094770432 -1.289910674 -1.249869108 -0.7210344076 -0.9068789482 -0.1988134235 -0.3278206587 -0.8654219508 -0.7071698308 1.135054111 -1.895164251 -0.7949581146 -1.250328422 -0.9984998107 -0.09211537242 0.314479351 0.6850012541 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01535347197 0.01647323184 0.05236145854 0.009026882239 0.007731883321 0.01529272459 0.07421530038 0.001277129399 0.00254728063 0.01292677131 0.002309917705 0.002831740072 0.01461229846 0.01139023341 0.0009792926721 0.02943981625 0.0122836791 0.01124979462 0.02139613964 0.004868297838 0.00406907592 0.01309567876 0.01789659448 0.01020175777 0.03645388037 0.009963966906 0.003070269711 0.00846402999 0.02699785866 0.007662036456 0.002815898741 0.002057357691 0.003035753267 0.007092775311 0.006611220073 0.01034597401 0.003968872596 0.007855464704 0.002781510819 0.01012329664 0.008839287795 0.00531011587 0.001304555917 0.2610479593 0.001830971567 0.00532548083 0.03811443225 0.001604989404 0.003589371918 0.003736011917 0.00633983966 0.005264619365 0.01068749465 0.009393963031 0.005487461574 0.00642835116 0.04056647047 0.001959566958 0.005888078362 0.003734296653 0.004803707357 0.01189088821 0.01785649173 0.02586495504 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.5571003 28.55917358 28.59553719 28.5402832  28.545187 28.54511833 28.60928535 28.54493141 28.54381752 28.55276489 28.54596329 28.5464859 28.55302048 28.55456734 28.54415512 28.56546402 28.55545998 28.55442619 28.55694389 28.54375267 28.54772186 28.55388832 28.5610733 28.54431915 28.57676888 28.54980278 28.54195595 28.54019737 28.56445312 28.55083847 28.5421772 28.54428101 28.54621315 28.55027008 28.54931068 28.54780006 28.54714584  28.548172 28.54452705 28.55330086 28.5520153 28.5470562 28.54448128 28.79707146 28.54310036 28.54659462 28.57843018 28.54478073 28.54724312 28.54166794 28.54903984 28.54557991 28.55338669 28.55257034 28.54866409 28.54912758 28.58326721 28.5451355 28.54429626 28.54691124 28.54750443 28.55459023 28.56055641 28.56856537 

-------
======================
selected experts : 2, 6, 24, 43, 46, 56, 
layer11_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded85530>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.110667 -0.0970047 -0.1928990.0703382 -0.0718385 -0.0774949 0.0410839 -0.230315 -0.184965]

layer11_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded84d30>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.271696 -0.118983 0.197365-0.0768817 0.252471 -0.0910772 0.1285 0.0436299 -0.0418973]

layer12_wq's input 
<N9nntrainer6TensorE at 0x5682dedc4470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.587024 -0.265787 0.436063-0.182064 0.520833 -0.210122 0.302734 0.0916035 -0.090523]
==============================
layer12_wq's output 
<N9nntrainer6TensorE at 0x5682ded84be0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.195443 0.0918374 -0.399431-0.0701363 -0.641462 -1.13066 0.0613714 -0.661867 -0.174475]
============================
layer12_wk's input 
<N9nntrainer6TensorE at 0x5682dedc61d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.587024 -0.265787 0.436063-0.182064 0.520833 -0.210122 0.302734 0.0916035 -0.090523]
==============================
layer12_wk's output 
<N9nntrainer6TensorE at 0x5682dedc5f40>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.81585 4.64406 -2.971531.07527 0.725059 -2.12363 0.344063 3.10269 -0.357611]
============================
layer12_wv's input 
<N9nntrainer6TensorE at 0x5682dedc6fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.587024 -0.265787 0.436063-0.182064 0.520833 -0.210122 0.302734 0.0916035 -0.090523]
==============================
layer12_wv's output 
<N9nntrainer6TensorE at 0x5682dedc6d50>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.606237 -0.376929 -0.2368030.537972 -0.0929719 0.621698 -0.115335 -0.129155 -0.282883]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.119297 0.180001 -0.372323-0.160749 -1.29575 -0.104359 -0.635938 0.193435 0.364508]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0c61858
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer12_attention_out's input 
<N9nntrainer6TensorE at 0x5682dedc9470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer12_attention_out's output 
<N9nntrainer6TensorE at 0x5682dedc93d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer12_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dedca4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.271696 -0.118983 0.197365-0.0768817 0.252471 -0.0910772 0.1285 0.0436299 -0.0418973]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.268638 -0.300644 0.448109-0.203649 0.585551 -0.247921 0.349791 0.108113 -0.0966601]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5848432779 -0.06417887658 -1.037602186 -1.280631304 -1.952714562 -0.7851061225 0.4353520572 -0.9345266223 -1.532158494 -1.828743815 0.4825015366 2.507848501 0.07632251829 -0.888548851 -0.5898402929 -0.4689797163 -1.602545977 -0.6417217255 -1.735739827 -0.5481534004 1.384607673 -1.051821113 -1.005732775 1.02190423 -1.972499847 3.210705757 -0.7393202186 -0.4116578698 1.16415596 -1.84118855 -2.054331779 -1.744372249 1.187615275 -0.9100969434 -1.870270967 0.6191681623 -0.4727206528 -0.5952572227 0.1113234684 0.4223324656 -1.865560293 1.320002913 -0.8549823761 0.6602346301 -0.7330172658 -1.084182143 0.5193742514 0.9488451481 -0.7109173536 -1.60622704 -1.243872404 -1.451077938 -0.1899505407 -0.8899843097 0.0192386359 0.5107498169 -0.5357310176 0.801186204 -1.535245895 -0.2447298169 -0.4390060008 0.4783777595 -0.001597560942 -1.822441101 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005956804845 0.01002616808 0.003787760623 0.002970547648 0.001516891061 0.004875736777 0.01652260497 0.004199019168 0.002309934236 0.001717094216 0.01732029393 0.1312660128 0.01153862383 0.004396587145 0.005927111488 0.006688552909 0.002152934205 0.005627445411 0.001884453231 0.006179417484 0.04269086942 0.003734284313 0.003910419997 0.02970399708 0.001487173839 0.2650936544 0.00510416599 0.007083156146 0.03424475342 0.001695858315 0.001370321726 0.001868255436 0.03505761549 0.004302861635 0.001647249097 0.01985678263 0.006663579494 0.005895091686 0.01194963511 0.01630888321 0.001655026223 0.04002003744 0.004546669312 0.02068920434 0.005136439577 0.00361537328 0.01797086187 0.02761122957 0.005251217168 0.002145023551 0.003081772011 0.002505026758 0.008841237985 0.004390281159 0.01089840103 0.01781653985 0.006256658584 0.02382090315 0.002302813111 0.008369946852 0.006892068777 0.01724901795 0.01067366824 0.001727950992 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
30.81029129 30.81483841 30.80812263 30.80682755 30.80489731 30.80730247 30.82133484 30.80853271 30.80330658 30.80652809 30.82213211 30.93178558 30.81635094 30.80730057 30.80883217 30.81102371 30.80696487 30.80948448 30.80669594 30.81003761 30.84368706 30.80854607 30.80872154 30.83403778 30.80629921 31.06990433 30.80896187 30.81189537 30.83714867 30.8050766 30.80570412 30.80668068 30.83891487 30.80434608 30.80598259 30.82085419 30.81099892 30.80975342 30.81628418 30.82064438 30.80599022 30.84483147 30.80649757 30.82502365 30.80947113 30.80794907 30.82135201 30.82383919 30.80815506 30.80695724 30.80741882 30.8044548 30.8131752 30.80634117 30.81571007 30.82262802 30.81059074 30.82672501 30.80663681 30.81270409 30.81170273 30.82205963 30.80404091 30.80510902 

-------
======================
selected experts : 11, 20, 25, 28, 32, 41, 
layer12_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dedcd730>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0773612 -0.0899024 -0.0828959-0.0931412 -0.197045 0.172348 -0.07765 0.0527294 0.366331]

layer12_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dedccdf0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349057 -0.208885 0.11447-0.170023 0.0554258 0.0812705 0.0508505 0.0963593 0.324434]

layer13_wq's input 
<N9nntrainer6TensorE at 0x5682dee397f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.461882 -0.434706 0.234089-0.398826 0.100677 0.199437 0.115611 0.181985 0.636145]
==============================
layer13_wq's output 
<N9nntrainer6TensorE at 0x5682dedccca0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.638957 -0.286022 -0.2500940.205265 0.251586 -0.456803 0.130424 0.103303 0.140089]
============================
layer13_wk's input 
<N9nntrainer6TensorE at 0x5682dc471a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.461882 -0.434706 0.234089-0.398826 0.100677 0.199437 0.115611 0.181985 0.636145]
==============================
layer13_wk's output 
<N9nntrainer6TensorE at 0x5682dc4717a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.526126 2.17734 1.116081.92351 -0.739024 1.67844 -2.07329 0.114944 0.717841]
============================
layer13_wv's input 
<N9nntrainer6TensorE at 0x5682dc472820>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.461882 -0.434706 0.234089-0.398826 0.100677 0.199437 0.115611 0.181985 0.636145]
==============================
layer13_wv's output 
<N9nntrainer6TensorE at 0x5682dc4725b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.260204 -0.896868 0.430393-0.162672 0.192095 -0.0549694 -0.108279 0.371327 -0.0893489]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.375946 -0.590541 -0.2908380.141753 -0.236624 -0.46473 0.0463214 -0.1598 -0.107564]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0a5c848
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer13_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc474cd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer13_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc474c30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer13_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc475da0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349057 -0.208885 0.11447-0.170023 0.0554258 0.0812705 0.0508505 0.0963593 0.324434]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.342213 -0.532703 0.261629-0.456094 0.127347 0.225833 0.138244 0.239942 0.745421]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8907374144 -0.2349317372 0.4580129087 -0.9498534799 0.8698978424 -0.1809544414 -0.4279190898 -1.527326465 0.4683110118 -1.227486372 -0.1315159798 2.054972887 -0.3449802697 -0.4493123293 -0.4004764557 -1.177681446 -0.4874285161 -1.356473684 3.522906542 -0.8342306614 -0.8314092755 -0.8831923008 -0.8793950677 -0.8831965923 -1.476154804 -1.014450431 -1.720691442 -1.865071416 -0.9642260075 -1.74390769 -0.981577754 -0.2707402706 -1.329746127 -1.580141306 -1.104965568 -0.227812171 -0.3364129663 1.441262126 -2.311327696 -0.09721283615 -0.556394577 -2.072245598 -0.4464695454 -0.6179936528 -0.519634068 -0.9891636968 -0.3636598587 0.2545301914 1.943602204 -0.0002803578973 0.4254202247 -0.4662814438 -1.054075718 0.08678603917 -0.05748613551 -0.07400264591 -1.778453827 0.4547889531 -1.29742372 -1.191100597 0.5785340071 -0.7324755192 0.7080338001 -0.008419480175 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.004408756271 0.008494324982 0.01698520593 0.004155681003 0.02564190328 0.008965425193 0.007003505249 0.002332646865 0.01716102846 0.00314824027 0.009419801645 0.08387292176 0.007609136403 0.006855268497 0.00719836168 0.003309007501 0.006598890759 0.002767256228 0.364030093 0.00466505345 0.004678234458 0.004442146514 0.004459045362 0.004442127421 0.002455118345 0.003895724425 0.001922523137 0.001664056676 0.004096380901 0.001878403593 0.004025915638 0.008195537142 0.002842215821 0.00221264502 0.003558590543 0.008555017412 0.007674606517 0.04540362582 0.001065029297 0.009748536162 0.00615913095 0.001352675608 0.006874785293 0.005791181233 0.006389754824 0.00399549026 0.007468319964 0.01385796536 0.07503330708 0.01074079983 0.01644054055 0.006739923265 0.003744372167 0.01171788108 0.01014360972 0.009977446869 0.001814620453 0.01693053544 0.002935583936 0.003264899831 0.01916074939 0.005164738279 0.02180989459 0.01065373421 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.72639847 28.73143768 28.73945236 28.72710037 28.74715614 28.73095512 28.72947121 28.72432327 28.74058151 28.72657013 28.72854996 28.79871178 28.72864532 28.7288456 28.72823524 28.72673035 28.72954369 28.72142029 29.08745193 28.72808647 28.72714615 28.72547913 28.72644997 28.72738647 28.72635269 28.72683907 28.72200584 28.72413063 28.72704124 28.72386932 28.72649384 28.73114014 28.72578621 28.72515678  28.721735 28.73006821 28.73061943 28.76596451 28.7244854 28.73269272 28.72957993 28.72429657 28.72695732 28.72873497 28.72694969 28.72646332 28.73041344 28.73155785 28.79750061 28.73416138 28.73986244 28.72968483 28.72668839 28.73466301 28.73308754 28.73339844 28.72428131 28.73844337 28.72540283 28.72477913 28.74210548 28.72763252 28.74523163 28.73407555 

-------
======================
selected experts : 4, 11, 18, 37, 48, 62, 
layer13_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee45420>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0729003 -0.406801 -0.0252013-0.0780241 0.037404 -0.3087 0.00187028 0.0189472 0.107898]

layer13_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc478790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.276157 -0.615686 0.0892683-0.248047 0.0928298 -0.22743 0.0527207 0.115307 0.432332]

layer14_wq's input 
<N9nntrainer6TensorE at 0x5682dee98c10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.36022 -1.20466 0.166346-0.540219 0.176226 -0.537696 0.113592 0.205466 0.840868]
==============================
layer14_wq's output 
<N9nntrainer6TensorE at 0x5682dc478730>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.12488 -0.544552 -0.317194-0.0739089 -0.0644269 -0.186063 -0.590938 -2.86144 -0.181958]
============================
layer14_wk's input 
<N9nntrainer6TensorE at 0x5682dee9aab0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.36022 -1.20466 0.166346-0.540219 0.176226 -0.537696 0.113592 0.205466 0.840868]
==============================
layer14_wk's output 
<N9nntrainer6TensorE at 0x5682dee9a7d0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.98509 -0.163158 2.52324-0.284793 0.998914 1.36633 0.93989 1.91786 0.308451]
============================
layer14_wv's input 
<N9nntrainer6TensorE at 0x5682dee9b8a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.36022 -1.20466 0.166346-0.540219 0.176226 -0.537696 0.113592 0.205466 0.840868]
==============================
layer14_wv's output 
<N9nntrainer6TensorE at 0x5682dee9b630>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.182041 -0.249189 -0.7183710.144929 0.19251 0.802127 -0.24679 0.0621993 0.0480825]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.229587 2.1815 -0.291448-0.14537 -0.190127 -0.0512049 -2.42559 1.62898 0.183453]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2eb6968
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer14_attention_out's input 
<N9nntrainer6TensorE at 0x5682dee9dda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer14_attention_out's output 
<N9nntrainer6TensorE at 0x5682dee9dd00>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer14_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dee9ee70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.276157 -0.615686 0.0892683-0.248047 0.0928298 -0.22743 0.0527207 0.115307 0.432332]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.276598 -1.60621 0.203773-0.670218 0.214065 -0.646295 0.144906 0.287383 0.996957]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
2.169183016 -0.1604429483 -0.9380071163 1.747939944 -0.8642760515 0.1506029963 -1.677625179 -0.8631830812 0.1483230442 -0.08318985999 -1.837387323 -1.404093146 -1.562247038 0.2200235873 -0.9583565593 -1.2070961 -0.4648033679 0.3947082162 -1.420911908 -1.946756005 -1.052036047 -0.1699156612 -0.2060705721 -0.6792519093 -1.332456946 -0.8604491353 -0.2004051059 0.3646580279 -0.4279718995 0.6756101847 -1.140719056 -1.863321185 -0.36134848 -0.4934558272 -1.52702415 -1.021582603 -1.233463764 -0.6591947675 -0.408067733 0.9524257183 1.252907276 0.1095041335 -1.392297745 -0.7397685647 -0.05964815244 -1.079560161 -0.3602063656 1.245722413 0.01374107972 0.6682664156 -1.669662714 -1.121862054 -2.291163206 -1.056569099 -0.3179639578 0.9675385952 -0.3354649842 0.9148709178 -0.1700505018 0.08554217219 -1.779774308 -0.8672316074 -0.3966808021 -1.210223794 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1360198706 0.01323910523 0.006083686836 0.08926039934 0.006549192593 0.01806942001 0.002903720364 0.006556356326 0.01802826859 0.01430241019 0.002474976005 0.003817229765 0.003258838784 0.01936837658 0.005961137824 0.004648394883 0.00976509694 0.02306522615 0.003753564786 0.002218567999 0.005428060889 0.01311428845 0.0126486104 0.007880301215 0.004100714345 0.00657430524 0.01272047404 0.02238242328 0.01013146713 0.03054583073 0.004967411514 0.002411615569 0.01082945429 0.009489273652 0.003375670407 0.005595907103 0.004527429119 0.008039953187 0.01033514552 0.04028759897 0.05440876633 0.01734184287 0.003862521611 0.007417555433 0.01464311127 0.005280696321 0.01084182784 0.05401924998 0.01575817168 0.03032233194 0.002926933579 0.005061970092 0.001572166802 0.005403510761 0.01130962465 0.0409010835 0.0111134164 0.03880266473 0.01311252173 0.01693123579 0.002621754073 0.006529865786 0.01045350265 0.004633877892 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.29637337 27.17406845 27.16596031 27.24722862 27.16499519 27.17842293 27.16373253 27.16547775 27.1788578 27.17513275 27.16187477 27.1627388 27.16456604 27.17447662 27.1615448 27.16404724 27.16964149 27.18294144 27.16506004 27.15970993 27.16578102 27.17394447 27.17347908 27.1634655 27.16493034 27.16692734 27.17354965 27.18321228 27.17096138 27.19185257 27.16484261 27.16228676 27.17165947 27.16936493 27.16372871 27.16499519 27.1629734 27.16791534 27.17116547 27.20063972 27.21523857 27.17769432 27.16230774 27.16681671 27.17547226 27.16563416 27.17167091 27.21055794 27.17515755 27.19115257 27.16232681 27.16446114 27.16192436 27.16623306 27.17214012 27.20077705 27.17194366 27.19915581 27.16822052 27.1768074 27.16297531 27.16783714 27.16127014 27.16546249 

-------
======================
selected experts : 0, 3, 39, 40, 47, 55, 
layer14_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deea2ef0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.279306 0.135505 -0.261712-0.00655481 0.0436773 0.142907 0.18215 0.0979225 -0.15622]

layer14_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deea2970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.555463 -0.480181 -0.172444-0.254602 0.136507 -0.0845226 0.234871 0.213229 0.276112]

layer15_wq's input 
<N9nntrainer6TensorE at 0x5682deedb770>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.634636 -0.924824 -0.287091-0.537457 0.227262 -0.199578 0.483027 0.359632 0.49273]
==============================
layer15_wq's output 
<N9nntrainer6TensorE at 0x5682deea2820>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.233871 0.664037 0.2406980.172847 0.303741 0.385071 0.666595 -0.662647 0.309314]
============================
layer15_wk's input 
<N9nntrainer6TensorE at 0x5682deedd610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.634636 -0.924824 -0.287091-0.537457 0.227262 -0.199578 0.483027 0.359632 0.49273]
==============================
layer15_wk's output 
<N9nntrainer6TensorE at 0x5682deedd330>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.92189 -2.39179 0.02301212.86165 -1.21816 1.07583 1.87755 0.562447 1.75388]
============================
layer15_wv's input 
<N9nntrainer6TensorE at 0x5682deede400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.634636 -0.924824 -0.287091-0.537457 0.227262 -0.199578 0.483027 0.359632 0.49273]
==============================
layer15_wv's output 
<N9nntrainer6TensorE at 0x5682deede190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.453229 -0.0764084 0.201708-0.115856 0.961992 -0.409499 -0.061211 -0.629738 -0.174694]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.622942 -0.328 0.1941150.223899 0.489196 -0.0350124 -0.865494 -0.366566 -0.56656]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2baf150
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer15_attention_out's input 
<N9nntrainer6TensorE at 0x5682deee0900>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer15_attention_out's output 
<N9nntrainer6TensorE at 0x5682deee0860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer15_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682deee19d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.555463 -0.480181 -0.172444-0.254602 0.136507 -0.0845226 0.234871 0.213229 0.276112]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.565129 -1.21742 -0.375283-0.662125 0.301531 -0.230849 0.615923 0.501165 0.606899]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.9196115136 -0.7669365406 -0.1744032204 -0.2425152659 -0.2824247777 -1.25149405 -1.074480534 -1.513965726 -1.402485013 -1.540763378 -0.1442510784 -0.7152411938 -1.841566443 -0.6420508027 0.04125054926 1.053928852 0.3776424229 -0.5294575691 -1.38181293 -0.04154314101 -1.268128037 -0.3668287992  1.1564219 -0.6394540071 -0.5798906684 -1.367501974 -0.1567556113 -1.181677222 -0.6673570871 0.073171556 0.06182174385 -0.3293156624 -1.589536548 -0.4025172889 0.5978791714 -0.7584404349 -0.4674280584 -0.4243714213 0.5434920788 -0.5038707256 -0.7242248058 -0.7007819414 0.5043699741 -2.407653093 -1.076235056 -0.1618063748 -0.6935269237 -1.068996668 1.034954309 0.138767764 0.5236951113 -1.64547205 0.9407889843 -1.954601169 -0.7338450551 -1.331152916 -0.2034887075 -1.151724339 2.390234232 -1.969763517 -0.3684638143 1.214165568 -1.248273849 -0.7750394344 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006471737288 0.007539226674 0.01363517623 0.01273737662 0.01223904733 0.004643934313 0.005543219857 0.003571873531 0.003993112594 0.00347742741 0.01405256521 0.007939218543 0.002574073849 0.008542086929 0.01691678911 0.04657132179 0.02368160337 0.009560103528 0.004076518584 0.01557259727 0.004567326047 0.0112484172 0.05159774423 0.008564296179 0.009089913219 0.004135276191 0.0138779385 0.004979746882 0.008328628726 0.01746550389 0.01726839133 0.011678393 0.00331189204 0.01085405517 0.02951608226 0.007603552658 0.01017189119 0.01061942242 0.02795366012 0.009807872586 0.007868215442 0.008054846898 0.02688117139 0.001461411826 0.005533502903 0.01380802132 0.008113497868 0.005573702045 0.04569597915 0.01864958368 0.0274057053 0.003131724428 0.04158939049 0.002298955806 0.00779288495 0.004288354889 0.01324430294 0.005131159909 0.1772020012 0.002264360897 0.01123004034 0.05466489494 0.00465891324 0.007478383835 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.89748573 25.89855385 25.89606667 25.9027977 25.90182304 25.8918438 25.89703369 25.8950634 25.89596176 25.89258385 25.90602112 25.89466095 25.89358902 25.89955711 25.90888405 25.93710899 25.91564941 25.9015274 25.89652061 25.9065876 25.89605904 25.90035439 25.94070435 25.90005493 25.89772034 25.89610291 25.9053688 25.89694786 25.89838982 25.90704918 25.90876007 25.90221596 25.89480209 25.90186882 25.92148399 25.89766312 25.90023232 25.90258789 25.91992188 25.88651657 25.89983559 25.8947773 25.9183712 25.89438248 25.89750099 25.90529823 25.89865112 25.88895798 25.93718719 25.91061783 25.91841888 25.88985443  25.932127 25.89426613 25.89833069 25.89625549 25.9052124 25.89423752 26.06630898 25.89089394 25.90319824 25.94615555 25.8937664 25.88943291 

-------
======================
selected experts : 15, 22, 48, 52, 58, 61, 
layer15_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deee4f80>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0327959 0.187632 -0.1807630.204037 0.164419 -0.0681101 0.291705 0.0602662 -0.180333]

layer15_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deee44b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.588259 -0.292549 -0.353207-0.0505649 0.300926 -0.152633 0.526576 0.273495 0.0957787]

layer16_wq's input 
<N9nntrainer6TensorE at 0x5682def24710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.24158 -0.706571 -0.695522-0.125426 0.586026 -0.428421 1.23742 0.538557 0.20215]
==============================
layer16_wq's output 
<N9nntrainer6TensorE at 0x5682deee4360>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.102363 0.226864 0.0246720.308009 -0.648733 0.0484672 0.830685 0.0413778 -0.381088]
============================
layer16_wk's input 
<N9nntrainer6TensorE at 0x5682def26470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.24158 -0.706571 -0.695522-0.125426 0.586026 -0.428421 1.23742 0.538557 0.20215]
==============================
layer16_wk's output 
<N9nntrainer6TensorE at 0x5682def261e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.9102 -0.102631 -0.171847-0.533853 2.44988 0.0296557 -1.81455 -0.814734 0.755135]
============================
layer16_wv's input 
<N9nntrainer6TensorE at 0x5682def27260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.24158 -0.706571 -0.695522-0.125426 0.586026 -0.428421 1.23742 0.538557 0.20215]
==============================
layer16_wv's output 
<N9nntrainer6TensorE at 0x5682def26ff0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0874291 -1.24879 -0.3393321.28179 0.497896 0.352713 -0.0204428 0.3092 -1.14995]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.209556 -0.134283 -0.0473430.305347 -0.324284 0.563953 -0.275774 -0.784664 0.0605691]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a20938f8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer16_attention_out's input 
<N9nntrainer6TensorE at 0x5682def29710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer16_attention_out's output 
<N9nntrainer6TensorE at 0x5682def29670>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer16_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def2a790>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.588259 -0.292549 -0.353207-0.0505649 0.300926 -0.152633 0.526576 0.273495 0.0957787]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.694387 -0.776591 -0.826173-0.138629 0.703886 -0.441706 1.42648 0.669477 0.224033]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2243914902 -1.273052216 -0.3731522858 0.7100962996 -1.470478892 -1.412188768 -0.6100212336 0.3334301412 -1.558926463 3.685372591 -1.342689157 2.300887823 -1.008253455 -1.188391924 -0.5533849001 -0.7647204995 -1.543614745 -1.685294986 -0.8623319864 -1.274074912 -0.7444522977 -0.1626450568 -0.0900862366 1.783777118 -1.973642945 -1.383884192 -0.04768214375 0.01108001545 -1.786719918 -1.643375397 -1.694744349 0.89670223 0.2155798376 -0.7740887403 -0.7881854773 -2.029365301 -0.8679792285 -1.80484283 -1.472986341 0.3872671127 0.8609884977 -1.821317554 -3.562850237 -0.8730406761 -0.6067320704 -2.005383253 0.7215870023 0.3278435469 -1.254088759 0.5948729515 -0.8321160078 0.3374435306 2.182619333 -1.570125222 -0.9135497212 -2.348448277 -1.675305605 -0.09843407571 0.3884909153 -0.2105440795 -0.694961071 -1.161129594 -0.6163506508 -1.226319551 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007750793826 0.002715930808 0.006679440383 0.01973281801 0.002229345264 0.002363155829 0.005270711146 0.01353957411 0.002040633699 0.386665225 0.002533235587 0.0968413949 0.003539315425 0.002955875359 0.005577840377 0.004515274428 0.002072119853 0.001798390062 0.004095360171 0.002713154303 0.004607725888 0.00824446138 0.008864907548 0.05774079263 0.001347894431 0.002430999419 0.009248900227 0.009808670729 0.001624933095 0.00187538052 0.001781476196 0.02378105 0.01203436684 0.004473173525 0.00441055838 0.001274840906 0.00407229783 0.001595750335 0.002223761752 0.01428848319 0.02294672094 0.00156967598 0.0002750881831 0.004051737487 0.005288076587 0.00130578375 0.01996086724 0.0134641435 0.002767925384 0.01758523658 0.004220994655 0.01359402388 0.0860394612 0.002017908031 0.00389088667 0.000926573528 0.001816444681 0.008791213855 0.01430597994 0.007858868688 0.004841504153 0.00303756725 0.00523745548 0.002845865209 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
23.53842545 23.52433205 23.53735352 23.55040741 23.52241516 23.53351402 23.53642082 23.53658676 23.52699471 23.91781616 23.5313015 23.62703896 23.53421402 23.53124809 23.52576256 23.52613068 23.53179169 23.53009033 23.53381538 23.53290939 23.52908516 23.53939438 23.53953934 23.58793831 23.53202248 23.5259552 23.53896904 23.54096031 23.53229904 23.53064346 23.53245544 23.55397797 23.54127884 23.53466988 23.5341301 23.53194809 23.53141022 23.53322411 23.53337479 23.54400826 23.55314445 23.52890778 23.5304718 23.53424835 23.53405571 23.53055191 23.55063438 23.54366112 23.53344154 23.54683113 23.53108215 23.54474449 23.61337662 23.52458763 23.53504181 23.53255463 23.53248978 23.53469849 23.54402542 23.53805542 23.53551483 23.53275871 23.5363884 23.53447342 

-------
======================
selected experts : 9, 11, 23, 31, 40, 52, 
layer16_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def2d9d0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.275041 -0.0150698 0.1121280.106804 0.0153342 0.117826 -0.297133 -0.0696298 -0.113063]

layer16_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def2d090>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.863299 -0.307619 -0.2410780.0562393 0.31626 -0.0348067 0.229443 0.203865 -0.0172845]

layer17_wq's input 
<N9nntrainer6TensorE at 0x5682def6d870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.955608 -0.647937 -0.3954220.118961 0.484722 -0.0861039 0.495614 0.321594 -0.0298995]
==============================
layer17_wq's output 
<N9nntrainer6TensorE at 0x5682def2cf40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0768425 0.187951 -0.32892-0.0927655 -0.281091 0.0565282 0.16259 0.139941 -0.147259]
============================
layer17_wk's input 
<N9nntrainer6TensorE at 0x5682def6f5d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.955608 -0.647937 -0.3954220.118961 0.484722 -0.0861039 0.495614 0.321594 -0.0298995]
==============================
layer17_wk's output 
<N9nntrainer6TensorE at 0x5682def6f340>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.58195 0.714871 2.247810.698659 0.00432331 0.300537 -2.55857 -0.410296 0.803148]
============================
layer17_wv's input 
<N9nntrainer6TensorE at 0x5682def703c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.955608 -0.647937 -0.3954220.118961 0.484722 -0.0861039 0.495614 0.321594 -0.0298995]
==============================
layer17_wv's output 
<N9nntrainer6TensorE at 0x5682def70150>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.346848 -1.11488 0.153260.0998686 0.317869 -0.707371 0.349783 -0.456701 -0.521514]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.197131 0.0486779 -0.298488-0.16643 -0.111116 0.264312 0.0680778 -0.203432 -0.0231972]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2298908
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer17_attention_out's input 
<N9nntrainer6TensorE at 0x5682def72870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer17_attention_out's output 
<N9nntrainer6TensorE at 0x5682def727d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer17_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def738f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.863299 -0.307619 -0.2410780.0562393 0.31626 -0.0348067 0.229443 0.203865 -0.0172845]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.971084 -0.716866 -0.50130.132066 0.660469 -0.0867279 0.5388 0.447673 -0.0356316]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5649166703 -1.567571998 0.3276652992 2.513124704 -0.1520899236 -0.8303835988 -3.270487309 -1.296907067 -0.04425581917 -0.9040798545 -2.194829941 -0.8708052635 -0.01627292112 -1.334774017 -1.348267436 -0.3647217751 0.8149148822 -1.805742145 -0.7421472073 -1.794073939 0.04781312495 -0.8486894369 -2.223347902 -0.2245208025 -1.042313933 -1.049682975 -0.2846728563 -0.4662835598 0.1692023426 -1.313108087 -2.433745384 -0.4951153398 -0.1207370013 -1.148418069 -1.066797137 0.3209392726 1.22931695 -2.256134033 -1.501471758 -2.023600817 -2.457115412 -0.7980403304 -0.4143774509 -0.1150985137 -0.3079393506 -0.4383943379 2.676130772 -0.9510215521 -0.9202147722 -1.216504931 -1.759028435 -2.573677063 0.2100169212 -1.125802994 2.914211035 1.666934848 -2.273659468 -0.2277843654 -1.183776975 -0.9288334846 -0.7405062914 -0.147444278 -0.6151849627 -0.9241185188 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006672522053 0.002448174171 0.01629046351 0.1448993236 0.01008273568 0.005116808694 0.0004459392221 0.003209153889 0.0112307854 0.004753278103 0.001307457336 0.00491410261 0.01154949237 0.003089904552 0.003048492363 0.008151424117 0.02651815116 0.001929329243 0.005588814616 0.001951972954 0.01231388748 0.005023993552 0.001270698267 0.009378253482 0.004139606375 0.004109213129 0.0088307634 0.007364203688 0.01390316896 0.003157581203 0.00102959841 0.007154912688 0.01040386595 0.003722875379 0.004039485939 0.01618126035 0.04013430327 0.001229712274 0.00261546718 0.00155164185 0.001005815924 0.005285007879 0.007756545208 0.0104626948 0.008627676405 0.007572476752 0.1705528498 0.004535308108 0.004677199759 0.003477833932 0.002021593042 0.0008951509953 0.01448236126 0.003808027133 0.2163993418 0.0621685572 0.001208349015 0.00934769772 0.003593538655 0.004637062084 0.005597992335 0.01012968458 0.00634539593 0.004658977035 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
22.11065292 22.11453629 22.12980843 22.25078773 22.12073898 22.11243629 22.11396408 22.11672783 22.12427139 22.11827087 22.11291695 22.11795425 22.11696053 22.11565399 22.11608887 22.12214661 22.14003563 22.11592484 22.10527802 22.11499214 22.12201691 22.11377335 22.11240387 22.12003517 22.11717987 22.11333466 22.12282562 22.12088203 22.11883736 22.11524391 22.11407089 22.12019539 22.12296867 22.11724091 22.11755753 22.12111664 22.15317535 22.11427116 22.11279488 22.11459351 22.11452293 22.11117363 22.12127495 22.12016487 22.11403847 22.12156677 22.28073311 22.11805344 22.11342621 22.11699486 22.11553955 22.11393547 22.10892677 22.1092205 22.32419586 22.17234802 22.11520386 22.11905098 22.11520386 22.11338615 22.11863899 22.12317085 22.12034035 22.11579323 

-------
======================
selected experts : 3, 16, 36, 46, 54, 55, 
layer17_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def76b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.119878 0.0427516 0.0836584-0.082742 -0.192372 -0.123712 -0.352863 0.0408223 0.0129357]

layer17_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def761f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.743421 -0.264867 -0.15742-0.0265027 0.123888 -0.158519 -0.12342 0.244688 -0.00434877]

layer18_wq's input 
<N9nntrainer6TensorE at 0x5682defb6420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.2624 -0.541026 -0.275062-0.0539179 0.198178 -0.361506 -0.252102 0.383386 -0.00774135]
==============================
layer18_wq's output 
<N9nntrainer6TensorE at 0x5682def760a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.5232 0.418725 1.278382.72879 1.82538 -3.37991 2.63293 1.65801 -2.0232]
============================
layer18_wk's input 
<N9nntrainer6TensorE at 0x5682defb8180>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.2624 -0.541026 -0.275062-0.0539179 0.198178 -0.361506 -0.252102 0.383386 -0.00774135]
==============================
layer18_wk's output 
<N9nntrainer6TensorE at 0x5682defb7ef0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.25415 1.13258 -0.5479561.12094 1.30056 1.08249 0.19233 2.1954 -1.79507]
============================
layer18_wv's input 
<N9nntrainer6TensorE at 0x5682defb8f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.2624 -0.541026 -0.275062-0.0539179 0.198178 -0.361506 -0.252102 0.383386 -0.00774135]
==============================
layer18_wv's output 
<N9nntrainer6TensorE at 0x5682defb8d00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0587756 -2.15294 1.13441-0.139991 1.24529 -1.41666 1.10897 -0.340765 -0.298185]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.781394 2.43542 0.6115462.95069 -1.77108 -3.40867 0.539421 -3.06436 2.77112]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a249d918
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer18_attention_out's input 
<N9nntrainer6TensorE at 0x5682defbb420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer18_attention_out's output 
<N9nntrainer6TensorE at 0x5682defbb380>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer18_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682defbc4a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.743421 -0.264867 -0.15742-0.0265027 0.123888 -0.158519 -0.12342 0.244688 -0.00434877]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.853795 -0.573618 -0.312511-0.0582662 0.245943 -0.364107 -0.271338 0.501814 -0.00852619]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.6273706555 -0.3092482686 -0.5520982742 0.7557987571 -0.8661976457 -1.701852083 -0.7072938085 -0.8364729881 2.185483932 -1.531793118 0.2034626007 -1.502796769 -2.203984737 -1.11043334 -3.4694345 -1.465497494 0.04039787501 -0.8558729887 -0.8649594784 -0.1077571064 -1.545637369 -0.1326479465 -1.634534836 0.9015256166 -0.9431143999 0.08800459653 0.1092985123 0.880182445 -1.240120649 1.658906698 -0.6974722147 0.2955052853 -0.584644258 -0.2497467101 -0.6149420738 -0.1882206351 -1.878281355 0.670244813 -1.747626901 -0.8226674795 -0.1309736073 -0.2170142829 -0.9305517077 -0.02207532339 -2.079432011 -0.9483323097 -0.7753231525 -1.186023712 -0.00827340968 0.1153657958 -0.4481774271 -1.542468667 -0.3585171103 0.4268810451 -0.4900393784 -1.062475324 0.4979901612 -0.4232053757 -0.2158964276 0.3050209582 -0.2451109588 -1.548001289 -0.1942561567 0.5499870181 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03072108515 0.01204115618 0.00944495108 0.03493109718 0.00689903181 0.002991355257 0.008087218739 0.007107180543 0.1459205896 0.003545877058 0.02010646276 0.003650200088 0.001810483402 0.005404031835 0.0005107596517 0.003788920352 0.01708116755 0.006970629096 0.006907578558 0.01472904719 0.003497125115 0.0143669527 0.003199657658 0.04041108862 0.006388275418 0.01791401207 0.01829956099 0.03955772892 0.004746739287 0.08618406951 0.008167039603 0.02204495855 0.009142503142 0.01277936529 0.008869660087 0.01359032094 0.002507527126 0.03206687048 0.00285751326 0.007205978502 0.01439102925 0.01320458762 0.006469034124 0.01604669914 0.002050629118 0.006355028134 0.007555346936 0.005010596476 0.01626971178 0.01841092855 0.01047929376 0.003508224618 0.01146227773 0.02513998747 0.01004966535 0.005669514183 0.02699276246 0.01074427739 0.0132193584 0.02225573175 0.01283874549 0.003488867776 0.01350854617 0.0284334328 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
24.24374962 24.21648598 24.22151947 24.24462128 24.21992683 24.21649551 24.22111511 24.22061157 24.35799408 24.21705055 24.22932053 24.21620178 24.21293068 24.21700096 24.21401596 24.21681595 24.22247887 24.2185688 24.2189827 24.22727966 24.21032715 24.22071838 24.21622849 24.25296211 24.21893883 24.22951126 24.23037338 24.24543381 24.20203972 24.2992115 24.21976471 24.23554993 24.22073936 24.21770096 24.22189713 24.22614098 24.21601295 24.23078918 24.21493149 24.21928024 24.22694206 24.22623253 24.21854401 24.22859764 24.21555519 24.21509171 24.21772194 24.21660805 24.22929764 24.23048592 24.22350693 24.21701241 24.21543121 24.23816872 24.22355461 24.21535873 24.24002075 24.22377205 24.22624779 24.2352829 24.22300529 24.21556282 24.22605896 24.2414608 

-------
======================
selected experts : 3, 8, 23, 27, 29, 37, 
layer18_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682defbf6e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0224344 0.0454053 -0.0709348-0.187937 0.124586 0.226347 -0.290267 -0.267766 -0.0996515]

layer18_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682defbeda0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.765856 -0.219462 -0.228355-0.214439 0.248474 0.0678284 -0.413687 -0.0230783 -0.104]

layer19_wq's input 
<N9nntrainer6TensorE at 0x5682deffefd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1351 -0.389111 -0.347942-0.37575 0.359667 0.135294 -0.727746 -0.0334059 -0.170709]
==============================
layer19_wq's output 
<N9nntrainer6TensorE at 0x5682defbec50>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.673518 0.446467 0.06407090.0890631 -0.215499 -0.0496878 -0.193079 -0.477774 -0.15175]
============================
layer19_wk's input 
<N9nntrainer6TensorE at 0x5682df001130>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1351 -0.389111 -0.347942-0.37575 0.359667 0.135294 -0.727746 -0.0334059 -0.170709]
==============================
layer19_wk's output 
<N9nntrainer6TensorE at 0x5682df001100>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.884585 -1.93369 1.787090.760586 0.241383 -0.515798 1.96247 1.30788 -1.42562]
============================
layer19_wv's input 
<N9nntrainer6TensorE at 0x5682df002000>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.1351 -0.389111 -0.347942-0.37575 0.359667 0.135294 -0.727746 -0.0334059 -0.170709]
==============================
layer19_wv's output 
<N9nntrainer6TensorE at 0x5682df001d90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.888076 -0.00238157 -0.1487370.265708 -0.512243 0.150262 0.424696 -0.238823 -1.16209]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.539713 0.60139 0.04169880.101482 -0.162152 0.150385 -0.369304 0.359392 0.174288]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a28a7938
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer19_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0044b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer19_attention_out's output 
<N9nntrainer6TensorE at 0x5682df004410>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer19_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df005580>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.765856 -0.219462 -0.228355-0.214439 0.248474 0.0678284 -0.413687 -0.0230783 -0.104]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.838065 -0.41343 -0.404878-0.409909 0.435386 0.135294 -0.80797 -0.0412379 -0.182234]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.6672039032 1.011161685 0.3233934939 -0.5856403112 0.2339823842 -1.09533155 -0.2589462996 -1.10770607 -0.5928098559 -1.665809155 0.1330215782 1.439721942 -0.8517971039 -0.3086450398 -0.06121952832 -2.85298562 -1.539274931 0.7510276437 -1.042135715 -0.7157807946 0.00371193327 -0.07794098556 -0.5857000351 -0.1359512359 0.2269063443 -1.96133101 -0.1968873888 -0.7613671422 -0.9728127718 0.08115919679 0.6174609065 0.7811871767 -0.2542393506 -0.6601142883 -0.5794465542 -0.4633648992 -1.890489697 -0.8679003119 -1.077695847 -0.3713322282 -1.334422827 0.2955068052 -1.211002588 -0.4735624194 -2.129509211 1.023646951 -0.8193566203 -1.493514538 0.2843222618 -1.879455209 0.4954262972 1.167628288 -0.9052318335 -0.4109098315 -1.314629674 -2.20801115 0.2125170231 -0.6533298492 0.8769615293 -0.951233983 -2.019967318 1.744927764 -0.07661728561 -0.1612648964 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.008408664726 0.0450434871 0.02264321409 0.009123252705 0.02070653066 0.005480164662 0.01264826953 0.005412767641 0.00905807782 0.003097692272 0.01871804893 0.06914381683 0.00699132029 0.01203502994 0.01541355159 0.0009450486978 0.0035155355 0.03472619876 0.005779579282 0.008009960875 0.01644758508 0.01515795942 0.00912270695 0.01430366002 0.02056052536 0.002305126982 0.01345807593 0.007653013803 0.006194451358 0.01777203195 0.03038434684 0.03578947484 0.01270794496 0.008468491025 0.009179935791 0.01030987035 0.002474348294 0.006879640743 0.005577668082 0.01130374894 0.004314769991 0.02202049457 0.004881557077 0.01020527072 0.001948300865 0.04560939223 0.00722184265 0.003680144902 0.02177557722 0.002501802519 0.02689372748 0.05267257988 0.00662754802 0.01086511184 0.004401023034 0.001801204169 0.02026679181 0.008526139893 0.03938670084 0.006329572294 0.002173849382 0.09382154047 0.01517803781 0.01394612622 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.25514412 26.28605652 26.2622261 26.25538063 26.26791763 26.24315453 26.25795174 26.25214767 26.25579262 26.24983215 26.25973129 26.31492424 26.25229454 26.25876999 26.2621479 26.24815559 26.25024986 26.27860069 26.25203705 26.25426865 26.26365852 26.26141548 26.25061226 26.25960732 26.26777267 26.2490406 26.26019287 26.25391006 26.25245285 26.26212311 26.27759552 26.28300095 26.25992012 26.25568008 26.25400734 26.25609016 26.2473011 26.25123024 26.25231171 26.24993134 26.25104904 26.26875496 26.25161552 26.25407982 26.24248314 26.29234314 26.25395584 26.25041389 26.26755714 26.24494553 26.2731514 26.29845428 26.25288582 26.25378418 26.23778343 26.24901199 26.26652527 26.2557373 26.28659821 26.24829674 26.24938583 26.33817291 26.2619133 26.25972748 

-------
======================
selected experts : 1, 11, 45, 51, 58, 61, 
layer19_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df008b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.215267 -0.39338 -0.000695813-0.0864399 -0.112795 -0.0509957 0.289701 0.168486 -0.00108794]

layer19_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df008060>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.981122 -0.612842 -0.229051-0.300879 0.135679 0.0168326 -0.123986 0.145408 -0.105088]

layer20_wq's input 
<N9nntrainer6TensorE at 0x5682df047b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.958103 -0.910237 -0.334845-0.431053 0.180098 0.0257885 -0.183428 0.183659 -0.144409]
==============================
layer20_wq's output 
<N9nntrainer6TensorE at 0x5682df007f10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.876517 0.0806131 -1.10045-0.950074 1.5474 -0.0318424 1.07022 0.0833046 1.55108]
============================
layer20_wk's input 
<N9nntrainer6TensorE at 0x5682df0498e0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.958103 -0.910237 -0.334845-0.431053 0.180098 0.0257885 -0.183428 0.183659 -0.144409]
==============================
layer20_wk's output 
<N9nntrainer6TensorE at 0x5682df049650>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.846784 -2.53762 1.45796-1.87529 0.273083 1.54017 1.20665 1.44815 1.83976]
============================
layer20_wv's input 
<N9nntrainer6TensorE at 0x5682df04a6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.958103 -0.910237 -0.334845-0.431053 0.180098 0.0257885 -0.183428 0.183659 -0.144409]
==============================
layer20_wv's output 
<N9nntrainer6TensorE at 0x5682df04a460>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.58004 -0.259193 0.555010.26039 0.126245 -0.290294 -0.940173 -0.403823 -0.0109447]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.047778 -0.878918 -0.850456-1.17913 0.842806 -1.29813 -0.327527 -1.02227 -2.07105]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2cb1958
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer20_attention_out's input 
<N9nntrainer6TensorE at 0x5682df04cb80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer20_attention_out's output 
<N9nntrainer6TensorE at 0x5682df04cae0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer20_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df04dc00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.981122 -0.612842 -0.229051-0.300879 0.135679 0.0168326 -0.123986 0.145408 -0.105088]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.0499 -1.01058 -0.361632-0.49967 0.209454 0.0291351 -0.211703 0.229574 -0.163459]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8655126095 -0.70669806 -1.061430693 -2.783363581 -0.2065856159 -1.022460699 0.2129929066 -1.197860122 -1.765060186 -0.4202759564 -1.40267086 0.1384142488 -0.4667899311 0.519497931 -0.8139014244 -0.7501202226 -0.5346457958 -0.2915263474 0.2705768645 -1.274973035 -0.9905731678 -1.995363832 0.3463840187 0.3722329736 -0.7950048447 0.1706930399 -0.4584597349 -0.921906352 -0.128356114 -1.033184409 -1.007602215 0.4361215532 2.485273838 -0.09640012681 -0.3592478633 -0.608148098 -0.2030857652 0.9808261991 -0.533608377 -1.060790062 -0.230525136 -0.3972931206 -0.6110050678 -0.6829974651 -0.7350553274 0.05229857937 -0.8097520471 0.1194356456 -0.5318554044 -1.408503294 -1.412146211 -0.8701547384 -0.1973832399 0.2585422397 0.1805107296 0.8161994219 -1.081575871 -1.17308712 0.1499855518 -0.9741865396 -1.142312765 0.02617833763 -0.6642144322 -1.035818815 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007350394502 0.008615549654 0.006042608991 0.001079937094 0.0142062353 0.006282737944 0.02161223255 0.005271981936 0.002989800414 0.01147293393 0.004295619205 0.02005905658 0.01095150225 0.02936385572 0.007739717606 0.008249448612 0.01023303065 0.01304937527 0.02289328352 0.004880724475 0.00648630783 0.002374775475 0.02469623089 0.02534292266 0.007887362503 0.02071710117 0.01104311086 0.006947348826 0.01536220685 0.006215723231 0.006376787089 0.02701488696 0.2096711695 0.01586105116 0.01219491009 0.009507857263 0.01425604336 0.04657634348 0.01024365239 0.006046481431 0.01387018524 0.01173966751 0.009480731562 0.008822181262 0.008374665864 0.01840394735 0.007771899924 0.01968195476 0.01026162598 0.004270638339 0.004255109467 0.007316350937 0.01433757041 0.02261942253 0.0209215004 0.03950653225 0.005922097713 0.005404216703 0.0202925168 0.006593472324 0.005573113449 0.01792945713 0.008989455178 0.006199370604 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.40150261 25.40372086 25.40305519 25.39856911 25.41026497 25.40377235 25.41385651 25.40228462 25.40000343 25.40228653 25.40083122 25.41421127 25.40796471 25.42589951 25.40475273 25.40383148 25.40152359 25.40434074 25.41799927 25.40093994 25.4034996 25.39938736 25.41646385 25.42092514 25.40156174 25.41773033 25.40328789 25.40348244 25.40665245 25.40322876 25.40338898 25.42450523 25.60573006 25.41192055 25.4092083 25.40604401 25.41126823 25.43452835 25.40296555 25.40115166 25.41088295 25.40732193 25.40458679 25.40631104 25.40395737 25.41589355 25.40478516 25.41669464 25.40679741 25.40080643 25.39888382 25.4043293 25.39704514 25.41963196 25.41698074 25.43556595 25.40341187 25.39907837 25.41492081 25.40026855 25.40115547 25.41351128 25.40123367 25.39844322 

-------
======================
selected experts : 13, 23, 31, 32, 37, 55, 
layer20_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df050e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.885376 -0.319169 0.5262190.70381 -0.196865 -0.350957 0.573935 -0.108444 0.136571]

layer20_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df050500>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.8665 -0.932011 0.2971680.402931 -0.061186 -0.334124 0.449949 0.0369634 0.0314824]

layer21_wq's input 
<N9nntrainer6TensorE at 0x5682df091030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.34343 -1.12902 0.3250060.462413 -0.0660174 -0.435887 0.5252 0.0393383 0.0359756]
==============================
layer21_wq's output 
<N9nntrainer6TensorE at 0x5682df0503b0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.438507 -0.128789 0.342350.258348 0.64409 -0.20004 -0.185343 -0.0576341 -0.281783]
============================
layer21_wk's input 
<N9nntrainer6TensorE at 0x5682df092d90>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.34343 -1.12902 0.3250060.462413 -0.0660174 -0.435887 0.5252 0.0393383 0.0359756]
==============================
layer21_wk's output 
<N9nntrainer6TensorE at 0x5682df092b00>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.141955 -1.32763 -0.06101911.14812 1.04022 0.493206 2.01475 -0.189959 -0.493183]
============================
layer21_wv's input 
<N9nntrainer6TensorE at 0x5682df093b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.34343 -1.12902 0.3250060.462413 -0.0660174 -0.435887 0.5252 0.0393383 0.0359756]
==============================
layer21_wv's output 
<N9nntrainer6TensorE at 0x5682df093910>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.848235 -1.16323 -0.1315370.66145 -1.24199 0.601555 0.0756982 -0.25 0.0249144]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.191221 -0.415102 0.2731990.33062 0.196273 -0.645248 0.0167222 0.193375 0.754487]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1f910f0
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer21_attention_out's input 
<N9nntrainer6TensorE at 0x5682df096030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer21_attention_out's output 
<N9nntrainer6TensorE at 0x5682df095f90>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer21_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0970b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.8665 -0.932011 0.2971680.402931 -0.061186 -0.334124 0.449949 0.0369634 0.0314824]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.79419 -1.38042 0.4255680.600742 -0.0864228 -0.524375 0.697324 0.0532971 0.0444677]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.338927716 -0.8085083365 -0.3935043216 -0.2765239775 -1.24435389 -0.5573443174 -1.160563588 -1.030288935 0.6692617536 -1.052990317 -0.06676454842 -0.3132822514 -0.6337903738 -0.5771283507 -1.292338848 -0.7287265062 0.2857293487 -0.967897892 -0.9411482811 -1.694105983 -0.8988958001 0.2688181698 0.01038398501 -1.540452242 -1.435884714 0.8472945094 0.6545837522 -1.271214008 0.688174367 0.7262431979 1.963293791 -1.16886127 -2.187511683 -0.9855898023 -1.560562253 -1.163798332 -1.570108056 0.5532386899 0.03886730224 -1.896592736 -1.347119093 -1.031612039 -0.1494785547 0.2236829996 0.130858317 -1.156510353 1.787328124 -1.326728463 -0.7687029839 -0.6601318717 -0.3301847577 -0.3158607781 0.6373904347 2.850577593 0.06893432885 0.979413867 -0.1041699052 0.04358827695 0.4303562045 0.220823437 0.630808413 -0.0217722021 -0.3897924423 -0.5688437819 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01735400409 0.005509022158 0.008342735469 0.009378045797 0.003562781261 0.007081964053 0.003874171525 0.004413228948 0.02414692938 0.004314171616 0.01156670786 0.009039585479 0.006560752634 0.006943230517 0.003395857988 0.005966550205 0.01645492762 0.004697345663 0.00482469378 0.00227229367 0.005032917485 0.01617899351 0.01249438897 0.002649691654 0.002941768151 0.02885231189 0.02379508875 0.003468357958 0.02460796013 0.02556281723 0.08807505667 0.003842158942 0.001387333847 0.004614972044 0.002596938284 0.003861661302 0.002572266385 0.02150174603 0.01285538543 0.001855775598 0.003214836353 0.00440739328 0.01064847689 0.01546498947 0.01409406774 0.00388990785 0.07386386395 0.003281061538 0.005732734222 0.006390187424 0.008888077922 0.009016307071 0.02338946983 0.2138924152 0.0132477805 0.0329275392 0.0111420434 0.01291621756 0.01901545003 0.01542082801 0.02323602512 0.01209900714 0.00837376155 0.007000990678 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.65564346 25.64379883 25.64615631  25.647192 25.63994598 25.64489555 25.64216423 25.64031982 25.6619606 25.64165115 25.63888931 25.63826942 25.64103699 25.64284897 25.64168549 25.64377975 25.6547451 25.6429882 25.64025497 25.64056206 25.64284706 25.65446854 25.65030861 25.6395092 25.64123154 25.66618919 25.66160774 25.64032745 25.66289902 25.66385269 25.72636604 25.64070129 25.63872337 25.64242935 25.6394577 25.64119911 25.64086342 25.65931511 25.64876175 25.63919258 25.6415062 25.64269829 25.64750862 25.65327835 25.64809227 25.64170265 25.71215439 25.64109421 25.63877869  25.641819 25.64717865 25.64349174 25.65357399 25.85218239 25.65153885 25.66931152 25.64418793 25.65073013 25.64920044 25.65323448 25.66009521 25.64991188 25.64475632 25.64433861 

-------
======================
selected experts : 25, 29, 30, 46, 53, 55, 
layer21_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df09a2f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.203484 0.325646 -0.08617490.263837 -0.197649 -0.211468 -0.165355 0.027559 -0.218294]

layer21_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df0999b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.06998 -0.606365 0.2109930.666768 -0.258835 -0.545592 0.284594 0.0645224 -0.186811]

layer22_wq's input 
<N9nntrainer6TensorE at 0x5682df0d9be0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52088 -0.661526 0.2176970.727424 -0.272531 -0.641366 0.290025 0.065481 -0.206965]
==============================
layer22_wq's output 
<N9nntrainer6TensorE at 0x5682df099860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.437703 1.93202 -0.130586-1.09558 -0.350645 2.35805 0.589283 0.483181 -1.41336]
============================
layer22_wk's input 
<N9nntrainer6TensorE at 0x5682df0db940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52088 -0.661526 0.2176970.727424 -0.272531 -0.641366 0.290025 0.065481 -0.206965]
==============================
layer22_wk's output 
<N9nntrainer6TensorE at 0x5682df0db6b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.46632 2.72871 1.06410.640243 -2.17135 -0.228131 0.0903081 -0.916295 0.0818679]
============================
layer22_wv's input 
<N9nntrainer6TensorE at 0x5682df0dc730>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52088 -0.661526 0.2176970.727424 -0.272531 -0.641366 0.290025 0.065481 -0.206965]
==============================
layer22_wv's output 
<N9nntrainer6TensorE at 0x5682df0dc4c0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.220364 1.69392 0.3736711.04747 0.378844 0.398043 -0.296168 -0.251376 -0.942125]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.97514 0.151936 0.126732-1.09603 1.75398 1.61459 0.224506 -0.728228 0.755233]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a30bb978
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer22_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0debe0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer22_attention_out's output 
<N9nntrainer6TensorE at 0x5682df0deb40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer22_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0dfc60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.06998 -0.606365 0.2109930.666768 -0.258835 -0.545592 0.284594 0.0645224 -0.186811]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.17076 -0.846138 0.2872880.919148 -0.343673 -0.798248 0.404351 0.0883993 -0.248042]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8047953844 -0.01834646985 -0.3145961165 -0.1551435143 -0.1897218674 -0.6782951951 -0.001238539815 -0.1476960182 0.8379756808 -0.3640313745 0.08346153051 -0.7165501118 -0.9255920649 0.1504372358 -0.8932706118 -0.4338618517 0.1948764473 0.2700033784 -1.274457693 -0.1353416145 0.4278050363 -0.8345499039 -0.1699510664 0.9164355397 -1.557055831 0.668407321 -0.7479814291 -0.5342580676 -1.330482841 -0.1022242233 -1.963770986 -1.084569573 -1.34240365 -0.1084434316 -0.565561533 -0.5060130954 -1.144616723 1.264299154 -0.1902586669 0.02174477838 -1.254423261 -0.9504104853 -0.8645780683 -0.1366228163 -0.144697085 -0.5823468566 -1.647065759 -0.5357928872 -0.8950794339 0.5012350082 -1.256810546 1.121241927 -0.6218414307 -0.2271721363 -0.5474994183 -0.4918791652 0.3645601869 -0.9830704927 2.122302771 -0.6177154779 -0.6622462273 -0.9478222728 -0.01968348585 1.327158451 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007012990303 0.01539762318 0.01144970022 0.01342899539 0.01297258027 0.007958691567 0.01566331089 0.01352938171 0.0362534821 0.01089744549 0.01704780012 0.007659981493 0.006215011235 0.01822869293 0.006419171114 0.01016243175 0.01905703172 0.0205438789 0.004384615924 0.0136975646 0.02405552752 0.00680739712 0.01323161181 0.03921248391 0.003305223072 0.03059899248 0.007422963623 0.009191705845 0.004145721905 0.01415878907 0.002200728748 0.005301501136 0.004096594639 0.01407100353 0.008908431046 0.009455027059 0.004992530216 0.05552641675 0.01296561677 0.01602747478 0.004473344889 0.006062662695 0.006606022362 0.01368002594 0.01357001439 0.008760148659 0.0030207159 0.009177611209 0.006407571491 0.02588839456 0.004462679382 0.04812499508 0.00842091348 0.01249573752 0.009070798755 0.009589612484 0.02258124948 0.005867854692 0.1309561431 0.008455728181 0.008087449707 0.006078375038 0.01537704933 0.05912880227 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.01239395 27.02077866 27.0149231 27.01737976 27.01882935 27.00809479 27.01961327 27.01747894 27.04211044 27.01580048 27.02290535 27.01304054 27.01159477 27.02313232 27.00893784 27.01601982 27.02443695 27.02640152 27.01024246 27.01287842 27.0280056 27.01218796 27.01908875 27.03887177 27.0091629 27.03598022 27.01328087 27.01314163 27.00905037 27.02001572 27.00758171 27.00925255 27.00661659 27.01992798 27.00427628 27.01245117 27.0056057 27.05518532 27.01262474 27.01950073 27.00985336 27.01001358 27.01198578 27.01906013 27.01942825 27.01271057 27.00887871 27.01360512 27.01226425 27.03174591 27.01032066 27.05207443 27.00855637 27.01835251 27.01445198 27.01449394 27.02843857 27.00790977 27.13681412 27.01383591 27.01156044 27.01193619 27.02075768 27.06498718 

-------
======================
selected experts : 8, 23, 37, 51, 58, 63, 
layer22_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df0e2e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.459906 -0.801032 -0.4119380.196134 -0.324941 0.14068 0.0877142 0.237325 -0.955242]

layer22_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dde69cd0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52989 -1.4074 -0.2009450.862902 -0.583776 -0.404912 0.372308 0.301847 -1.14205]

layer23_wq's input 
<N9nntrainer6TensorE at 0x5682de368560>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.32152 -1.33011 -0.1922740.768143 -0.565455 -0.404908 0.344564 0.266333 -1.05695]
==============================
layer23_wq's output 
<N9nntrainer6TensorE at 0x5682de2bfbc0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60922 2.58156 -3.89571.96592 1.101 3.35278 -1.33262 2.75291 -3.83909]
============================
layer23_wk's input 
<N9nntrainer6TensorE at 0x5682de266760>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.32152 -1.33011 -0.1922740.768143 -0.565455 -0.404908 0.344564 0.266333 -1.05695]
==============================
layer23_wk's output 
<N9nntrainer6TensorE at 0x5682de82d610>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.06271 3.21187 -2.23235-2.24058 -2.63303 2.30116 -0.501631 -1.88495 2.02967]
============================
layer23_wv's input 
<N9nntrainer6TensorE at 0x5682de40ebf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.32152 -1.33011 -0.1922740.768143 -0.565455 -0.404908 0.344564 0.266333 -1.05695]
==============================
layer23_wv's output 
<N9nntrainer6TensorE at 0x5682de7736d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.178801 -0.967032 0.719379-1.08272 -0.607393 -0.18185 -0.818278 -0.941207 -0.217915]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-3.07923 3.19519 -4.245121.0101 3.39234 0.972287 3.05242 0.192824 2.95508]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a32c0988
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer23_attention_out's input 
<N9nntrainer6TensorE at 0x5682ddf81aa0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer23_attention_out's output 
<N9nntrainer6TensorE at 0x5682de55e330>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer23_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0fe910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.52989 -1.4074 -0.2009450.862902 -0.583776 -0.404912 0.372308 0.301847 -1.14205]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.07552 -1.95378 -0.2758031.18436 -0.796674 -0.587513 0.534366 0.414296 -1.54959]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4839372635 -0.9653638005 -0.2139574289 -0.4169965982 -0.9937536716 -2.169672012 -0.2422578484 -1.502996802 -0.8820543885 -1.586862683 -2.791267872 0.3879947662 0.2185072303 0.8950022459 -0.311399132 0.2695389986 -0.6820523143 -0.01871247217 0.1456014663 -0.4945863783 0.7300466895 -0.5971394777 -0.5344864726 -0.5229815245 -1.184855461 -1.106283307 -0.7813099623 -0.5901976228 0.5363240242 0.7315717936 -1.264652252 -0.4504970312 0.6880748272 0.6829567552 -0.008895480074 -1.164098144 0.3065220416 -0.6324129105 -1.468803048 0.1183366179 -1.34001267 -0.1585486531 -1.519421697 -1.86741221 0.5924387574 -0.7581304312 -1.252984047 -0.6759970188 -1.148257971 0.4346925616 0.1837275922 2.585729837 0.6428440213 -0.5275315046 -0.9693915844 -0.2661961317 -0.9315228462 0.7165947556 0.05729415268 0.2847727537 -0.4847031832 -0.06007727981 -0.8921365738 0.2510969937 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009283553809 0.00573632028 0.01216087956 0.009926272556 0.005575756542 0.001720319386 0.01182154752 0.003350752639 0.006234680768 0.003081199247 0.0009239601204 0.02220186964 0.01874053851 0.03686210141 0.01103180554 0.01972172596 0.007615071256 0.01478287205 0.01742286049 0.00918521639 0.03125653416 0.008289935067 0.008825941011 0.008928070776 0.004605845548 0.004982333165 0.006895519327 0.008347684518 0.02575183101 0.03130424023 0.004252595361 0.009599248879 0.02997178771 0.02981878258 0.01492871158 0.004702450242 0.02046475001 0.008002618328 0.003467308125 0.01695424691 0.003943895455 0.01285371929 0.003296165727 0.002327441005 0.02723819949 0.007057221606 0.004302506335 0.007661323529 0.004777530674 0.02326323837 0.01809995063 0.1999188513 0.02864634059 0.008887539618 0.00571326213 0.01154192071 0.005933764856 0.03083888628 0.01595027186 0.02002445795 0.009276445955 0.01418385748 0.006172136869 0.01936134696 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.92597198 26.92147064 26.92885017 26.92613792 26.92035675 26.91793251 26.92708015 26.91956329 26.9224472 26.91976929 26.91761208 26.9355526 26.93495178 26.95164299 26.92724419 26.93450356 26.9171505 26.93099403 26.93172836 26.92206001 26.9474678 26.92450142 26.92551422 26.92561722 26.92129517 26.9202404 26.9211998 26.92503738 26.94244003 26.94703865 26.91998863 26.92390442 26.94332314 26.94317055 26.93018723 26.92043686 26.93715286 26.92373848 26.91967964 26.92982864 26.91777229 26.9290657 26.91998482 26.91806221 26.94297409 26.92326927 26.91765404 26.91958237 26.92098999 26.93756866 26.93478966 27.11613083 26.94533539 26.92414665 26.91858673 26.92632294 26.92119217 26.94085121 26.93216324 26.9357605 26.92596626 26.92848778 26.9228611 26.9346199 

-------
======================
selected experts : 13, 20, 29, 32, 51, 57, 
layer23_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee1eb60>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.906188 -0.93121 -0.0112482-0.0990461 0.00702408 -1.02714 -0.165144 0.382759 0.00785814]

layer23_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de7806d0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.6237 -2.33861 -0.2121930.763855 -0.576752 -1.43206 0.207164 0.684606 -1.1342]

layer24_wq's input 
<N9nntrainer6TensorE at 0x5682de5e9620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.23194 -1.76072 -0.16460.548961 -0.457261 -1.08635 0.150064 0.474435 -0.847459]
==============================
layer24_wq's output 
<N9nntrainer6TensorE at 0x5682de23a580>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00566128 0.0150758 0.4445990.272002 0.00526445 0.243909 0.0761507 0.0756884 0.0855249]
============================
layer24_wk's input 
<N9nntrainer6TensorE at 0x5682de680bc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.23194 -1.76072 -0.16460.548961 -0.457261 -1.08635 0.150064 0.474435 -0.847459]
==============================
layer24_wk's output 
<N9nntrainer6TensorE at 0x5682de1e9fa0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.20187 1.80715 1.48120.76211 -0.307243 1.50088 -0.724443 0.979726 -0.9136]
============================
layer24_wv's input 
<N9nntrainer6TensorE at 0x5682de7cdb70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.23194 -1.76072 -0.16460.548961 -0.457261 -1.08635 0.150064 0.474435 -0.847459]
==============================
layer24_wv's output 
<N9nntrainer6TensorE at 0x5682de067420>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.0577 -0.642175 2.07097-2.49102 -1.41601 2.35112 -0.627438 2.78031 -2.84199]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.015739 0.00340751 0.3695040.367587 0.204755 0.132644 0.0412773 -0.0991153 0.096114]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a36ca9a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer24_attention_out's input 
<N9nntrainer6TensorE at 0x5682de40b530>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer24_attention_out's output 
<N9nntrainer6TensorE at 0x5682de646540>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer24_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de7c4940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.6237 -2.33861 -0.2121930.763855 -0.576752 -1.43206 0.207164 0.684606 -1.1342]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.6207 -2.6811 -0.2396380.871366 -0.64477 -1.70713 0.246956 0.780963 -1.27442]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.074664474 -0.8922616839 -0.102407448 0.07062817365 -0.1484004259 -0.2287002653 0.5861350894 0.1625005603 -0.2460435629 -0.3501291871 -1.06761992 -0.003797911108 1.444381356 -0.2615830898 -0.7064641118 -0.7513090372 -0.7412349582 -0.6171593666 -0.3239291012 0.02110742219 -0.7781904936 0.538713336 -0.255209446 -1.102991581 1.804532766 0.3891856074 -0.1016360149 -0.2039393783 -1.245521784 -0.1747154146 -1.308147907 1.133462429 -0.7939858437 -1.383263707 0.3777789772 -0.802591145 -1.066303134 0.01695022546 0.304941386 -1.007137418 -0.5375985503 -0.9835063219 -0.8290171027 -0.7907453775 0.5081122518 -0.939088285 -0.6026405692 -0.6043896675 -1.491520166 -0.5610138774 -0.09709006548 -0.3465279341 0.1509504467 -0.8219507337 -0.6634860635 -0.9424288273 -0.1440306008 -0.1431129873 -0.3499019742 -0.9935693741 -0.1177032068 -0.7337630987 -0.95454216 -0.2616923749 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005998932756 0.007199303247 0.01586060785 0.01885681041 0.01514765248 0.01397885382 0.03157548606 0.02067130618 0.01373850647 0.01238042768 0.00604134053 0.01750432514 0.07448720187 0.01352666412 0.008669246919 0.008289061487 0.008372988552 0.009479073808 0.0127090821 0.01794575155 0.008069209754 0.03011306934 0.01361315325 0.0058313841 0.1067808643 0.02593080327 0.01587284729 0.01432930212 0.005056750961 0.01475424133 0.004749778658 0.05458222702 0.007942754775 0.00440606568 0.02563670091 0.007874698378 0.006049302407 0.01787130348 0.02383576892 0.006418012083 0.01026404835 0.006571482867 0.007669326849 0.007968532853 0.02920553274 0.006869955454 0.009617701173 0.009600894526 0.003953992389 0.01002650429 0.01594517007 0.01242509391 0.02043392323 0.007723713294 0.009049955755 0.006847044453 0.01521398965 0.0152279567 0.01238324121 0.006505685858 0.01561985258 0.008435786702 0.006764604244 0.01352518704 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.83670807 28.83695602 28.84657097 28.84336662 28.84538078 28.8432579 28.86276245 28.85185814 28.84444809 28.84309006 28.83388901 28.84869003 28.90567398 28.84042168 28.83842659 28.83947563 28.83860588 28.83589745 28.84008026 28.84913254 28.83925629 28.85557747 28.84146309 28.83701706 28.9379673 28.8571167 28.8451519 28.8455162 28.83624268 28.8454628 28.83593559 28.88481522 28.83912849 28.8346386 28.85682297 28.83906174 28.83771324 28.84905815 28.84882355 28.83760452 28.83763504 28.83775711 28.83885574 28.83677101 28.85848427 28.83757973 28.84080315 28.83935738 28.83227921 28.83930588 28.84617805 28.84361076 28.85066605 28.8370018 28.84023666 28.83612633 28.84640121 28.84641457 28.84404564 28.83769226 28.84680557 28.83676147 28.83795166 28.84423447 

-------
======================
selected experts : 6, 12, 21, 24, 31, 44, 
layer24_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df21d1f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.628785 0.184833 -0.112852-0.955649 0.0126883 -0.311257 -0.82243 -0.778489 0.780474]

layer24_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de2b2790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25249 -2.15377 -0.325045-0.191793 -0.564064 -1.74331 -0.615266 -0.0938824 -0.353721]

layer25_wq's input 
<N9nntrainer6TensorE at 0x5682ddf10a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.871 -1.26846 -0.211436-0.109585 -0.366913 -0.996073 -0.370473 -0.0557046 -0.236307]
==============================
layer25_wq's output 
<N9nntrainer6TensorE at 0x5682de7d58a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.72197 4.42588 -4.597341.49702 -2.261 4.52404 -2.91168 -0.674019 -2.79383]
============================
layer25_wk's input 
<N9nntrainer6TensorE at 0x5682de480fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.871 -1.26846 -0.211436-0.109585 -0.366913 -0.996073 -0.370473 -0.0557046 -0.236307]
==============================
layer25_wk's output 
<N9nntrainer6TensorE at 0x5682de0aef30>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.34389 1.4774 -0.535676-0.850426 -0.684613 -0.76615 0.418316 -1.17355 0.647725]
============================
layer25_wv's input 
<N9nntrainer6TensorE at 0x5682ddd64050>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.871 -1.26846 -0.211436-0.109585 -0.366913 -0.996073 -0.370473 -0.0557046 -0.236307]
==============================
layer25_wv's output 
<N9nntrainer6TensorE at 0x5682de58dbd0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.854036 0.851605 -3.935430.344204 -0.228041 -2.01824 -1.358 0.834995 -4.27294]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-5.06583 4.02775 -4.819070.391429 2.473 4.41173 0.476917 2.95038 1.3988]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a38cf9b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer25_attention_out's input 
<N9nntrainer6TensorE at 0x5682df211490>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer25_attention_out's output 
<N9nntrainer6TensorE at 0x5682dddde7f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer25_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0184b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25249 -2.15377 -0.325045-0.191793 -0.564064 -1.74331 -0.615266 -0.0938824 -0.353721]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.881 -2.12042 -0.314296-0.187137 -0.540453 -1.77761 -0.616553 -0.0916031 -0.338914]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4517963231 -0.09050495923 -0.8284288645 -0.4897360504 -0.2275577635 -1.753577471 -1.147008538 1.391741633 -0.6251775622 -0.3415489197 0.6419427395 -0.5139391422 -1.198913932 -0.6744518876 -0.06356103718 0.0596325025 -0.9952005744 0.1956784427 0.7104929686 -1.46526897 -0.3979146183 -0.3888883293 -1.125691056 -0.0878001377 -1.128727078 -0.6170650721 -0.02985788137 -0.358745873 0.193454355 -1.149133563 -1.199773073 -0.5610435009 -1.269292355 1.229914904 -0.7043933868 -0.6024431586 -1.094941974 1.197730541 0.2244047076 -0.9261249304 -1.127594829 0.5340222716 -0.5747808814 -0.4632236958 -1.321432948 0.2379128188 -0.06032478064 -0.4061294496 0.6326365471 -0.4532514513 -0.1660106778 -0.599544704 -0.3058767021 -0.8097100258 -0.871348083 0.2680715322 -0.2872420549 0.7725386024 -0.3412109613 1.382186532 -0.1154797748 1.190463305 -0.2778798938 -0.3134531379 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01020949334 0.01465247478 0.007005429361 0.009829403833 0.01277584769 0.002777460264 0.00509421574 0.06451230496 0.008584315889 0.01139945351 0.03047958203 0.009594357572 0.004836543929 0.008171580732 0.01505263709 0.01702608913 0.005929345265 0.01950737834 0.03264224529 0.003705600509 0.01077468786 0.0108723836 0.005203977693 0.01469216216 0.00518820202 0.008654238656 0.01556860562 0.01120509207 0.01946404018 0.005083402153 0.004832390696 0.009152900428 0.004507856909 0.05487342551 0.007930537686 0.00878171064 0.005366480444 0.05313547701 0.02007587813 0.006353395525 0.005194080062 0.0273614917 0.009028023109 0.01009348966 0.004278837703 0.02034890465 0.01510143094 0.01068653818 0.03019724973 0.01019464806 0.01358686574 0.008807200938 0.01181343663 0.007137796842 0.006711123046 0.02097195014 0.01203564089 0.03473170474 0.01140330639 0.0638988167 0.01429106481 0.05275073275 0.01214884967 0.01172427181 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.69834518 28.70564842 28.69561768 28.70130157 28.70377159 28.69377327 28.6960907 28.75360107 28.69958115 28.70144272 28.72195244 28.70106697 28.69678688 28.69821358 28.70223427 28.70516205 28.69740295 28.70668793 28.72363853 28.69517899 28.69890976 28.69900703 28.69619942 28.70616531  28.696661 28.69917297 28.70704079 28.70267868 28.70521545 28.69083405 28.69582939 28.70062637 28.69598007 28.74634552 28.69892693 28.70025444 28.69636345 28.74460793 28.71107292 28.69639587 28.69428253 28.71788025 28.70050049 28.70061302 28.69575119 28.71182251 28.70466614 28.69929886 28.72119331 28.70119095 28.70172119 28.69932747 28.69899559 28.69813347 28.69770813 28.70958328 28.70207787 28.72620392 28.70287704 28.75489426 28.7009964 28.74374771 28.70362091 28.70319748 

-------
======================
selected experts : 7, 33, 37, 57, 59, 61, 
layer25_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df270060>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.181181 1.97758 1.990520.33743 0.29224 -0.657881 0.751527 -0.182415 1.26058]

layer25_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddfd81b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.43367 -0.176199 1.665470.145637 -0.271824 -2.40119 0.136262 -0.276298 0.906856]

layer26_wq's input 
<N9nntrainer6TensorE at 0x5682de245ed0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.6407 -0.117968 1.076610.0874191 -0.190357 -1.54295 0.0823158 -0.166911 0.575747]
==============================
layer26_wq's output 
<N9nntrainer6TensorE at 0x5682de21e590>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-5.11612 4.31771 1.10957-0.466114 -5.50468 5.45947 2.49852 1.2956 -1.05644]
============================
layer26_wk's input 
<N9nntrainer6TensorE at 0x5682de23ab70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.6407 -0.117968 1.076610.0874191 -0.190357 -1.54295 0.0823158 -0.166911 0.575747]
==============================
layer26_wk's output 
<N9nntrainer6TensorE at 0x5682de320f60>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.00795 -1.36418 0.3074020.544895 -1.04127 -0.565749 -0.416073 0.374108 0.161235]
============================
layer26_wv's input 
<N9nntrainer6TensorE at 0x5682dde7eae0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.6407 -0.117968 1.076610.0874191 -0.190357 -1.54295 0.0823158 -0.166911 0.575747]
==============================
layer26_wv's output 
<N9nntrainer6TensorE at 0x5682ddeee690>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.85801 -1.24985 -3.019780.374335 -0.668769 1.9824 -2.17322 1.1992 -4.69897]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-3.52737 -5.6899 1.18736-0.196428 1.425 7.62081 0.254735 -2.8029 0.589474]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a116e080
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer26_attention_out's input 
<N9nntrainer6TensorE at 0x5682df278ee0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer26_attention_out's output 
<N9nntrainer6TensorE at 0x5682df278e40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer26_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df27a260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.43367 -0.176199 1.665470.145637 -0.271824 -2.40119 0.136262 -0.276298 0.906856]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.1444 -0.158646 1.499560.131689 -0.237423 -2.24514 0.12426 -0.246646 0.806046]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7976108193 -1.237690926 0.3693436384 -1.320588946 0.4601677656 -1.316403985 0.3657962978 1.585767984 0.7315429449 -0.1187434494 -0.7654778361 -2.125173807 0.1955475211 -1.207199097 2.000904083 -0.7493480444 1.018078804 -0.07063479722 -0.3333452046 -0.7209935188 -0.02316588908 0.04870539159 0.1151986048 -0.7828495502 0.01025529951 1.13081646 -0.690267086 0.3549180925 -0.9964004755 -0.4106429815 -1.097838998 -1.076774597 -0.07724364102 -1.294981956 -0.7529384494 -0.9240140319 0.2047221065 -0.4458819628 -0.08619339764 -0.601223588 -0.3765991032 -0.6582266092 -0.8708590269 -0.2210022956 -1.058641672 -0.8108075857 0.9971785545 -1.19317472 -0.669097662 0.03125523776 -0.10601601 -0.1617669761 -0.7126160264 -0.3440948129 -0.2707051635 0.7163293362 0.3726058006 -0.2156991065 -0.7929415107 0.1992799789 0.1424860656 -1.363229513 -0.7534536123 -0.4182652831 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006906083319 0.004447412677 0.02218368277 0.004093598109 0.02429282852 0.004110766575 0.02210512944 0.07487210631 0.03186653554 0.01361633185 0.007131599355 0.001830958994 0.01864468306 0.004585111048 0.1133995578 0.00724756252 0.04244003817 0.01428740844 0.0109865116 0.007456006017 0.01498196926 0.01609838195 0.01720520668 0.007008781657 0.01549114659 0.04750476032 0.007688658312 0.02186596952 0.005661070812 0.01016926859 0.005114985164 0.005223871674 0.01419329736 0.004199777264 0.007221587934 0.006086050533 0.01881652698 0.009817156941 0.01406683773 0.008404689841 0.01052143238 0.007938996889 0.006418306381 0.01229276787 0.005319459364 0.006815542933 0.04156223312 0.004649866838 0.007853157818 0.01581989974 0.01379074156 0.01304293238 0.007518731523 0.01086904295 0.01169671677 0.0313853994 0.02225616761 0.01235813089 0.006938404404 0.01871440373 0.01768115722 0.003922714386 0.007217868231 0.01009205077 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.06643677 33.06493378 33.08457565 33.06553268 33.08573151 33.06459808 33.08354568 33.12963486 33.09044647 33.07123947 33.06952667 33.06422424 33.08008575 33.06697845 33.17483902 33.06868744 33.10387802 33.07572556 33.07147217 33.06412888 33.07641983 33.07753754 33.07578278 33.06844711 33.07597733 33.10894394 33.06817627 33.07758331 33.06614685 33.07256317 33.0675087 33.06666183 33.07086563 33.0656395 33.06675339 33.06847763 33.08025742 33.07030487 33.07646179 33.06507492 33.0700531 33.0693779 33.06785965 33.07373047 33.06771088 33.06921005 33.10300064 33.0670433 33.07024765 33.07630539 33.0733223 33.07543564 33.06895828 33.07326126 33.07027435 33.0937767 33.08369446 33.07189178 33.06837845 33.08015442 33.08007431 33.06345367 33.06674957 33.07057953 

-------
======================
selected experts : 7, 8, 14, 16, 25, 46, 
layer26_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df27d4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-2.04064 -0.314795 -1.400310.827417 1.52577 -2.1098 -1.85683 1.97067 0.542728]

layer26_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddd52130>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.393023 -0.490994 0.2651620.973054 1.25395 -4.51099 -1.72057 1.69437 1.44958]

layer27_wq's input 
<N9nntrainer6TensorE at 0x5682de328070>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349417 -0.31544 0.1772360.634612 0.874767 -3.0591 -1.11655 1.13253 0.978322]
==============================
layer27_wq's output 
<N9nntrainer6TensorE at 0x5682ddefef30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.47915 2.14073 0.8226340.55384 1.33991 0.998374 -1.32992 1.91716 -1.1047]
============================
layer27_wk's input 
<N9nntrainer6TensorE at 0x5682de1e5e50>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349417 -0.31544 0.1772360.634612 0.874767 -3.0591 -1.11655 1.13253 0.978322]
==============================
layer27_wk's output 
<N9nntrainer6TensorE at 0x5682ddfc8350>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.56288 2.69319 1.58043-0.311879 0.972928 0.535231 -0.916197 0.858185 0.225043]
============================
layer27_wv's input 
<N9nntrainer6TensorE at 0x5682de7969c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.349417 -0.31544 0.1772360.634612 0.874767 -3.0591 -1.11655 1.13253 0.978322]
==============================
layer27_wv's output 
<N9nntrainer6TensorE at 0x5682de46fef0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.39497 -3.06129 2.057072.83891 -0.841989 -0.0350844 -3.97103 0.705508 2.87695]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.90273 -1.77488 0.6719760.729324 1.57861 -0.547807 2.27768 0.506317 1.50292]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0550020
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer27_attention_out's input 
<N9nntrainer6TensorE at 0x5682de426170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer27_attention_out's output 
<N9nntrainer6TensorE at 0x5682de0d2950>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer27_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de6e6390>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.393023 -0.490994 0.2651620.973054 1.25395 -4.51099 -1.72057 1.69437 1.44958]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.326462 -0.396689 0.2116510.776689 1.03751 -3.74703 -1.40127 1.35244 1.15235]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4075613916 -1.537694812 -1.079890847 -1.658623457 -0.7141698599 -0.2288180739 -0.1915958375 -0.421092689 -0.3735206723 -1.561541319 -1.216026425 -0.9826565981 -0.783592999 0.02853864431 0.3969347179 -0.001903982367 1.232006073 -0.5751284957 -2.305074215 -1.735985398 1.168386698 -1.215337038 -1.044820428 -1.323595166 -1.625537992 -1.10840559 1.333244324 -0.7492160201 -0.4535664916 -1.268533945 -0.9302008152 1.042670369 -0.133242324 -0.2272001654 -0.9168794751 2.142210484 0.3906172514 0.3940891325 -0.1735385656 -0.6589808464 -1.141647696 -1.435662866 -0.8268273473 0.4714540839 -1.632031679 -0.6181524992 -0.7313773632 -0.7323353291 -0.3073841035 -1.545512915 0.5358894467 0.81878829 1.656416535 -0.4525648057 -0.9500568509 -0.5141102672 -0.7638406754 -0.1650416851 0.7898381948 -0.04235753417 0.6157683134 -1.09482491 -0.0324466154 0.3313139081 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.02213611454 0.003164370079 0.005001602229 0.00280393986 0.007210072596 0.01171453949 0.01215879992 0.009665436111 0.01013635378 0.003089804202 0.0043650195 0.005512358155 0.006726507097 0.01515283622 0.02190212719 0.01469849329 0.05048392713 0.008285610937 0.001468989532 0.002595200436 0.04737220705 0.004368029069 0.005180122331 0.003919851966 0.00289826165 0.004860996269 0.05586250126 0.006961764302 0.009356603958 0.004141735844 0.00580923073 0.04177588969 0.01288941782 0.01173350867 0.005887135863 0.125443995 0.02176419646 0.02183989063 0.01238034666 0.007619175594 0.004702062346 0.003504283959 0.006441887934 0.02359661087 0.002879502019 0.007936690003 0.007087067235 0.007080281153 0.010829404 0.003139727516 0.02516711876 0.03339603916 0.07717422396 0.009365982376 0.005695020314 0.00880692713 0.006860691588 0.0124859903 0.0324430801 0.01411575451 0.0272599142 0.004927462433 0.01425634976 0.02051103115 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
31.51359177 31.49461937 31.49645615 31.49473572 31.49723434 31.50126266 31.5045681 31.50064278 31.50111389 31.49502182 31.49629784 31.4955368 31.49675179 31.50708389 31.51288033 31.5047226 31.54193878 31.49640274 31.49340057 31.48356056 31.53930473 31.49629974 31.49711227 31.49203682 31.49340057 31.49631691 31.5473175 31.49603271 31.50128937 31.49225807 31.4977417 31.5327549 31.50434494 31.50318909 31.49543571 31.61689949 31.50845146 31.50804901 31.50478935 31.49907494 31.49663353 31.49543571 31.49694252 31.51552773 31.49528885 31.49891472 31.48805237 31.49853516 31.50323868 31.49507141 31.51709938 31.52485085 31.56863022 31.49938965 31.49715042 31.49740028 31.49879265 31.50298691 31.52437592 31.5060482 31.51919174 31.49638176 31.50618744 31.51196671 

-------
======================
selected experts : 16, 20, 26, 31, 35, 52, 
layer27_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df2fed10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-4.31966 -0.122392 6.770020.867754 -0.695816 2.88133 1.86454 -0.848765 -0.0286945]

layer27_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de4dbd00>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-3.92664 -0.613386 7.035181.84081 0.55813 -1.62966 0.143973 0.845604 1.42089]

(269) layer0_wq's input 
<N9nntrainer6TensorE at 0x5682dde663b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00533584 -0.00181849 0.03675270.05615 -0.0456777 -0.00173874 -0.0301168 -0.0278517 0.0253552]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5682de7965e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.340285 -1.96606 1.93697-0.305517 1.33136 1.26645 -0.936659 -1.37615 1.32085]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5682ddd56d10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00533584 -0.00181849 0.03675270.05615 -0.0456777 -0.00173874 -0.0301168 -0.0278517 0.0253552]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5682de0a36b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.36719 -0.829909 0.716176-1.44964 1.40511 -0.75517 -2.5288 0.252318 1.2568]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5682e0a65b00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00533584 -0.00181849 0.03675270.05615 -0.0456777 -0.00173874 -0.0301168 -0.0278517 0.0253552]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5682dde490d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.077627 -0.0288866 -0.01865970.0186231 -0.0536395 0.0625538 0.0203159 -0.044671 0.0258807]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.12029 1.6511 1.231281.52615 1.65486 0.79866 -1.50271 0.716227 -1.00599]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a25a0520
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer0_attention_out's input 
<N9nntrainer6TensorE at 0x5682e0a64030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer0_attention_out's output 
<N9nntrainer6TensorE at 0x5682e0a638e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer0_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dde13420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0038867 -0.00129557 0.03109360.0414581 -0.029798 -0.00129557 -0.0207291 -0.0233202 0.0220246]

layer0_ffn_gate's input 
<N9nntrainer6TensorE at 0x5682ddfb82c0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0238318 -0.00788014 0.1860610.239914 -0.180509 -0.00730588 -0.126082 -0.140694 0.129624]
==============================
layer0_ffn_gate's output 
<N9nntrainer6TensorE at 0x5682dde852c0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.0094283 -0.0215598 -0.05527670.0783745 -0.00284603 0.0299465 0.149653 0.102264 0.0322584]
============================
layer0_ffn_up's input 
<N9nntrainer6TensorE at 0x5682de34f990>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0238318 -0.00788014 0.1860610.239914 -0.180509 -0.00730588 -0.126082 -0.140694 0.129624]
==============================
layer0_ffn_up's output 
<N9nntrainer6TensorE at 0x5682dde690c0>
data addr: 0x7fc0a7fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.0954491 0.0131496 -0.09047790.163799 -0.131224 -0.0671627 -0.091035 -0.367695 0.0737123]
============================
layer0_ffn_down's input 
<N9nntrainer6TensorE at 0x5682dc3e1140>
data addr: 0x7fc0aafd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[0.00044784 -0.000140224 0.002431570.00667022 0.000186468 -0.0010207 -0.00732061 -0.0197615 0.00120809]
==============================
layer0_ffn_down's output 
<N9nntrainer6TensorE at 0x5682dc3e0770>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.530313 -0.039013 0.00509636-0.0215666 0.0196059 -0.013654 -0.0333485 0.135026 -0.0696264]
============================
layer0_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3e1bb0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.5342 -0.0403086 0.036190.0198915 -0.0101922 -0.0149496 -0.0540776 0.111705 -0.0476018]

layer1_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e48b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.770854 -0.0559952 0.04267420.0306314 -0.0110854 -0.0144084 -0.0710461 0.123901 -0.0758662]
==============================
layer1_wq's output 
<N9nntrainer6TensorE at 0x5682dc3e2330>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.05036 0.665655 0.332401-0.370155 1.02647 0.764256 -1.18285 2.57484 0.0606972]
============================
layer1_wk's input 
<N9nntrainer6TensorE at 0x5682dc3e6610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.770854 -0.0559952 0.04267420.0306314 -0.0110854 -0.0144084 -0.0710461 0.123901 -0.0758662]
==============================
layer1_wk's output 
<N9nntrainer6TensorE at 0x5682dc3e6380>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.24526 1.03814 0.9174490.701469 1.23946 1.46682 -2.86744 -0.60461 1.33113]
============================
layer1_wv's input 
<N9nntrainer6TensorE at 0x5682dc3e7400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.770854 -0.0559952 0.04267420.0306314 -0.0110854 -0.0144084 -0.0710461 0.123901 -0.0758662]
==============================
layer1_wv's output 
<N9nntrainer6TensorE at 0x5682dc3e7190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.204227 0.0149028 0.0230723-0.0187487 0.161088 0.184685 0.0454985 -0.0533836 0.0407351]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.682684 -1.03937 0.4866440.103361 1.211 0.413758 2.36474 1.56107 -0.923159]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a34c5d98
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer1_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ea340>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer1_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ea2a0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer1_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3eb440>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.5342 -0.0403086 0.036190.0198915 -0.0101922 -0.0149496 -0.0540776 0.111705 -0.0476018]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.716204 -0.16842 0.1441960.0981063 -0.041488 -0.076952 -0.269044 0.52688 -0.153783]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4938856959 0.2744270563 -0.8380575776 2.652425766 0.3581895828 -0.3603386879 3.49582696 1.066620708 -0.07572924346 -1.366705418 -0.1647537351 -0.2697153091 -0.2739833891 -0.2273011953 -0.28377226 0.4387896359 0.1971707344 -0.6836133599 0.8687351942 -0.1118115112 -0.08855776489 -0.276751399 0.3082902133 0.1831746846 -0.3872572482 0.157389462 -0.6663765907 1.623328567 -0.928239882 0.9732655883 -0.4263276458 0.08605601639 -0.7634534836 -0.237398982 -0.7045798898 0.2429447472 0.01626846194 -0.9829031825 -0.3773329854 -0.6508309245 -0.7802859545 -0.2845839858 -0.4929048717 -0.319824338 0.4986183345 0.105902642 1.925558448 -0.3053503633 -0.413780421 -0.5639892817 -0.4926785231 -0.9096289873 -0.9575096369 0.2258247584 -0.4971837699 0.3114612699 0.9630727768 -0.1422177702 -0.2463431656 0.2854246497 -0.7421780825 -0.7862241864 -0.3267106712 -0.7311197519 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005316769239 0.01146362349 0.003768563503 0.1236156747 0.01246520597 0.006076402962 0.2873148322 0.02531437017 0.0080770161 0.002221196424 0.007389040664 0.006652789656 0.006624455098 0.00694103213 0.006559926085 0.01351150032 0.01061133016 0.004397948273 0.02076952346 0.007790774107 0.007974061184 0.006606145296 0.01185846422 0.01046384685 0.005915016402 0.01019748393 0.004474411253 0.04417151585 0.003443579888 0.0230581034 0.005688371137 0.009495400824 0.004060468171 0.006871296093 0.004306698218 0.01110834163 0.008855334483 0.003260395024 0.005974011496 0.0045445133 0.00399269117 0.006554603111 0.005321986508 0.006327638868 0.01434454881 0.00968573615 0.05975841358 0.006419891957 0.005760194268 0.004956808873 0.00532319257 0.003508268157 0.003344248049 0.01091978699 0.005299263634 0.01189612597 0.02282426693 0.007557449397 0.006810111459 0.01159039047 0.004147780593 0.003969052806 0.006284215022 0.004193902947 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
62.86138916 62.86658096 62.85984039 62.97777939 62.86663055 62.86119461 63.14243317 62.88043213 62.86319351 62.85733795 62.86250687 62.86177063 62.86174393 62.86206055 62.86167908 62.86672211 62.86573029 62.85951614 62.87588882 62.86290741 62.86309052 62.86172485 62.86220932 62.86653519 62.86103439 62.86531448 62.85959244 62.90024185 62.85665512 62.87722397 62.86175919 62.86461258 62.86013031 62.86198807 62.86037827 62.8662262 62.86397171 62.85647202 62.86109161 62.8596611 62.85911179 62.86262512 62.85853195 62.86144638 62.86946106 62.86480331 62.91296768 62.86153793 62.85992432 62.86007309 62.8604393 62.85862732 62.85846329 62.86603928 62.86041641 62.86605835 62.87698746 62.86267471 62.86192703 62.86670685 62.85926437 62.85908508 62.8614006 62.85931015 

-------
======================
selected experts : 3, 6, 7, 27, 29, 46, 
layer1_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e0a3ef10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.121317 -0.0599546 0.0436244-0.0415144 -0.0689801 -0.0147215 0.0202303 0.024195 -0.0197212]

layer1_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3ee080>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.655517 -0.100263 0.0798143-0.0216228 -0.0791723 -0.0296711 -0.0338473 0.1359 -0.067323]

layer2_wq's input 
<N9nntrainer6TensorE at 0x5682dc3ee2c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.50176 -0.286059 0.204058-0.0689026 -0.180415 -0.0945488 -0.100959 0.385217 -0.1821]
==============================
layer2_wq's output 
<N9nntrainer6TensorE at 0x5682dc3ee260>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0462497 0.124748 -0.389427-0.181901 0.158622 0.0341469 -0.150277 0.784759 -0.579801]
============================
layer2_wk's input 
<N9nntrainer6TensorE at 0x5682dc3edf00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.50176 -0.286059 0.204058-0.0689026 -0.180415 -0.0945488 -0.100959 0.385217 -0.1821]
==============================
layer2_wk's output 
<N9nntrainer6TensorE at 0x5682dc3ede70>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.66199 -0.380247 1.43585-1.95493 -2.02044 -0.628309 -0.453666 1.36711 -1.76648]
============================
layer2_wv's input 
<N9nntrainer6TensorE at 0x5682dc3ee380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.50176 -0.286059 0.204058-0.0689026 -0.180415 -0.0945488 -0.100959 0.385217 -0.1821]
==============================
layer2_wv's output 
<N9nntrainer6TensorE at 0x5682dc3ee3b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.16022 -0.046587 -0.08186970.00729331 -0.0579034 -0.106257 0.0585689 0.194708 -0.107775]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00927144 -0.132722 -0.0366806-0.428247 0.161465 -0.0159946 0.752732 0.268001 0.702956]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0857c38
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer2_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ee500>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer2_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ee620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer2_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3fefb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.655517 -0.100263 0.0798143-0.0216228 -0.0791723 -0.0296711 -0.0338473 0.1359 -0.067323]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.11729 -0.397511 0.30313-0.0929383 -0.305092 -0.12973 -0.144227 0.571532 -0.230743]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.0007239356637 0.3967224956 0.7473183274 -0.3814888 0.7392625213 2.840141058 -0.4369773269 -0.6523282528 -0.7334950566 -0.2333211303 -0.191916123 -0.6012032032 0.9653558731 -0.3224940598 -0.4581566751 0.1935741156 -0.4096742272 -0.1640245169 -0.3989120722 -0.2542994618 -0.9824817777 -0.9129154682 0.01834851131 -0.004838172346 0.2320720404 0.01329177432 2.106049538 0.08493182063 -1.030921578 -0.05433372408 -0.05983022228 0.237671569 -0.1196894795 -0.01123329997 -0.4972101152 -0.2299947292 -0.4662125707 -0.7897862792 0.09493773431 -0.4111535251 -0.7961652279 -0.4509711862 -0.003034375608 0.7694603801 0.5840034485 0.7430487871 -0.3115803897 -0.389572531 -0.2015502304 0.1198345572 -0.7311477661 -0.4564379752 0.1348663867 1.469751716 0.6477128863 0.1367376447 0.4490277767 -0.4847815335 0.4408440888 -0.5562569499 -1.426332355 -0.4745022058 -0.273398757 -0.3905330002 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01132527925 0.01685224101 0.02392871864 0.007738999091 0.02373673022 0.1940085441 0.007321269251 0.005902835634 0.005442650523 0.008974973112 0.009354382753 0.006212466396 0.02975856699 0.008209295571 0.007167841308 0.01375407632 0.007523918059 0.009618964046 0.007605327293 0.008788655512 0.004243037663 0.004548719153 0.01154335123 0.01127877831 0.01429390535 0.01148512773 0.09311270714 0.01233811118 0.004042403307 0.01073411945 0.01067528129 0.01437416859 0.01005501579 0.01120687928 0.006893307902 0.009004876949 0.007110329345 0.005144739989 0.01246218476 0.007512794808 0.005112026352 0.007219531108 0.01129914168 0.02446446382 0.02032322995 0.02382677607 0.008299378678 0.007676690351 0.009264694527 0.01277634967 0.005455440376 0.00718016969 0.01296985243 0.04927973077 0.0216601491 0.01299414318 0.01775716059 0.006979516242 0.01761243492 0.006498062517 0.002722168807 0.007051630411 0.008622392081 0.007669321261 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
53.42508698 53.43061447 53.43769073 53.42150116 53.43749619 53.60586166 53.42108154 53.41966248 53.41920471 53.42273712 53.42311478 53.41711426 53.44351959 53.42197037 53.42092896 53.42751694 53.42033005 53.42338181 53.42136765 53.42159653 53.41800308 53.41640091 53.42530441 53.42408752 53.42805481 53.42524719 53.50592041 53.42609787 53.41780472 53.4244957 53.42443466 53.42813492 53.42381668 53.42496872 53.4206543 53.42276764 53.42087173 53.41795349 53.42622375 53.42127228 53.41887283 53.42098236 53.42506027 53.43822479 53.43408585 53.43758774 53.42206192 53.42143631 53.42016602 53.42653656 53.41921616 53.41903305 53.42673111 53.4630394 53.43446732  53.426754 53.43151855 53.42074203 53.43041992 53.42025757 53.41553116 53.41986084 53.42238235 53.42142868 

-------
======================
selected experts : 2, 5, 12, 26, 43, 53, 
layer2_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e09f8dd0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.108269 0.067201 0.00380213-0.0592974 -0.0135828 0.000535565 -0.0324741 0.0812852 -0.0584557]

layer2_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc401970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.763786 -0.0330622 0.0836164-0.0809202 -0.0927551 -0.0291355 -0.0663213 0.217186 -0.125779]

layer3_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e86c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.46605 -0.0902244 0.21921-0.200976 -0.213305 -0.0674484 -0.160651 0.52609 -0.383736]
==============================
layer3_wq's output 
<N9nntrainer6TensorE at 0x5682dc409160>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.707984 0.0854658 1.18397-0.202544 -0.690064 0.887325 -0.748177 -0.459255 0.0479311]
============================
layer3_wk's input 
<N9nntrainer6TensorE at 0x5682dc41f6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.46605 -0.0902244 0.21921-0.200976 -0.213305 -0.0674484 -0.160651 0.52609 -0.383736]
==============================
layer3_wk's output 
<N9nntrainer6TensorE at 0x5682dc41f440>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.97 -0.264283 1.824420.813446 -1.20373 0.686917 -0.606336 1.37327 0.799509]
============================
layer3_wv's input 
<N9nntrainer6TensorE at 0x5682dc4204c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.46605 -0.0902244 0.21921-0.200976 -0.213305 -0.0674484 -0.160651 0.52609 -0.383736]
==============================
layer3_wv's output 
<N9nntrainer6TensorE at 0x5682dc420250>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.081883 -0.2498 -0.0316294-0.00160729 0.140572 -0.270699 -0.00854238 0.0444744 -0.062748]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.680288 0.213903 0.7663090.924973 -0.385668 1.05584 -0.567808 0.669536 0.873531]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a167aca8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer3_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc422910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer3_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc422870>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer3_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc423990>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.763786 -0.0330622 0.0836164-0.0809202 -0.0927551 -0.0291355 -0.0663213 0.217186 -0.125779]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.31148 -0.12013 0.29228-0.31511 -0.327068 -0.11435 -0.255211 0.809113 -0.399162]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.1962377876 -0.103987515 0.4357120097 -0.2954514623 0.2231798172 -0.8020195365 -0.6774917245 1.119437695 -0.9338757396 -0.6962167621 1.503954053 0.1658852398 0.7134883404 -0.01098105684 -0.6858609319 -0.7453010082 -0.1625581384 -0.6343906522 -1.371559501 0.3677153885 -0.8660032153 -0.2938483655 1.433504224 -0.2337851226 -0.5885555148 -0.6060359478 -0.2926838398 0.1693664789 -0.3851058781 -0.1493725628 1.251326323 -0.4069331884 -0.1012405455 -0.1888886988 1.836473346 -0.4836421609 0.4375371933 -0.6476139426 0.1758795381 0.1851105392 -0.6089960337 -0.9272542596 0.03914502636 -0.680539012 0.02375158295 -0.6262216568 0.02406140417 0.4593750536 -0.180501461 -0.2702381611 -0.5046441555 -0.7031311989 -1.169670343 -0.161546275 -0.02932170779 -0.1969992369 -0.2860062122 -0.623481214 -0.6204127073 0.712192893 1.42602241 -0.7648400664 -0.6141082644 -0.7594501376 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01130137499 0.01239352953 0.02126099169 0.01023394894 0.01719024219 0.006166568957 0.00698433863 0.04212324694 0.005404794123 0.006854773965 0.06187498942 0.01623301767 0.02806856856 0.01360151265 0.006926128641 0.006526436657 0.01168848109 0.007291952148 0.003488956019 0.01986337081 0.005784366746 0.01025036909 0.05766591802 0.01088490617 0.007633958943 0.00750167435 0.01026231423 0.01628962718 0.009356358089 0.01184362173 0.04806183279 0.009154347703 0.01242762152 0.01138473488 0.08628324419 0.008478383534 0.02129983343 0.007196164224 0.0163960699 0.01654812135 0.007479500491 0.005440699868 0.01430067979 0.006963088177 0.0140822297 0.007351764012 0.01408659294 0.02177009173 0.01148062106 0.01049526315 0.008302179165 0.006807539612 0.004269479308 0.01170031633 0.0133543266 0.01129277237 0.01033107098 0.007371940184 0.007394595072 0.02803223021 0.05723607913 0.006400153972 0.007441361435 0.006434743758 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
42.54652405 42.54380035 42.55648041 42.54545593 42.55145645 42.54138947 42.53839111 42.57829666 42.54062653 42.54302979 42.59614182 42.55145264 42.56042862 42.54882431 42.54214859 42.54174805 42.54690933 42.54156113 42.53966522 42.55317688 42.54100418 42.54642487 42.59384155 42.54610443 42.54285431 42.54272461 42.54548264 42.55150986 42.54457855 42.54706573 42.58328247 42.54437637 42.54478836 42.54660416 42.62150574 42.54370117 42.55652237 42.54241562 42.55161667 42.55176926 42.54270172 42.54066086 42.55047607 42.54218292 42.54739761 42.54257202 42.54930878 42.55699158 42.54765701 42.54571533 42.54447556 42.54203033 42.53853607 42.54692078 42.54857635 42.54555893 42.5455513 42.54354858 42.54166031 42.5594368 42.59245682 42.54162216 42.54266357 42.54165649 

-------
======================
selected experts : 7, 10, 22, 30, 34, 60, 
layer3_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc426710>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141647 -0.00445617 0.00815817-0.0470299 0.0815447 -0.00950901 -0.0401189 -0.0316625 0.0468293]

layer3_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc426050>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.905433 -0.0375184 0.0917746-0.12795 -0.0112103 -0.0386445 -0.10644 0.185523 -0.0789494]

layer4_wq's input 
<N9nntrainer6TensorE at 0x5682dc44b9a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25242 -0.106134 0.255702-0.381958 -0.028047 -0.116461 -0.308668 0.556463 -0.233436]
==============================
layer4_wq's output 
<N9nntrainer6TensorE at 0x5682dc492890>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.030635 1.00211 -0.774273-0.0781808 0.867989 0.037558 0.177326 0.147243 -0.0249077]
============================
layer4_wk's input 
<N9nntrainer6TensorE at 0x5682dc44d700>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25242 -0.106134 0.255702-0.381958 -0.028047 -0.116461 -0.308668 0.556463 -0.233436]
==============================
layer4_wk's output 
<N9nntrainer6TensorE at 0x5682dc44d470>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.249979 -0.474866 0.5057910.318708 -0.907339 -0.236762 -0.611483 -0.579829 0.15471]
============================
layer4_wv's input 
<N9nntrainer6TensorE at 0x5682dc44e4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.25242 -0.106134 0.255702-0.381958 -0.028047 -0.116461 -0.308668 0.556463 -0.233436]
==============================
layer4_wv's output 
<N9nntrainer6TensorE at 0x5682dc44e280>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.39199 -0.576836 -0.292241-0.205637 0.461115 -0.0912468 -0.0864808 0.0981705 -0.163482]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.440902 -0.900431 -0.318598-0.710004 0.837895 -0.229668 0.172523 -0.152842 0.430208]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1e8ece8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer4_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc450940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer4_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4508a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer4_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4519c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.905433 -0.0375184 0.0917746-0.12795 -0.0112103 -0.0386445 -0.10644 0.185523 -0.0789494]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.63462 -0.1408 0.330064-0.509277 -0.0420705 -0.156013 -0.432741 0.717336 -0.268227]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.9344680309 -0.1224616915 0.7122747302 -0.879663825 -1.050984979 -0.7712023854 -0.3001823127 0.3099183738 0.6146305799 -0.2456123233 0.09972074628 -0.1390371174 -1.008883476 0.470620662 -1.563606739 -0.5021421313 1.683896899 -0.5823207498 -0.7483549118 -0.7811715007 -0.09415169805 -0.3758384883 -0.3066797853 -0.7935734987 -0.3613235056 -0.182633847 0.3211717308 -0.1839020997 -1.400904298 -0.5521258712 -0.7814593315 -0.6820674539 0.07244253904 -0.554870069 0.3046645224 0.4763628244 -0.2898865044 -0.5237286091 -0.3867425323 -1.036280394 -0.3734202087 -0.272709161 -0.9219664931 -0.1225607991 -0.6516411304 0.2383146882 -0.6645326018 -0.1037149951 -0.7804605365 0.3365232646 -0.5520038009 0.4484129548 3.885401487 0.1329425722 -0.8620144725 -0.3145994842 1.132389545 -0.4294472635 -0.005604511127 -0.1885679513 0.178714633 -0.5649235845 -1.028280616 -0.8051867485 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003731110599 0.008404039778 0.01936464198 0.003941298928 0.003320744028 0.004392821342 0.00703566242 0.01294995565 0.01756317541 0.007430265658 0.01049495582 0.008265887387 0.003463536967 0.01520758867 0.001988871722 0.005749033764 0.05116577074 0.005306078587 0.004494340159 0.00434924569 0.008645355701 0.006523007061 0.006990094204 0.004295639228 0.006618378684 0.007913264446 0.0130965095 0.007903233171 0.002340277657 0.005468740594 0.004347995389 0.004802354611 0.01021254156 0.005453753751 0.01288209856 0.01529516745 0.007108471822 0.005626262631 0.00645226799 0.003369935555 0.006538802292 0.007231632713 0.003778048558 0.008403205313 0.004950718954 0.01205511019 0.004887307528 0.008563072421 0.004352339078 0.01329911221 0.005469407886 0.0148735866 0.462467134 0.01084947493 0.004011476878 0.006934956182 0.02947562188 0.00618252391 0.009445792995 0.007866444066 0.0113576157 0.005399198271 0.003397002816 0.004246043041 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.82138824 40.82606125 40.8360672 40.82255173 40.82193375 40.82300568 40.82564545 40.82965469 40.83140564 40.82604218 40.8281517 40.82687759 40.82207489 40.83286667 40.8205986 40.82435989 40.86787033 40.82201004 40.82310486 40.8229599 40.82630157 40.82513428 40.82273865 40.82099915 40.82427597 40.82652283 40.82884598 40.82460785 40.82094955 40.82408142 40.8229599 40.82341385 40.82882309 40.82406616 40.83149338 40.83200073 40.8228569 40.8213768 40.8250618 40.82007217 40.82419586 40.82584381 40.8223877 40.82606125 40.82356262 40.82685089 40.82349777 40.82622147 40.82201004 40.82427979 40.82312775 40.83062363 41.28107834 40.82850647 40.82167053 40.82554626 40.84808731 40.82479477 40.82519531 40.82647705 40.8299675 40.82400894 40.82201004 40.8228569 

-------
======================
selected experts : 2, 8, 16, 35, 52, 56, 
layer4_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc454a40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.120465 -0.0358364 -0.05859290.166895 0.0969606 0.00967123 -0.031883 -0.0466452 0.0645548]

layer4_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc454380>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.0259 -0.0733548 0.03318170.0389447 0.0857503 -0.0289733 -0.138323 0.138878 -0.0143946]

layer5_wq's input 
<N9nntrainer6TensorE at 0x5682dc4a0910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.91652 -0.18809 0.0753580.0946279 0.174852 -0.0746445 -0.342854 0.364577 -0.0351518]
==============================
layer5_wq's output 
<N9nntrainer6TensorE at 0x5682dc454560>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.663014 -1.19488 -0.8537191.46899 -1.12072 -0.569173 1.06715 0.145476 -1.55287]
============================
layer5_wk's input 
<N9nntrainer6TensorE at 0x5682dc4a2670>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.91652 -0.18809 0.0753580.0946279 0.174852 -0.0746445 -0.342854 0.364577 -0.0351518]
==============================
layer5_wk's output 
<N9nntrainer6TensorE at 0x5682dc4a23e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.19873 0.192916 -1.6543-0.510519 0.482255 -1.19605 0.612818 0.82119 -1.07766]
============================
layer5_wv's input 
<N9nntrainer6TensorE at 0x5682dc4a3460>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.91652 -0.18809 0.0753580.0946279 0.174852 -0.0746445 -0.342854 0.364577 -0.0351518]
==============================
layer5_wv's output 
<N9nntrainer6TensorE at 0x5682dc4a31f0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.155008 0.274099 0.359369-0.512762 -0.0739251 -0.105005 0.0591907 0.0220726 0.146967]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.111659 1.36194 -1.69904-0.00683852 -1.24109 -0.199196 0.306249 -1.03256 1.65032]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1c89cd8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer5_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc4a58b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer5_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4a5810>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer5_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a6930>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.0259 -0.0733548 0.03318170.0389447 0.0857503 -0.0289733 -0.138323 0.138878 -0.0143946]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.77873 -0.254369 0.1102010.143606 0.282694 -0.10613 -0.506681 0.498538 -0.0456973]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3291094005 -1.067005634 -0.2928633988 -0.1757128835 -1.373118639 0.4114755392 0.2584048212 -0.2752860188 -1.167376161 -1.057608366 -0.8374167085 0.9554618001 -0.2741447389 0.1757035106 -0.9989030957 -0.576164782 -0.8192147017 2.311264992 -1.016098022 -1.270412564 1.849908113 -1.933212638 -2.491990566 -0.2602374554 -0.3482982516 -0.05025612563 -0.3480886519 -0.7141461372 -1.404352665 -1.230741978 -0.6166434288 -0.3129088879 0.2098553181 -1.20407033 -0.556591928 -0.04374771565 -1.015693903 -0.8262186646 -0.04862868041 0.3627088964 -0.01372391731 -0.4134725928 -0.2538684905 -0.03223772347 0.5227943659 -0.1476397663 -0.6841863394 -1.285633087 -1.073455691 -0.1691674292 -1.354353428 -1.352234244 0.2500188053 -0.3856589496 0.6190481186 1.555152297 -1.104683876 -1.076963305 -0.0127296634 -0.9971109629 -0.788003087 -0.2736488283 -0.186482653 -0.8268713355 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01124760229 0.005377688911 0.01166276168 0.01311231125 0.003959611058 0.02358804271 0.02024016716 0.01186957583 0.004864132497 0.005428462755 0.006765577942 0.04063891247 0.01188312937 0.01863362826 0.005756682716 0.008785473183 0.006889851298 0.1576739699 0.005658542272 0.004387905356 0.09940202534 0.002261552727 0.001293399138 0.01204954553 0.01103383023 0.01486498397 0.01103614364 0.007653156761 0.003837847617 0.004565474112 0.008436950855 0.01143130288 0.01928099059 0.004688881338 0.008959123865 0.01496204641 0.0056608296 0.006841765717 0.01488919556 0.02246533148 0.01541807503 0.01033764146 0.01212653238 0.01513525192 0.02636556327 0.01348562911 0.007885912433 0.004321624059 0.005343114026 0.01319841668 0.004034615587 0.004043173976 0.02007114515 0.01062920503 0.02902949974 0.07402602583 0.00517883664 0.005324405152 0.01543341111 0.005767008755 0.007108287886 0.01188902464 0.01297185197 0.006837300025 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.24911499 33.24515533 33.25334549 33.25479507 33.24373627 33.26145554 33.26192474 33.24687958 33.24559402 33.24711227 33.24749756 33.28136826 33.25356674 33.25745773 33.24744034 33.25046921 33.2485733 33.39077377 33.24734116 33.24607086 33.3315506 33.24394608 33.24297714 33.25373459 33.24794769 33.25654984 33.25271988 33.24933624 33.24552155 33.24529648 33.25012207 33.25120926 33.25524139 33.24637222 33.25064468 33.25569153 33.24734497 33.24852753 33.25275803 33.26128769 33.25710297 33.25202179 33.25285721 33.25682068 33.2661438 33.25516891 33.24956894 33.24505234 33.24607468 33.25488281 33.24381256 33.24572754 33.2579422 33.25135803 33.26785278 33.31189346 33.24686432 33.24224091 33.25711823 33.24745178 33.24879074  33.248806 33.25274658 33.24184418 

-------
======================
selected experts : 11, 17, 20, 44, 54, 55, 
layer5_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc4a9a10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.147336 -0.141224 0.01327730.0567547 0.0745959 0.013839 0.0319384 -0.0718612 -0.0475456]

layer5_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a9350>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.17323 -0.214579 0.0464590.0956994 0.160346 -0.0151342 -0.106385 0.0670166 -0.0619403]

layer6_wq's input 
<N9nntrainer6TensorE at 0x5682dc4e8620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.77169 -0.724071 0.1546520.329472 0.46064 -0.0486533 -0.332302 0.20322 -0.189239]
==============================
layer6_wq's output 
<N9nntrainer6TensorE at 0x5682dc4a9530>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0864339 -0.612978 -0.835630.900747 -0.667181 -0.993839 0.76025 0.722293 -1.56412]
============================
layer6_wk's input 
<N9nntrainer6TensorE at 0x5682dc4ea380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.77169 -0.724071 0.1546520.329472 0.46064 -0.0486533 -0.332302 0.20322 -0.189239]
==============================
layer6_wk's output 
<N9nntrainer6TensorE at 0x5682dc4ea0f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.11929 -0.10324 -0.009236750.557981 0.238305 -1.40537 0.128687 -0.405944 0.023759]
============================
layer6_wv's input 
<N9nntrainer6TensorE at 0x5682dc4eb170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.77169 -0.724071 0.1546520.329472 0.46064 -0.0486533 -0.332302 0.20322 -0.189239]
==============================
layer6_wv's output 
<N9nntrainer6TensorE at 0x5682dc4eaf00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.271435 -0.148165 0.352868-0.367987 0.232461 -0.637829 -0.47838 -0.252549 0.428962]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.173867 0.594123 -1.19756-0.274707 -0.939133 -0.742211 0.829618 -0.641421 1.26432]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1a84cc8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer6_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc41beb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer6_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc41be10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer6_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc41cf30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.17323 -0.214579 0.0464590.0956994 0.160346 -0.0151342 -0.106385 0.0670166 -0.0619403]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.88585 -0.74364 0.1557110.344746 0.533758 -0.0555545 -0.390516 0.239891 -0.199125]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4638691545 -0.7094838023 0.1943017393 -0.2551833391 -0.4816714525 0.08862743527 -1.246662021 -0.6691928506 -0.4370101988 -0.5953332186 -0.5229797363 0.4946106672 -1.15014708 0.185185194 0.7983567119 -0.8995850682 -0.8456157446 -1.121740341 -0.3646734655 -0.4495363235 -0.2456588447 0.5531499386 -1.047222018 -0.5409777164 -0.8014068604 -0.2398983538 -0.4034435749 -0.6143152714 -1.069929123 -0.6744322777 0.4236513376 2.86834383 -0.04825428128 0.4091398716 -0.129275769 -0.394715786 0.06413892657 -0.7999017835 -1.228420734 -0.2379585207 -1.191629887 -0.4292249382 -0.2913487256 0.1080761105 0.006064817309 -0.5773868561 0.6052529216 -1.192215562 -0.08549895883 -0.3021603227 -0.3416296244 -0.9069536924 -1.036425352 -1.180878758 -1.012220144 0.3234274983 -0.7495288253 -0.5062260628 0.5414540172 0.2662356794 -0.7921816111 1.482537866 0.05718161911 0.3893421292 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.02210799232 0.006838622037 0.01688409224 0.01077131834 0.008588282391 0.01519091334 0.003996456042 0.0071197832 0.008980538696 0.007665555924 0.008240742609 0.02279818431 0.004401402082 0.01673086733 0.0308898259 0.005654688459 0.005968253128 0.004528223537 0.009654235095 0.008868749253 0.01087439805 0.02417260781 0.004878549371 0.008093751967 0.006238022354 0.01093722042 0.009287101217 0.00752141932 0.004769020714 0.007082577329 0.02123649791 0.2447932363 0.01324759237 0.02093055286 0.01221658289 0.009368512779 0.01482342929 0.006247418467 0.004070025869 0.01095845923 0.004222554155 0.009050727822 0.01038872823 0.01548924856 0.01398709323 0.007804365829 0.02546546049 0.004220082425 0.01276326459 0.01027701516 0.009879290126 0.005613173824 0.004931507632 0.004268196877 0.005052331835 0.01921127737 0.006570179947 0.008379967883 0.02389153279 0.0181433782 0.006295836996 0.06122820452 0.01472065598 0.02052024938 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.14548874 40.13022232 40.13263702 40.13415527 40.13196945 40.13857269 40.12833405 40.13050079 40.13236237 40.1310463 40.13162231 40.14331818 40.12778473 40.13916016 40.15427399 40.12903595 40.12935257 40.12791061 40.13303757 40.13225174 40.13425827 40.1475563 40.12826157 40.13147736 40.1296196 40.13431931 40.13362503 40.13090515 40.12815094 40.13046646 40.14175797 40.36722183 40.13663101 40.14431381 40.13560104 40.13275146 40.13820648 40.12963104 40.12745285 40.13434219 40.12760544 40.13243484 40.13281631 40.13887024 40.13737106 40.13214111 40.14789581 40.12760162 40.13519287 40.13365936 40.13326263 40.12899399 40.12831497 40.12765121 40.1255722 40.14259338 40.1289978 40.13176346 40.14536667 40.14152527 40.12967682 40.18175125 40.13810349 40.14390182 

-------
======================
selected experts : 14, 21, 31, 46, 58, 61, 
layer6_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc47b4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0381875 0.16281 -0.0595574-0.0959639 -0.0746384 -0.10199 0.129345 0.000853485 -0.0417668]

layer6_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc47ae20>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21142 -0.0517691 -0.0130984-0.000264518 0.0857079 -0.117124 0.0229602 0.0678701 -0.103707]

layer7_wq's input 
<N9nntrainer6TensorE at 0x5682dc5555c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.06715 -0.156838 -0.037982-0.000744136 0.224419 -0.319354 0.0645911 0.178447 -0.305212]
==============================
layer7_wq's output 
<N9nntrainer6TensorE at 0x5682dc47b000>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.903018 0.200069 1.34658-0.212974 0.689655 0.979595 0.824704 0.675663 0.359885]
============================
layer7_wk's input 
<N9nntrainer6TensorE at 0x5682dc557b30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.06715 -0.156838 -0.037982-0.000744136 0.224419 -0.319354 0.0645911 0.178447 -0.305212]
==============================
layer7_wk's output 
<N9nntrainer6TensorE at 0x5682dc5578a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.66909 -0.428646 0.909704-0.847044 -0.0576201 0.999694 0.516561 1.05539 -0.210069]
============================
layer7_wv's input 
<N9nntrainer6TensorE at 0x5682dc558920>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.06715 -0.156838 -0.037982-0.000744136 0.224419 -0.319354 0.0645911 0.178447 -0.305212]
==============================
layer7_wv's output 
<N9nntrainer6TensorE at 0x5682dc5586b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.139538 0.504087 -0.0269906-0.0404803 -0.30488 0.0463377 0.531681 -0.183999 -0.504003]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.905219 0.189862 0.8564881.06069 0.956174 0.721776 0.793343 -0.712224 -0.98095]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a187fcb8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer7_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc55ad70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer7_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc55acd0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer7_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55bdf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21142 -0.0517691 -0.0130984-0.000264518 0.0857079 -0.117124 0.0229602 0.0678701 -0.103707]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.93991 -0.183725 -0.0447848-0.000973101 0.293043 -0.430874 0.0864527 0.243804 -0.345607]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.3026745021 -1.071165562 -0.3273747563 -0.3650847971 -0.2735459805 -0.6784827709 1.032438159 2.836415529 1.677007675 -1.012084246 -0.1210446581 0.1496284902 -1.072111249 -0.857732594 -0.7717418671 0.05227683112 -0.5959703326 -1.45846653 -0.6093594432 0.867061615 -1.10264802 -0.7392890453 0.1881039739 0.110251382 0.2924830019 -0.08666624129 -0.6546859741 -0.9960862994 0.6259451509 0.3693005443 0.2066856623 -0.7935817838 -0.7881087065 -0.8844150305 1.500858426 -0.2022871673 0.4411149323 -0.07829384506 -1.144552827 -0.7370305061 -0.7500447631 -0.7711327076 -0.4614872336 -0.4749506414 -1.833411813 -0.8816303015 -0.2007179558 -0.6693396568 0.4736348987 -0.004009608179 -0.3746697903 1.359379292 -1.315992475 -0.5028767586 -1.085083485 -0.9007630944 -1.366281986 -0.6700772643 -0.801158905 -0.9570243955 -1.029290915 -1.147143722 -2.838216066 -1.361460567 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01824202761 0.004617659841 0.009715076536 0.009355541319 0.01025235746 0.006838516798 0.0378447324 0.2298597097 0.07210052013 0.004898698069 0.01194137242 0.01565330476 0.004613294732 0.005716296379 0.006229598075 0.01420125738 0.007426712196 0.003134869039 0.007327937521 0.03207623214 0.004474549089 0.006435082294 0.01626730897 0.01504890248 0.0180570595 0.01235903427 0.0070032035 0.004977696575 0.02520390041 0.01949882694 0.0165724121 0.006095019169 0.006128469482 0.005565788597 0.06045577303 0.01100958697 0.02095062658 0.01246294565 0.004290917888 0.006449632347 0.006366238929 0.00623339368 0.0084957527 0.008382138796 0.002154678805 0.005581310019 0.01102687791 0.006901328918 0.02164314128 0.01342399698 0.009266297333 0.05248004198 0.003614888526 0.008151295595 0.004553837236 0.005475538317 0.003437592648 0.006896240171 0.006049010903 0.005175983068 0.004815128632 0.004279816058 0.0007888631662 0.003454208141 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
35.94260406 35.93374634 35.93789291 35.93466949 35.93747711 35.93597031 35.94981003 36.1570816 36.00027847 35.93307495 35.94107056 35.94478226 35.93374252 35.93293762 35.93535995  35.942379 35.93655777 35.93226624 35.93455124 35.96025467 35.93265152 35.93461227 35.9425354 35.94227219 35.93669891 35.93958282 35.93613434 35.93315506 35.94193649 35.94863129 35.94474792 35.93427277 35.9343071 35.9346962 35.98958588 35.9353714 35.9491272 35.93968582 35.93246841 35.93462753 35.93263626 35.93345642 35.93571854 35.93751144 35.93128586 35.93089676 35.93920517 35.93603134 35.94982147 35.9377861 35.93744278 35.97684097 35.93274689 35.93632889 35.9336853 35.9326973 35.93161392 35.93602753 35.93518066 35.9343071 35.93203735 35.93341064 35.9299202 35.93162918 

-------
======================
selected experts : 6, 7, 8, 19, 34, 51, 
layer7_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5969b0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00565025 0.0566365 0.0758908-0.164418 0.0241856 0.0410004 0.0588157 -0.00652726 0.0165999]

layer7_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55e510>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21707 0.0048674 0.0627924-0.164683 0.109893 -0.0761241 0.0817759 0.0613428 -0.0871072]

layer8_wq's input 
<N9nntrainer6TensorE at 0x5682dc59a250>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.71025 0.0132039 0.158897-0.433402 0.265852 -0.194175 0.206936 0.152125 -0.22748]
==============================
layer8_wq's output 
<N9nntrainer6TensorE at 0x5682dc5d3620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.113811 0.124451 -0.4443170.0557785 -0.156237 -0.0434516 0.0620928 0.0876601 -0.309255]
============================
layer8_wk's input 
<N9nntrainer6TensorE at 0x5682dc59bfb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.71025 0.0132039 0.158897-0.433402 0.265852 -0.194175 0.206936 0.152125 -0.22748]
==============================
layer8_wk's output 
<N9nntrainer6TensorE at 0x5682dc59bd20>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.407766 -1.14437 1.048860.735342 -0.108753 -0.838916 0.525454 -1.19989 0.509964]
============================
layer8_wv's input 
<N9nntrainer6TensorE at 0x5682dc59cda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.71025 0.0132039 0.158897-0.433402 0.265852 -0.194175 0.206936 0.152125 -0.22748]
==============================
layer8_wv's output 
<N9nntrainer6TensorE at 0x5682dc59cb30>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.155474 -0.0211943 -0.246304-0.226146 -0.513429 -0.183102 -0.704311 -0.585059 0.931872]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0524083 -0.160294 -0.270046-0.357217 -0.16204 0.00640626 0.0960916 -0.0480231 0.154662]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1475c98
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer8_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc59f1f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer8_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc59f150>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer8_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a0270>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.21707 0.0048674 0.0627924-0.164683 0.109893 -0.0761241 0.0817759 0.0613428 -0.0871072]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.00805 0.017441 0.211016-0.620099 0.37375 -0.28818 0.30792 0.222288 -0.290963]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.008404136 -0.4691090584 -0.9366872311 -0.7921546102 -1.274636269 0.006863810122 2.454214811 -1.383565426 -0.8426497579 0.05605497584 -1.409932137 0.1777789742 -1.179196596 -1.211033463 -1.666357994 1.034234285 -0.3294745088 -1.14750886 0.9802370667 1.069889188 -0.03552164137 -0.7446625829 -0.1001953781 -0.6484101415 -1.137970924 -1.197386622 0.05350415409 -0.1711198688 -0.7221972346 0.2002630532 -0.9857591391 -1.11968112 0.1529440433 -0.9305140972 0.003514394164 0.2896854579 -0.1185809597 -0.4627895951 -1.680969238 0.3894585669 -0.7379513383 -0.4079317153 -0.6289588809 -0.6414070129 -2.64396143 0.7762132287 -1.07730329 -0.1143154651 -0.9056591392 -1.619636178 -0.8199756145 -1.296906233 -0.08220855147 -1.223901033 -0.2582148612 -0.9574040771 -1.854082346 -1.161227226 -0.7291987538 -1.523873329 0.2886013985 -0.07492308319 1.134797335 1.669533372 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005677468609 0.009735708125 0.006099594291 0.007048077881 0.004350423347 0.01567039452 0.1811135709 0.0039014332 0.006701019593 0.01646051556 0.003799909726 0.01859120093 0.004786085337 0.004636111204 0.002940416336 0.0437785387 0.01119463891 0.00494017452 0.04147730768 0.04536761716 0.01502007525 0.007390880957 0.01407941896 0.008137633093 0.004987518769 0.004699814133 0.01641858183 0.01311543211 0.007558797952 0.01901394129 0.00580750173 0.005079578608 0.01813517697 0.006137364078 0.01561799366 0.0207925532 0.01382292435 0.009797427803 0.002897765487 0.02297411487 0.007440649439 0.01034990791 0.008297468536 0.008194821887 0.001106219366 0.03382237628 0.005299467128 0.01388201211 0.006291819271 0.003081058385 0.006854694802 0.004254610278 0.01433495339 0.00457683811 0.01202147361 0.005974529311 0.002437144518 0.004872865975 0.007506060414 0.003390699159 0.02077002451 0.01443977375 0.04841001704 0.08263579011 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.07800674 34.08301926 34.07843018 34.08033371 34.07667923 34.08895493 34.25439835 34.07718658 34.0790329 34.08879089 34.07708359 34.08615494 34.0742569 34.07791901 34.07622528 34.11515427 34.08352661 34.07822418 34.0871048 34.11102295 34.08734894 34.07971954 34.0873642 34.08046722 34.07731628 34.07703018 34.08970261 34.0854454 34.08084106 34.09134293 34.07909012 34.07836533 34.09046555 34.07847214 34.0822258 34.09217072 34.08710861 34.08212662 34.07522964 34.09435272 34.07977295 34.08363342 34.08062744 34.0786171 34.07439041 34.10710526 34.07858276 34.08621216 34.07862091 34.07636642 34.08013916 34.07658386 34.08571243 34.07786179 34.08053589 34.07925797 34.07572174 34.07720184 34.0798378 34.07667542 34.09405518 34.0867691 34.11597061 34.14256668 

-------
======================
selected experts : 6, 15, 18, 19, 62, 63, 
layer8_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5a3350>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.152072 0.210309 0.0329533-0.00769576 0.160583 0.0579157 0.109306 0.0401298 0.0594724]

layer8_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a2c90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.36914 0.215177 0.0957457-0.172378 0.270477 -0.0182084 0.191082 0.101473 -0.0276348]

layer9_wq's input 
<N9nntrainer6TensorE at 0x5682dc5e1750>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.68563 0.619512 0.26179-0.521262 0.719953 -0.0514344 0.53284 0.279286 -0.0840663]
==============================
layer9_wq's output 
<N9nntrainer6TensorE at 0x5682dc5a2e70>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.591752 -0.374015 0.415191-0.627025 0.363317 0.275043 0.417152 0.358708 0.439543]
============================
layer9_wk's input 
<N9nntrainer6TensorE at 0x5682dc5e3c80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.68563 0.619512 0.26179-0.521262 0.719953 -0.0514344 0.53284 0.279286 -0.0840663]
==============================
layer9_wk's output 
<N9nntrainer6TensorE at 0x5682dc5e39f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.461237 -0.0227207 -0.3632830.355216 -0.12193 -0.141143 -0.366343 -0.083101 -0.283239]
============================
layer9_wv's input 
<N9nntrainer6TensorE at 0x5682dc5e4a70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.68563 0.619512 0.26179-0.521262 0.719953 -0.0514344 0.53284 0.279286 -0.0840663]
==============================
layer9_wv's output 
<N9nntrainer6TensorE at 0x5682dc5e4800>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.194997 0.478782 0.0529553-0.439892 -0.131646 0.0185741 0.000719097 0.660515 0.598036]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.385025 0.584649 0.750560.0469337 0.43002 0.150767 0.418036 -0.357677 0.146778]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1270c88
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer9_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc5e6ec0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer9_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc5e6e20>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer9_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5e7f40>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.36914 0.215177 0.0957457-0.172378 0.270477 -0.0182084 0.191082 0.101473 -0.0276348]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.14448 0.728608 0.306867-0.611781 0.866882 -0.0649524 0.68162 0.345433 -0.087569]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7255349159 -0.5672965646 -0.7764482498 -0.6477704048 -0.03378194571 -0.7673395872 0.1534353197 -1.082969308 -0.07606554031 0.767480731 -0.2667455077 -0.748966217 -1.318661094 -1.149337053 -1.112321019 -0.1356878877 -1.085234404 -1.697420955 0.1044918671 -0.4385250807 2.16889739 -1.998455286 -1.768396854 -1.40848434 -1.780827403 -2.222319603 -2.025152922 -3.420464516 -0.6627473831 -0.01339121908 0.4632426202 -1.924889922 -0.2594430447 -0.2274001539 -1.100752831 2.526510239 0.1277280599 -0.03995922208 0.839887917 -0.6934179664 0.2299685776 -1.154621005 0.8696126342 1.671569228 -1.055778384 -1.093514442 -1.236648202 0.5946958661 -0.2920380831 -1.948354721 -0.1334101111 -1.829491615 -1.338919282 -1.027295113 -0.6525812745 -1.12422967 -1.035017014 -0.9695008993 -0.1200153977 0.3410769403 0.1406766176 -1.76957798 -1.523997784 -1.030200601 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007330521941 0.008587306365 0.00696664257 0.007923327386 0.01464061718 0.007030388806 0.01765496284 0.005127470475 0.01403446496 0.03262446076 0.01159803942 0.007160754874 0.004050824791 0.004798217677 0.00497915782 0.01322215516 0.005115868989 0.002773640212 0.01681167632 0.009767460637 0.1324862838 0.002052639611 0.002583602676 0.003702829126 0.002551685553 0.001640928211 0.001998563064 0.0004951558076 0.007805544417 0.01494221482 0.02406658046 0.0022093351 0.01168304496 0.01206346601 0.005037091672 0.1894437075 0.01720688678 0.01455045864 0.03507433087 0.007569777314 0.01905920543 0.004772930872 0.03613255918 0.08057197928 0.005268802866 0.005073684268 0.004397048615 0.02744756453 0.01130837668 0.002158097224 0.01325230394 0.002430483 0.003969588783 0.005421033595 0.007885301486 0.004920213483 0.005379334558 0.005743568297 0.01343101077 0.02129896544 0.01743113808 0.002580552828 0.003298882861 0.00540530635 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.4592247 34.46047974 34.45313644 34.4588623 34.46557999 34.45892334 34.44761276 34.45701981 34.46592712 34.48356247 34.46348953 34.45905304 34.45594406 34.45669174 34.45687103 34.46511459 34.45605469 34.45466614 34.46775055 34.46165848 34.57865524 34.45394516 34.45352173 34.45368958 34.45444489 34.45353317 34.45389175 34.45238876 34.44920731 34.46683502 34.47595978 34.45410156 34.4626236 34.46300125 34.45692825 34.63275528 34.46337891 34.46548843 34.48696899 34.45946121 34.44710922 34.45666504 34.48325729 34.5315094 34.45716095 34.4569664 34.4562912 34.47457123 34.46129227 34.45405197 34.46037674 34.45432281 34.45586395 34.45731354 34.45691681 34.45490646 34.45441055 34.45668411 34.46341705 34.47223663 34.46741486 34.45447159 34.45519257 34.45539093 

-------
======================
selected experts : 9, 20, 35, 38, 42, 43, 
layer9_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5eb020>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0103548 -0.0827766 -0.0817536-0.102075 0.068178 0.173603 -0.188488 -0.0705576 0.106281]

layer9_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5ea960>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.3795 0.1324 0.0139921-0.274454 0.338655 0.155395 0.00259337 0.0309151 0.0786466]

layer10_wq's input 
<N9nntrainer6TensorE at 0x5682ded33210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.45415 0.362037 0.0377992-0.777595 0.814453 0.432593 0.00709134 0.0763867 0.199506]
==============================
layer10_wq's output 
<N9nntrainer6TensorE at 0x5682dc5eab40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.38492 -1.21453 1.34427-0.00452872 -1.3604 1.30168 -0.661107 -1.8578 -1.70101]
============================
layer10_wk's input 
<N9nntrainer6TensorE at 0x5682ded34f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.45415 0.362037 0.0377992-0.777595 0.814453 0.432593 0.00709134 0.0763867 0.199506]
==============================
layer10_wk's output 
<N9nntrainer6TensorE at 0x5682ded34ce0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.873695 -0.283103 0.4851621.0017 0.0310412 -0.544273 1.10511 -0.63873 -0.25015]
============================
layer10_wv's input 
<N9nntrainer6TensorE at 0x5682ded35d60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.45415 0.362037 0.0377992-0.777595 0.814453 0.432593 0.00709134 0.0763867 0.199506]
==============================
layer10_wv's output 
<N9nntrainer6TensorE at 0x5682ded35af0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.13422 -0.16506 0.07610980.152348 -0.368472 -0.381889 0.432319 -0.0450181 0.801782]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.851243 0.947962 0.6746961.1627 -0.897189 1.65533 -1.93679 0.370559 1.45393]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a106bc78
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer10_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded38210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer10_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded38170>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer10_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded39290>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.3795 0.1324 0.0139921-0.274454 0.338655 0.155395 0.00259337 0.0309151 0.0786466]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.96559 0.427465 0.0424089-0.931306 1.02643 0.529862 0.00897098 0.100321 0.23578]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.075698853 -2.146638155 -1.572076797 -1.239016533 -0.6601934433 -1.058405876 -0.8171054125 -0.5537326932 0.8124222159 -1.65486455 -1.263222814 -0.2799122632 -0.5027951002 -0.9667331576 1.368038416 -0.9534963369 -1.396287799 -0.8885353208 -0.773917675 -0.5835622549 -0.1159888133 -0.5864533782 -1.190278411 1.46242857 -0.7600318193 0.1094364524 -0.527754426 -1.326165557 -1.424989223 -0.2970946431 -0.1208939254 -1.036193252 -0.2115094513 -0.1717701852 -1.760190725 -0.5123511553 -0.834112525 -1.510728478 0.2634393275 -0.08949471265 0.3920693099 -0.2159163058 -0.9869779348 -0.1603210419 -0.5909483433 -0.3569854796 -1.103301883 -1.43753016 1.086938024 0.04133091494 -0.6025595069 -0.9155442715 -0.1440999508 -0.4863758683 -1.130069971 -0.870148778 -0.9056789875 1.548809886 -0.2099162936 -1.09917748 -1.344641328 -0.5869354606 -1.286455154 -1.634610772 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006908041891 0.002367292996 0.004205143079 0.005867147353 0.01046662498 0.007028541528 0.008946655318 0.01164238621 0.04564104602 0.003871030407 0.005726831034 0.01530949119 0.01225078478 0.007703325246 0.07955300808 0.007805970032 0.005013315007 0.008329886012 0.009341505356 0.01130022854 0.01803647913 0.01126760617 0.006160184741 0.08742783219 0.009472126141 0.02259709872 0.01194879878 0.005377478898 0.004871470388 0.01504868269 0.01794822514 0.007186411414 0.01639334857 0.01705792546 0.003484047018 0.01213427354 0.008795784786 0.004471199121 0.0263593886 0.01852072589 0.02997772209 0.01632126607 0.007548940834 0.01725434884 0.01121707261 0.01417386346 0.00671996735 0.004810759798 0.06005874649 0.02110935003 0.01108758152 0.008107917383 0.01753651351 0.01245359331 0.006542474031 0.008484461345 0.008188299835 0.09531574696 0.01641948894 0.006747740787 0.005279037636 0.01126217563 0.005595316179 0.00395023264 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.10935593 33.10577011 33.10760498 33.10926819 33.11386871 33.10089111 33.11234665 33.11504364 33.14713669 33.1072731 33.10912704 33.11775589 33.11565018 33.10538101 33.17913818 33.11120605 33.1084137 33.11077881 33.10606766 33.11183929 33.1204834 33.1146698 33.10956192 33.18510818 33.11001205 33.12123108 33.11439514 33.10877991 33.10731888 33.11845016 33.12039566 33.11058807 33.11979294 33.12046051  33.106884 33.11362839 33.11029053 33.10787201 33.12976074 33.12192154 33.11525726 33.10065079 33.11095047 33.12065506 33.11461639 33.11566925 33.10916901 33.10821152 33.15869141 33.12451172 33.11067581 33.11150742 33.12093735 33.11394882 33.10994339 33.11188507 33.10968399 33.19394684 33.11791229 33.10919571 33.10868073 33.11275482 33.10899734 33.10735321 

-------
======================
selected experts : 8, 14, 23, 40, 48, 57, 
layer10_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded3c110>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.100843 -0.160853 -0.002693580.1557 -0.206979 -0.0521097 0.0486964 -0.0564466 0.0430339]

layer10_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded3bb90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.48034 -0.0284524 0.0112985-0.118753 0.131675 0.103285 0.0512898 -0.0255316 0.12168]

layer11_wq's input 
<N9nntrainer6TensorE at 0x5682ded7c3b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.82488 -0.0757713 0.0285557-0.338408 0.321627 0.287321 0.136589 -0.0614967 0.319918]
==============================
layer11_wq's output 
<N9nntrainer6TensorE at 0x5682ded3ba40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.711116 -0.0312718 0.6831160.309559 0.223987 -1.01384 0.898509 0.212579 -1.42737]
============================
layer11_wk's input 
<N9nntrainer6TensorE at 0x5682ded7e110>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.82488 -0.0757713 0.0285557-0.338408 0.321627 0.287321 0.136589 -0.0614967 0.319918]
==============================
layer11_wk's output 
<N9nntrainer6TensorE at 0x5682ded7de80>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.919881 0.605903 -1.4669-0.890419 -1.10398 0.894191 -0.587251 0.00590786 1.58978]
============================
layer11_wv's input 
<N9nntrainer6TensorE at 0x5682ded7ef00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.82488 -0.0757713 0.0285557-0.338408 0.321627 0.287321 0.136589 -0.0614967 0.319918]
==============================
layer11_wv's output 
<N9nntrainer6TensorE at 0x5682ded7ec90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.272071 0.685627 -0.546734-0.0507568 0.0982439 -0.692871 -0.549821 0.199806 -0.310142]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.660807 -0.264571 0.07259770.746461 -0.0967698 -1.03377 0.346895 -0.855671 0.703146]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0e66c68
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer11_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded813b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer11_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded81310>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer11_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded82430>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.48034 -0.0284524 0.0112985-0.118753 0.131675 0.103285 0.0512898 -0.0255316 0.12168]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.14691 -0.0994196 0.0364134-0.433081 0.431069 0.38543 0.191399 -0.0883474 0.390093]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.288918138 -0.845023632 -0.4500235617 0.09027478844 -0.02849121951 0.4326645136 0.861541748 -2.127013445 -1.683238268 -0.9644001126 -0.7943502069 -1.822052717 -0.2006771863 -1.047119379 -0.4974162877 0.2427326739 -0.09994769096 -0.3965860903 0.2931783795 -0.9949479103 -2.787274361 -0.0202193968 0.06953013688 -0.5222980976 0.183985889 0.3801911771 -0.7795951962 0.9515047073 -0.2640305758 -1.946425319 -0.3005286753 -0.3565134406 -0.8987566829 -1.200834036 -0.6032832861 -0.7825671434 0.3121511042 -1.317822576 -1.634918094 -2.074688435 -0.6773531437 -1.798682928 -0.8446490765 1.976724267 -0.8513905406 -1.06051755 1.735411763 -0.9552757144 -0.468685925 -0.08455939591 -0.4899786115 -1.069809794 -0.06575390697 -1.333945274 -1.214619875 -2.006838083 -0.262242198 -1.690782309 -0.7679491043 -0.9080834985 -1.099174023 -0.9894859791 -0.2361604422 -1.029676914 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.00526396744 0.008205294609 0.01217980962 0.02090687305 0.01856562868 0.02944333665 0.0452112034 0.002276842482 0.003548641223 0.007281980943 0.008631798439 0.003088699887 0.01562896371 0.006703861058 0.01161603816 0.02435009554 0.01728527993 0.01284837071 0.0256099645 0.007062897086 0.001176482299 0.01871983521 0.02047763392 0.01133057568 0.02296081185 0.0279381834 0.008760104887 0.04946710169 0.01466953009 0.002727479208 0.01414377335 0.01337369531 0.00777603453 0.005748672411 0.0104491422 0.008734109811 0.0261004921 0.005113993306 0.003724322887 0.002399150748 0.009703142568 0.00316173234 0.008208367042 0.1378998011 0.008153217845 0.006614640355 0.1083335504 0.007348729763 0.01195461117 0.01755333133 0.0117027564 0.00655346131 0.01788655482 0.005032203626 0.005669965874 0.002567582764 0.0146957878 0.003521970706 0.008862723596 0.007703845389 0.006363822613 0.007101578172 0.01508412324 0.006821820047 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.54701042 28.55090523 28.55535698 28.55216217 28.55602074 28.55926895 28.58028221 28.54593086 28.54481888 28.54712105 28.55228615 28.54674149 28.55403709 28.54988098 28.5547924 28.56037331 28.56046104 28.55602455 28.56115723 28.54594803 28.54483032 28.55951309 28.56365395 28.5454464 28.56327629 28.56777763 28.54764557 28.58119965 28.55212402 28.54590416 28.55350494 28.55559731 28.55095291 28.5489254 28.55314827 28.54618835 28.56927681 28.54542923 28.54547119 28.5455761 28.55287933 28.54490852 28.55138588 28.67392349 28.54942322 28.54788399 28.64864922 28.55052567 28.55560875 28.55548477 28.55440331 28.54686928 28.56058693 28.54820824 28.5488472 28.54526711 28.55739594 28.54669952 28.54727173 28.55088043 28.54906273 28.54980087 28.55778313 28.5495224 

-------
======================
selected experts : 5, 6, 25, 27, 43, 46, 
layer11_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded85530>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.333288 -0.129826 0.0946371-0.126506 0.0569822 -0.0248454 0.022742 -0.0304357 -0.0313503]

layer11_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded84d30>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.81363 -0.158279 0.105936-0.245259 0.188657 0.0784395 0.0740318 -0.0559673 0.0903302]

layer12_wq's input 
<N9nntrainer6TensorE at 0x5682dedc4470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.89637 -0.441801 0.292464-0.725737 0.48631 0.226125 0.217936 -0.14683 0.24387]
==============================
layer12_wq's output 
<N9nntrainer6TensorE at 0x5682ded84be0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.348987 0.440544 0.5327880.103167 -0.98111 -0.391637 0.483843 -0.561279 0.615396]
============================
layer12_wk's input 
<N9nntrainer6TensorE at 0x5682dedc61d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.89637 -0.441801 0.292464-0.725737 0.48631 0.226125 0.217936 -0.14683 0.24387]
==============================
layer12_wk's output 
<N9nntrainer6TensorE at 0x5682dedc5f40>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.94753 2.73744 -1.06041-0.612855 -0.205349 -1.58668 1.13056 1.90304 -0.65085]
============================
layer12_wv's input 
<N9nntrainer6TensorE at 0x5682dedc6fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.89637 -0.441801 0.292464-0.725737 0.48631 0.226125 0.217936 -0.14683 0.24387]
==============================
layer12_wv's output 
<N9nntrainer6TensorE at 0x5682dedc6d50>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.51248 -0.402007 0.1068260.234327 -0.535508 -0.147109 -0.676383 -0.230129 1.07105]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.499529 -0.257569 0.1764470.513198 -1.05387 -0.0728576 -0.481074 -0.563655 -0.3076]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0c61c58
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer12_attention_out's input 
<N9nntrainer6TensorE at 0x5682dedc9470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer12_attention_out's output 
<N9nntrainer6TensorE at 0x5682dedc93d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer12_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dedca4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.81363 -0.158279 0.105936-0.245259 0.188657 0.0784395 0.0740318 -0.0559673 0.0903302]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.24071 -0.499742 0.300544-0.811778 0.546739 0.266804 0.251812 -0.173294 0.260404]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.293932796 -0.3431039155 -2.383466959 -1.621967912 -0.7980388999 -0.5974785686 0.1122665331 -0.1272202879 -1.179748893 -1.615149617 -0.006524482276 1.812610626 -0.6442659497 -0.4597440958 -1.410847545 -0.171241641 0.3463445008 -0.6412830353 -0.8454797268 -1.184060097 0.4546080232 -0.3660334647 -0.001814156771 -0.4574493468 -1.220888734 1.647700906 -1.07535696 -1.064948797 -0.2735287845 -1.309849143 -0.6186333895 -0.214939326 -0.0545353815 0.04064106569 -1.461414933 2.050419092 -0.3244403005 -0.6647894382 -0.5618572235 0.7115014791 -1.880402684 2.990878344 -0.04464754835 -0.509827733 -1.141849995 -2.116267204 0.530513227 -0.2795463204 -0.5140702128 -1.890625715 -0.4986811876 -0.3700327575 -0.9741646647 -1.60545063 -0.9082166553 0.1884768605 -1.114508629 0.2282897979 -1.38516736 -0.4846554399 -0.957275033 0.7046700716 0.6681559682 -1.846594334 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003478836035 0.009002718143 0.001170186908 0.002505936194 0.005712127313 0.006980718113 0.01419510134 0.01117199287 0.003899629926 0.002523080911 0.01260515582 0.07772998512 0.006661632098 0.008011565544 0.003094984917 0.01069085672 0.01793896034 0.006681532599 0.005447466858 0.003882854478 0.01999012567 0.008798637427 0.01266467106 0.008029971272 0.003742454108 0.06591271609 0.00432872586 0.004374016076 0.00965138711 0.003423903836 0.006834593136 0.01023374964 0.01201426983 0.01321392972 0.002942370018 0.09859785438 0.009172319435 0.00652630534 0.007233863231 0.02584537677 0.00193523278 0.2525246143 0.01213365421 0.007620199583 0.004050256219 0.001528617111 0.0215665549 0.009593484923 0.007587940432 0.001915549859 0.007705613505 0.008763519116 0.004789690487 0.002547672251 0.005116208922 0.01531920396 0.004162525758 0.01594141312 0.003175493563 0.007814453915 0.004871272948 0.02566942573 0.02474903129 0.002001778223 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
30.80781364 30.81381416 30.80550575 30.80636406 30.80909348 30.80940819 30.81900597 30.81550598 30.80489731 30.8073349 30.81741714 30.87825012 30.81147385 30.81091499 30.80599976 30.81502533 30.82275009 30.81053925 30.81025887 30.80774117 30.8209877 30.81361008 30.81747627 30.81236458 30.8085537 30.87072372 30.80818558 30.80918503 30.81255531 30.80680466 30.81116867 30.8150444 30.81587219 30.81325722 30.80727768 30.89959526 30.81350708 30.81038475 30.81156921 30.83017921 30.8062706 31.05733681 30.81408501 30.8119545 30.80838585 30.80586243 30.82494736 30.80582237 30.81049156 30.80672646 30.81204224 30.81071472 30.80912399 30.80449867 30.80992699 30.8201313 30.80849648 30.81884575 30.80751038 30.81214905 30.80968285 30.83048058 30.81811714 30.80538368 

-------
======================
selected experts : 11, 25, 35, 39, 41, 61, 
layer12_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dedcd730>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.112173 -0.131077 0.02260420.128528 0.194601 0.0424895 0.20247 0.0769971 0.138645]

layer12_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dedccdf0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.9258 -0.289355 0.12854-0.116731 0.383258 0.120929 0.276502 0.0210298 0.228975]

layer13_wq's input 
<N9nntrainer6TensorE at 0x5682dee397f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.16659 -0.748282 0.326644-0.340257 0.865079 0.368764 0.781172 0.0493541 0.55791]
==============================
layer13_wq's output 
<N9nntrainer6TensorE at 0x5682dedccca0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.146461 -0.826287 0.551154-0.545832 0.223024 -1.19836 0.793292 0.190072 -0.0831282]
============================
layer13_wk's input 
<N9nntrainer6TensorE at 0x5682dc471a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.16659 -0.748282 0.326644-0.340257 0.865079 0.368764 0.781172 0.0493541 0.55791]
==============================
layer13_wk's output 
<N9nntrainer6TensorE at 0x5682dc4717a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.402265 0.759593 -0.07713470.614578 0.107329 0.575085 -0.997259 0.0339192 0.130419]
============================
layer13_wv's input 
<N9nntrainer6TensorE at 0x5682dc472820>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.16659 -0.748282 0.326644-0.340257 0.865079 0.368764 0.781172 0.0493541 0.55791]
==============================
layer13_wv's output 
<N9nntrainer6TensorE at 0x5682dc4725b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.566453 -0.334422 0.3136370.445715 -0.460067 0.359764 0.332423 0.159887 -0.479781]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.207083 0.813214 0.7480410.205275 -0.154111 -1.20915 0.308631 -0.755107 -0.409883]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0a5cc48
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer13_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc474cd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer13_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc474c30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer13_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc475da0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.9258 -0.289355 0.12854-0.116731 0.383258 0.120929 0.276502 0.0210298 0.228975]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.34616 -0.91697 0.365072-0.389114 1.09424 0.417571 0.9341 0.065072 0.653747]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7220129371 -0.05478731543 0.6278259754 -0.9891938567 1.762662411 -1.380978107 1.996001959 -0.8052836061 -0.9301933646 -1.203303814 0.8459310532 2.089992046 -0.199139744 -1.273727894 0.3800617158 -1.414164662 1.100451708 -0.2400038391 2.241235256 -2.743719339 -1.01332128 -0.2049026638 -0.4105205238 -0.9677480459 -1.712805986 -0.8239360452 -0.2945116162 -0.7590095401 -1.885005236 -1.946353197 -1.634285212 0.4477111399 -1.928819418 0.2596154809 -1.967078924 0.3224657178 -1.111128688 -0.7384868264 -1.687330604 0.1799392998 -0.6839897633 -0.3906354308 -1.360973239 -0.6651363373 -0.4168076515 -0.9761619568 -0.7915734649 -0.1483076811 -0.4143925905 0.6110135317 0.3685078025 -1.747005105 0.08016446978 -0.8501906395 -0.5594712496 -0.5311316848 -1.084499002 0.2401874214 -0.3063743711 -0.02832869813 0.33382985 -0.3051034212 -0.5633391738 -0.5100511909 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006589851342 0.01284245402 0.02541576885 0.005044758786 0.07905992866 0.003409500234 0.09983768314 0.006063336506 0.005351358093 0.004072430544 0.03161004186 0.1096765697 0.01111620478 0.003795498982 0.01983812451 0.003298207885 0.04077199474 0.01067110803 0.127584517 0.0008726891829 0.004924498498 0.01105232816 0.00899818819 0.005154115614 0.002446694067 0.005951288622 0.0101050185 0.006350503769 0.002059654566 0.001937096706 0.002646554494 0.02122659422 0.001971361926 0.0175869856 0.001897363109 0.01872780733 0.004465650767 0.006482180674 0.002509825164 0.01624009199 0.006845243275 0.00917890761 0.003478393191 0.006975524127 0.008941792883 0.005110932048 0.006147037726 0.01169587206 0.008963414468 0.02499203756 0.01961023547 0.002364434302 0.01469795313 0.005797072779 0.007752943784 0.007975799963 0.004586168099 0.01724860258 0.009985852987 0.01318678353 0.01894184761 0.009998554364 0.007723012473 0.008145718835 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.72858047 28.73578644 28.74788284 28.7279892 28.80057335 28.72540092 28.82230568 28.72805405 28.72877312 28.72749329 28.75074005 28.82451439 28.73215294 28.72578621 28.74087524 28.7267189 28.76371574 28.72932434 28.85100555 28.72429466 28.7273922   28.73209 28.73098946 28.72809792 28.72634506 28.72889519 28.73018837 28.72881699 28.7250042 28.72392845 28.72511482 28.74417114 28.72491646 28.74053192 28.7200737  28.740242 28.72740936 28.72704315 28.72593117 28.73918343 28.73026657 28.73212242 28.72356224 28.72991943 28.72950172 28.72757912 28.72909164 28.72939491 28.73143005 28.74841309 28.74303055 28.72530937 28.73764229 28.72874069 28.73069763 28.73139763 28.72705269 28.7387619 28.73245239 28.73470116 28.74188614 28.73246574 28.73114395 28.73156738 

-------
======================
selected experts : 4, 6, 10, 11, 16, 18, 
layer13_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee45420>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.155227 -0.00390031 0.166556-0.0488616 0.0151408 -0.1858 0.310591 -0.101189 0.0405358]

layer13_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc478790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.08103 -0.293256 0.295096-0.165592 0.398399 -0.0648707 0.587092 -0.0801589 0.269511]

layer14_wq's input 
<N9nntrainer6TensorE at 0x5682dee98c10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04213 -0.643039 0.616261-0.404169 0.847593 -0.17188 1.41762 -0.160076 0.587455]
==============================
layer14_wq's output 
<N9nntrainer6TensorE at 0x5682dc478730>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.58019 0.258 -0.471951-0.137936 0.0589217 -0.443345 -1.4416 -2.72168 -0.39271]
============================
layer14_wk's input 
<N9nntrainer6TensorE at 0x5682dee9aab0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04213 -0.643039 0.616261-0.404169 0.847593 -0.17188 1.41762 -0.160076 0.587455]
==============================
layer14_wk's output 
<N9nntrainer6TensorE at 0x5682dee9a7d0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.12019 0.159095 1.60696-0.118079 1.05921 1.02661 0.26934 0.833747 0.0833444]
============================
layer14_wv's input 
<N9nntrainer6TensorE at 0x5682dee9b8a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04213 -0.643039 0.616261-0.404169 0.847593 -0.17188 1.41762 -0.160076 0.587455]
==============================
layer14_wv's output 
<N9nntrainer6TensorE at 0x5682dee9b630>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.13295 -0.965879 -0.733511-0.177862 0.0406729 0.341231 -0.450788 0.578666 0.315487]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.54609 0.416154 -0.115959-0.477826 -0.0794735 -0.440125 -2.90943 1.01043 0.0551087]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2eb6d68
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer14_attention_out's input 
<N9nntrainer6TensorE at 0x5682dee9dda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer14_attention_out's output 
<N9nntrainer6TensorE at 0x5682dee9dd00>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer14_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dee9ee70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.08103 -0.293256 0.295096-0.165592 0.398399 -0.0648707 0.587092 -0.0801589 0.269511]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.33592 -0.857385 0.754919-0.501429 1.02959 -0.206595 1.80842 -0.223897 0.696504]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.890654683 -0.677886188 -0.8622816205 -0.8444775343 -0.6838998199 -0.4321343005 -0.6509006023 -0.5058846474 1.295049429 -0.8424673676 -1.344491839 -1.465663314 0.8016123176 0.7685012817 -0.516190052 -0.9302549362 -1.699092507 0.3788572848 -3.006859779 -1.006314635 -1.602183938 -1.416317463 -0.9968240261 -1.496439219 -0.5641298294 -1.308431149 -0.3583960533 -0.7280638814 -1.764087915 -0.2883976698 -1.896824598 -1.733500719 1.287511587 -0.8243377209 -0.4451369345 -1.575756311 -0.472317487 -0.8194108605 -0.1870341748 -1.031679988 -0.5676518083 0.06790029258 -0.8494802117 -0.09206518531 -0.4842657745 -0.2350678742 -1.721546173 -0.3043273389 -1.466235518 1.14675498 -1.694718361 -0.5937050581 -0.3306755126 -0.7036556602 -0.9399239421 1.586244106 0.6639513373 0.7030807137 0.4497053325 -0.159288466 -1.697398186 -0.0456347391 -0.105351761 0.3423116803 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1113802493 0.00853699632 0.007099424489 0.007226955611 0.008485811763 0.01091525145 0.008770506829 0.0101392176 0.06139600277 0.007241496816 0.004383307416 0.00388309313 0.0374837555 0.03626295179 0.01003526524 0.006632889621 0.003074686043 0.02456082404 0.0008314664592 0.006147101987 0.003387565026 0.004079514649 0.006205718499 0.003765407018 0.00956552662 0.004544257652 0.01175054256 0.008119198494 0.002881201217 0.01260253135 0.0025230553 0.002970690606 0.06093495339 0.007373979315 0.01077424362 0.003478283528 0.01048533712 0.007410400081 0.01394695323 0.005993139464 0.009531894699 0.01799683087 0.007190891076 0.01533641573 0.01036080252 0.0132928649 0.003006418003 0.01240336709 0.003880871926 0.05293423682 0.003088165075 0.009286765009 0.01208082959 0.008319811895 0.006569064688 0.08214939386 0.03266312182 0.03396654502 0.02636403404 0.01433934085 0.003079900518 0.01606528275 0.0151339937 0.02367943898 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.27173233 27.16936684 27.16697502 27.16519547 27.16693115 27.17126846 27.16959953 27.16906166 27.22222519 27.16807175 27.16378212 27.16280556 27.1987896 27.19137001 27.1656189 27.16603279 27.16295052 27.1844368 27.16213799 27.16363907 27.16374016 27.16490936 27.16703606 27.15934944 27.1703949 27.16489601 27.17258072 27.16894913 27.16371155 27.17390823 27.16239929 27.16284561 27.22176361 27.16724968 27.17112732 27.16287804 27.16893005 27.16728592 27.17477608 27.1663456 27.17036057 27.17835045 27.16563606 27.17473602 27.17119026 27.17364502 27.16383553 27.1689415 27.16328049 27.21376419 27.16248703 27.16868591 27.17243385 27.1691494 27.16739845 27.24202538 27.19349289 27.19431877 27.18147087 27.17421532 27.16343307 27.17737198 27.16595078 27.18450928 

-------
======================
selected experts : 0, 8, 12, 32, 49, 55, 
layer14_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deea2ef0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0442295 0.142497 -0.183646-0.151549 0.0582103 0.0591179 -0.199296 0.0431362 -0.149447]

layer14_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deea2970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.12526 -0.150758 0.11145-0.317141 0.456609 -0.00575276 0.387797 -0.0370227 0.120064]

layer15_wq's input 
<N9nntrainer6TensorE at 0x5682deedb770>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.77349 -0.33165 0.211932-0.764679 0.868282 -0.0155153 0.910942 -0.0713222 0.244728]
==============================
layer15_wq's output 
<N9nntrainer6TensorE at 0x5682deea2820>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00260178 0.611024 -0.150906-0.25107 0.966889 -0.0170978 -0.14178 -0.448184 -0.40272]
============================
layer15_wk's input 
<N9nntrainer6TensorE at 0x5682deedd610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.77349 -0.33165 0.211932-0.764679 0.868282 -0.0155153 0.910942 -0.0713222 0.244728]
==============================
layer15_wk's output 
<N9nntrainer6TensorE at 0x5682deedd330>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.591653 -1.26591 0.07956451.14947 -0.494893 0.228183 1.02436 0.556575 0.497839]
============================
layer15_wv's input 
<N9nntrainer6TensorE at 0x5682deede400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.77349 -0.33165 0.211932-0.764679 0.868282 -0.0155153 0.910942 -0.0713222 0.244728]
==============================
layer15_wv's output 
<N9nntrainer6TensorE at 0x5682deede190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.461074 0.0829068 -0.469892-0.137902 -0.0689102 -0.205022 -0.708806 -0.3385 -0.00434557]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.254185 -0.55565 0.14228-0.256056 0.915344 -0.311949 -0.464545 0.0718933 -0.329022]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2baf550
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer15_attention_out's input 
<N9nntrainer6TensorE at 0x5682deee0900>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer15_attention_out's output 
<N9nntrainer6TensorE at 0x5682deee0860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer15_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682deee19d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.12526 -0.150758 0.11145-0.317141 0.456609 -0.00575276 0.387797 -0.0370227 0.120064]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.46972 -0.436579 0.277035-0.942053 1.15203 -0.0179463 1.16157 -0.099391 0.301433]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2218439579 -0.6005067229 -0.007580773905 -0.7548547983 0.0933939144 -0.8238271475 -0.3696285486 -1.379104376 -1.4727844 -1.010642409 0.03440863639 -0.8138206601 -0.7815232277 -0.4850285351 -1.464040756 1.524754405 -0.9279221892 -0.5366939902 -1.547908783 -0.245569557 -1.846567154 -0.4650019109 2.035564899 -1.926776528 -0.1271660626 -0.9479135871 0.1389866769 -0.8522074223 -1.067058682 0.2254901528 -0.4206766188 -0.4966990054 -1.859713674 -0.08688179404 0.07939142734 -0.3981376886 -0.7420488 0.1732515693 1.48654604 0.07724988461 -1.073909998 -0.9899170399 -0.7569380999 -2.455502748 -1.836840987 -0.6345955729 -0.5112048984 -1.380798697 0.3201414645 0.5749521255 0.1245499775 -0.6584037542 -0.3076282442 -0.5475282669 -1.27268219 -1.233708143 1.157920361 -1.180791736 0.08818650246 -1.08333075 -0.1766496301 0.6963065863 -1.426909804 -1.258859158 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01397671271 0.009570924565 0.01731643081 0.008202031255 0.01915627718 0.007655384485 0.01205655094 0.004393525887 0.004000630695 0.006350883748 0.01805901714 0.007732374128 0.007986186072 0.01074250136 0.004035764374 0.08015730232 0.006898571271 0.01020157803 0.003711097874 0.01364901103 0.002752939938 0.01095980778 0.1335934699 0.002540752059 0.01536466647 0.006762028206 0.02004988119 0.007441177499 0.006002511829 0.02186148986 0.01145652961 0.01061785966 0.002716985298 0.01599625498 0.01888991147 0.01171768177 0.008307741024 0.02074879594 0.07715238631 0.01884950139 0.005961526185 0.006483882666 0.008184961975 0.001497404883 0.002779845614 0.009250160307 0.01046494953 0.00438608788 0.02403180115 0.03100624494 0.01976250671 0.00903253071 0.01282771863 0.01009164937 0.004886881448 0.005081103183 0.05554296449 0.005357217509 0.01905678213 0.00590562867 0.01462287363 0.03500682861 0.004188432824 0.00495490199 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.90499115 25.90058517 25.89974785 25.89826202 25.90873909 25.8948555 25.90354729 25.89588356 25.89596748 25.89545822 25.91002655 25.89445496 25.89900017 25.90175629 25.89600372 25.9706955 25.89886665 25.90217018 25.89615631 25.90466309 25.89424324 25.90006638 26.02269936 25.89403152 25.90399551 25.89872932 25.91154099 25.89940834 25.89606285 25.91144562 25.90294838 25.90115547  25.894207 25.90701103 25.91085815 25.90177727 25.89836884 25.91271591 25.96912003 25.89555931 25.89793015 25.89320564 25.89967537 25.89441872 25.89474678 25.90074158 25.90100288 25.88777161 25.91552353 25.92297363 25.91077614 25.89575577 25.90336418 25.90205956 25.89542389 25.89704895 25.94751167 25.89446449 25.90816307 25.89453506 25.90659142 25.92649841 25.89329529 25.88690948 

-------
======================
selected experts : 15, 22, 38, 49, 56, 61, 
layer15_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deee4f80>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.211953 0.234548 -0.2150810.176693 -0.00234827 0.111494 -0.40818 0.163585 0.0598682]

layer15_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deee44b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.33721 0.0837894 -0.103631-0.140448 0.454261 0.105741 -0.0203833 0.126562 0.179933]

layer16_wq's input 
<N9nntrainer6TensorE at 0x5682def24710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.31761 0.218152 -0.219981-0.375548 0.953619 0.319948 -0.0516351 0.268658 0.409382]
==============================
layer16_wq's output 
<N9nntrainer6TensorE at 0x5682deee4360>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.618402 -0.131074 -0.5364070.337663 -0.519812 -0.376648 1.02457 0.418604 -0.127396]
============================
layer16_wk's input 
<N9nntrainer6TensorE at 0x5682def26470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.31761 0.218152 -0.219981-0.375548 0.953619 0.319948 -0.0516351 0.268658 0.409382]
==============================
layer16_wk's output 
<N9nntrainer6TensorE at 0x5682def261e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.42494 0.0491374 0.692216-1.36299 1.31172 0.350764 -1.39053 -0.210663 1.22936]
============================
layer16_wv's input 
<N9nntrainer6TensorE at 0x5682def27260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.31761 0.218152 -0.219981-0.375548 0.953619 0.319948 -0.0516351 0.268658 0.409382]
==============================
layer16_wv's output 
<N9nntrainer6TensorE at 0x5682def26ff0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.317676 0.0349983 -0.5024191.1096 -0.649026 -0.662572 0.484461 -0.665229 -0.147114]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.617463 -0.135429 -0.560281-0.296368 -0.610089 -0.19965 0.56971 -0.948896 -0.460931]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2093cf8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer16_attention_out's input 
<N9nntrainer6TensorE at 0x5682def29710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer16_attention_out's output 
<N9nntrainer6TensorE at 0x5682def29670>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer16_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def2a790>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.33721 0.0837894 -0.103631-0.140448 0.454261 0.105741 -0.0203833 0.126562 0.179933]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.97402 0.23977 -0.261304-0.41508 1.14541 0.329869 -0.0595238 0.333967 0.453696]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.363337874 -1.736756444 -0.4215849638 1.753603697 -0.6389190555 -1.77861166 -0.2765093744 0.7122148871 -0.5134734511 -0.3759033382 -1.253976345 1.214964628 -0.7106405497 -0.3341830969 0.9082656503 -0.1438941211 -0.8174051046 -0.6503274441 -0.85016644 -0.2432413399 -0.9850304127 -2.22254467 -0.9448741674 0.2155602872 -1.159727931 -0.6424306035 -1.199065208 -0.3694017529 -0.7249289751 -2.222334862 -1.334394097 0.4562349319 -0.2326183468 -1.090725303 -0.700260818 -0.9060382843 -1.269330025 -2.373129845 -1.232488871 -0.5860313177 0.6837432384 -1.275163651 -2.348347187 -0.650632441 -0.553194344 -1.861816406 -0.8980414271 0.5922238827 -0.8130593896 -0.6252757907 -1.020447969 -0.6618753672 -0.5517811775 -0.8442652822 -2.194777489 -0.3334437609 -0.532897532 -0.5412735343 -0.8869378567 -0.002399519086 -0.6179801226 -0.02949033678 -0.2771101594 -1.085317016 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005518888123 0.003799074795 0.01415303815 0.1246011481 0.01138839684 0.003643345786 0.01636270806 0.04397974163 0.01291049644 0.01481456496 0.00615668064 0.07270998508 0.01060020551 0.01544570737 0.05350525305 0.01868311316 0.009526803158 0.01125921216 0.009219747037 0.01691621915 0.008056536317 0.002337236889 0.008386641741 0.02676444873 0.006765163038 0.01134847756 0.006504205056 0.01491119713 0.01044982299 0.002337727463 0.005680958275 0.03404724225 0.0170968771 0.007248459384 0.01071080659 0.008718749508 0.006062875036 0.002010501223 0.00629040366 0.01200691797 0.04274522141 0.006027609576 0.002060950501 0.0112557793 0.0124077322 0.003352471162 0.008788751438 0.03900688142 0.009568292648 0.01154483669 0.007776187733 0.011129939 0.01242527831 0.009274316952 0.00240304484 0.01545712817 0.01266214345 0.01255652681 0.008886882104 0.02152283676 0.01162937097 0.0209475942 0.01635288075 0.00728776725 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
23.53619194 23.52541542 23.54482651 23.65527534 23.53157425 23.53479385 23.54751396 23.56702614 23.53786469 23.54596519 23.53492546 23.60290718 23.54127502 23.54373741 23.57369041 23.54029846 23.53924751 23.53955078 23.53894043 23.54711342 23.53253365 23.53348732 23.53906059 23.55696106 23.53743935 23.53487206 23.53622437 23.54606247 23.54112434 23.53110695 23.53635406 23.56424522 23.54634285 23.53744507 23.54043198 23.53939247 23.53340149  23.533638 23.53744125 23.54172707 23.57294273 23.53336525 23.53225899 23.54145241 23.54117584 23.5325985 23.53946304 23.56920433 23.54024315 23.54079056 23.53463745 23.5422802 23.5397625 23.53184319 23.53355408 23.54708481 23.54333687 23.53846359 23.53860664 23.55171967 23.54230309 23.55066872 23.54750443 23.53891563 

-------
======================
selected experts : 3, 7, 11, 14, 40, 47, 
layer16_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def2d9d0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.06765 0.135349 0.03424350.176277 0.000973045 0.105585 0.174205 0.0174802 -0.465571]

layer16_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def2d090>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.40486 0.219138 -0.06938780.0358294 0.455234 0.211325 0.153822 0.144042 -0.285638]

layer17_wq's input 
<N9nntrainer6TensorE at 0x5682def6d870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8694 0.49753 -0.1226780.0816931 0.752081 0.563501 0.358153 0.244927 -0.532607]
==============================
layer17_wq's output 
<N9nntrainer6TensorE at 0x5682def2cf40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0256799 0.0705974 0.1823790.217593 0.266656 -0.00630807 -0.365624 -0.29495 -0.195453]
============================
layer17_wk's input 
<N9nntrainer6TensorE at 0x5682def6f5d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8694 0.49753 -0.1226780.0816931 0.752081 0.563501 0.358153 0.244927 -0.532607]
==============================
layer17_wk's output 
<N9nntrainer6TensorE at 0x5682def6f340>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-2.17511 -0.059102 1.942110.653518 0.191876 0.562744 -1.34005 -0.450133 0.671633]
============================
layer17_wv's input 
<N9nntrainer6TensorE at 0x5682def703c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8694 0.49753 -0.1226780.0816931 0.752081 0.563501 0.358153 0.244927 -0.532607]
==============================
layer17_wv's output 
<N9nntrainer6TensorE at 0x5682def70150>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.94471 -1.1771 0.439853-0.419611 0.35281 -0.0350813 -0.527458 -0.84754 -1.3832]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0524922 -0.0537402 -0.09756370.266627 0.251953 -0.087548 -0.347176 0.316457 0.298744]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2298d08
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer17_attention_out's input 
<N9nntrainer6TensorE at 0x5682def72870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer17_attention_out's output 
<N9nntrainer6TensorE at 0x5682def727d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer17_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def738f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.40486 0.219138 -0.06938780.0358294 0.455234 0.211325 0.153822 0.144042 -0.285638]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.91587 0.550459 -0.1555270.0906932 1.02477 0.567585 0.389361 0.34095 -0.634713]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.02730626427 -1.069718957 -1.153170466 1.221750617 -2.066622972 -0.6677621007 -0.7245548368 -0.7949968576 -0.4414895177 -1.43932271 -1.94204855 -0.9670998454 0.1795118153 -0.2821341157 -0.05507342517 -0.2822469175 0.2484291792 -1.22727263 -0.05082730949 -1.032768846 -1.087264657 -1.23376894 -1.694174886 0.5322695971 -1.270576835 -0.889942646 -0.7890108824 -1.251397491 1.160098314 -0.435328722 -1.485999465 -0.008478671312 -1.682764173 -2.35131669 -0.5163273811 -0.3666296601 -0.8657974005 -1.863427281 -1.073807955 -0.5735812187 -1.754856706 -0.1780351698 -1.234422684 0.2845253944 -2.078668356 -0.7848764062 0.08920755982 -0.5364621878 -1.624352455 -0.9305257797 -1.41782701 -1.152937055 -0.9347455502 -0.1895541549 1.260882735 0.2797592282 -0.7419340014 -0.0863994956 -0.2757208943 -1.148961782 -1.375760078 0.1735088974 -0.2640367746 -0.1926818788 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0220124498 0.007761654444 0.007140222937 0.07675857842 0.002864207374 0.0116017079 0.0109611759 0.01021561678 0.01454758272 0.005363366567 0.003244190244 0.008600451984 0.02707000449 0.01706074737 0.0214096345 0.01705882326 0.02900138684 0.006630245596 0.02150073647 0.00805381313 0.007626658771 0.006587312091 0.004156775307 0.03852025047 0.006349256262 0.00929030776 0.0102769509 0.006472205743 0.07216915488 0.01463748515 0.005118774716 0.02243081853 0.004204478581 0.002154584508 0.01349861547 0.01567841321 0.009517355822 0.003509547794 0.007729982957 0.01274747588 0.003912035376 0.01893248782 0.006583007518 0.03006735072 0.002829913748 0.01031952724 0.02473259531 0.01322954148 0.004457383417 0.008920826018 0.005479903426 0.007141890004 0.008883263916 0.01871565729 0.07982184738 0.02992438525 0.01077232696 0.02074935101 0.01717051305 0.007170338184 0.005715342704 0.02690799162 0.01737231202 0.01865720935 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
22.12599373 22.11984825 22.12065887 22.18264771 22.11352158 22.11892128 22.12447929 22.12373352 22.12758827 22.11888123 22.11485481 22.12164116 22.13248062 22.12962532 22.13445091 22.13105392  22.142519 22.12062454 22.12119102 22.12109566 22.11733055 22.11533737 22.11528969 22.14917755 22.11939049 22.11851692 22.12427139 22.1199894 22.17710304 22.12672424 22.11816025 22.13547134 22.11676788 22.11567307 22.12701607 22.1206131 22.12255859 22.11655045 22.11791039 22.12578773 22.11742973 22.12482071 22.12010002 22.13977051 22.10824203 22.12431335 22.13491249 22.12674713 22.11320686 22.12243843 22.11899757 22.12018204 22.1033268 22.12412643 22.18761826 22.14010429 22.1247673 22.13045311 22.12878036 22.11591911 22.11875534 22.1399498 22.13136673 22.12979126 

-------
======================
selected experts : 3, 23, 28, 43, 54, 55, 
layer17_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def76b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.253826 -0.0186747 0.03773680.0680806 -0.473988 0.129516 -0.478414 0.0785916 -0.034919]

layer17_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def761f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.65869 0.200463 -0.03165090.10391 -0.0187538 0.340841 -0.324593 0.222634 -0.320557]

layer18_wq's input 
<N9nntrainer6TensorE at 0x5682defb6420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.10791 0.463276 -0.06257080.239174 -0.0339414 0.879432 -0.750142 0.394667 -0.64561]
==============================
layer18_wq's output 
<N9nntrainer6TensorE at 0x5682def760a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.10673 -0.153221 0.5897311.9506 1.29427 -2.68213 1.67582 1.40147 -1.31853]
============================
layer18_wk's input 
<N9nntrainer6TensorE at 0x5682defb8180>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.10791 0.463276 -0.06257080.239174 -0.0339414 0.879432 -0.750142 0.394667 -0.64561]
==============================
layer18_wk's output 
<N9nntrainer6TensorE at 0x5682defb7ef0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.28275 1.297 -0.2089410.677472 1.33644 0.660171 -0.293485 1.65407 -1.16858]
============================
layer18_wv's input 
<N9nntrainer6TensorE at 0x5682defb8f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.10791 0.463276 -0.06257080.239174 -0.0339414 0.879432 -0.750142 0.394667 -0.64561]
==============================
layer18_wv's output 
<N9nntrainer6TensorE at 0x5682defb8d00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.591238 0.102822 -0.5731520.478514 0.657506 -1.73205 0.866751 -0.900636 0.185941]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.85636 1.00783 -1.396141.48438 0.41209 -2.94943 1.64027 -1.44292 2.43184]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a249dd18
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer18_attention_out's input 
<N9nntrainer6TensorE at 0x5682defbb420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer18_attention_out's output 
<N9nntrainer6TensorE at 0x5682defbb380>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer18_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682defbc4a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.65869 0.200463 -0.03165090.10391 -0.0187538 0.340841 -0.324593 0.222634 -0.320557]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.45462 0.491184 -0.07108980.258463 -0.0421222 0.885759 -0.807382 0.516579 -0.711064]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.062613368 -0.3103205264 -0.813877821 -0.05949025229 -1.83977294 -2.380988598 -1.19530642 0.3794342577 0.3779788911 -2.770207644 0.5257703662 -2.53913641 -0.9748841524 -1.182571411 -2.624329329 -1.193560004 0.9496892095 0.1868463457 -0.9716626406 -0.2941969931 -0.9582231045 0.3939257562 -1.022436738 -0.07888153195 -1.747231841 -0.07336111367 -0.8625987768 0.2567335069 -2.161632538 0.2967662215 -0.8609887362 1.667371035 0.07463056594 -0.2470603138 -0.6184720993 -0.4640968144 -1.307123542 -0.8273018599 -1.310783267 -0.7721133828 0.4477494657 -1.912881017 -0.8133640289 1.033631086 -0.767663002 0.2045336962 -0.9569313526 -1.185732603 1.950773239 -0.01261408255 -1.979505777 -1.264241338 0.571731925 -0.2704636157 -0.9788761139 0.2174901217 -0.8327384591 -1.441499591 -1.883395791 -1.240181923 0.1753808558 -0.3174679875 -0.3530494571 0.9615533352 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005993448198 0.01271725539 0.00768601615 0.01634284481 0.002755248221 0.001603665296 0.005248666741 0.02534837648 0.02531151287 0.00108662108 0.02934290655 0.001369086909 0.006543003954 0.005315935705 0.001257280237 0.005257840268 0.04483412579 0.02090789378 0.006564116571 0.01292396523 0.006652929354 0.02571838722 0.006239148788 0.01602898911 0.003022391582 0.01611771993 0.007320521399 0.02242135629 0.001997003565 0.02333715372 0.007332318462 0.09189544618 0.01868855022 0.0135477446 0.009344690479 0.01090458781 0.004693397786 0.00758352736 0.004676252604 0.00801381655 0.02714057639 0.002561004367 0.007689965889 0.0487600565 0.008049559779 0.02128098905 0.006661529187 0.005299157463 0.12200398 0.01712717302 0.002395937452 0.004899039865 0.03072302416 0.01323436294 0.006516935769 0.02155850641 0.007542411797 0.004103255458 0.002637640573 0.005018336698 0.02066954225 0.0126266852 0.01218530722 0.04536921531 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
24.21902084 24.21716309 24.21976089 24.22603226 24.21578407 24.21510887 24.21827698 24.23885345 24.2373867 24.21459198 24.23855591 24.21392059 24.21766281 24.21691322 24.21476173 24.21828651 24.2502327 24.2325058 24.21863747 24.22547531 24.2134819 24.23207092 24.21926689 24.22858047 24.21557426 24.22771454 24.21939468 24.22829628 24.19928932 24.23636436 24.21892929 24.30540085 24.23028564 24.21846962 24.22237206 24.22345543 24.21819878 24.20630646 24.2167511 24.22008896 24.23969078 24.21558952 24.21976471 24.26131058 24.2215538 24.23001671 24.2168293 24.21689606 24.33503151 24.22920227 24.21542358 24.21840477 24.23469162 24.22626305 24.2200222 24.23124886 24.22056961 24.21713066 24.21566582 24.21804619 24.23083687 24.22470093 24.22473717 24.25839806 

-------
======================
selected experts : 16, 31, 43, 48, 52, 63, 
layer18_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682defbf6e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.560586 0.0277587 -0.1215660.0890109 -0.0883643 -0.106343 -0.0221612 0.0365498 -0.135021]

layer18_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682defbeda0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.21927 0.228222 -0.1532170.192921 -0.107118 0.234498 -0.346754 0.259184 -0.455578]

layer19_wq's input 
<N9nntrainer6TensorE at 0x5682deffefd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.33037 0.452046 -0.2608050.377646 -0.173219 0.522538 -0.68146 0.419121 -0.835404]
==============================
layer19_wq's output 
<N9nntrainer6TensorE at 0x5682defbec50>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0782116 -0.28653 -0.0172082-0.619468 -0.0762679 -0.593608 0.282658 -0.80718 -0.135468]
============================
layer19_wk's input 
<N9nntrainer6TensorE at 0x5682df001130>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.33037 0.452046 -0.2608050.377646 -0.173219 0.522538 -0.68146 0.419121 -0.835404]
==============================
layer19_wk's output 
<N9nntrainer6TensorE at 0x5682df001100>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[1.05797 -0.676246 0.9896371.00173 0.42944 -0.338087 0.795811 1.07648 -0.594723]
============================
layer19_wv's input 
<N9nntrainer6TensorE at 0x5682df002000>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.33037 0.452046 -0.2608050.377646 -0.173219 0.522538 -0.68146 0.419121 -0.835404]
==============================
layer19_wv's output 
<N9nntrainer6TensorE at 0x5682df001d90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.917758 -0.238449 -0.2498290.0371437 1.04362 0.315361 0.489691 0.719257 0.336181]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.189345 0.228834 0.528251-0.324018 -0.254137 -0.54185 -0.754737 -0.402252 -0.275156]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a28a7d38
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer19_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0044b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer19_attention_out's output 
<N9nntrainer6TensorE at 0x5682df004410>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer19_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df005580>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.21927 0.228222 -0.1532170.192921 -0.107118 0.234498 -0.346754 0.259184 -0.455578]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.9355 0.480299 -0.3034820.411978 -0.209686 0.522538 -0.756582 0.517384 -0.891803]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2560965121 0.5607023835 1.380713105 -1.156835437 -1.137527227 -0.9903067946 -1.374790668 -1.243409276 -1.533348918 -1.82641983 -0.8730707169 0.501588583 -1.044003844 -0.9129401445 -1.779503822 -2.349038363 -1.573071957 0.2331105024 -1.77170682 -1.189740181 -0.1851579547 -0.1333834082 0.828663528 -0.5412015915 -0.8152538538 -1.159140587 -1.81690979 -0.7082381845 0.1524386406 -0.7536927462 -0.3860671818 -0.6523693204 -0.5111266375 -1.121736884 -0.5304392576 -0.4721988142 0.4311973155 -0.5876043439 1.234532952 -0.3707628846 -1.116874456 -0.5162636638 -1.205090284 -0.6366769671 -1.703146935 -0.2628949583 -1.272262096 -0.930413425 -0.8881460428 -0.6206386685 -0.490003556 -0.1590138078 -0.4007500708 -0.7877420187 -1.791340947 -0.6367516518 -0.6509783864 -1.25172472 -0.5542578101 -0.6510242224 0.4458911121 1.347165823 -1.530253649 -2.132788897 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01686263829 0.03816425428 0.08665286005 0.006850772537 0.006984333508 0.008092115633 0.005509127863 0.006282622926 0.004701341968 0.003507056739 0.00909865275 0.03597360477 0.007669052109 0.008743029088 0.003675514599 0.00207956438 0.0045182514 0.02750333957 0.003704283852 0.006629019044 0.01810229942 0.01906422339 0.04989198968 0.01267961133 0.009640211239 0.006834999658 0.003540568054 0.01072908845 0.02537173033 0.01025232114 0.01480743941 0.01134557184 0.01306674257 0.007095494773 0.01281681098 0.0135854315 0.03352844343 0.01210468449 0.07486824691 0.01503579877 0.007130078971 0.01299979072 0.006528038532 0.01152501628 0.003967158496 0.01674838737 0.006103943102 0.008591587655 0.00896251481 0.01171134692 0.01334568765 0.01858180761 0.01459161192 0.009909112938 0.00363226328 0.01152415574 0.01136136334 0.00623059785 0.01251513977 0.0113608446 0.03402474523 0.08379410952 0.004715915769 0.002581596142 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.26359749 26.27917671 26.32623482 26.25310898 26.25419617 26.24576759 26.25081253 26.25301743 26.25143623 26.25024223 26.25011063 26.28175545 26.25297356 26.25547791 26.25041008 26.24929047 26.25125313 26.27137756 26.24996185 26.25288773 26.2653141 26.26532173 26.29138184 26.25798416 26.2568512 26.25357056 26.25027466 26.25698662 26.27162933 26.25460243 26.2620182 26.25855637 26.2602787 26.25430679 26.25764465 26.25936699 26.27835655 26.25645447 26.32160378 26.25366402 26.25386429 26.25973511 26.25326347 26.2553978 26.24450302 26.26348305 26.25283813 26.25532532 26.25474358 26.25415421 26.2596035 26.26436234  26.260849 26.2528286 26.23701477 26.25873566 26.25761986 26.25344276 26.25972748 26.25332642 26.28123665 26.32814407 26.25144958 26.24836159 

-------
======================
selected experts : 1, 2, 11, 22, 38, 61, 
layer19_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df008b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.302106 0.0097258 -0.285841-0.0748007 -0.230624 -0.0890906 -0.0904621 -0.372348 0.37356]

layer19_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df008060>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.52138 0.237948 -0.4390580.11812 -0.337743 0.145408 -0.437216 -0.113164 -0.082018]

layer20_wq's input 
<N9nntrainer6TensorE at 0x5682df047b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60653 0.37066 -0.6731660.17748 -0.470188 0.233641 -0.678386 -0.149907 -0.118205]
==============================
layer20_wq's output 
<N9nntrainer6TensorE at 0x5682df007f10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.07461 -0.517926 -0.684738-0.743797 1.84935 0.4878 1.43956 -0.376304 1.23786]
============================
layer20_wk's input 
<N9nntrainer6TensorE at 0x5682df0498e0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60653 0.37066 -0.6731660.17748 -0.470188 0.233641 -0.678386 -0.149907 -0.118205]
==============================
layer20_wk's output 
<N9nntrainer6TensorE at 0x5682df049650>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.186323 -1.42675 1.10225-1.13125 -0.496273 0.775429 0.251476 0.979608 0.500795]
============================
layer20_wv's input 
<N9nntrainer6TensorE at 0x5682df04a6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.60653 0.37066 -0.6731660.17748 -0.470188 0.233641 -0.678386 -0.149907 -0.118205]
==============================
layer20_wv's output 
<N9nntrainer6TensorE at 0x5682df04a460>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.877532 -0.0883245 0.607350.314175 0.0202026 0.753049 -1.47165 -0.321368 0.507924]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.19256 0.0290313 0.302909-0.964545 1.90993 -0.10109 -0.152751 -1.48007 -1.89781]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2cb1d58
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer20_attention_out's input 
<N9nntrainer6TensorE at 0x5682df04cb80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer20_attention_out's output 
<N9nntrainer6TensorE at 0x5682df04cae0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer20_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df04dc00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.52138 0.237948 -0.4390580.11812 -0.337743 0.145408 -0.437216 -0.113164 -0.082018]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.95207 0.41152 -0.7270190.205732 -0.546827 0.263961 -0.782959 -0.187384 -0.133798]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4138334095 -0.7941479683 -0.9165152907 -2.569709539 -1.421836019 -0.1668744236 -0.9031383395 -2.294758081 -1.237062454 -0.1760980487 -0.3693721592 -0.1580355465 -1.632927299 0.4013758898 -1.187618256 -0.1161043495 -0.6882314682 -0.03248381615 -0.8780407906 -0.3582237363 0.6017161012 -2.62579751 -0.9137005806 -0.3008619547 -1.031279802 -0.5180200934 -0.8078605533 0.3422093987 -1.578213811 -0.4726060033 -0.7385864258 -0.6835306287 -0.1002677679 -1.033990622 0.3952358961 -1.323274851 0.8766098619 1.240920305 -0.342014432 -0.6332079172 -1.222097993 -0.6673287749 -1.852769852 -1.920262098 -0.04423336685 -0.7442017794 -1.4834162 0.1318867505 1.003386855 0.03271181881 -0.3037775457 -2.032606363 -1.716417551 0.04686329514 -0.2210749388 -1.228260994 -0.8499057293 -0.2385745198 -0.2812626958 -0.5164778829 -0.6176597476 -0.6172142625 -0.09065865725 -1.061925769 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01473560743 0.01007394399 0.008913659491 0.00170640822 0.005377717782 0.01886344329 0.009033697657 0.002246429678 0.006469104905 0.01869025268 0.01540555339 0.01903091371 0.004354340024 0.03329729289 0.006797004491 0.01984586939 0.01119949669 0.02157675289 0.009263291024 0.01557826251 0.04068324715 0.001613333821 0.008938784711 0.01649798453 0.007947205566 0.01327762194 0.00993674621 0.03138435632 0.004599218257 0.01389451697 0.0106495088 0.01125226822 0.02016266063 0.007925692014 0.03309347481 0.005934752524 0.053555049 0.07709362358 0.01583283208   0.011833 0.006566638593 0.01143605821 0.00349498936 0.003266888903 0.02132471837 0.01058987528 0.005056547001 0.02543145977 0.06079375744 0.0230303295 0.01644995436 0.002919737948 0.004005557392 0.0233585611 0.01786824688 0.006526293699 0.009527615272 0.01755828224 0.01682452485 0.01329811662 0.0120184198 0.01202377584 0.02035734057 0.007707351353 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.40888786 25.40517998 25.40592575 25.39919662 25.40143585 25.41635323 25.40127754 25.39925957 25.40348244 25.40950394 25.41194153 25.41318321 25.40136719 25.42983246 25.4038105 25.41542816 25.40249062 25.41286659 25.40436935 25.41163635 25.43769646 25.39862633 25.40070534 25.41208076 25.40162277 25.41028976 25.40218163 25.42791939 25.39588928 25.41090775 25.40766144  25.408741 25.41622162 25.40398407 25.43010712 25.40247154 25.45056725 25.46504593 25.40855408 25.40693855 25.40357971 25.40701866 25.39859962 25.40075684 25.41690636 25.40807915 25.40206909 25.42244339 25.4573288 25.41956711 25.41107941 25.39993286 25.38671303 25.42037201 25.41392708 25.40258598 25.40701675 25.4112339 25.41145325 25.40697289 25.4076004 25.40760612 25.41260147 25.39995193 

-------
======================
selected experts : 13, 20, 34, 36, 37, 48, 
layer20_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df050e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.27992 -0.123736 0.109519-0.0913493 0.248634 0.13094 0.216233 -0.0920996 0.00966147]

layer20_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df050500>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.24146 0.114212 -0.3295390.026771 -0.0891088 0.276347 -0.220983 -0.205264 -0.0723565]

layer21_wq's input 
<N9nntrainer6TensorE at 0x5682df091030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.96238 0.168701 -0.4394620.0374619 -0.117234 0.439588 -0.314518 -0.266368 -0.100819]
==============================
layer21_wq's output 
<N9nntrainer6TensorE at 0x5682df0503b0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.15064 0.0532157 -0.042246-0.203928 0.30255 -0.100603 -0.534653 -0.137248 0.0665243]
============================
layer21_wk's input 
<N9nntrainer6TensorE at 0x5682df092d90>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.96238 0.168701 -0.4394620.0374619 -0.117234 0.439588 -0.314518 -0.266368 -0.100819]
==============================
layer21_wk's output 
<N9nntrainer6TensorE at 0x5682df092b00>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0929967 -0.866341 0.09207010.728006 0.901695 1.11479 1.49877 -0.121993 -0.628814]
============================
layer21_wv's input 
<N9nntrainer6TensorE at 0x5682df093b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.96238 0.168701 -0.4394620.0374619 -0.117234 0.439588 -0.314518 -0.266368 -0.100819]
==============================
layer21_wv's output 
<N9nntrainer6TensorE at 0x5682df093910>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.24552 -1.54342 0.110974-0.205941 -1.38733 0.791705 -0.401286 -0.701056 -0.336938]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.115321 -0.110568 0.155646-0.138368 0.257293 -0.188303 -0.217046 0.507525 0.349009]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1f914f0
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer21_attention_out's input 
<N9nntrainer6TensorE at 0x5682df096030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer21_attention_out's output 
<N9nntrainer6TensorE at 0x5682df095f90>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer21_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0970b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.24146 0.114212 -0.3295390.026771 -0.0891088 0.276347 -0.220983 -0.205264 -0.0723565]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.79932 0.206266 -0.5754390.0486684 -0.15347 0.528828 -0.417595 -0.360885 -0.124618]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.1783123165 -0.29889974 -0.5538125634 0.3373761773 -0.472266376 -0.7141254544 -1.454328179 0.2542715371 -0.7339566946 -1.226141095 -1.311332822 -0.9130453467 -0.2845664322 0.2438750714 -0.8389728665 -1.112065434 -0.823212266 -0.7511786819 -0.5577736497 -0.945778966 -2.06117177 -0.1704679281 -0.1381780356 -1.486085892 -0.07875689864 -0.2048711777 0.07434412837 -0.4823636711 -0.7482740283 -2.119517803 -0.8294374347 -1.46167469 -1.50707984 -0.399132967 -0.5167472959 -1.082633853 -0.6440500021 0.2263461798 -1.25105834 2.997587919 -0.533398509 -0.1614771187 -0.9952273965 -1.202630043 -0.3438590467 -1.079587579 -0.7780657411 -1.948967695 -0.2780954838 -0.7075446844 -0.2848754823 -1.309324741 -0.4318304956 -1.394148946 -0.9812729359 1.677747846 -0.4324631393 -0.1824264973 -0.516405642 0.2792288959 -0.6079953313 0.2241086811 -0.6234211326 -0.5771641731 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01918534376 0.01190471742 0.009225965478 0.02249314077 0.01000983268 0.007859389298 0.003749063471 0.02069942281 0.007705063559 0.004710024688 0.004325386137 0.006441676989 0.0120765781 0.02048533782 0.006936945021 0.005279169418 0.007047140971 0.007573502138 0.009189493023 0.006234230939 0.00204349705 0.01353618503 0.01398039889 0.003631872125 0.01483630948 0.01307841484 0.01729086787 0.0099092694 0.007595532574 0.001927679172 0.00700340746 0.003721621353 0.003556420328 0.01076931972 0.009574345313 0.005436854437 0.008429896086 0.02012938447 0.004594114609 0.3216365874 0.009416241199 0.01365843415 0.005933457054 0.004822073504 0.01138134208 0.005453440361 0.007372586988 0.002286144067 0.01215497777 0.00791128166 0.01207284816 0.004334082361 0.01042288635 0.003981606103 0.006016835105 0.0859342292 0.01041629259 0.01337527577 0.009577617049 0.02122252807 0.008739378303 0.02008439414 0.008605599403 0.009013019502 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.65747643 25.65019608 25.64703941 25.66030693 25.64639282 25.64567375 25.64204025 25.65660477 25.64551926 25.64204597 25.63164902 25.63567162 25.64655304 25.65639114 25.64522743 25.64309311 25.64533806 25.64586449 25.64461899 25.64452553 25.63985634 25.65182686 25.65179443 25.64049149 25.65312576 25.65041542 25.65510368 25.64676857 25.64588547 25.64021873 25.64529419 25.64058113 25.64089394 25.64858246 25.64643478 25.64277267 25.64672089 25.65794373 25.64050102 25.95897293 25.64770699 25.65194893 25.64279366 25.64263535 25.64538002 25.64326668 25.64566231 25.64010048 25.64520073 25.64334106 25.65036392 25.6388092 25.64060783 25.64227295 25.64430809 25.72231674 25.64346123 25.6511879 25.63976097 25.65903664 25.64559937 25.65789795 25.64498901 25.64634895 

-------
======================
selected experts : 3, 7, 13, 39, 55, 59, 
layer21_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df09a2f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.643184 0.222712 -0.7929290.183264 0.747842 0.786664 0.0493223 0.199264 -0.0933151]

layer21_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df0999b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.88464 0.336924 -1.122470.210035 0.658733 1.06301 -0.171661 -0.00599937 -0.165672]

layer22_wq's input 
<N9nntrainer6TensorE at 0x5682df0d9be0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.15133 0.400246 -1.261070.249509 0.755238 1.36069 -0.190486 -0.00662968 -0.19986]
==============================
layer22_wq's output 
<N9nntrainer6TensorE at 0x5682df099860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.546149 1.16361 0.626299-1.24008 -0.672939 1.76016 -0.502856 -0.075978 -2.78427]
============================
layer22_wk's input 
<N9nntrainer6TensorE at 0x5682df0db940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.15133 0.400246 -1.261070.249509 0.755238 1.36069 -0.190486 -0.00662968 -0.19986]
==============================
layer22_wk's output 
<N9nntrainer6TensorE at 0x5682df0db6b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.747404 2.64771 1.071541.4648 -1.04922 -0.578845 1.52732 -0.831963 -0.0360067]
============================
layer22_wv's input 
<N9nntrainer6TensorE at 0x5682df0dc730>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.15133 0.400246 -1.261070.249509 0.755238 1.36069 -0.190486 -0.00662968 -0.19986]
==============================
layer22_wv's output 
<N9nntrainer6TensorE at 0x5682df0dc4c0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.654865 0.853878 0.4372470.199922 -0.88083 0.138692 0.835335 -0.370026 0.868068]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.977158 -0.835122 1.38718-0.0760219 -0.102454 1.88163 -0.15165 0.485427 0.74813]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a30bbd78
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer22_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0debe0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer22_attention_out's output 
<N9nntrainer6TensorE at 0x5682df0deb40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer22_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0dfc60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.88464 0.336924 -1.122470.210035 0.658733 1.06301 -0.171661 -0.00599937 -0.165672]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.43586 0.511943 -1.66420.315271 0.952389 1.69352 -0.265574 -0.00895006 -0.239526]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7397916913 -0.4645708799 -1.015678048 -0.1586270481 2.572156906 -1.184009671 0.1542642117 -0.7809244394 1.002029419 -0.7511141896 -0.4391508102 -0.6108403206 -0.4246154726 -1.049105287 -0.07224667072 -0.260074079 -1.30487287 0.001101973467 -1.751760244 -0.5972699523 0.02286567539 2.529406548 -1.568264842 0.06576365978 -2.270291805 -1.031431913 -0.950517118 -0.2471860498 -0.7377126217 -1.35686934 -1.336291909 -1.579776406 -0.5386202931 -0.6078422666 -0.1715735197 -2.634065151 -0.8631902933 0.9276689887 1.088684678 -0.5127094984 0.7183439732 -0.5988658071 0.1742632091 -0.2389595211 -0.3931342363 -0.6965096593 -1.324651122 -0.9061495662 -1.457275152 -0.810759604 -0.3742614985 -1.45335412 -0.3097060919 -0.9273035526 -1.475761294 -0.845074892 -1.814042211 -0.7738408446 -0.5757521391 0.7166854739 -0.4288810194 -0.4447434545 0.2580054104 -1.245664835 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.006957845762 0.009162238799 0.005280303769 0.01244146097 0.1909131259 0.004462245386 0.01701211557 0.006677457131 0.03971349075 0.006879509892 0.009398129769 0.007915486582 0.00953573361 0.00510671502 0.01356394216 0.01124121994 0.003954240587 0.01459623408 0.002529195044 0.008023634553 0.01491738483 0.1829235107 0.003038599156 0.01557123382 0.001505868393 0.005197769962 0.005635829642 0.01138703711 0.006972326431 0.003753888886 0.003831934649 0.003003821475 0.008508292958 0.007939253934 0.01228142437 0.001046651974 0.006150119007 0.0368675068 0.04330838472 0.008731628768 0.0299043972 0.008010840975 0.01735576615 0.01148109697 0.009840706363 0.007265607361 0.003876801115 0.005891507491 0.003395279869 0.006481176242 0.01002819091 0.003408620367 0.01069691405 0.00576818781 0.00333309127 0.006262545008 0.0023764777 0.006724923849 0.008198156022 0.02985484339 0.00949514471 0.009345716797 0.01887176558 0.004195433576 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.01233864 27.01454353 27.00875282 27.01639175 27.19676971 27.00459862 27.02096176 27.01062775 27.04557037 27.0117836 27.01525497 27.01329613 27.01491547 27.01000977 27.01608276 27.01709938 27.00933456 27.02045441 27.00838661 27.00720596 27.01886749 27.1883049 27.00889587 27.01523018 27.00736427 27.01057816 27.01149368 27.01533699 27.01187706 27.00961113 27.00921249 27.00695419 27.01102829 27.01379585 27.00764847 27.00404358 27.00676155 27.03652573 27.04296684 27.01220512 27.03528595 27.01196098 27.0227356 27.01686096 27.01569748 27.01121521 27.00973511 27.01031876 27.00925255 27.01233864 27.01588631 27.00735855 27.01083183 27.01162529 27.00871277 27.01116562 27.00823402 27.00876808 27.01405525 27.03523636 27.01296806 27.01520348 27.02425194 27.01005363 

-------
======================
selected experts : 4, 8, 21, 37, 38, 40, 
layer22_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df0e2e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.488194 0.377901 0.466394-0.0167934 -0.273322 0.297149 -0.392417 -0.31235 -0.740184]

layer22_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dde69cd0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.39645 0.714826 -0.6560750.193241 0.385411 1.36016 -0.564077 -0.318349 -0.905855]

layer23_wq's input 
<N9nntrainer6TensorE at 0x5682de368560>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88793 0.625983 -0.5816860.159394 0.345913 1.2603 -0.483722 -0.260274 -0.776812]
==============================
layer23_wq's output 
<N9nntrainer6TensorE at 0x5682de2bfbc0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.81287 2.46712 -3.204050.161744 -0.160598 2.96982 -1.30325 1.66376 -2.68029]
============================
layer23_wk's input 
<N9nntrainer6TensorE at 0x5682de266760>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88793 0.625983 -0.5816860.159394 0.345913 1.2603 -0.483722 -0.260274 -0.776812]
==============================
layer23_wk's output 
<N9nntrainer6TensorE at 0x5682de82d610>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[2.31819 1.55241 -2.13453-1.49608 -1.32869 1.37024 -0.700615 -1.14271 -0.10444]
============================
layer23_wv's input 
<N9nntrainer6TensorE at 0x5682de40ebf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88793 0.625983 -0.5816860.159394 0.345913 1.2603 -0.483722 -0.260274 -0.776812]
==============================
layer23_wv's output 
<N9nntrainer6TensorE at 0x5682de7736d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0659388 0.12311 0.4507320.32833 -1.39694 -0.600461 -0.907153 -1.79537 1.35136]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-2.6685 -1.50075 -1.73894-2.69595 0.755252 2.87667 1.44595 1.54135 0.437631]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a32c0d88
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer23_attention_out's input 
<N9nntrainer6TensorE at 0x5682ddf81aa0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer23_attention_out's output 
<N9nntrainer6TensorE at 0x5682de55e330>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer23_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0fe910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.39645 0.714826 -0.6560750.193241 0.385411 1.36016 -0.564077 -0.318349 -0.905855]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.82589 0.919493 -0.8343850.245761 0.487359 1.82868 -0.750179 -0.404871 -1.13889]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.872992158 0.2064440399 -1.035467386 -0.640977025 -0.1961841881 -0.1090170741 -0.34689942 -1.025684476 -0.8059713244 -1.519582868 -1.232269287 -0.7925223112 -0.03936348855 0.9528845549 -0.4500332177 1.322859287 0.7175119519 0.7044981122 1.78325367 -0.5533096194 -0.7680734396 -0.7863910198 -1.033133268 -0.03407310322 -1.032354474 -0.9097954631 -0.4200244546 -0.2161732614 -0.6270029545 -0.3525469303 -0.06292621791 0.7336152792 -0.673283577 0.5641796589 -0.1569390148 -0.8231748343 -0.2828865051 -0.728974402 -0.8087525368 -0.003392666578 -2.537916422 -1.832093239 0.2140242308 -2.572942972 -0.5260803699 -0.7155008912 -1.603597641 -0.6312178969 0.1997449249 -0.2652683854 -2.51944685 -1.796715975 2.482131004 -0.3266799748 -0.3935008347 -1.422336698 -0.2271452546 -0.5259958506 -0.9059403539 0.8565720916 -0.8876277208 -1.621199846 -0.04766143113 -1.352401018 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.002359084319 0.01887257025 0.005450995173 0.008087249473 0.01261745673 0.01376664173 0.01085218042 0.00550458394 0.006857165601 0.003359132679 0.004477193113 0.00695001008 0.01475972496 0.03981127217 0.00978873577 0.05763470009 0.03146190196 0.03105511516 0.0913336426 0.008828241378 0.007122023962 0.006992754061 0.005463732872 0.01483801473 0.005467990413 0.006180937402 0.01008693594 0.01236775145 0.008201053366 0.01079106703 0.01441600733 0.03197265044 0.007830152288 0.02698942646 0.01312247664 0.006740206853 0.01156957727 0.00740600517 0.006838120986 0.01530030556 0.001213306561 0.002457568189 0.01901617274 0.001171544311 0.009071931243 0.007506465539 0.003088445636 0.008166558109 0.01874656416 0.01177521888 0.00123592373 0.002546067117 0.1837169975 0.01107383985 0.01035805792 0.003702206304 0.0122327935 0.009072699584 0.006204812787 0.03615581244 0.006319486536 0.003034558613 0.01463775244 0.003970390651 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.91904831 26.93460846 26.92214012 26.92429924 26.92739868 26.92997932 26.92611122 26.92171669  26.923069 26.92004776 26.92116547 26.92030144 26.93097115 26.95459366 26.9260006 26.97241592 26.94099808 26.94726753 27.00563812 26.92170334 26.92333412 26.92320442 26.92215347 26.93152618 26.92215729 26.92144012 26.92439079 26.92905617 26.92489052 26.92652702 26.93015099 26.94627762 26.92118073 26.94034004 26.92838097 26.92247581 26.9282589 26.92314148 26.92304993 26.92817497 26.91504097 26.91866875 26.93570518 26.91690636 26.92480659 26.92371941 26.91643906 26.92008781 26.93495941 26.9260807 26.91792488 26.91875839 27.10040665 26.92633247 26.92323303 26.91848373 26.92749214 26.91908646 26.92241669 26.95189095 26.92300797 26.91733932 26.93132591 26.91922951 

-------
======================
selected experts : 13, 15, 18, 31, 52, 59, 
layer23_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee1eb60>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.506976 0.458975 -0.696784-1.91816 -0.823732 0.977666 0.0765063 1.047 0.0117463]

layer23_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de7806d0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.90343 1.1738 -1.35286-1.72492 -0.43832 2.33783 -0.487571 0.728649 -0.894109]

layer24_wq's input 
<N9nntrainer6TensorE at 0x5682de5e9620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.51394 0.90817 -1.07843-1.27391 -0.357113 1.82248 -0.362945 0.518912 -0.686532]
==============================
layer24_wq's output 
<N9nntrainer6TensorE at 0x5682de23a580>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.47825 -0.488654 0.184464-0.519587 0.487288 -0.0527524 -0.216239 0.226775 -0.161041]
============================
layer24_wk's input 
<N9nntrainer6TensorE at 0x5682de680bc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.51394 0.90817 -1.07843-1.27391 -0.357113 1.82248 -0.362945 0.518912 -0.686532]
==============================
layer24_wk's output 
<N9nntrainer6TensorE at 0x5682de1e9fa0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00326021 1.4771 1.20550.866987 -0.189965 0.885759 -0.672452 0.556131 0.303197]
============================
layer24_wv's input 
<N9nntrainer6TensorE at 0x5682de7cdb70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.51394 0.90817 -1.07843-1.27391 -0.357113 1.82248 -0.362945 0.518912 -0.686532]
==============================
layer24_wv's output 
<N9nntrainer6TensorE at 0x5682de067420>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.291303 3.60319 -1.58111-0.0753707 2.08941 -3.37433 2.6696 -1.44074 0.555183]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.234365 0.642323 0.542325-0.0994077 0.447814 -0.199236 0.19121 0.248244 0.471909]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a36cada8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer24_attention_out's input 
<N9nntrainer6TensorE at 0x5682de40b530>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer24_attention_out's output 
<N9nntrainer6TensorE at 0x5682de646540>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer24_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de7c4940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.90343 1.1738 -1.35286-1.72492 -0.43832 2.33783 -0.487571 0.728649 -0.894109]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.0039 1.3829 -1.57006-2.02208 -0.503555 2.8639 -0.597287 0.854176 -1.03242]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.369717717 0.4141850471 -0.1664281189 0.3237210214 -0.750937283 -0.8741667867 -0.1055953726 -1.083861828 -0.4515500367 -0.7865809202 -1.144575119 -0.08553080261 -0.3235462606 -0.9011095762 -0.8509297967 0.184768945 -0.1499087811 -0.6074998379 -0.9416130185 -0.3370392323 -0.6768990755 -0.3038922846 -0.9472158551 -0.4724726975 -0.1225259677 0.7403610349 -0.8168305159 -1.12814188 -0.7372927666 -0.6504989862 -0.9537336826 -0.6664224863 -0.2640016377 0.5276591778 -0.6773705482 -0.5016269684 -0.7963917255 0.2570232451 -0.4677351713 -0.005658693612 -0.9181857705 0.3472033143 -0.233420372 -1.923967242 -0.7331756353 0.5005047917 -1.65133512 -0.4732036889 -0.7726078033 -0.7602410913 -0.958774209 0.01471002214 -1.592873096 -0.923161149 0.342824012 -0.5423586369 -0.1020421833 -0.0777990818 -0.727165103 -1.42258203 -0.2568499744 -1.058764815 -0.324097693 0.5694395304 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.08025097102 0.03086510301 0.01727072708 0.02819549479 0.00962634664 0.008510274813 0.018353967 0.006900400389 0.01298624929 0.00928927213 0.006493918132 0.01872595213 0.01475961693 0.008284046315 0.008710343391 0.0245376844 0.01755839773 0.01111106295 0.007955217734 0.01456180308 0.01036611199 0.01505257189 0.007910770364 0.01271736529 0.01804584078 0.04276851192 0.00901248306 0.006601516157 0.009758595377 0.01064342353 0.007859376259 0.01047528442 0.01566516608 0.03457394242 0.01036122721 0.01235195249 0.009198580869 0.02637626044 0.0127777569 0.02028298564 0.008143787272 0.02886542305 0.01615162566 0.002978660865 0.009798854589 0.0336477384 0.003912223969 0.01270807255 0.009419984184 0.009537200443 0.007819862105 0.02070036158 0.004147758707 0.008103369735 0.02873928659 0.01185894478 0.01841929741 0.0188712962 0.00985792838 0.004917789251 0.0157775972 0.007075770292 0.01475147903 0.0360490568 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.91096115 28.8606205 28.8479805 28.85270691 28.83985901 28.83778954 28.84954071 28.83808708 28.84369659 28.83999825 28.83434296 28.84991264 28.84594536 28.83517838 28.83846855 28.85572433 28.84779167 28.83752823 28.83532715 28.8457489 28.84155273 28.84051704 28.83576202 28.8439045 28.84923172 28.87395477 28.83829117 28.83778763 28.84094429 28.84135246 28.83904648 28.84070778 28.84685135 28.86480713 28.84154701 28.84353828 28.84086227 28.85756302 28.83776474 28.85146904 28.83551598 28.86005211 28.84733772 28.83178139  28.839077 28.86435699 28.83509827 28.84246445 28.83774567 28.83881569 28.83805275 28.85188675 28.8343811 28.83738136 28.85992622 28.84113884 28.84960556 28.8500576 28.84152031 28.83610344 28.84696388 28.83540154 28.84593773 28.86675835 

-------
======================
selected experts : 0, 1, 25, 33, 45, 63, 
layer24_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df21d1f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.605617 -0.646749 0.3423190.583574 -0.679776 -0.100882 -0.309929 0.861299 0.362823]

layer24_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de2b2790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.29781 0.527051 -1.01054-1.14134 -1.1181 2.23694 -0.7975 1.58995 -0.531286]

layer25_wq's input 
<N9nntrainer6TensorE at 0x5682ddf10a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.7088 0.347731 -0.73638-0.730544 -0.814756 1.43181 -0.537945 1.05683 -0.397611]
==============================
layer25_wq's output 
<N9nntrainer6TensorE at 0x5682de7d58a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.83559 3.91835 -4.080750.0644075 -3.05639 2.98326 -3.06824 -0.246444 -1.04628]
============================
layer25_wk's input 
<N9nntrainer6TensorE at 0x5682de480fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.7088 0.347731 -0.73638-0.730544 -0.814756 1.43181 -0.537945 1.05683 -0.397611]
==============================
layer25_wk's output 
<N9nntrainer6TensorE at 0x5682de0aef30>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.475826 0.562091 -0.47697-0.568508 -0.792714 -0.737048 -0.359451 -0.803374 -0.195476]
============================
layer25_wv's input 
<N9nntrainer6TensorE at 0x5682ddd64050>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.7088 0.347731 -0.73638-0.730544 -0.814756 1.43181 -0.537945 1.05683 -0.397611]
==============================
layer25_wv's output 
<N9nntrainer6TensorE at 0x5682de58dbd0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.840023 -4.61997 -2.585693.21929 -0.908869 1.03073 -2.44439 0.160528 -3.1034]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-5.10955 -1.98941 -2.09205-3.50429 -1.99771 3.77498 -0.710696 2.99495 -1.93312]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a38cfdb8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer25_attention_out's input 
<N9nntrainer6TensorE at 0x5682df211490>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer25_attention_out's output 
<N9nntrainer6TensorE at 0x5682dddde7f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer25_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0184b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.29781 0.527051 -1.01054-1.14134 -1.1181 2.23694 -0.7975 1.58995 -0.531286]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.08507 0.581282 -1.09462-1.24754 -1.20011 2.55523 -0.895266 1.73789 -0.570258]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3521238267 0.7037926912 -0.8344409466 -0.2512977123 -0.403291285 -1.932332873 -0.543863833 0.06713044643 -0.4288933575 -0.004103213549 -0.8570634127 -1.144786596 -0.09808783978 -0.003877218813 -0.6428384185 -0.8870458603 -0.6276754737 -0.985355854 -0.3978602886 0.09748359025 -0.8429579735 0.2512204945 -0.4472000003 -1.10507071 1.46047616 -0.5447825789 -1.209560871 -0.8008135557 -0.2794691622 -0.915550828 -1.310251117 -0.01395785809 -0.7888618708 0.691167593 -0.7541944385 0.01394310407 -0.9679329395 0.4135997593 0.5579542518 -0.3448362052 -0.94643116 0.2649400532 1.001892567 -0.8317495584 -1.023207664 -0.8339598775 -0.7867859006 -0.05729614943 0.08660242707 -0.7493286729 0.1543898433 -0.2039871514 -0.7524009943 -0.5948024392 -0.2189787924 -1.112606168 -0.4913251698 -0.4672349393 -0.7243953347 -0.7608498931 -0.421402812 -0.4930419922 -0.4981641471 -0.9012343884 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0139128631 0.03999403864 0.008589124307 0.01538879983 0.01321888436 0.002865104936 0.01148536801 0.0211590603 0.01288475003 0.01970425434 0.008396997117 0.006297489628 0.01793671958 0.01970870793 0.01040305197 0.008148972876 0.01056199521 0.007385967299 0.01329087093 0.02181115001 0.008516280912 0.02543581463 0.01265101787 0.006552632432 0.08523514867 0.01147481985 0.005902505014 0.008882866241 0.01496132556 0.007919964381 0.005337122362 0.01951102912 0.008989665657 0.03949228302 0.009306780063 0.02006307058 0.007515779696 0.02992030978 0.03456674144 0.01401462499 0.007679132279 0.02578718588 0.05388382077 0.008612271398 0.007111619692 0.008593257517 0.009008348919 0.01868351549 0.02157510631 0.00935217645 0.02308833599 0.01613434963 0.009323486127 0.01091497112 0.01589427516 0.006503441371 0.01210492663 0.01240007859 0.009588289075 0.009245045483 0.01298162527 0.01208416373 0.01202242356 0.00803416688 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.70204735 28.73098946 28.69720078 28.7068615  28.704216 28.69386101 28.70248222 28.71024704 28.70388031 28.70974731 28.69986916 28.69777107 28.70988655 28.70975113 28.69758415 28.69628334 28.7020359 28.69456673 28.70428658 28.71328354 28.69665146 28.71357155 28.70364761 28.69802475 28.7767086 28.70199394 28.69737625 28.70035553 28.7007122 28.69367027 28.69633293 28.71098328 28.70046234 28.73096466 28.70030212 28.71153641 28.69851112 28.72139359 28.72556305 28.70405769 28.69676781 28.71630669 28.74535751 28.69913101 28.69858551 28.70006561 28.69857407 28.70729637 28.7125721 28.7003479 28.7112236 28.70665359 28.69650459 28.70191193 28.70689011 28.69511604 28.70214653 28.70387268 28.70106125 28.70024109 28.69968605 28.70308113 28.70349503 28.69950676 

-------
======================
selected experts : 1, 24, 33, 37, 38, 42, 
layer25_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df270060>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.929537 0.615093 0.4607850.747286 1.42073 -1.73008 0.312851 -0.646419 -0.217662]

layer25_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddfd81b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.22735 1.14214 -0.549755-0.394058 0.302637 0.50686 -0.484649 0.943529 -0.748947]

layer26_wq's input 
<N9nntrainer6TensorE at 0x5682de245ed0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.35866 0.893325 -0.415162-0.276328 0.24759 0.380491 -0.342032 0.665878 -0.555488]
==============================
layer26_wq's output 
<N9nntrainer6TensorE at 0x5682de21e590>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-4.69165 2.99857 0.631250.0792068 -5.66683 2.75762 3.25285 2.31526 -2.07136]
============================
layer26_wk's input 
<N9nntrainer6TensorE at 0x5682de23ab70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.35866 0.893325 -0.415162-0.276328 0.24759 0.380491 -0.342032 0.665878 -0.555488]
==============================
layer26_wk's output 
<N9nntrainer6TensorE at 0x5682de320f60>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.52201 -0.0364019 1.006851.02954 -0.914028 -0.0709108 -0.168282 0.383635 0.519894]
============================
layer26_wv's input 
<N9nntrainer6TensorE at 0x5682dde7eae0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.35866 0.893325 -0.415162-0.276328 0.24759 0.380491 -0.342032 0.665878 -0.555488]
==============================
layer26_wv's output 
<N9nntrainer6TensorE at 0x5682ddeee690>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-3.73006 -3.97706 -7.653534.56543 1.57953 2.92632 3.35135 -1.13161 0.936454]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[3.03894 -4.6656 0.2463420.586571 -4.5521 4.35841 2.7835 -2.86244 0.366715]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a116e480
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer26_attention_out's input 
<N9nntrainer6TensorE at 0x5682df278ee0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer26_attention_out's output 
<N9nntrainer6TensorE at 0x5682df278e40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer26_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df27a260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[4.22735 1.14214 -0.549755-0.394058 0.302637 0.50686 -0.484649 0.943529 -0.748947]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.35154 1.20137 -0.578262-0.416263 0.308807 0.553649 -0.516316 0.983972 -0.777683]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.2759172022 -0.1387059689 -0.7067614198 -1.268479586 -0.3612571657 1.021911383 -0.2966087461 -0.26906389 -0.1048665121 0.0133791212 -1.354461908 -1.306173325 -0.02691921592 0.2491696626 0.3892656267 -1.124330401 -0.1418023109 -0.3649367988 -0.5551408529 -0.3173350692 -0.7594336271 0.4147895873 -0.08907012641 -0.3768146932 -0.1962184012 -0.3255196214 -0.07426039129 0.01923182607 -0.04550541565 -0.9463357925 -0.6037111282 -0.5362623334 -0.813598752 -0.7713258266 -1.054637551 -1.169281721 -1.212759495 -0.35141325 0.1003354192 1.251168966 -0.6620184779 -0.4314883053 -0.9407871962 -0.7866211534 -0.9597117305 -1.313242674 -0.192396909 -0.334353596 -0.5201273561 -0.7273904085 0.04272904992 -0.5805600882 -0.5623420477 0.1588353813 0.4589306712 -0.6584821939 -1.201208353 -0.9459183812 0.04744794592 -0.6764290333 -0.6047253013 0.1458210498 -0.9528331757 -0.4144361615 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.02648847364 0.01749799959 0.009914824739 0.005653715692 0.01400669292 0.05585191771 0.0149421161 0.01535941381 0.01810025424 0.02037220635 0.005187908188 0.005444572307 0.01956756413 0.02578936704 0.02966767736 0.006530360784 0.01744390279 0.01395524852 0.01153806597 0.01463560667 0.009406105615 0.03043466061 0.01838844456 0.01379047055 0.01652003825 0.01451631077 0.01866279915 0.02049179003 0.01920723729 0.007802597713 0.01099105086 0.01175795775 0.008910172619 0.009294907562 0.007001713384 0.0062433118 0.005977682769 0.01414525602 0.02222300135 0.07024306059 0.01036851667 0.01305673737 0.007846012712 0.009153821506 0.007698924746 0.005406218581 0.01658329181 0.01438863948 0.01194921136 0.009712387808 0.02097899094 0.01124847401 0.01145527698 0.02356182784 0.03180817142 0.01040524896 0.006047131959 0.007805855479 0.02107822336 0.01022017282 0.01097990945 0.0232571736 0.007752065547 0.01328129135 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.08602142 33.07798386 33.07230759 33.0670929 33.07544708 33.11633682 33.07638168 33.07012177 33.07667923 33.0779953 33.06758118 33.06783676 33.08100891 33.08818436 33.09110641 33.06797028 33.07888412 33.07539368 33.0720253 33.07130814 33.07084656 33.09187317 33.07696533 33.07522964 33.07700729 33.07595444 33.07914734 33.07621002 33.07969284 33.07019424 33.07338333 33.07319641 33.06558228 33.07073593 33.06653214 33.06863785 33.06741714 33.07463074 33.08461761 33.12691498 33.06990051 33.07449722 33.06928635 33.07059479 33.07009125 33.06779861  33.078022 33.07678223 33.07434082 33.07019806  33.080513 33.07364273 33.07289505 33.08595657 33.09038544 33.07279968 33.06748581 33.06733704 33.08251953 33.07165909 33.07337189 33.08279037 33.06728363 33.07376862 

-------
======================
selected experts : 0, 5, 14, 21, 39, 54, 
layer26_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df27d4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-3.32686 1.13824 2.549562.01513 -2.48562 -0.516023 -2.50276 -2.9583 0.0558259]

layer26_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddd52130>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.900489 2.28039 1.99981.62107 -2.18298 -0.00916255 -2.98741 -2.01477 -0.693121]

layer27_wq's input 
<N9nntrainer6TensorE at 0x5682de328070>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.777849 1.42344 1.298731.02722 -1.47964 -0.0060371 -1.88361 -1.30845 -0.454505]
==============================
layer27_wq's output 
<N9nntrainer6TensorE at 0x5682ddefef30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.73188 1.85899 0.7583631.4781 1.7505 1.43621 -1.66906 1.5717 -0.972143]
============================
layer27_wk's input 
<N9nntrainer6TensorE at 0x5682de1e5e50>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.777849 1.42344 1.298731.02722 -1.47964 -0.0060371 -1.88361 -1.30845 -0.454505]
==============================
layer27_wk's output 
<N9nntrainer6TensorE at 0x5682ddfc8350>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.743974 1.18005 0.6682281.29277 0.611509 0.311492 -0.605846 0.68516 0.0157546]
============================
layer27_wv's input 
<N9nntrainer6TensorE at 0x5682de7969c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.777849 1.42344 1.298731.02722 -1.47964 -0.0060371 -1.88361 -1.30845 -0.454505]
==============================
layer27_wv's output 
<N9nntrainer6TensorE at 0x5682de46fef0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.19192 2.79636 -1.47562-2.0129 -0.243943 0.46185 0.810476 2.93607 -2.04597]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.811845 -2.40753 -0.9025261.39476 2.10583 0.832118 1.29927 1.88889 2.19072]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0550420
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer27_attention_out's input 
<N9nntrainer6TensorE at 0x5682de426170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer27_attention_out's output 
<N9nntrainer6TensorE at 0x5682de0d2950>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer27_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de6e6390>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.900489 2.28039 1.99981.62107 -2.18298 -0.00916255 -2.98741 -2.01477 -0.693121]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.726749 1.79009 1.550921.25719 -1.75492 -0.00739473 -2.36393 -1.56252 -0.535355]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.5099403262 -1.220533609 -0.0565347448 -0.2577859163 -0.2888199985 -0.2733395696 -0.3190815151 -0.1558616161 0.7160744667 -0.7994988561 -0.4760230482 -1.204645514 -0.2987708151 0.2233734429 -0.08029260486 -1.236840963 -1.258179665 -0.3760178685 -0.8201752305 -1.427593231 0.6406546235 -0.3322273195 -0.5550384521 -1.472351193 -1.734372973 -0.6209437847 -0.126408428 0.6248345971 -0.194844991 -0.5386272669 0.632547617 -0.9789749384 0.249084428 0.1696014851 -0.2190168798 -0.4187732339 -0.5208759308 -0.8158570528 0.09890311211 0.1262154281 -1.107846975 -0.1528904587 -0.8031591177 0.1494600177 -0.8999056816 -0.1750700027 0.5058190823 0.3375385106 -0.01996741071 -1.69429338 0.4086866975 -0.1200674474 -0.7148858905 -0.694650948 -0.348574698 -0.5709431767 -1.013030648 -0.2335567027 0.4432167411 0.1251413524 -0.1332988739 0.1675446182 -1.052818179 1.052858591 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01116948295 0.005488154478 0.01757699437 0.01437283214 0.01393363532 0.01415101252 0.01351829711 0.01591503248 0.03806138411 0.008361408487 0.01155481953 0.005576048046 0.01379567198 0.02325451188 0.01716432534 0.005399383605 0.005285388324 0.01277011819 0.008190300316 0.004461711738 0.03529637679 0.01334175188 0.01067695022 0.00426641712 0.003282984253 0.009995969012 0.01639075018 0.03474238142 0.01530654822 0.01085361745 0.03501138464 0.006987694185 0.02386016026 0.02203709632 0.01494099572 0.01223563403 0.01104800403 0.008225743659 0.02053290792 0.02110143751 0.006142788101 0.01596238837 0.008330859244 0.02159767598 0.007562637795 0.0156122474 0.03084407747 0.02606684528 0.01823163591 0.003417237429 0.02798902243 0.01649501547 0.009099684656 0.009285693057 0.01312542334 0.01050848048 0.006753730122 0.01472532749 0.02897236496 0.02107878588 0.01627820171 0.02199181356 0.006490292493 0.05330255628 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
31.50262451 31.49694252 31.5090313 31.50630569 31.50395775 31.50369835 31.50592613 31.50689316 31.52903938 31.50029373 31.50348663 31.49559975 31.50382042 31.51518631 31.50814247 31.49542427 31.49674034 31.50088692 31.50012207 31.48542595 31.5272274 31.50527382 31.50260925 31.49238396 31.49378395 31.50145149 31.50784492 31.52381325 31.50723839 31.49897003 31.52694321 31.49796677 31.51531601 31.51349258 31.50448799 31.50369072 31.49773407 31.49443626 31.51294136 31.51255608 31.49807549 31.50789452 31.4988327 31.51352882 31.49997139 31.50658989 31.5118084 31.51752281 31.5106411 31.49534988 31.51992035 31.50794983 31.50055504 31.49930954 31.50458145 31.49910164 31.49868584 31.50522614 31.52090454 31.51301003 31.50820923 31.51344681 31.49842262 31.54475784 

-------
======================
selected experts : 8, 20, 27, 30, 46, 63, 
layer27_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df2fed10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.78379 -4.10973 0.174737-0.765252 2.4391 -2.11893 -2.19582 -0.143156 2.99934]

layer27_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de4dbd00>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.883297 -1.82934 2.174540.855816 0.256112 -2.1281 -5.18323 -2.15792 2.30621]

(93919)layer0_wq's input 
<N9nntrainer6TensorE at 0x5682dde663b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wq's output 
<N9nntrainer6TensorE at 0x5682de7965e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-1.13528 -2.40334 2.68629-0.919085 2.00659 2.0107 -1.72146 -1.10937 2.11685]
============================
layer0_wk's input 
<N9nntrainer6TensorE at 0x5682ddd56d10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wk's output 
<N9nntrainer6TensorE at 0x5682de0a36b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.89838 -1.3551 1.40273-1.31928 1.80822 0.0189238 -3.15912 0.501596 1.80267]
============================
layer0_wv's input 
<N9nntrainer6TensorE at 0x5682e0a65b00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00377398 -0.0308688 0.01868370.00558481 -0.033712 -0.0046117 -0.0259609 0.00410399 0.008703]
==============================
layer0_wv's output 
<N9nntrainer6TensorE at 0x5682dde490d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0171632 -0.00860554 -0.02487710.023363 0.0279423 0.00942741 0.0125607 0.108111 -0.0271058]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.354883 2.63419 0.1063422.83718 1.18818 2.58022 -1.95349 0.614836 -0.685461]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a25a0920
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer0_attention_out's input 
<N9nntrainer6TensorE at 0x5682e0a64030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer0_attention_out's output 
<N9nntrainer6TensorE at 0x5682e0a638e0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer0_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dde13420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00261426 -0.0209141 0.0150320.00392139 -0.0209141 -0.00326782 -0.0169927 0.00326782 0.00718921]

layer0_ffn_gate's input 
<N9nntrainer6TensorE at 0x5682ddfb82c0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.016856 -0.133765 0.09458650.0238624 -0.133223 -0.0193776 -0.108684 0.0207315 0.0444924]
==============================
layer0_ffn_gate's output 
<N9nntrainer6TensorE at 0x5682dde852c0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.0745774 -0.045048 -0.104621-0.0199713 -0.0449096 0.327996 0.0860863 0.095988 -0.0662891]
============================
layer0_ffn_up's input 
<N9nntrainer6TensorE at 0x5682de34f990>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.016856 -0.133765 0.09458650.0238624 -0.133223 -0.0193776 -0.108684 0.0207315 0.0444924]
==============================
layer0_ffn_up's output 
<N9nntrainer6TensorE at 0x5682dde690c0>
data addr: 0x7fc0a7fd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[-0.107725 -0.084519 -0.0651140.108516 -0.371791 -0.215119 -0.0580026 -0.266965 0.0745787]
============================
layer0_ffn_down's input 
<N9nntrainer6TensorE at 0x5682dc3e1140>
data addr: 0x7fc0aafd51d0
Shape: 1:1:1024:12288 [ FP32 : NCHW ]
[0.0038672 0.00186083 0.00322812-0.00107278 0.00816106 -0.0410134 -0.00260401 -0.0134272 -0.00238998]
==============================
layer0_ffn_down's output 
<N9nntrainer6TensorE at 0x5682dc3e0770>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.019992 -0.0625515 0.0377594-0.0686288 -0.133513 -0.0569278 -0.00148558 0.141268 0.0288674]
============================
layer0_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3e1bb0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0173777 -0.0834656 0.0527914-0.0647074 -0.154427 -0.0601957 -0.0184783 0.144535 0.0360566]

layer1_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e48b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wq's output 
<N9nntrainer6TensorE at 0x5682dc3e2330>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.796753 0.125337 -0.343608-0.150926 0.507089 0.41414 -0.255773 -0.0929489 0.288512]
============================
layer1_wk's input 
<N9nntrainer6TensorE at 0x5682dc3e6610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wk's output 
<N9nntrainer6TensorE at 0x5682dc3e6380>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-1.57238 0.950343 0.763138-0.230196 1.08302 0.869608 -0.770607 0.449956 1.26046]
============================
layer1_wv's input 
<N9nntrainer6TensorE at 0x5682dc3e7400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00914728 -0.0422953 0.0227076-0.0363483 -0.061269 -0.0211633 -0.00885555 0.0584798 0.0209624]
==============================
layer1_wv's output 
<N9nntrainer6TensorE at 0x5682dc3e7190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.181 0.0291937 0.03531750.0125654 -0.00638554 0.189028 -0.105657 -0.2298 0.067497]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.736719 0.328284 0.243506-0.28557 0.332745 0.563854 -0.234967 0.137295 -0.170494]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a34c6198
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer1_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ea340>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer1_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ea2a0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer1_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3eb440>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0173777 -0.0834656 0.0527914-0.0647074 -0.154427 -0.0601957 -0.0184783 0.144535 0.0360566]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00849878 -0.127214 0.076729-0.116416 -0.229304 -0.113028 -0.033535 0.248681 0.0424914]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.1702160239 -0.2239896655 -0.1769756079 0.04392522946 0.2368980944 0.6970673203 -0.3592808545 0.1850829422 0.05595271289 -0.5391097665 -0.4449483454 -0.1334935427 -0.4149801433 -0.1864147633 -0.1508485675 1.056051373 -0.3195793629 0.2847701907 -0.2090599388 0.2084010988 0.0856358707 -0.2458385676 0.4397518933 -0.2768904567 -0.3535001278 -0.3292910159 -0.614720583 -0.2910648882 -0.5341821313 1.065764666 -0.4363492429 -0.01145206578 -0.3598379493 0.01293567009 -0.4634871483 0.6671438813 0.07331451029 4.606241703 -0.1133288145 -0.4652608633 -0.276211381 -0.27166453 0.3908366859 -0.07471401989 -0.2063711286 -0.08803310245 0.8862541914 0.1459055394 0.1584375054 -0.7652307153 -0.911662221 -0.3270534873 -0.7755787373 -0.1130612567 -0.363222748 -0.1517439485 1.124939442 0.2087254822 -0.1229620501 0.2299077511 -0.002020265907 -0.2369497269 -0.2072182894 0.03846488521 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005106037483 0.004838720895 0.005071639083 0.006325348746 0.0076716966 0.0121545922 0.00422643451 0.007284310181 0.00640188437 0.003530820133 0.003879443277 0.005297030788 0.003997462802 0.005023993552 0.005205893889 0.01740384474 0.004397606011 0.008047888987 0.004911503755 0.007456163876 0.006594760343 0.004734145477 0.009397014044 0.004589401186 0.004250939004 0.004355106037 0.003273693845 0.004524807911 0.003548261477 0.01757371798 0.003912945744 0.005984588526 0.004224081524 0.006132334471 0.003808184993 0.01179627329 0.006514005363 0.6060009599 0.005404926836 0.003801435698 0.004592518788 0.004613446537 0.008948416449 0.005617718678 0.004924725275 0.005543392152 0.01468599215 0.007004447747 0.007092781365 0.002816258464 0.002432641573 0.00436486071 0.002787265228 0.005406372715 0.00420980854 0.005201234482 0.01864502393 0.007458582055 0.005353110842 0.007618254982 0.00604130188 0.004776413552 0.004920556676 0.006290904246 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
62.86117935 62.85995483 62.8611412 62.86048889 62.86183548 62.86727142 62.85934448 62.86240387 62.86151886 62.85865021 62.85899734 62.86041641 62.8591156 62.86014175 62.86032486 62.8706131 62.85951614 62.86316681 62.86003113 62.86257553 62.86171341 62.85985184 62.85974503 62.86066055 62.85936737 62.85947418 62.85839081 62.8605957 62.85675812 62.87173843 62.85998535 62.86110306 62.86029434 62.86125183 62.85987854 62.86691284 62.8616333 63.45921326 62.86052322 62.85892105 62.85971069 62.86068344 62.86215973 62.86073685 62.86004257 62.86066055 62.86789703 62.86212158 62.86125565 62.85793304 62.85755157 62.85948181 62.85790634 62.86052322 62.85932922 62.85936356 62.87281036 62.86257553 62.86046982 62.86273575 62.86116028 62.8598938 62.86003876 62.86140823 

-------
======================
selected experts : 5, 15, 29, 37, 46, 56, 
layer1_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e0a3ef10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00353315 -0.0549329 0.126958-0.123369 0.276545 -0.191098 0.106235 0.309095 -0.178975]

layer1_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3ee080>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0209109 -0.138399 0.179749-0.188076 0.122118 -0.251294 0.0877565 0.45363 -0.142918]

layer2_wq's input 
<N9nntrainer6TensorE at 0x5682dc3ee2c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wq's output 
<N9nntrainer6TensorE at 0x5682dc3ee260>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.311247 0.115223 -0.416898-0.165847 -0.237754 -0.201397 0.366615 0.127884 -0.336297]
============================
layer2_wk's input 
<N9nntrainer6TensorE at 0x5682dc3edf00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wk's output 
<N9nntrainer6TensorE at 0x5682dc3ede70>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0170464 -0.00491821 -0.00816116-0.0380695 0.0298006 -0.00619471 0.0300897 0.0291104 -0.00756178]
============================
layer2_wv's input 
<N9nntrainer6TensorE at 0x5682dc3ee380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00257263 -0.0127289 0.0148144-0.0193197 0.0089706 -0.0258135 0.00843806 0.0414506 -0.0124617]
==============================
layer2_wv's output 
<N9nntrainer6TensorE at 0x5682dc3ee3b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0488053 0.00885962 0.00802386-0.00675694 -0.00410349 -0.01637 0.00385213 -0.0244586 -0.011974]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.323842 0.0726447 0.278906-0.351455 -0.153515 -0.271148 0.332681 -0.20021 0.238201]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0858038
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer2_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc3ee500>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer2_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc3ee620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer2_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc3fefb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0209109 -0.138399 0.179749-0.188076 0.122118 -0.251294 0.0877565 0.45363 -0.142918]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00114894 -0.0176881 0.0220069-0.0260591 0.0151698 -0.0354185 0.0120544 0.0614986 -0.0157906]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.2300609797 -0.0573739633 -0.0792670846 -0.07990511507 -0.02465081401 0.3291009963 -0.0433845073 0.0155646475 -0.0844059214 0.0009286757559 0.03862661868 -0.08860354871 -0.003646862693 -0.01065728627 0.02001750097 0.02708270214 0.04012955353 0.008215387352 -0.02356889471 -0.008847231045 -0.1422992498 2.097109318 -0.2351353914 0.4799684286 -0.5973323584 0.03877436742 0.04228200763 0.03647579625 -0.1728328317 0.0651492998 0.9051232338 0.01538673695 -0.1603259444 -0.3426310718 0.1016679481 0.5145780444 -0.05423829705 -0.0345232375 -0.1464090049 0.08176235855 -0.0002122647129 -0.1026671231 0.08935724944 0.1386951506 0.009488531388 0.03291593865 -0.3518608809 -0.01619542576 0.1929396689 -0.04016084224 0.006257107947 0.08056685328 -0.2241435498 -0.1660892814 0.1276066601 0.09963126481 -0.1244759187 0.005371605046 -0.127043888 -0.3551532924 -0.3419806063 -0.0312563628 -0.01512844954 -0.1615694612 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01110433694 0.01319743972 0.01291164756 0.0129034128 0.01363644563 0.01942377351 0.01338336244 0.01419601869 0.01284546684 0.01398975775 0.01452721003 0.01279165968 0.01392589416 0.01382860821 0.01425937004 0.01436047349 0.01454906166 0.01409207098 0.01365120709 0.01385366265 0.01212291792 0.1138072386 0.01104813442 0.02258679084 0.007691104431 0.0145293558 0.01458041091 0.01449599955 0.01175835636 0.01491766516 0.03455388919 0.01419349387 0.01190633792 0.009922111407 0.01547250804 0.02338219807 0.0132388873 0.01350248232 0.01207319647 0.01516756415 0.01397380698 0.01261302177 0.01528319623 0.0160561502 0.01411002409 0.01444448438 0.009830952622 0.01375223417 0.01695116423 0.01342657488 0.01406450011 0.01514944155 0.01117024291 0.01183791552 0.01587909646 0.0154410284 0.01234092377 0.01405205205 0.01230927277 0.009798639454 0.009928567335 0.0135466652 0.01376691833 0.01189154293 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
53.42486572 53.42695999 53.42667389 53.42666626 53.42739868 53.43127823 53.4271431 53.42795563 53.42660522 53.42774963 53.42828751 53.4236908 53.4276886 53.42758942 53.42802048 53.42812347 53.42735672 53.42785263 53.42741394 53.42666245 53.42588425 53.52566147 53.4248085 53.43539429 53.42145157 53.42829132 53.42738724 53.42825699 53.42551804 53.42868042 53.44831467 53.42795563 53.42566681 53.42368317 53.42923355 53.43714523 53.42699814 53.42631149 53.42583466 53.42892838 53.42773438 53.42637253 53.42904282 53.4298172 53.4278717 53.4282074 53.42359161 53.42751312 53.42785263 53.42718887 53.42782593 53.42700195 53.42493057 53.42559814 53.42868805 53.42920303 53.42610168 53.42781448 53.42511749 53.4235611 53.42273712 53.42635345 53.42752838 53.42565155 

-------
======================
selected experts : 5, 21, 23, 30, 35, 48, 
layer2_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682e09f8dd0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00287643 0.0675208 -0.00951222-0.0402701 -0.0273482 0.0245452 0.04068 0.00865384 -0.00745776]

layer2_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc401970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0180344 -0.0708777 0.170237-0.228346 0.0947696 -0.226748 0.128437 0.462284 -0.150376]

layer3_wq's input 
<N9nntrainer6TensorE at 0x5682dc3e86c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wq's output 
<N9nntrainer6TensorE at 0x5682dc409160>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.367673 -0.164716 0.417190.0188933 -0.448419 0.281779 -0.241015 -0.0599261 0.228738]
============================
layer3_wk's input 
<N9nntrainer6TensorE at 0x5682dc41f6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wk's output 
<N9nntrainer6TensorE at 0x5682dc41f440>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0494961 -0.00890612 -0.00339991-0.0380567 -0.012209 -0.0539861 0.0167038 0.0355852 0.0534441]
============================
layer3_wv's input 
<N9nntrainer6TensorE at 0x5682dc4204c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.00309217 -0.007308 0.0168624-0.0214278 0.00823435 -0.0198331 0.0117548 0.0423092 -0.0173341]
==============================
layer3_wv's output 
<N9nntrainer6TensorE at 0x5682dc420250>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00987394 -0.0372493 0.01608040.0108743 -0.00258411 -0.0155564 0.00276103 0.00223089 -0.00269894]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.398113 -0.0618134 -0.1382640.394065 -0.518166 0.109468 -0.200137 0.147053 0.179842]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a167b0a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer3_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc422910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer3_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc422870>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer3_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc423990>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0180344 -0.0708777 0.170237-0.228346 0.0947696 -0.226748 0.128437 0.462284 -0.150376]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00117001 -0.00973031 0.0224832-0.0335967 0.012626 -0.0336243 0.0186737 0.0650705 -0.0180309]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.7030926943 0.730641067 0.9185103774 1.089624643 0.6388058662 0.8775565028 0.3533841074 0.9655683041 0.9445055723 0.9198542237 0.6780980229 1.313909769 1.142851233 1.079918623 0.7256379724 0.9863049984 0.9989354014 0.95402354 0.8960082531 0.8800563216 0.8590018153 0.3948054016 1.023362279 0.8607522845 1.028882027 1.132201791 0.9340718389 1.035694122 1.269880891 1.17101717 1.161755562 0.8632258773 7.094688416 0.9837840796 1.429793835 0.3792514503 1.048365355 0.4638099968 1.291579366 0.9866654277 1.075057983 0.7833786011 0.8463903069 0.3343887925 1.796683669 1.537041783 0.5512750745 1.040719032 0.6032510996 0.8395021558 0.1258548796 0.3762799203 0.7514244914 1.113770843 0.7281199098 1.025203586 0.4975908697 0.7822400331 1.484714389 1.298515081 0.8620041013 0.9687132239 0.9522148371 0.9354790449 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001474627294 0.0015158155 0.001829098328 0.002170455642 0.001382811344 0.001755702426 0.001039455179 0.001917229616 0.001877269591 0.001831557835 0.001438226667 0.002716168528 0.002289112192 0.002149492037 0.001508250833 0.001957401866 0.001982280519 0.001895222114 0.001788399648 0.001760097337 0.001723426278 0.001083415002 0.002031297656 0.001726445742 0.00204254128 0.002264863113 0.001857784577 0.002056502737 0.002599173458 0.002354503609 0.00233279774 0.001730722026 0.8800697327 0.001952473191 0.003049893072 0.001066694036 0.002082727384 0.001160815358 0.002656187862 0.001958106412 0.00213906914 0.00159790169 0.001701827976 0.001019896823 0.004401725251 0.003395171836 0.00126691896 0.002066862537 0.001334509347 0.001690146164 0.0008279253379 0.001063528936 0.001547649037 0.002223502612 0.00151199894 0.002035042038 0.001200698782 0.001596083166 0.00322208018 0.002674675314 0.001728608971 0.001923268428 0.001891797525 0.001860400545 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
42.53669739 42.53292084 42.53704834 42.53739166 42.53564835 42.53697586  42.532444 42.53809357 42.53709793 42.53800583 42.53570557 42.53793716 42.5346489 42.53736877 42.53672791 42.53717804 42.53720474 42.53616333 42.53796387 42.53507233 42.53694534 42.53725815 42.53820419 42.53694916 42.53726196 42.53748703 42.53707886 42.53727722 42.53781891 42.53757477 42.53755569 42.53695297 43.41242981 42.53717422 42.53827286 42.53628922 42.53730392 42.53638077 42.53787613 42.53717804 42.53736115 42.53681946 42.53787613 42.53623962 42.53771591 42.53861618 42.53648758 42.53728867 42.53750992 42.53691101 42.53700256 42.5362854 42.53581619 42.53744507 42.53673172 42.53630066 42.53642273 42.53776932 42.53749084 42.53408051 42.53694916 42.53714371 42.53711319 42.53708267 

-------
======================
selected experts : 11, 32, 34, 44, 45, 58, 
layer3_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc426710>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.40804 -0.163766 -0.0283651-0.0258024 0.375191 -0.636849 0.150238 0.480676 -0.0173886]

layer3_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc426050>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.426075 -0.234644 0.141872-0.254149 0.469961 -0.863597 0.278674 0.942961 -0.167765]

layer4_wq's input 
<N9nntrainer6TensorE at 0x5682dc44b9a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wq's output 
<N9nntrainer6TensorE at 0x5682dc492890>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0362699 0.0761985 -0.162530.0108048 0.133773 0.0730457 0.019711 0.0756074 0.0487248]
============================
layer4_wk's input 
<N9nntrainer6TensorE at 0x5682dc44d700>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wk's output 
<N9nntrainer6TensorE at 0x5682dc44d470>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00265456 0.0108227 0.006283270.0177541 -0.0206112 0.00339958 -0.00927054 0.0110561 -0.0341779]
============================
layer4_wv's input 
<N9nntrainer6TensorE at 0x5682dc44e4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0251348 -0.0157404 0.00937357-0.0179911 0.0278822 -0.0617162 0.0191637 0.0670699 -0.0117629]
==============================
layer4_wv's output 
<N9nntrainer6TensorE at 0x5682dc44e280>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00723192 0.0269832 0.01238150.00259692 -0.0625021 0.0233134 -0.0178625 -0.0133778 -0.0104791]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0718866 -0.0442044 0.0364701-0.158753 0.100292 0.114772 0.0707456 0.0331671 0.0634373]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1e8f0e8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer4_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc450940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer4_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4508a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer4_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4519c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.426075 -0.234644 0.141872-0.254149 0.469961 -0.863597 0.278674 0.942961 -0.167765]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0182407 -0.0208817 0.0120996-0.0239882 0.0418232 -0.0826764 0.0268667 0.0864598 -0.0135161]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.4858219922 -0.6959101558 -1.212872982 -0.5218012333 -0.3581064343 -0.6095018983 -0.9364464879 -0.09696792811 0.1423784941 -0.6651900411 -0.3415829241 -0.6328966618 -0.448492974 0.1721494049 -0.6025950313 -0.3689320683 0.2208227664 -0.4570725858 -0.2653499246 -0.5709964633 -0.5247528553 -0.8439400792 -0.7144295573 -0.4792812765 -0.2926749885 -0.719201386 5.035842419 -0.5945936441 -0.8254883885 -0.2731153667 -0.396169126 -0.2761000395 -0.4569109082 -0.4405405819 -0.4258541465 -0.9477441907 -0.5268508196 -0.8339192271 -0.6794077754 -0.0201159101 -0.3519995511 -0.3451288044 -0.7215133309 -0.1839890182 -0.3048131168 -0.4804430902 -0.3798335195 -0.1730620563 -0.3575777709 -0.1691406071 -0.5078726411 -0.7150136232 -0.4467060566 -0.5603669286 -0.3437692225 -0.2371052802 -0.9603158832 -0.3850839734 -0.2239291668 -0.5798804164 -0.4820096195 -0.009696807712 -0.3213909268 -0.4072785378 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003149774857 0.002552933758 0.001522388076 0.003038462717 0.003578868229 0.002783339238 0.002007131465 0.004646830726 0.005903418176 0.002632576274 0.003638495924 0.002718978561 0.003269575769 0.006081810221 0.002802630188 0.00354033336 0.006385156885 0.003241643542 0.003926715348 0.002892603399 0.003029507585 0.002201662865 0.002506090095 0.003170444164 0.003820870072 0.002494159155 0.7876041532 0.002825144911 0.002242664341 0.003896341659 0.003445207141 0.003884728299 0.003242167644 0.003295679577 0.003344439203 0.001984582981 0.003023159457 0.002223837189 0.002595413011 0.005018029362 0.003600790864 0.003625615733 0.002488400089 0.004259552807 0.003774773097 0.00316676381 0.003501948435 0.004306353163 0.003580761142 0.004323271569 0.003081081435 0.002504626755 0.003275422612 0.002923513297 0.00363054988 0.004039204679 0.001959790243 0.003483609762 0.004092779011 0.002867019502 0.003161807079 0.005070585292 0.003712710226 0.003407144919 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.82080841 40.8202095 40.81822586 40.82165146 40.82218933 40.82139587 40.82061768 40.8213501 40.81974792 40.82124329 40.82129669 40.82133102 40.82188034 40.8237381 40.82141495 40.82215118 40.8230896 40.81994629 40.82253647 40.82150269 40.82068634 40.82081223 40.81825638 40.81987381 40.8214798 40.82110596 41.60335541 40.81953049 40.82085419 40.82250595 40.82205582 40.82249451 40.82185364 40.82190704 40.82195663 40.81868744 40.81877518 40.81797409 40.82120514 40.82172012 40.82125854 40.82223511 40.82109833 40.82191849 40.8223877 40.81796265 40.82211304 40.82196426 40.82123947 40.8153038 40.82073975 40.81825638 40.82188797 40.82057953 40.82128906 40.82265091 40.8205719 40.82209396 40.81984329 40.8214798 40.82177353 40.82368088 40.82232285 40.82201767 

-------
======================
selected experts : 8, 13, 16, 26, 39, 61, 
layer4_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc454a40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0859682 -0.410187 -0.0549648-0.0186526 0.0215153 0.136957 0.138183 0.141585 -0.052018]

layer4_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc454380>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.512043 -0.644831 0.0869074-0.272801 0.491476 -0.72664 0.416858 1.08455 -0.219783]

layer5_wq's input 
<N9nntrainer6TensorE at 0x5682dc4a0910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wq's output 
<N9nntrainer6TensorE at 0x5682dc454560>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.275413 -0.275119 -0.4205730.130582 -0.153064 -0.171391 0.250294 0.344814 -0.237526]
============================
layer5_wk's input 
<N9nntrainer6TensorE at 0x5682dc4a2670>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wk's output 
<N9nntrainer6TensorE at 0x5682dc4a23e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0251711 0.00994586 -0.00368810.0447051 -0.0208935 -0.0184831 -0.00454087 0.00173929 -5.86053e-05]
============================
layer5_wv's input 
<N9nntrainer6TensorE at 0x5682dc4a3460>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.011277 -0.0194921 0.00232682-0.00781436 0.0118144 -0.0220697 0.0121809 0.0335645 -0.00632729]
==============================
layer5_wv's output 
<N9nntrainer6TensorE at 0x5682dc4a31f0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00785 0.000318006 -0.00348613-0.00889498 -0.0160193 0.010875 -0.0116615 -0.00481091 -0.00860701]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.380762 0.0810138 -0.00390088-0.440361 -0.0844108 -0.213725 0.425165 0.0279037 0.256778]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1c8a0d8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer5_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc4a58b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer5_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc4a5810>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer5_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a6930>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.512043 -0.644831 0.0869074-0.272801 0.491476 -0.72664 0.416858 1.08455 -0.219783]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0104662 -0.0263608 0.00340267-0.011859 0.0191012 -0.0313787 0.0180013 0.0458975 -0.00822548]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.07918033749 -0.2179847509 -0.1854854673 -0.02147212252 -0.2435834855 -0.04457190633 -0.05281364918 0.02368463762 -0.7193178535 -0.03581977263 1.976906419 -0.0489499718 -0.1354791224 0.1448095441 -0.05553285405 -0.09898391366 -0.3166708648 -0.1941818893 -0.1947810501 -0.2095515877 -0.3199042678 -0.01641224325 -0.1026784554 -0.07198929787 -0.6075111628 -0.3197972476 -0.03667161986 -0.07751637697 0.02160535939 -0.2651851773 -0.04437225312 -0.3091673255 -0.003033100627 -0.08875891566 -0.05681180954 0.985704422 -0.1130490974 -0.03929310292 -0.3192313612 0.09553340077 -0.003807086032 -0.145200029 -0.2841767073 -0.1278078854 2.390167236 -0.05618714541 -0.1036904231 -0.02516179718 0.9318757057 -0.4884956181 -0.7425076962 -1.161397815 -0.01418332662 0.03714296594 1.100428462 -0.02066170983 -0.01740192436 -0.5280942917 -0.0759184286 -1.118462682 -0.1128986701 -0.281962961 -0.1339662522 0.06412689388 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01403941866 0.01043018512 0.01077472791 0.01269510575 0.0101665752 0.0124052139 0.0123033952 0.01328151859 0.006317798514 0.01251426246 0.09365288168 0.0123510221 0.01132723037 0.01499172207 0.01226998307 0.01174825523 0.009450029582 0.01068143174 0.01067503355 0.01051851641 0.00941952318 0.01275950484 0.01170493197 0.01206971519 0.00706517417 0.009420530871 0.01250360627 0.01200318988 0.01325392816 0.009949313477 0.01240768936 0.009521204047 0.01293136273 0.01186899748 0.01225430053 0.03475742415 0.01158417203 0.01247087214 0.009425864555 0.01427089516 0.01292135939 0.01121765375 0.009762142785 0.01141445898 0.1415787339 0.01226195786 0.01169309299 0.01264835335 0.03293593973 0.007958122529 0.006172975991 0.004060437903 0.01278797723 0.0134614734 0.03898267075 0.01270540152 0.01274688449 0.007649149746 0.01202238444 0.00423857104 0.01158591546 0.009783779271 0.01134438068 0.01382966246 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.25190735 33.25020599 33.25246048 33.25437927 33.24994278 33.25027466 33.25398636 33.24829102 33.24704742 33.25419998 33.33438492 33.25308228 33.2530098 33.2538147 33.25395584 33.25343323 33.25113297 33.24378204 33.25235748 33.25220108 33.2415657 33.25444412 33.25338745 33.25375366 33.24398041 33.25110626 33.25418854 33.25368881 33.25493622 33.25067902 33.25409317 33.2492981 33.24889374 33.25355148 33.25393677 33.27548599 33.2532692 33.25415421 33.24729538 33.25309372 33.25460434 33.25290298 33.2504921 33.25309753 33.38135529 33.2539444 33.25337601 33.25337982 33.27366638 33.24964142 33.24594879 33.2457428 33.25065613 33.25419235 33.27780533 33.25057602 33.25443268 33.24456406 33.25370789 33.24592209 33.2532692 33.24670029 33.25112152 33.24883652 

-------
======================
selected experts : 10, 13, 35, 44, 48, 54, 
layer5_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc4a9a10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.230467 0.147142 0.06459260.0019409 -0.181316 0.0733079 0.0421877 0.0761149 -0.146847]

layer5_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc4a9350>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.74251 -0.497689 0.1515-0.27086 0.310161 -0.653332 0.459045 1.16066 -0.36663]

layer6_wq's input 
<N9nntrainer6TensorE at 0x5682dc4e8620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wq's output 
<N9nntrainer6TensorE at 0x5682dc4a9530>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.695634 -0.228144 -0.5810460.323757 -0.197663 -0.540155 0.504746 0.847593 -0.763714]
============================
layer6_wk's input 
<N9nntrainer6TensorE at 0x5682dc4ea380>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wk's output 
<N9nntrainer6TensorE at 0x5682dc4ea0f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0214494 -0.00297009 0.00338558-0.00782245 0.00143022 0.00439973 0.00877311 -0.0147463 -0.046852]
============================
layer6_wv's input 
<N9nntrainer6TensorE at 0x5682dc4eb170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.029461 -0.0207274 0.00622431-0.0115093 0.0109972 -0.0259226 0.0176971 0.0434393 -0.0138248]
==============================
layer6_wv's output 
<N9nntrainer6TensorE at 0x5682dc4eaf00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0156485 0.0104525 0.01945610.00157869 0.0098697 0.000841773 -0.0121287 0.00979754 -0.00119108]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.707802 -0.18701 -0.142664-0.649677 0.0011655 -0.575184 0.974473 0.153576 0.66587]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1a850c8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer6_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc41beb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer6_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc41be10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer6_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc41cf30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.74251 -0.497689 0.1515-0.27086 0.310161 -0.653332 0.459045 1.16066 -0.36663]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0147305 -0.0212876 0.00626695-0.0120428 0.0127428 -0.0295996 0.0207973 0.051278 -0.014547]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.04598842189 0.871989727 0.1590040326 -0.8808486462 -0.7566508055 -0.0392893441 0.2642817199 0.3292520642 0.2644926012 0.08304589987 0.0166921448 -0.2166069597 1.023880839 -0.08878401667 -0.2583498955 0.2684820294 0.1323997676 -0.9021778703 0.135657087 0.2334127873 0.1226155683 0.1617766619 0.007764321752 1.611345887 0.2760307789 -0.5341758728 -0.6800649762 0.1462279111 0.2474199682 -0.1545801759 -0.6242238879 -0.3659591973 0.0122226933 -0.2061981857 -0.1350325495 -0.7296162844 1.269290686 -0.002525131684 0.3083646595 -0.1382303983 0.2969625592 0.06327658892 0.1928350031 0.676184237 0.2964215279 0.01302839536 0.08529359847 0.2071783841 -0.05202829838 -0.6404911876 -0.05744434148 0.4427712262 0.3092009425 0.38174209 -0.3089568913 0.2807747126 0.3261196911 0.22609815 -0.1027657315 0.3057509661 0.296938926 0.3073717356 0.02158760652 -0.1024745256 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01360130031 0.03106763959 0.01522868965 0.005383443553 0.006095350254 0.01248949207 0.01691936329 0.01805511862 0.01692293212 0.01411478501 0.01320861373 0.01046012156 0.03616377339 0.01188637782 0.01003247313 0.01699057966 0.01482888218 0.005269835237 0.01487726346 0.01640505902 0.01468450017 0.01527097076 0.013091214 0.06507385522 0.01711932197 0.007614096161 0.006580508314 0.01503536291 0.01663646474 0.0111294724 0.006958425511 0.009008944035 0.01314970851 0.01056956686 0.01134916861 0.006262382492 0.04622254521 0.01295720413 0.01768190227 0.01131293271 0.01748143882 0.01383848768 0.01575270295 0.02554294653 0.01747198217 0.01316030882 0.0141465487 0.01598027907 0.0123313982 0.006846146192 0.01226479094 0.02022558078 0.01769669354 0.01902814396 0.009537393227 0.01720072888 0.01799864694 0.01628550142 0.01172134187 0.01763574779 0.01748102345 0.01766435429 0.01327343471 0.01172475517 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
40.13698196 40.15444946 40.13098145 40.12876511 40.12947845 40.13587189 40.14125443 40.14143753 40.14030457 40.13749695 40.13659286 40.13098145 40.1595459 40.13431549 40.13341522 40.14037323 40.1382103 40.12865067 40.13825989 40.13978577 40.13806534 40.1386528 40.13647461 40.18845749 40.14050293 40.1309967 40.1309166 40.13841629 40.14001846 40.13451385 40.12747955 40.13143921 40.13653183 40.13395309 40.13473129 40.1296463 40.16960526 40.13634109 40.14106369 40.13469696 40.14086533 40.13722229 40.13817978 40.14892578 40.14085388 40.13749695 40.13657379 40.13936234 40.13476181 40.13022995 40.13564682 40.14360809 40.14107895 40.14241028 40.13005829 40.14058304 40.14042664 40.13966751 40.13319778 40.14101791 40.14086533 40.13818741 40.13665771 40.13510895 

-------
======================
selected experts : 1, 12, 23, 36, 43, 51, 
layer6_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc47b4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0510724 -0.0072978 0.002230830.066627 0.0371369 -0.00985265 -0.0324661 0.0408974 0.107894]

layer6_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc47ae20>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.793582 -0.504987 0.153731-0.204233 0.347298 -0.663184 0.426579 1.20156 -0.258736]

layer7_wq's input 
<N9nntrainer6TensorE at 0x5682dc5555c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wq's output 
<N9nntrainer6TensorE at 0x5682dc47b000>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.657963 0.508159 0.759416-0.493352 0.0679253 0.91612 0.356312 0.745763 0.297703]
============================
layer7_wk's input 
<N9nntrainer6TensorE at 0x5682dc557b30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wk's output 
<N9nntrainer6TensorE at 0x5682dc5578a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00883845 -0.00656046 -0.02105710.0099999 0.028946 0.0126508 0.00832559 -0.0132098 -0.0295955]
============================
layer7_wv's input 
<N9nntrainer6TensorE at 0x5682dc558920>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0258066 -0.0196499 0.00572557-0.00737943 0.0116799 -0.0232251 0.0154133 0.0405764 -0.00978022]
==============================
layer7_wv's output 
<N9nntrainer6TensorE at 0x5682dc5586b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0188292 0.010387 -0.0138226-0.0142297 0.00276319 0.00587439 0.00344935 -0.0125941 0.00343755]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.275629 -0.784327 0.2536910.869339 -0.252827 0.883158 0.801284 0.202644 -0.657893]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a18800b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer7_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc55ad70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer7_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc55acd0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer7_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55bdf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.793582 -0.504987 0.153731-0.204233 0.347298 -0.663184 0.426579 1.20156 -0.258736]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0163221 -0.0230185 0.00675105-0.00965002 0.0152515 -0.0313355 0.0206301 0.0554378 -0.0110747]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.168024302 0.6618694067 -0.4694300592 -0.07413705438 0.7391534448 -0.06975306571 0.1814451218 0.4088294804 0.2756572068 -0.01008156221 0.5435899496 0.4069769084 -0.6550350189 0.07319442928 -0.56976825 0.3659587801 0.6475477815 0.04731979966 0.2641719878 0.295361042 0.4828495979 0.6668714285 -0.2184385061 -0.2693095505 -0.4303425848 0.4009917974 0.5435461998 -0.2240395248 0.3005890548 0.2294455171 0.1688566357 1.472923517 0.4575823247 0.5258388519 0.4786459804 -0.03981018811 0.3397579789 -0.005647979677 0.05844898149 0.6566990614 -0.944694221 0.03326295689 1.298671484 1.307865739 0.6658383608 0.252460748 0.4188720584 0.521461308 0.061222516 0.3877601027 0.6422598958 0.1709300727 0.5699272752 -0.7041506171 -0.5168834329 -0.1764284968 -0.09934764355 0.5614067316 0.6186754107 0.6668535471 0.02402624302 1.682482243 0.5926005244 -0.3600988984 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.03339649364 0.02013170719 0.006494766567 0.009643552825 0.02174926735 0.009685923345 0.01245188154 0.01563099958 0.01368203759 0.01028148923 0.01788596809 0.01560206991 0.005394563079 0.01117435098 0.005874720402 0.01497504953 0.01984544285 0.01088892762 0.01352579426 0.0139542995 0.01683190651 0.02023265883 0.008347717114 0.007933680899 0.006753655616 0.01550896745 0.01788518578 0.00830109138 0.01402744371 0.01306415349 0.01229611319 0.04530195147 0.01641193777 0.01757127605 0.01676130109 0.009980333038 0.01458778512 0.0103271734 0.01101079024 0.02002788708 0.00403793063 0.01073693391 0.03805749863 0.03840902448 0.02021176741 0.01336831506 0.01578876749 0.0174945239 0.01104137115 0.01530511118 0.01974077895 0.01232163515 0.01836329512 0.005136006977 0.006193765905 0.008705874905 0.009403472766 0.01820749603 0.01928065158 0.02023229748 0.01063821744 0.05586336926 0.01878440939 0.007245117333 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
35.95775986 35.94926071 35.93467331 35.93495941 35.94897079 35.93881607 35.92441559 35.94285583 35.9418602 35.93845749 35.94701767 35.94473267 35.93452454 35.93839645 35.93500519 35.94315338 35.94897461 35.9400177 35.94075012 35.94213104 35.94500732 35.94841003 35.93461609 35.93515778 35.92539215 35.94273376 35.94701385 35.93647766 35.93075943 35.94219589 35.94047165 35.97348022 35.94458771 35.94670105 35.94589233 35.93434143 35.94276428 35.93754959 35.9391861 35.94820404 35.9303093 35.93796158 35.96528244 35.96754074 35.94934082 35.93868256 35.94396591 35.94662476 35.93921661 35.93966675 35.94791794 35.93668365 35.94749451 35.93331146 35.93532562 35.93592834 35.93758011 35.9473381 35.94841003 35.94936371 35.9378624 35.98499298 35.94791412 35.93542099 

-------
======================
selected experts : 0, 4, 31, 42, 43, 61, 
layer7_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5969b0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0358682 0.0494057 -0.02676070.00325278 -0.0567075 -0.0131402 0.0472899 0.0318014 0.108935]

layer7_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc55e510>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.757714 -0.455581 0.12697-0.20098 0.29059 -0.676324 0.473869 1.23336 -0.149801]

layer8_wq's input 
<N9nntrainer6TensorE at 0x5682dc59a250>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wq's output 
<N9nntrainer6TensorE at 0x5682dc5d3620>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.17101 -0.653928 0.222739-0.618268 0.202001 -0.518507 -0.352742 -0.371231 0.40923]
============================
layer8_wk's input 
<N9nntrainer6TensorE at 0x5682dc59bfb0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wk's output 
<N9nntrainer6TensorE at 0x5682dc59bd20>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0122512 -0.0240249 0.0049726-0.00696511 -0.00671129 0.0076463 -0.00612936 0.00283497 -0.00945466]
============================
layer8_wv's input 
<N9nntrainer6TensorE at 0x5682dc59cda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0229478 -0.0168079 0.00436973-0.00719349 0.00956074 -0.0234622 0.0163084 0.0415976 -0.00532043]
==============================
layer8_wv's output 
<N9nntrainer6TensorE at 0x5682dc59cb30>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0125965 -0.00244861 0.007529460.00303611 0.0145719 0.00140784 -0.0154647 -0.0179054 0.00261313]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.212261 0.641725 0.5279030.391391 0.36873 -0.416765 -0.510963 0.0340006 -0.141562]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1476098
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer8_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc59f1f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer8_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc59f150>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer8_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a0270>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.757714 -0.455581 0.12697-0.20098 0.29059 -0.676324 0.473869 1.23336 -0.149801]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0170022 -0.0222015 0.005803-0.0102922 0.013441 -0.0348208 0.0242669 0.0607834 -0.0068052]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.04677072912 0.0153601896 0.2453148216 0.3004711866 -0.3885725439 0.05983536318 -0.01540975925 0.05687586218 0.2940652668  0.1836714 -0.01984599419 0.4423549771 0.2803600132 0.05182646215 0.1945592016 0.2888280451 0.1189836785 0.1493378282 -0.5161525607 0.266795069 -0.8293113112 0.2661831379 0.08042082191 0.07239897549 0.05997288972 0.3686698079 -1.536476731 -0.3078627288 -0.7882967591 0.24841474 0.2563607693 -0.04476862773 0.5374804139 -0.3126162291 4.726294041 0.2904126942 -0.4587142169 0.1429113746 0.2790945172 -0.3088897169 0.3767482638 0.1019092426 0.2512847781 0.5570003986 0.134382531 -0.3317438364 0.1961397231 -0.2455921173 -0.03754698113 0.2989471853 0.1975146532 0.2983741462 0.5875585675 0.003402953502 0.7836763859 -0.401131928 0.07859761268 0.2543839812 0.2182640433 0.1351471692 0.2176695615 0.1511563063 0.435500294 0.8533852696 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005646863021 0.005472250748 0.006887059659 0.007277598605 0.003653760534 0.005721122492 0.005306432024 0.005704214796 0.007231128402 0.006475340109 0.005282944534 0.008387016132 0.007132700179 0.005675485358 0.00654622633 0.007193353958 0.006069725845 0.006256790832 0.003216125071 0.007036597934 0.002351417439 0.007032294292 0.005840115249 0.005793454591 0.005721908063 0.007791236974 0.001159342472 0.003960882314 0.002449864987 0.006908441894 0.006963555235 0.005152905826 0.009224010631 0.003942098934 0.6082729101 0.007204764523 0.003406262491 0.00621671183 0.007123679388 0.003956816625 0.007854430005 0.005966967437 0.006928298157 0.009405835532 0.006163916085 0.003867413383 0.006556582171 0.004215370398 0.005190253723 0.007266516332 0.006565601565 0.007262352388 0.009697696194 0.005407207645 0.01179889683 0.003608158557 0.005829476751 0.006949805655 0.006703258492 0.006168629508 0.006699273828 0.006268180441 0.008329719305 0.01265072823 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.07797623 34.07875824  34.079216 34.08056259 34.07598495 34.0790062 34.07859039 34.07898712 34.07956314 34.07880402 34.0785675 34.07595062 34.07660294 34.07896042 34.07983017 34.07857132 34.07839966 34.07954025 34.04884338 34.07269287 34.07468033 34.07936096 34.07912445  34.078125 34.07805252 34.08012009 34.07444382 34.07629013 34.07573318 34.07923889 34.08024597 34.07843781 34.08155441 34.07627487 34.67488098 34.07858276 34.07669067 34.07854843 34.07945251 34.07533264 34.08018494 34.07925034 34.07925797 34.07983017 34.0794487 34.07715225 34.07984161 34.07654572 34.07752228 34.08055115 34.07984924 34.07959366 34.08107376 34.07868958 34.08031464 34.07689285 34.07911301 34.07928085 34.0790329 34.07945251 34.07998276 34.07859802 34.0758934 34.07258224 

-------
======================
selected experts : 32, 34, 43, 52, 54, 63, 
layer8_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5a3350>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0681935 -0.0987799 -0.1255480.266272 -0.427989 -0.0341151 -0.182963 0.2666 0.19531]

layer8_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5a2c90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.68952 -0.554361 0.00142260.0652915 -0.137399 -0.71044 0.290906 1.49996 0.0455094]

layer9_wq's input 
<N9nntrainer6TensorE at 0x5682dc5e1750>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wq's output 
<N9nntrainer6TensorE at 0x5682dc5a2e70>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141972 0.0167292 -0.2640250.310849 -0.154788 0.0734234 -0.210784 -0.00362809 -0.189374]
============================
layer9_wk's input 
<N9nntrainer6TensorE at 0x5682dc5e3c80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wk's output 
<N9nntrainer6TensorE at 0x5682dc5e39f0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00161957 -0.00211483 -0.01375779.81252e-05 -0.00883225 0.00970442 -0.0232949 -0.00734125 -0.0170646]
============================
layer9_wv's input 
<N9nntrainer6TensorE at 0x5682dc5e4a70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.035769 -0.0241929 5.89601e-050.00299276 -0.00554368 -0.0304194 0.0122962 0.062578 0.0020985]
==============================
layer9_wv's output 
<N9nntrainer6TensorE at 0x5682dc5e4800>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.011892 -0.000943265 -0.006786920.0114438 -0.0217582 0.0152061 -0.00763955 -0.0135636 0.0142479]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.110024 -0.0912728 -0.221621-0.342375 -0.170625 0.0154129 -0.137517 0.159787 0.157668]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1271088
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer9_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc5e6ec0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer9_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc5e6e20>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer9_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5e7f40>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.68952 -0.554361 0.00142260.0652915 -0.137399 -0.71044 0.290906 1.49996 0.0455094]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0163705 -0.0284533 6.91121e-050.00351246 -0.00667504 -0.0384142 0.0157296 0.0773991 0.00218593]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3258353472 0.183533296 -0.09342952073 -1.036007285 2.088111162 0.008346061222 -0.7364020944 -1.349478364 0.3679609299 0.1264469326 1.101921201 0.259608686 0.4678474665 -1.35572803 0.4126421809 -0.07927054912 0.1937977076 0.3577730358 -0.3610570133 -0.1297360808 0.3895307481 1.095702529 0.1365136802 0.2798104882 0.4129787385 0.1292768866 0.1402641833 -0.1215476245 -0.04986479506 -0.7106806636 0.4740997851 0.4535753131 -0.2847249806 1.092014313 -1.758917809 -0.2847560942 -0.2298212647 -0.6525506973 -0.1235622168 0.4583579898 -0.7284759879 0.4226437807 1.040506482 0.5733621716 0.317548275 -0.7666806579 -0.6158863902 -0.1706359237 -0.3159227073 0.4458977878 -0.1455331892 -0.06074886769 0.1500902325 -0.07550656796 -0.2112460881 -0.4560808241 -0.04254198447 -0.6656578779 -0.3927685916 -0.1671101898 -0.002543612383 0.1304136366 0.551289022 -0.1643009335 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009224582464 0.01535192225 0.01163802482 0.004534433596 0.1031122804 0.01288486551 0.006118428428 0.003314241767 0.01846114546 0.01450008154 0.0384603776 0.01656539738 0.02040040493 0.003293594345 0.01930471882 0.01180397905 0.01551031135 0.0182740204 0.008905332536 0.01122306567 0.01886367425 0.03822194785 0.0146467872 0.01690345071 0.01931121573 0.01454117335 0.01470182277 0.0113153439 0.01215623971 0.00627784431 0.02052835561 0.02011131682 0.009611711837 0.03808123246 0.002200730843 0.009611411951 0.01015418675 0.006653590593 0.01129257306 0.02020773478 0.006167116109 0.01949876361 0.03616941348 0.02267061174 0.01755353995 0.005935947411 0.006902066525 0.01077330578 0.009316476993 0.01995750144 0.01104716957 0.01202464849 0.01484699547 0.01184849534 0.01034456585 0.008098075166 0.01224558335 0.006566950586 0.008627361618 0.01081135683 0.01274531428 0.01455771364 0.02217568457 0.01084177103 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
34.46111679 34.46724319 34.45780945 34.45547485 34.55405045 34.4647789 34.43607712 34.45520782 34.47035217 34.46543884 34.49035263 34.46846008 34.47229385 34.45518494 34.47119904 34.46369553 34.46644974 34.47016525 34.45984268 34.46311569 34.46503448 34.49011612 34.46558762 34.46688843 34.47120285 34.46643448 34.4665947 34.46320724 34.45355988 34.45817184 34.47241974 34.47200394 34.46055222 34.4890213 34.45409393 34.45292282 34.45632553 34.45759201 34.46318436 34.4720993 34.43421936 34.47138977 34.48329544 34.47360992 34.46944809 34.45782852 34.45879364 34.45789719 34.45930099 34.47185135 34.45817184 34.46391678 34.46673965 34.4637413 34.45937729 34.45808411 34.46127701 34.45750427 34.45861435 34.46175003 34.46273041 34.46644974 34.47406769 34.46082687 

-------
======================
selected experts : 4, 10, 21, 33, 42, 43, 
layer9_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dc5eb020>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.104579 -0.000398263 -0.07572780.115588 0.014312 0.0643511 0.122948 -0.0377023 0.091618]

layer9_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc5ea960>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.584942 -0.554759 -0.07430520.18088 -0.123087 -0.646088 0.413854 1.46226 0.137127]

layer10_wq's input 
<N9nntrainer6TensorE at 0x5682ded33210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wq's output 
<N9nntrainer6TensorE at 0x5682dc5eab40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.37707 -0.407332 -0.004689360.264799 -0.450686 0.237675 0.354465 0.042499 -0.208016]
============================
layer10_wk's input 
<N9nntrainer6TensorE at 0x5682ded34f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wk's output 
<N9nntrainer6TensorE at 0x5682ded34ce0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0208244 0.0187902 -0.0183501-5.44079e-05 0.00482989 0.0189981 -0.00186447 -0.0230889 0.00503917]
============================
layer10_wv's input 
<N9nntrainer6TensorE at 0x5682ded35d60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0172925 -0.0252078 -0.003335680.00851608 -0.0049191 -0.0298882 0.0188052 0.0600394 0.00578052]
==============================
layer10_wv's output 
<N9nntrainer6TensorE at 0x5682ded35af0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0224915 0.00636522 0.0154213-0.00975636 0.0199064 0.0167431 -0.0279089 -0.0151201 0.023924]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.537986 0.136646 -0.252225-0.0807662 -0.505053 0.0672979 0.259249 -0.245442 -0.0147793]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a106c078
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer10_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded38210>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer10_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded38170>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer10_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded39290>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.584942 -0.554759 -0.07430520.18088 -0.123087 -0.646088 0.413854 1.46226 0.137127]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.01385 -0.0297634 -0.003742470.0101995 -0.00619941 -0.0366087 0.0237897 0.0788518 0.00683152]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.2405900508 0.2403998226 0.002393446397 0.09837586433 1.045801878 -0.8216309547 -1.209175825 0.3056552112 -0.2752718031 0.3853158951 -1.040553689 -0.4904887974 0.2650624514 -0.7685959339 -0.8298601508 -1.237736106 0.03745195642 -0.165141806 -0.4367792606 -0.7191370726 -0.961849153 0.3766517937 -0.4394464791 0.6722314358 -0.05634330213 0.07336346805 0.2354294658 -0.00606180029 -1.113972902 0.9323561192 -0.3637063205 0.3454566598 0.2466523647 0.2701610923 0.3343005478 -0.5620473027 -1.098581672 0.1022080481 -0.1563752741 0.02149196714 0.1330704093 -1.023319602 -0.3335804641 -0.1875314862 0.009166814387 -0.7846198082 0.1157286912 -0.9036570191 -0.8283277154 1.769645333 -0.7296331525 -0.4721302688 -0.02899205871 0.1692908704 0.2316015065 1.04218781 -0.1277344823 0.7623437047 -0.3691411912 0.1704837829 -0.1390079856 0.9013450146 0.08754011244 0.1399177164 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01815791614 0.01815446094 0.01430930384 0.01575081982 0.0406223461 0.006276959088 0.004260303918 0.01937864535 0.01084001828 0.02098551393 0.005042806268 0.008741025813 0.01860776357 0.006618842017 0.006225516088 0.004140350502 0.01481986418 0.01210204791 0.009223339148 0.006954433862 0.00545573514 0.02080447786 0.00919877179 0.02795924433 0.01349302847 0.01536173839 0.01806444861 0.01418882515 0.004685831722 0.03626570851 0.009922552854 0.0201654993 0.01826832816 0.01870287955 0.01994178072 0.008137387224 0.004758510739 0.01581129432 0.01220860705 0.01458521653 0.01630687527 0.005130467936 0.01022602711 0.01183409803 0.01440655533 0.006513629574 0.01602652669 0.005782634486 0.006235063076 0.08377727866 0.006881820504 0.008902981877 0.01386717334 0.01690834761 0.01799543202 0.04047580063 0.0125633264 0.03059572168 0.009868769906 0.01692852937 0.01242249086 0.03515832499 0.01558106858 0.0164189171 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.12060547 33.12155533 33.11771011 33.11915207 33.1440239 33.10013962 33.1076622 33.12277985 33.11233521 33.12438583 33.10844421 33.11118698 33.12200928 33.10429764 33.10581207 33.10754013 33.11822128 33.11454773 33.1059494 33.10749435 33.10790253 33.12420654 33.11259842 33.12563705 33.11403275 33.1139946 33.1205101 33.11759186 33.10713196 33.13966751 33.11236954 33.12356567 33.12166977 33.12210464 33.12334442 33.10963058 33.10625076 33.1192131 33.11560822 33.11798477 33.1015892 33.08945847 33.11362839 33.11523438 33.1178093 33.10800934 33.11847305 33.10918427 33.10486603 33.18717957 33.1064682 33.11230469 33.11726761 33.11840057 33.12139511 33.14387512 33.11405563 33.12922668 33.11136246 33.11937714 33.11582184 33.1366539 33.11898041 33.11981964 

-------
======================
selected experts : 4, 29, 49, 55, 57, 61, 
layer10_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded3c110>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.00871513 -0.0179093 -0.129039-0.00419578 -0.0721665 -0.0473022 0.0376891 -0.0830591 0.0259834]

layer10_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded3bb90>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.576227 -0.572668 -0.2033450.176684 -0.195253 -0.693391 0.451544 1.3792 0.163111]

layer11_wq's input 
<N9nntrainer6TensorE at 0x5682ded7c3b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wq's output 
<N9nntrainer6TensorE at 0x5682ded3ba40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.574647 -0.344996 -0.3160790.0666121 0.327954 0.336796 -0.180087 0.539557 0.764458]
============================
layer11_wk's input 
<N9nntrainer6TensorE at 0x5682ded7e110>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wk's output 
<N9nntrainer6TensorE at 0x5682ded7de80>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0108217 0.0526808 0.006898240.0209765 0.0171261 0.0374855 -0.0384892 0.0369667 0.0138322]
============================
layer11_wv's input 
<N9nntrainer6TensorE at 0x5682ded7ef00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0176427 -0.0244694 -0.008245920.00807842 -0.0076521 -0.0309487 0.0192939 0.053301 0.00688073]
==============================
layer11_wv's output 
<N9nntrainer6TensorE at 0x5682ded7ec90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00918804 0.00942161 0.0280262-0.0530578 0.0101649 0.00276343 0.00300308 0.0247157 0.0975801]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.669855 -0.0231438 0.027258-0.321869 0.191371 0.429374 0.299847 0.483368 -0.719676]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0e67068
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer11_attention_out's input 
<N9nntrainer6TensorE at 0x5682ded813b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer11_attention_out's output 
<N9nntrainer6TensorE at 0x5682ded81310>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer11_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682ded82430>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.576227 -0.572668 -0.2033450.176684 -0.195253 -0.693391 0.451544 1.3792 0.163111]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.0134085 -0.0321063 -0.01051490.0103385 -0.0102559 -0.0415165 0.027036 0.0765732 0.00839005]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8536322117 -0.350666672 -0.2271159291 -0.814027369 -0.24312675 -0.4555317461 -0.1419058442 2.084069014 -0.5543870926 0.160293147 -0.3175723851 -1.9721241 -0.2567070723 -1.214590073 -0.7125858068 0.09249140322 -0.09203302115 -0.7283654809 1.177680373 -0.4151083827 -0.1389609128 0.09961105138 -1.649830222 -0.6365466118 -0.4705213308 -0.9583889842 -0.7093999982 -1.075470805 -0.6670421362 -0.1231312156 -0.5486690998 -0.05667171255 0.2446939349 -0.4024503827 -0.2572669983 -0.4099058807 -0.1073041111 -1.158459306 -0.703230381 -0.5467608571 -0.07921869308 -0.1965308785 -2.247526884 -0.1062458828 -0.2751447856 -1.356668234 -0.3595725298 -0.07924947888 -1.645887733 -0.6230176091 -1.833443165 -0.3092767894 -0.6894958615 -0.2229477465 -0.4004736543 0.674198091 -0.08846428245 -0.1153771728 -0.8708809018 -1.661915421 -0.03361873329 0.5712429285 -1.02976048 -0.3162067533 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007948376238 0.01314357575 0.0148720555 0.00826948788 0.01463583857 0.01183508057 0.01619486138 0.1500050426 0.01072108932 0.02190889977 0.01358583197 0.002597307786 0.0144384224 0.005540084559 0.009152381681 0.02047267929 0.01702302694 0.009009093046 0.06059911102 0.0123232957 0.01624262705 0.0206189584 0.003585040569 0.009875463322 0.01165900286 0.007157857995 0.009181586094 0.006367004942 0.009578852914 0.01650178619 0.01078256872 0.01763575152 0.02383830771 0.01248027664 0.01443033852 0.01238757465 0.01676503941 0.005859945901 0.009238407016 0.01080316398 0.01724256761 0.01533394586 0.001972048776 0.01678278856 0.01417464856 0.004806319252 0.01302704029 0.01724203676 0.00359920226 0.01000997704 0.002983677667 0.0136990035 0.009366167709 0.01493417192 0.01250497065 0.0366274491 0.01708388515 0.01663023792 0.007812452968 0.003541974584 0.01804703102 0.03304409236 0.006664795801 0.01360439882 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.54969406 28.55584335 28.55804825 28.53952599 28.55208969 28.54166031 28.55126572 28.69365883 28.55199051 28.5617485 28.55723953 28.5462513 28.55284691 28.5487175 28.55232811 28.55649757 28.56019974 28.55218506 28.59614563 28.5512085 28.55989647 28.5614109 28.54676247  28.543993 28.55197525 28.54699707 28.54806709 28.53809929 28.54703331 28.55967903 28.5501442 28.55985832 28.56701469 28.55565643 28.55713081 28.54984283 28.55994225  28.546175 28.55098534 28.55397987 28.56041908 28.55707932 28.54514885 28.55280685 28.55544472 28.54607582 28.55334282 28.56041908 28.54725266 28.54794121 28.54568291 28.55401421 28.5520668 28.55811119 28.55568123 28.57932663 28.55978394 28.55980682 28.54622078 28.5467186 28.56074715 28.57574463 28.54936409 28.55630493 

-------
======================
selected experts : 7, 9, 18, 32, 55, 61, 
layer11_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682ded85530>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.333239 -0.0966277 0.0164065-0.155013 -0.154962 0.0912206 0.0206473 0.0287376 0.173099]

layer11_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ded84d30>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.242987 -0.669296 -0.1869380.0216705 -0.350215 -0.60217 0.472191 1.40794 0.336209]

layer12_wq's input 
<N9nntrainer6TensorE at 0x5682dedc4470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wq's output 
<N9nntrainer6TensorE at 0x5682ded84be0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.242823 0.417797 0.07170260.586705 0.501475 0.360597 0.460942 0.30801 0.72607]
============================
layer12_wk's input 
<N9nntrainer6TensorE at 0x5682dedc61d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wk's output 
<N9nntrainer6TensorE at 0x5682dedc5f40>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0059719 0.0473741 0.01258060.0277794 0.0201364 0.0578011 0.0204722 0.00987752 -0.0366265]
============================
layer12_wv's input 
<N9nntrainer6TensorE at 0x5682dedc6fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0116271 -0.0331119 -0.009147250.00113654 -0.0160006 -0.0307677 0.0246371 0.0654675 0.0160878]
==============================
layer12_wv's output 
<N9nntrainer6TensorE at 0x5682dedc6d50>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00766343 -0.0528842 0.0304772-0.00113746 -0.0263957 0.00103918 0.00807294 -0.021785 0.00503729]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0235448 -0.482662 -0.582492-0.100338 0.345979 0.51167 0.5315 -0.157623 -0.16038]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0c62058
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer12_attention_out's input 
<N9nntrainer6TensorE at 0x5682dedc9470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer12_attention_out's output 
<N9nntrainer6TensorE at 0x5682dedc93d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer12_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dedca4f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.242987 -0.669296 -0.1869380.0216705 -0.350215 -0.60217 0.472191 1.40794 0.336209]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.00532087 -0.0374544 -0.009399940.00127128 -0.0179888 -0.0363026 0.0284667 0.0772668 0.0171785]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.515114903 0.1988955289 -0.9148083925 0.4729863703 0.09639342874 -0.6808546782 0.1147310883 -0.4401502907 -0.1680116206 -0.3849343359 0.007665990852 0.2398532033 -0.804179132 -1.055164337 -0.8419640064 0.1758016348 -0.00687226234 -0.1439996511 -1.990939736 0.1290771216 0.2109279782 -1.326081753 0.06457764655 -1.200477242 -0.4049041867 -0.09832254797 -0.5622937083 -0.5176398158 -0.5233002305 -1.259488463 -1.66703105 -1.807760835 -1.113789678 -1.614046335 0.0009765264113 1.904020071 -0.4413326979 -0.8838368654 -0.04244723171 0.2512405515 -0.04221006855 -0.5307527184 -0.7680432796 -1.219922185 -0.0778702423 -1.0996387 -0.5135358572 -0.5197799802 -0.987991631 -0.5169560909 0.6045063138 -0.9295527935 -0.9713642001 -0.537006259 0.2595245838 0.04104918987 -0.4304583073 -1.368692636 0.4785416722 -0.1011550277 -0.1014918387 2.315051079 -0.7431070209 -0.141637668 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003567925189 0.01980618946 0.00650317641 0.02605176158 0.01787659712 0.008217320777 0.01820743643 0.01045362372 0.01372319274 0.0110470634 0.01635878161 0.02063424699 0.007263921667 0.005651577841 0.006994576193 0.01935403235 0.01612267829 0.01405670401 0.002217009896 0.01847052574 0.02004594728 0.004310342018 0.01731679216 0.004887211602 0.01082864497 0.01471366175 0.009251681156 0.009674167261 0.009619562887 0.004607154522 0.003065062687 0.002662693616 0.005329777021 0.003231843235 0.01624971814 0.1089750677 0.01044126973 0.006707741413 0.01555919368 0.02087055892 0.01556288544 0.009548139758 0.007531210314 0.004793098196 0.01501769014 0.005405734293 0.009713950567 0.009653486311 0.006044249982 0.009680784307 0.02971361391 0.006407993846 0.006145589985 0.009488614276 0.02104417048 0.01691411063 0.01055543404 0.004130532965 0.02619688772 0.0146720456 0.01466710307 0.1643749475 0.007721371017 0.0140899457 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
30.80790329 30.82461739 30.8108387 30.82991028 30.82125664 30.81064415 30.82301903 30.81478882 30.81472015 30.81585884 30.82117081 30.82115364 30.81207466 30.8085556 30.80989838 30.82368851 30.8209343 30.81791496 30.80702782 30.82232857 30.82104301 30.80912209 30.8221283 30.80922127 30.8156395 30.81952477 30.81311035 30.81448555 30.81252289 30.80798721 30.80739975 30.80747414 30.80918694 30.80327415 30.82058525 30.90997124 30.81477547 30.81056595 30.81989288 30.82520485 30.8198967 30.81435966 30.80948257 30.80912781 30.8193531 30.80974007 30.81309509 30.8058815 30.80894852 30.81449318 30.83404922 30.80835915 30.81048012 30.81143951 30.82585526 30.82172585 30.81488991 30.80703545 30.83053207 30.81900597 30.81947899 30.96918678 30.80108833 30.81747055 

-------
======================
selected experts : 3, 35, 50, 54, 58, 61, 
layer12_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dedcd730>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.261759 0.0260365 0.00151380.0209557 -0.246369 0.0859744 -0.00723364 -0.109461 0.183084]

layer12_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dedccdf0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0187714 -0.64326 -0.1854240.0426262 -0.596584 -0.516196 0.464957 1.29847 0.519293]

layer13_wq's input 
<N9nntrainer6TensorE at 0x5682dee397f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wq's output 
<N9nntrainer6TensorE at 0x5682dedccca0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.544315 0.211178 0.4857970.142756 0.287921 -0.0756668 -0.190495 0.334301 0.515609]
============================
layer13_wk's input 
<N9nntrainer6TensorE at 0x5682dc471a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wk's output 
<N9nntrainer6TensorE at 0x5682dc4717a0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00536536 0.0270588 0.0105784-0.0175378 -0.0381201 -0.00524855 -0.0441706 0.0075387 0.00437258]
============================
layer13_wv's input 
<N9nntrainer6TensorE at 0x5682dc472820>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.000555059 -0.0299145 -0.008473540.0022344 -0.0242157 -0.028307 0.0236224 0.0548002 0.0227536]
==============================
layer13_wv's output 
<N9nntrainer6TensorE at 0x5682dc4725b0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0538234 0.00921317 -0.00105804-0.0519059 -0.0114752 0.000672776 0.0390768 0.0122256 -0.005239]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.341833 -0.473312 -0.2766390.424086 0.296332 0.0284863 0.13534 0.360178 -0.498639]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0a5d048
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer13_attention_out's input 
<N9nntrainer6TensorE at 0x5682dc474cd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer13_attention_out's output 
<N9nntrainer6TensorE at 0x5682dc474c30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer13_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dc475da0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0187714 -0.64326 -0.1854240.0426262 -0.596584 -0.516196 0.464957 1.29847 0.519293]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.000411249 -0.0366582 -0.009470430.00255523 -0.0306305 -0.0320535 0.0282469 0.0722525 0.0266621]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.8210696578 0.01764702797 0.1705377102 -1.32864821 -0.6457030773 0.2107856125 -0.5317567587 0.4186590016 0.1665709466 -0.09206339717 -0.7631891966 0.5217927694 -0.4000129104 -0.0318245478 -0.6582522988 -0.6459796429 -0.1373912543 -0.6905651093 -0.9183356166 -0.1151067689 -1.146143317 -1.225360155 -0.8136463761 -1.787121296 -0.08054890484 0.2638849914 0.1978272647 -1.86265564 -0.3499395549 -1.720562339 -0.5657072663 -1.050999761 -0.5782107711 0.1856319308 -0.4710305333 0.3538194895 -0.02123886347 0.2299393564 -0.5446910262 -0.2708410919 0.1396059841 -0.009761870839 -0.4558828175 -0.8684517741 -1.109177709 -1.336254835 -0.4432338178 -0.7737660408 0.2498282343 3.344063044 0.06941227615 0.2823231816 -0.2373957634 -0.1085118875 0.5851342678 -0.1705833822 -0.638215065 -0.5434451699 0.4397984147 -0.7761206031 -0.911747992 -1.731405616 -0.6584652066 -1.277460694 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.00578087708 0.01337345783 0.01558271982 0.003479806008 0.00688897213 0.01622268371 0.007720416412 0.01997105218 0.01552102901 0.01198386867 0.006125349551 0.02214070037 0.008807573467 0.01272794977 0.006803059019 0.006887066178 0.01145279221 0.006586750038 0.005245073233 0.0117108766 0.004176533781 0.003858446609 0.005823947955 0.002200101269 0.01212265249 0.01710737869 0.01601382345 0.002040040214 0.009259826504 0.002351521747 0.007462702692 0.004593420774 0.007369973231 0.01581971347 0.008203774691 0.01871722937 0.01286340132 0.01653640531 0.007621199358 0.01002201065 0.01510809734 0.01301188301 0.008328989148 0.005513353739 0.004333809949 0.003453437472 0.008435011841 0.006060902029 0.01686858758 0.3722955287 0.01408396848 0.01742573269 0.01036286913 0.0117883645 0.02358849533 0.01107888855 0.00694074994 0.007630701177 0.02039772272 0.00604665 0.005279738922 0.002326161368 0.006801612675 0.003662566189 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.72777176 28.73631859 28.73805046 28.72642326 28.72840309 28.73821259 28.73018837 28.74196243 28.73894119 28.73540497 28.72525406 28.73697853 28.72984505 28.73471832 28.72784042 28.73030853 28.73439789 28.7252388 28.72866631 28.73513222 28.72664452 28.72489548 28.72781372 28.72514343 28.73602104 28.74005127 28.73609734 28.72450829 28.73220444 28.72434235 28.72993088 28.72753716 28.73031425 28.73876381 28.72637939 28.74023056 28.73580742 28.73709679 28.73104286 28.73296547 28.73852921 28.73595619 28.72841263 28.7284584 28.72489357 28.72592163 28.73137856 28.7237606 28.73933601 29.09571648 28.73750496 28.7403698 28.73330688 28.73473167 28.74653244 28.73450089 28.72940826 28.72914505 28.74286461 28.72756004 28.7282238 28.72479439 28.7302227 28.72708321 

-------
======================
selected experts : 7, 11, 35, 49, 54, 58, 
layer13_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee45420>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.337035 -0.127108 -0.2176710.144968 -0.150565 0.148819 0.00124518 -0.257126 0.256935]

layer13_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dc478790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.355807 -0.770368 -0.4030950.187594 -0.747149 -0.367376 0.466202 1.04135 0.776228]

layer14_wq's input 
<N9nntrainer6TensorE at 0x5682dee98c10>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wq's output 
<N9nntrainer6TensorE at 0x5682dc478730>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.310121 0.128975 0.07752420.61004 -0.194837 0.0533598 0.711713 0.43598 -0.135811]
============================
layer14_wk's input 
<N9nntrainer6TensorE at 0x5682dee9aab0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wk's output 
<N9nntrainer6TensorE at 0x5682dee9a7d0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.00563616 -0.0128344 0.0348296-0.0478778 0.0302346 0.0681164 0.063781 -0.00346803 -0.0459049]
============================
layer14_wv's input 
<N9nntrainer6TensorE at 0x5682dee9b8a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0106694 -0.0346508 -0.01726770.00939218 -0.0326063 -0.019967 0.0230915 0.0426573 0.0347066]
==============================
layer14_wv's output 
<N9nntrainer6TensorE at 0x5682dee9b630>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0533198 0.0518202 0.0305033-0.0279568 0.0927579 0.00337922 0.0188315 0.0349787 0.00499831]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.190049 -0.276932 -0.606515-0.101484 -0.201274 -0.0172538 0.790204 -0.268687 -0.103974]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2eb7168
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer14_attention_out's input 
<N9nntrainer6TensorE at 0x5682dee9dda0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer14_attention_out's output 
<N9nntrainer6TensorE at 0x5682dee9dd00>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer14_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682dee9ee70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.355807 -0.770368 -0.4030950.187594 -0.747149 -0.367376 0.466202 1.04135 0.776228]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.00819254 -0.0462011 -0.02115290.0116523 -0.0396076 -0.0239998 0.0294573 0.0596645 0.0411491]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.3146974742 -0.7524214983 -0.5073871613 1.047515512 -1.900506973 -0.5483075976 -0.8108694553 -1.170781374 -0.3059524596 -2.787629366 -0.9951738119 -0.8819032907 -0.03284237161 -1.08283782 -1.844440937 -0.9865199924 -0.8003217578 -1.080387592 0.4031157792 -1.560947061 -0.3382537067 -0.08784183115 0.1755543947 -0.5047937036 -1.889325738 -0.3198569417 -0.09724221379 -0.5367322564 -0.489025116 -0.007524366491 -2.364694357 -2.770090342 -0.593550086 -1.921137214 -0.9594412446 -0.5471981168 -0.2572587132 -1.150555253 -0.003611662425 -0.3223264217 -0.2941896915 0.8458377719 0.2309077829 -1.740465164 -0.182038337 0.1403097957 -0.5310169458 -2.140178204 -1.20871079 0.02241208963 -1.441024542 -1.899502873 -1.541872621 0.405549556 -0.9199211597 1.239122152 -0.1296442747 -0.2416889817 -0.3628253043 -0.6105259061 -1.894799471 2.003627777 -1.867062569 -0.0566174984 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01456574071 0.00940224342 0.01201291662 0.05687666684 0.002982800826 0.01153126452 0.00886845123 0.006187853869 0.01469367556 0.001228434499 0.007375736721 0.008260346018 0.01930814981 0.006756681949 0.003154811682 0.007439842448 0.008962488733 0.006773257162 0.02985897474 0.004188835621 0.01422663592 0.01827489026 0.02378188446 0.01204411406 0.003016339615 0.01449078415 0.01810390316 0.01166552026 0.01223553717 0.01980323717 0.001875124522 0.001250170055 0.0110211866 0.002921894891 0.007644057274 0.01154406741 0.01542687323 0.006314285565 0.01988087222 0.01445504278 0.01486753579 0.04648862034 0.02513540722 0.003500495572 0.01663204841 0.02295829915 0.01173238363 0.002347125672 0.005957548507 0.02040503547 0.004722532351 0.00298579759 0.004269502126 0.02993173338 0.007952199318 0.06888867915 0.01752669737 0.01566894539 0.01388132386 0.01083567459 0.002999873599 0.1479682177 0.003084245836 0.01885451004 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.17491913 27.17023087 27.17188835 27.21484566 27.16142845 27.17188454 27.16969872 27.16510963 27.17552376 27.16205788 27.16677475 27.16718292 27.18061447 27.16186333 27.15873909 27.1668396 27.1688385 27.16664886 27.19116592 27.16168022 27.17457962 27.17910385 27.18461227 27.16762924 27.16384506 27.17484283 27.1789341 27.17249489 27.17306519 27.18111038 27.16175079 27.16112518 27.1718502 27.16279793 27.16799736 27.17094231 27.17387199 27.1661911 27.18070984 27.1748085 27.17569733 27.20684052 27.1835804 27.16289902 27.17746162 27.18331146 27.17256165 27.15888596 27.16535568 27.18123436 27.16412163 27.16238403 27.16462135 27.19076157 27.16878128 27.22876549 27.17835617 27.17602158 27.16898918 27.17071152 27.16335297 27.30927467 27.15390015 27.17968369 

-------
======================
selected experts : 3, 18, 41, 53, 55, 61, 
layer14_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deea2ef0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.415789 0.0136436 -0.07160960.00549867 -0.0739112 0.0502533 -0.0109407 -0.342321 0.111997]

layer14_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deea2970>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.771596 -0.756724 -0.4747040.193093 -0.82106 -0.317123 0.455262 0.699027 0.888225]

layer15_wq's input 
<N9nntrainer6TensorE at 0x5682deedb770>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wq's output 
<N9nntrainer6TensorE at 0x5682deea2820>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.246993 -0.0980489 0.2560660.161456 0.156527 -0.0754717 0.249379 -0.286325 0.0365459]
============================
layer15_wk's input 
<N9nntrainer6TensorE at 0x5682deedd610>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wk's output 
<N9nntrainer6TensorE at 0x5682deedd330>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0280981 0.0160434 -0.020244-0.0687225 -0.0147608 0.0326301 -0.00132725 -0.034869 -0.0117971]
============================
layer15_wv's input 
<N9nntrainer6TensorE at 0x5682deede400>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0215504 -0.0356277 -0.01931930.00996423 -0.0334151 -0.0183048 0.0228876 0.0288206 0.0387475]
==============================
layer15_wv's output 
<N9nntrainer6TensorE at 0x5682deede190>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.027509 -0.0128741 -0.01039650.00837937 0.0063715 0.011103 0.00334155 -0.0227479 -0.0511434]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.153905 0.21664 -0.2283720.198705 0.172964 -0.0167344 -0.0608059 -0.374799 -0.2291]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2baf950
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer15_attention_out's input 
<N9nntrainer6TensorE at 0x5682deee0900>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer15_attention_out's output 
<N9nntrainer6TensorE at 0x5682deee0860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer15_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682deee19d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.771596 -0.756724 -0.4747040.193093 -0.82106 -0.317123 0.455262 0.699027 0.888225]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0191901 -0.0468997 -0.0252540.0122755 -0.0443351 -0.0211728 0.0291847 0.0401629 0.0477256]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-2.068495512 0.06064449251 -0.2854043543 -2.37253499 -0.5997478962 -1.363569617 -0.4294730723 0.3454683125 -2.21794486 -0.3285040855 -1.38233602 -0.9914281368 -1.088238001 -0.1005136892 0.2885901928 -0.3372989893 0.335038662 0.4939994216 -0.1296791434 -1.760103464 -1.571818233 -0.3351227045 0.3463970125 -1.455619454 4.249740124 -1.797733426 -0.3779758513 0.04171392322 -2.804435015 -1.001756907 -0.419159323 -0.5463706255 -1.305555463 -0.07715242356 0.08199023455 -0.2658957541 -1.742617965 -0.8322230577 0.1008040458 0.6929460168 0.6067660451 -1.113214135 -0.4716964066 0.1628283262 -0.9055261016 -3.344549894 -1.85081017 -1.61446631 -0.8867996931 -0.2743210196 -1.716823936 0.4269520342 -1.464987159 -0.145443514 -2.872466326 -0.7048119903 0.2177646607 -0.8569467664 -1.120281219 -0.7068556547 0.1902229339 -0.1809620261 -2.570884466 -1.580011606 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001140439766 0.009588398971 0.006783580873 0.0008414522745 0.004953830503 0.002307903487 0.005873415619 0.01274804026 0.0009821263375 0.006497419905 0.002264996292 0.003348395927 0.003039433155 0.008161237463 0.01204319112 0.006440527271 0.01261577383 0.01478937082 0.00792664662 0.001552405418 0.001874029636 0.006454559043 0.01275988482 0.002104946179 0.6324805021 0.001495074364 0.00618380215 0.009408589453 0.00054633338 0.003313987516 0.005934304558 0.005225438625 0.002445755294 0.008354138583 0.009795268998 0.006917216349 0.001579788863 0.003926256206 0.009981297888 0.01804475859 0.01655478589 0.002964461222 0.005630582571 0.0106199868 0.00364874443 0.0003183383669 0.001417789841 0.001795786549 0.003717715852 0.00685918238 0.00162106799 0.01383029483 0.002085319255 0.007802668959 0.0005104016745 0.004459770396 0.01121973339 0.00383037352 0.002943584695 0.004450664856 0.0109149348 0.007530393079 0.0006900612498 0.001858737436 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.89215469 25.90060234 25.88921547 25.89090157 25.89453697 25.88950729 25.89736366 25.90423965 25.89295006 25.89560509 25.8942337 25.89007187 25.89405441 25.89917564 25.90401077 25.89697838 25.90458298 25.90675735 25.90037155 25.89256668 25.89336586 25.89556122 25.90186691 25.89359665 26.52111053 25.89346313 25.89767456 25.90137672 25.89060593 25.89289665 25.8974247 25.8957634 25.89393616 25.89936829 25.90176392 25.89697838 25.89163971 25.8958931 25.90194893 25.89475441 25.90852165 25.88968658 25.89712143 25.90354156 25.89561653 25.89180946 25.89195442 25.88518143 25.89520836 25.8988266 25.89263535 25.90055275 25.89262199 25.89977074 25.89104843 25.89642715 25.9031868 25.89293671 25.89204979 25.89307976 25.90288353 25.89902115 25.88979721 25.88381386 

-------
======================
selected experts : 17, 22, 24, 39, 40, 51, 
layer15_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682deee4f80>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.420765 0.217941 0.222422-0.14563 -0.174842 -0.00262449 -0.196889 0.0361661 0.230033]

layer15_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682deee44b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.19236 -0.538783 -0.2522820.0474629 -0.995903 -0.319747 0.258373 0.735193 1.11826]

layer16_wq's input 
<N9nntrainer6TensorE at 0x5682def24710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wq's output 
<N9nntrainer6TensorE at 0x5682deee4360>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.355268 0.197313 -0.389867-0.372069 -0.160161 -0.638674 0.37698 0.298585 0.319134]
============================
layer16_wk's input 
<N9nntrainer6TensorE at 0x5682def26470>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wk's output 
<N9nntrainer6TensorE at 0x5682def261e0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0315604 -0.0124703 -0.07055450.0248561 0.0810568 -0.00435547 0.0442637 0.0670922 -0.00547626]
============================
layer16_wv's input 
<N9nntrainer6TensorE at 0x5682def27260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.061141 -0.0316148 -0.01206950.00286031 -0.0471187 -0.0218047 0.0147511 0.0351725 0.0573413]
==============================
layer16_wv's output 
<N9nntrainer6TensorE at 0x5682def26ff0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.037477 0.0743753 0.0621462-0.163479 0.00509745 -0.0277609 -0.0101428 -0.0310047 -0.0741977]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.405438 0.027714 0.468601-0.266168 0.0704009 -0.654675 0.470586 -0.099075 -0.27821]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a20940f8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer16_attention_out's input 
<N9nntrainer6TensorE at 0x5682def29710>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer16_attention_out's output 
<N9nntrainer6TensorE at 0x5682def29670>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer16_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def2a790>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.19236 -0.538783 -0.2522820.0474629 -0.995903 -0.319747 0.258373 0.735193 1.11826]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0341949 -0.0347478 -0.01433670.00316139 -0.0565951 -0.0224808 0.0170047 0.0437227 0.0635483]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.05211476982 -0.6416469216 -2.025191069 -0.1436697394 -0.6531259418 -0.6036865711 0.08149973303 0.3208004832 -3.047298193 -1.111545444 -1.02949369 -3.965992212 -1.467410803 -1.43652916 -1.315266013 -1.292850018 -1.682392359 -2.04670763 -1.666963696 0.1243281886 -0.3349597156 0.08837586641 -1.756295681 -0.1972560436 -0.1667171866 -0.7029651999 -1.273959517 -0.3595299125 -1.542718649 -0.3003361225 -0.304392606 -0.9442470074 -1.322111726 -0.8383237123 -1.063028097 -0.2437692136 0.8430628181 -0.2073403895 -1.313209176 -0.1361294836 2.023962736 -1.132570505 0.9384945631 -2.073050261 -0.5370718837 -2.903338671 -0.1327673644 -1.958109021 -3.113909483 -1.157161355 -1.999120355 -0.06422943622 -0.9717085361 -1.779744625 -0.4174019694 0.0480931066 -1.076514125 -2.244340897 -0.8149682879 -0.7359886765 -0.1602908522 -0.7065141797 0.3943091333 2.630728483 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01854330115 0.009265955538 0.002322868444 0.01524610445 0.009160199203 0.009624456055 0.01909628138 0.02425916307 0.0008358515333 0.005791831296 0.006287102588 0.0003335380461 0.004057565238 0.004184823018 0.004724340513 0.004831436556 0.003272654954 0.002273422666 0.003323538462 0.01993191056 0.0125916535 0.01922804117 0.003039516509 0.01445062645 0.01489873882 0.008714850992 0.004923572764 0.01228604373 0.003763220971 0.01303525735 0.01298248675 0.006846563891 0.00469210837 0.007611574605 0.006079763174 0.01379387639 0.04089700431 0.01430563349 0.004734066781 0.01536150184 0.1332139671 0.005671328399 0.0449921675 0.002214316046 0.01028742176 0.0009652726003 0.01541323401 0.002484036377 0.0007819882012 0.005533565767 0.002384223277 0.01650666818 0.00666110497 0.0029690722 0.01159520727 0.01846887544 0.005998322275 0.001865730737 0.007791439071 0.0084317578 0.01499479171 0.00868397858 0.02610959671 0.2443795055 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
23.54921722 23.53088188 23.53299713 23.54591942 23.52934647 23.5407753 23.55024719 23.54730606 23.52578926 23.53694344 23.53505516 23.53053093 23.53473091 23.53247643 23.52490997 23.5264473 23.53299332 23.53056526 23.53304291 23.55012894 23.53706932 23.5503788 23.53371429 23.54464722 23.54557228 23.53223801 23.53464317 23.54343605 23.53443718 23.54180336 23.5436573 23.53704453 23.53393745 23.53780937 23.53580093 23.54446793 23.5682354 23.54593277 23.53588486 23.54508209 23.66341019 23.53300858 23.57518959 23.53241158 23.53905678 23.53021049 23.54608727 23.53268051 23.53145599 23.53477859 23.52924538 23.54765701 23.53399849 23.5255394 23.54274559 23.55009651 23.53667259 23.5277729 23.53751183 23.53862953 23.54566956 23.53840446 23.55726051 23.7760067 

-------
======================
selected experts : 7, 36, 40, 42, 62, 63, 
layer16_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def2d9d0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.431278 -0.0191207 -0.0520095-0.191345 -0.0821877 0.0657345 0.0929842 -0.17835 0.119429]

layer16_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def2d090>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.62364 -0.557904 -0.304292-0.143882 -1.07809 -0.254013 0.351357 0.556844 1.23769]

layer17_wq's input 
<N9nntrainer6TensorE at 0x5682def6d870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wq's output 
<N9nntrainer6TensorE at 0x5682def2cf40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.0986049 0.941314 -0.409761-0.228745 -0.439152 -0.517336 0.20517 0.411878 0.786435]
============================
layer17_wk's input 
<N9nntrainer6TensorE at 0x5682def6f5d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wk's output 
<N9nntrainer6TensorE at 0x5682def6f340>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0270154 -0.012093 0.0181588-0.0148033 -0.0128511 0.0329365 -0.048675 0.0630503 0.0434794]
============================
layer17_wv's input 
<N9nntrainer6TensorE at 0x5682def703c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.052692 -0.0344521 -0.0146329-0.00892289 -0.0484439 -0.0184227 0.0222512 0.0257534 0.0627706]
==============================
layer17_wv's output 
<N9nntrainer6TensorE at 0x5682def70150>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.274216 -0.0489666 0.0310645-0.0363662 -0.0251874 -0.0699952 -0.236286 -0.151216 0.111659]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.429358 -0.843473 0.337081-0.326503 -0.233333 -0.637218 0.447899 0.105472 -1.08339]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2299108
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer17_attention_out's input 
<N9nntrainer6TensorE at 0x5682def72870>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer17_attention_out's output 
<N9nntrainer6TensorE at 0x5682def727d0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer17_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682def738f0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.62364 -0.557904 -0.304292-0.143882 -1.07809 -0.254013 0.351357 0.556844 1.23769]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0535453 -0.0381172 -0.018551-0.00990592 -0.0660084 -0.0185562 0.0241901 0.0358498 0.0748043]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
1.447009921 -1.251222968 0.4436779618 1.208736181 0.4357713461 -1.42989099 0.6122367978 0.2530575395 0.4667769969 0.4646663964 -2.264201641 -0.3218255341 -1.396860361 -0.2306746393 -0.1178826988 0.7724598646 0.2812962234 0.5701763034 -0.05667025223 -0.4016815722 0.5942981243 -0.2179611325 -1.151953578 1.020982146 0.1786067039 -0.5935477614 0.4067239463 0.5758956671 -0.2033901215 -1.378864169 0.6396024823 -0.2597191632 0.6028248668 -0.01780005358 -0.4718881547 -1.254062057 -0.4256217182 0.6643728614 -0.9968361259 0.7363439798 0.7514398098 0.1557527333 0.05587822571 -0.2031203806 0.02681217901 0.5725940466 1.238481522 0.2346255332 -0.7182914615 -0.5017694831 0.2432640791 -0.7048752308 5.43648386 -0.1543168426 -0.4374468923 0.8873459697 -0.7013961077 -0.7799318433 -0.2013331503 0.02283242717 -2.182951212 -0.4535562098 0.4822836518 -1.40295589 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01393856574 0.00093840505 0.005110653583 0.01098340377 0.005070406478 0.0007848665118 0.006048960611 0.004223680589 0.005230078474 0.00521905208 0.000340768398 0.00237696385 0.0008112239884 0.002603807254 0.002914699493 0.007100104354 0.004344652407 0.00579981273 0.003098689485 0.002194530331 0.005941415206 0.002637122059 0.001036340487 0.009103251621 0.003920644056 0.001811402966 0.00492524216 0.005833080504 0.002675829455 0.000825955125 0.006216780283 0.002529268386 0.005992292892 0.003221508116 0.002045743633 0.0009357446106 0.002142617013 0.006372694392 0.001210233429 0.006848250981 0.006952414755 0.003832058283 0.003467825241 0.002676551463 0.003368479898 0.005813853815 0.01131501887 0.0041465424 0.001598967589 0.001985518262 0.004182518926 0.001620563678 0.753051281 0.002810416045 0.002117428463 0.007964508608 0.00162621215 0.001503382344 0.002681339392 0.003355100984 0.0003696118365 0.002083592117 0.005311812274 0.000806294207 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
22.11791992 22.11302567 22.11862755 22.11687088 22.11572647 22.1081028 22.11956596 22.11774063 22.11827087 22.11873627 22.11195183 22.11541748 22.10622215 22.11516762 22.11595535 22.12109375 22.1178627 22.11979485 22.10278893 22.11523628 22.11564445 22.11138725 22.11216927 22.11976051 22.11696243 22.11103821 22.11891937 22.11935043 22.1076107 22.11291313 22.11925697 22.11557007 22.11855698 22.11673927 22.11556435 22.1058712 22.11518288 22.11941338 22.11139107 22.11988831 22.12047005 22.10972023 22.11698532 22.11237907 22.10877991 22.1198082 22.12149429 22.11766434 22.11034775 22.11550331 22.11770058 22.11466217 22.84749603 22.10822105 22.10991287 22.11814499 22.11562157 22.11120605 22.11429214 22.11210442 22.11341095 22.11512375 22.11930656 22.11194038 

-------
======================
selected experts : 0, 3, 23, 46, 52, 55, 
layer17_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682def76b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.34535 0.153269 -0.0514444-0.155825 0.00398532 -0.280045 -0.110691 -0.0676852 -0.0705817]

layer17_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682def761f0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.96899 -0.404635 -0.355736-0.299706 -1.07411 -0.534058 0.240666 0.489158 1.16711]

layer18_wq's input 
<N9nntrainer6TensorE at 0x5682defb6420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wq's output 
<N9nntrainer6TensorE at 0x5682def760a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.892632 0.785006 0.2843590.732417 0.502672 0.0353727 -0.273241 0.803194 -0.858658]
============================
layer18_wk's input 
<N9nntrainer6TensorE at 0x5682defb8180>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wk's output 
<N9nntrainer6TensorE at 0x5682defb7ef0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0625939 0.0209839 -0.02201980.140951 0.13563 0.073881 -0.0576498 0.0120187 -0.0372709]
============================
layer18_wv's input 
<N9nntrainer6TensorE at 0x5682defb8f70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.106703 -0.026377 -0.0198368-0.0194586 -0.0548333 -0.0388684 0.0156883 0.0244594 0.066303]
==============================
layer18_wv's output 
<N9nntrainer6TensorE at 0x5682defb8d00>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0673743 0.132851 -0.8126420.0689228 0.0105354 -0.0484212 -0.0431445 0.0169316 0.0487522]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.321922 -1.14429 -0.7832830.061333 0.459484 0.206893 0.44306 0.723519 0.637251]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a249e118
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer18_attention_out's input 
<N9nntrainer6TensorE at 0x5682defbb420>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer18_attention_out's output 
<N9nntrainer6TensorE at 0x5682defbb380>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer18_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682defbc4a0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.96899 -0.404635 -0.355736-0.299706 -1.07411 -0.534058 0.240666 0.489158 1.16711]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.0721664 -0.027966 -0.0225376-0.0210278 -0.0680496 -0.039148 0.0168854 0.032015 0.073025]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.7184080482 -1.151590586 -1.859447241 -0.977907002 -1.203753948 0.2016505301 0.3415195346 0.1751564294 -0.9603215456 0.07764619589 -0.7337498069 0.7458074093 -0.4427110255 -2.942986965 -1.691908717 -1.262107611 -1.842625141 3.898965359 -0.4046615362 0.1811235845 0.07861576974 0.7561917901 -2.544876337 -0.3593176007 -1.128900528 -0.5133380294 -0.7166668773 -1.134882569 -0.3825878203 -0.8983453512 -1.73834765 0.4515714049 -2.509013414 0.3447127342 -1.726599813 -1.201112628 0.3410312831 -1.635834694 -0.9594169855 -1.42271924 -0.5482043624 -0.2436633706 -0.3327748179 -0.1896322966 -0.08608092368 -0.4912527204 0.02922016196 0.4147014618 0.102746658 -1.13919425 -0.06142451242 -0.05008335412 0.8983634114 -0.6112719774 0.4918267131 -0.466303587 -0.5821825266 0.1258903295 -0.5778212547 0.5221877098 -2.873530388 -0.7968274951 -1.698697209 0.7144367695 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.005024361424 0.003258007113 0.001605217811 0.003875982948 0.003092415631 0.01260832138 0.01450112276 0.0122786602 0.003944747616 0.01113788877 0.004947867244 0.02172609232 0.006619339809 0.00054319849 0.001897994196 0.00291712652 0.001632448984 0.508605063 0.006876053289 0.01235214714 0.01114869118 0.02195287496 0.0008088270552 0.007195016835 0.003332777182 0.006167961285 0.005033118185 0.003312900197 0.007029520813 0.004196962342 0.001811869093 0.01618812606 0.0008383603999 0.01454750076 0.001833280083 0.00310059404 0.01449404284 0.002007463016 0.003948317841 0.002484290162 0.005956612993 0.008077182807 0.007388552651 0.008525605313 0.009455773048 0.006305697374 0.01061137579 0.01560213789 0.01142099407 0.003298647236 0.009691816755 0.009802358225 0.0253067147 0.00559254596 0.01685307547 0.006465000566 0.005757619161 0.01168839727 0.005782783963 0.01737259701 0.000582268287 0.004645407666 0.001885153819 0.0210551098 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
24.21805191 24.20770264 24.21368027 24.21356583 24.21611977 24.22611237 24.22752953 24.2257843 24.21601868 24.2246418 24.21416092 24.23427773 24.21773911 24.21214104 24.2154026 24.21594429 24.20703125 24.7202034 24.21895027 24.22490311 24.21797752 24.22830582 24.21383667 24.21974564 24.21588326 24.21776581 24.21710777 24.20918846 24.20432091 24.21722412 24.21340942 24.22969246 24.21243668 24.21946907 24.21486092 24.21565247 24.22799873 24.20072937 24.21602249 24.21455765 24.21850777 24.22110558 24.21946335 24.22107697 24.22296143 24.21504211 24.22077751 24.22719955 24.22444916 24.21537209 24.22271919 24.22330666 24.22927475 24.2186203 24.23035812 24.21615601 24.21878624 24.22471619 24.21881104 24.23040009 24.21074867 24.21672058 24.21443558 24.23408318 

-------
======================
selected experts : 11, 17, 21, 52, 59, 63, 
layer18_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682defbf6e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.57986 0.0943264 -0.0378901-0.0561241 -0.00075978 -0.0367193 -0.33725 -0.0977015 -0.0766937]

layer18_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682defbeda0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.54885 -0.310308 -0.393626-0.35583 -1.07486 -0.570777 -0.0965837 0.391457 1.09041]

layer19_wq's input 
<N9nntrainer6TensorE at 0x5682deffefd0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wq's output 
<N9nntrainer6TensorE at 0x5682defbec50>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.361323 -0.227422 0.290729-0.417 -0.367518 -0.121355 0.565305 -0.199414 0.142538]
============================
layer19_wk's input 
<N9nntrainer6TensorE at 0x5682df001130>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wk's output 
<N9nntrainer6TensorE at 0x5682df001100>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00226154 -0.0396273 0.06855920.0128666 0.0418959 -0.0108973 0.0969948 -0.022773 -0.0303774]
============================
layer19_wv's input 
<N9nntrainer6TensorE at 0x5682df002000>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.141955 -0.0206741 -0.0225373-0.0234292 -0.0584648 -0.0427812 -0.00638457 0.0212924 0.0672563]
==============================
layer19_wv's output 
<N9nntrainer6TensorE at 0x5682df001d90>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0179469 0.0446899 0.0160040.00136719 0.031549 0.0285391 -0.0551306 0.0632468 -0.0651789]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.179454 0.387391 0.315580.398524 -0.302944 -0.240876 0.207965 -0.562215 0.124689]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a28a8138
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer19_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0044b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer19_attention_out's output 
<N9nntrainer6TensorE at 0x5682df004410>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer19_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df005580>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.54885 -0.310308 -0.393626-0.35583 -1.07486 -0.570777 -0.0965837 0.391457 1.09041]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.104808 -0.0219663 -0.0262252-0.0255591 -0.0707731 -0.0427812 -0.00708838 0.0262844 0.0717968]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-0.870427072 -0.4297446311 0.3893831074 -2.882740974 -1.749268174 -1.140577197 -1.86351347 -2.083424807 -0.1198053062 -1.283785939 -3.595624924 -1.68920207 -0.931278646 1.751794577 -0.9549500942 -2.474923849 -0.3612092137 -2.245876074 0.4594415128 -1.703000188 -0.006122693419 -0.2473336458 -0.1874592602 -1.355520844 -1.34108603 -4.318873405 -0.1267712563 -3.603009701 0.3241306543 -2.305549383 -0.7661187053 -1.171770692 -0.2226484567 -1.774108052 -3.001091003 -2.214206457 -0.9160502553 -1.340917349 -0.1638941765 0.6700047255 -0.1463842988 -0.7276086211 -0.6233993769 -0.04615239799 -1.428402066 -0.2105231136 -1.808840513 -0.7044687271 -3.060681105 -1.606765389 -5.207351685 -3.351971865 -2.702824354 -1.067015171 -1.12849617 -0.5040866733 -2.808013678 -1.055145264 -0.2338203192 -3.263477802 -0.8612078428 0.8286098838 -0.3876197636 -1.732399702 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.01169053651 0.01816437021 0.0412062481 0.001562778838 0.004854657222 0.008922977373 0.004330544267 0.003475651378 0.02476425841 0.00773241045 0.0007661184645 0.005155193619 0.01100036036 0.1609351188 0.01074302476 0.002349688904 0.01945292763 0.002954503521 0.04419661686 0.005084549543 0.02774578705 0.02179919556 0.02314427681 0.007197155152 0.007301797625 0.000371700502 0.02459235303 0.0007604820421 0.03860328719 0.002783356002 0.01297582407 0.008648932911 0.02234400995 0.004735553171 0.001388349221 0.003049568972 0.01116916165 0.00730303023 0.02369614877 0.05455511436 0.02411472239 0.01348527148 0.01496639382 0.0266570691 0.00669127563 0.02261658758 0.004573899787 0.01380095724 0.001308034523 0.005598178133 0.0001528733992 0.0009774920763 0.001870830311 0.009604114108 0.009031428955 0.01686296798 0.001684035524 0.009718793444 0.02209577523 0.001067937468 0.01179881394 0.06393178552 0.01894588955 0.004937242717 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.25842476 26.25917625 26.28078842 26.2478199 26.25206566 26.24659729 26.24963379 26.25020981 26.27149963 26.25446701 26.24177933 26.25093651 26.25630379 26.40766907 26.25747681 26.24956131 26.26618767 26.24682808 26.29045486 26.25134277 26.27495766 26.26805687 26.26463318 26.25250053 26.25451279 26.24710655 26.27132607 26.24701881 26.28486061 26.24713326 26.26018715 26.25586128 26.26955605 26.2519474 26.24621582 26.2488308 26.2559967 26.25165367 26.27043152 26.29318428 26.27084923 26.26021957 26.26170158 26.2705307 26.24722672 26.26935196 26.25130844 26.26053619 26.24708939 26.24804115 26.24641037 26.24675751 26.24812889 26.25252342 26.24241447 26.26407433 26.24794197 26.2569294 26.26930809 26.24303436 26.25901031 26.30828285 26.26568031 26.25071907 

-------
======================
selected experts : 2, 13, 18, 28, 39, 61, 
layer19_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df008b30>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.291141 -0.0548041 0.1960420.0124939 0.0760055 -0.388228 -0.0445634 -0.0385717 0.00012557]

layer19_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df008060>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.83999 -0.365113 -0.197585-0.343336 -0.998859 -0.959005 -0.141147 0.352885 1.09054]

layer20_wq's input 
<N9nntrainer6TensorE at 0x5682df047b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wq's output 
<N9nntrainer6TensorE at 0x5682df007f10>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.443588 -0.365536 0.0309314-0.373895 1.03147 -0.199066 0.619521 -0.0463079 0.570942]
============================
layer20_wk's input 
<N9nntrainer6TensorE at 0x5682df0498e0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wk's output 
<N9nntrainer6TensorE at 0x5682df049650>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.061873 -0.0443794 0.0643148-0.0113864 0.0207143 0.00327355 0.052702 0.0385123 0.0354851]
============================
layer20_wv's input 
<N9nntrainer6TensorE at 0x5682df04a6d0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.123021 -0.0240551 -0.0128127-0.0218189 -0.0588136 -0.0651733 -0.00926275 0.0197713 0.0664746]
==============================
layer20_wv's output 
<N9nntrainer6TensorE at 0x5682df04a460>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.00685912 -0.00390602 -0.02020850.0231271 -0.0199988 0.0483193 -0.0235687 0.0313001 0.0278894]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.173343 0.548032 0.3491370.137321 1.03671 0.169623 0.360367 -0.50605 -0.528947]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a2cb2158
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer20_attention_out's input 
<N9nntrainer6TensorE at 0x5682df04cb80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer20_attention_out's output 
<N9nntrainer6TensorE at 0x5682df04cae0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer20_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df04dc00>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.83999 -0.365113 -0.197585-0.343336 -0.998859 -0.959005 -0.141147 0.352885 1.09054]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.134808 -0.0267069 -0.0138377-0.0252921 -0.0684 -0.0736309 -0.0106906 0.0247141 0.0752436]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.07704258 -2.381285906 -0.1274219602 0.474237591 -1.869292617 0.430000782 -0.9043648243 -0.4669285119 0.2660955489 -1.392124534 -0.8622024655  0.1724381 0.3264771998 0.9078991413 0.1739273667 -0.3697404861 -0.88002038 0.2017908543 0.6609428525 -2.082634687 0.03842191026 -1.76477313 -0.5597907901 -2.003566265 -0.2413147092 -0.1986148357 0.2799862325 -0.3508349657 -0.9200164676 0.4224737883 0.5498284101 0.2064149082 1.088294625 -1.623036504 -0.8739697933 -0.8394398689 0.6316232085 5.037063122 -0.5610482693 -2.034821033 -0.7283396125 -0.5939122438 -4.271018505 0.4074138105 0.9174279571 -0.8665634394 -1.88837862 -2.123327732 0.770165205 -1.222227216 0.05432872102 -0.7720525861 -1.608665943 -0.2474517077 0.5766109824 -1.176881194 -1.034535289 -0.09248919785 -1.464740157 -2.865098953 -1.450525284 -0.5726585388 0.5862969756 -0.6457912326 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.001647277153 0.0004470343119 0.004257765133 0.007771037985 0.0007459277986 0.007434765808 0.001957760425 0.00303204637 0.006310796365 0.001202065847 0.002042069333 0.005746577401 0.006703590509 0.01198991202 0.005755141377 0.003341520205 0.002006005961 0.00591775449 0.009366217069 0.0006026201881 0.005025818478 0.0008281121845 0.002763161901 0.0006522025797 0.003799431259 0.003965181299 0.006399069447 0.003405294614 0.001927357749 0.007379014976 0.008381230757 0.005945181008 0.01436020341 0.0009542113403 0.002018181141 0.002089085523 0.009095588699 0.7448846698 0.002759689698 0.0006321334513 0.002334567253 0.002670469228 6.755236245e-05 0.007268719841 0.01210470591 0.002033183817 0.0007318261196 0.0005785898538 0.01044717059 0.001424668473 0.005106402561 0.002234714571 0.0009680227959 0.003776186146 0.008608734235 0.001490758266 0.001718807616 0.004409128334 0.001117871027 0.0002755647292 0.00113387499 0.002727833577 0.008692523465 0.002535460284 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.39579964 25.39555168 25.40126991 25.40526009 25.39680481 25.40492439 25.39420128 25.40004539 25.40332413 25.39201546 25.39857864 25.39989853 25.40371704 25.40852547 25.40276718 25.39892387 25.3932972 25.39720917 25.40447235 25.39666176 25.40203857 25.3978405 25.39453125 25.39623451 25.39747429 25.40097809 25.39864349 25.39994049 25.39321709 25.40439224 25.4053936 25.40343475 25.41041946 25.39701271 25.39903069 25.39862442 25.40610886 26.1328373 25.39548111 25.39573669 25.39934731 25.39825249 25.39517212 25.40475845 25.40768623 25.39952278 25.39774513 25.39759064 25.40698242 25.39796066 25.3997345 25.39924812 25.38367653 25.40078926 25.4046669 25.39755058 25.39920807 25.39808464 25.39574623 25.39394951 25.39671516 25.39830971 25.40093613 25.39477921 

-------
======================
selected experts : 13, 18, 32, 37, 44, 48, 
layer20_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df050e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0120884 -0.209664 0.05369820.136559 0.0140424 -0.212215 -0.0268751 0.245811 -0.552276]

layer20_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df050500>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8279 -0.574777 -0.143887-0.206777 -0.984817 -1.17122 -0.168022 0.598696 0.538261]

layer21_wq's input 
<N9nntrainer6TensorE at 0x5682df091030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wq's output 
<N9nntrainer6TensorE at 0x5682df0503b0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.332466 -0.309924 0.2384420.07408 0.479344 -0.182912 -0.21657 -0.208468 -0.599435]
============================
layer21_wk's input 
<N9nntrainer6TensorE at 0x5682df092d90>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wk's output 
<N9nntrainer6TensorE at 0x5682df092b00>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0128925 -0.14536 -0.03713740.107526 -0.0377128 0.0351184 0.0651516 -0.0369747 -0.00649811]
============================
layer21_wv's input 
<N9nntrainer6TensorE at 0x5682df093b80>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.188853 -0.0370353 -0.00837037-0.0126223 -0.0565194 -0.0812717 -0.0104319 0.0338911 0.0327166]
==============================
layer21_wv's output 
<N9nntrainer6TensorE at 0x5682df093910>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0628524 0.476884 -0.03043020.0533559 0.0167144 -0.0309751 -0.0983312 -0.00852327 0.00372253]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.110357 0.440917 -0.1396240.206997 0.513021 -0.00600596 -0.298751 0.0333095 1.35437]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a1f918f0
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer21_attention_out's input 
<N9nntrainer6TensorE at 0x5682df096030>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer21_attention_out's output 
<N9nntrainer6TensorE at 0x5682df095f90>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer21_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0970b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.8279 -0.574777 -0.143887-0.206777 -0.984817 -1.17122 -0.168022 0.598696 0.538261]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.144591 -0.045282 -0.0109603-0.0163982 -0.073989 -0.0977705 -0.0138507 0.0459169 0.0404394]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.06304276 -0.6021475196 -2.169597626 -1.313102484 -2.742123365 -0.4679281712 0.3970277607 -2.853251934 -0.06517066061 -1.92474246 -4.035582066 0.06261336058 -2.236532211 -2.247601271 -0.04237207025 -1.586821675 -1.129099131 -0.2283283621 -2.213349104 -0.2064970732 -3.909958363 -0.2399390191 -1.702290535 -2.80487442 -1.139941931 -2.144385815 0.2781732678 -0.2992320657 -0.5869427323 -0.1516870111 -1.931723356 -3.424999952 -0.7316350341 -2.441805601 -2.182060957 -1.475407958 0.5334613919 -1.330709934 -1.049032211 3.90513134 0.4757867754 0.219257772 -2.52214694 -0.5174241662 0.6447601318 -0.966193676 0.1037304252 -1.640603065 -1.418705821 -1.239153266 -0.990398109 -3.344450474 -2.827080965 -0.2736230493 -0.09573896229 -0.2715366781 -0.3317405581 -0.1800187677 -1.254295468 0.3095138967 -0.3546442688 -3.898478985 -2.363801718 -1.45413053 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.004216297995 0.006684909109 0.001394314109 0.003283458995 0.0007865307853 0.007645156235 0.01815648749 0.0007038065814 0.01143672224 0.001781146857 0.0002157614508 0.0129956333 0.001304041129 0.001289685839 0.01170045976 0.00249722111 0.003946784884 0.009715008549 0.001334625646 0.009929428808 0.0002446422877 0.009602860548 0.002224894706 0.0007386920042 0.00390421995 0.001429914031 0.01612181589 0.009050031193 0.006787329447 0.01048885286 0.001768756192 0.0003973252606 0.005872997455 0.001062042895 0.00137704378 0.002791536273 0.02081057988 0.003226152388 0.004275786225 0.6061524749 0.01964429393 0.01519943215 0.0009800546104 0.007275962271 0.02326058596 0.004645070527 0.01354111452 0.002366464585 0.002954395954 0.003535471857 0.004533989821 0.0004306539777 0.0007224691217 0.009284785949 0.01109241135 0.009304176085 0.008760559373 0.01019585505 0.003482341068 0.01663508452 0.008562188596 0.0002474668145 0.001148203155 0.002851569559 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
25.64250755 25.64497566 25.63920784 25.64109612 25.63716888 25.64545822 25.65644646 25.63661003 25.64925003 25.63911819 25.62753868 25.64222527 25.63578033 25.63719559 25.64999008 25.64031029 25.64223671 25.64800453 25.63676453 25.64822006 25.63805771 25.64789391 25.64003754 25.63759804 25.64219475 25.63876724 25.65393448 25.64591026 25.64507866 25.64877892 25.64005852 25.63725662 25.64320946 25.63887596  25.638237 25.64012909 25.65910149 25.64103889 25.6401825 26.24348831 25.65793419 25.65349007 25.63784027 25.6450901 25.65725899 25.64245796 25.65183067 25.64018059 25.63599968 25.63896561 25.64282417 25.63490677 25.63090706 25.64757538 25.64938354 25.6456871 25.64180565 25.64801025 25.63366699 25.65444946 25.64542198 25.63806152 25.63753128 25.64018822 

-------
======================
selected experts : 6, 36, 39, 40, 44, 59, 
layer21_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df09a2f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.215912 0.0337436 -0.14080.25848 -0.380119 0.226237 0.102527 -0.408488 0.198852]

layer21_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682df0999b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04381 -0.541033 -0.2846860.0517024 -1.36494 -0.944982 -0.0654953 0.190208 0.737113]

layer22_wq's input 
<N9nntrainer6TensorE at 0x5682df0d9be0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wq's output 
<N9nntrainer6TensorE at 0x5682df099860>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0645966 2.94181 1.97864-1.35017 -2.31954 0.353108 -0.301218 -1.04382 -2.49729]
============================
layer22_wk's input 
<N9nntrainer6TensorE at 0x5682df0db940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wk's output 
<N9nntrainer6TensorE at 0x5682df0db6b0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0181593 0.194621 0.1058130.081483 -0.104169 -0.00915633 0.00530279 0.0582135 -0.174956]
============================
layer22_wv's input 
<N9nntrainer6TensorE at 0x5682df0dc730>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.228802 -0.0364328 -0.01813030.00348161 -0.0887076 -0.0685674 -0.00411981 0.0119149 0.0504063]
==============================
layer22_wv's output 
<N9nntrainer6TensorE at 0x5682df0dc4c0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.305374 -0.118744 0.1250070.0234811 0.348752 0.0440496 -0.268004 -0.125917 0.012953]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.65461 -2.43325 0.7229922.28369 -2.29867 -0.470166 -0.995298 -0.435527 0.72362]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a30bc178
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer22_attention_out's input 
<N9nntrainer6TensorE at 0x5682df0debe0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer22_attention_out's output 
<N9nntrainer6TensorE at 0x5682df0deb40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer22_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df0dfc60>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.04381 -0.541033 -0.2846860.0517024 -1.36494 -0.944982 -0.0654953 0.190208 0.737113]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.197024 -0.0466002 -0.02392610.00439924 -0.111864 -0.0853393 -0.0057438 0.0160851 0.0604106]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.199773863 -1.673453927 -1.750790596 -1.891195297 -0.7850407362 -0.5988141298 0.3508761823 0.4396923184 -0.5164562464 -0.1288634688 -0.439224124 -0.1732848287 -0.6426890492 0.3127274215 -1.910321116 -0.2244655788 0.03051177971 -1.879820585 0.03443358094 0.8580367565 -1.790165305 0.5585227013 -0.4073811471 -1.642910004 0.4139422178 -0.3693930805 -0.7692814469 -0.3295662105 -2.578949928 -0.6650422812 -2.566251755 -2.248004675 -0.9758638144 0.04356760532 0.9725430608 -2.060469627 -0.793438375 0.1285246015 0.4450246394 -1.208471537 -0.1679882407 0.3906342387 -1.493481159 -0.03915252537 -0.4554958344 -0.8757504225 0.291896075 -2.210798025 -0.09234327823 -0.6468251944 0.1034733579 -1.954865456 4.743592262 -3.236852884 -0.3848002851 -3.316403866 -0.5754801035 -1.129412532 0.2965017557 -0.4800824225 0.2253926992 -1.031445861 -1.540406108 -0.7616586685 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.007627194747 0.001171743148 0.001084539806 0.0009424721356 0.002848821692 0.00343196257 0.008871312253 0.009695276618 0.003726577386 0.005490849726 0.004025793634 0.00525227515 0.003284640145 0.008539254777 0.0009246177506 0.004990224726 0.006439546589 0.0009532533586 0.006464849226 0.01473142672 0.00104266603 0.01091861352 0.004156050738 0.001208084868 0.009448808618 0.004316968843 0.002894073259 0.00449236948 0.00047378405 0.003212032374 0.0004798386362 0.0006596416351 0.002353920834 0.00652417168 0.01651863754 0.0007957077469 0.002824998694 0.007102672476 0.009747110307 0.00186539907 0.005280168727 0.009231120348 0.00140279287 0.006006208714 0.003960817587 0.002601779765 0.008363208733 0.0006846469478 0.005695081782 0.003271082649 0.006926949136 0.000884335197 0.7173318863 0.0002453900233 0.004250964615 0.0002266253578 0.003512985772 0.00201886124 0.008401816711 0.003864621744 0.007825120352 0.002226654906 0.001338487375 0.002916218247 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
27.01300812 27.00655174 27.00455856 27.00489235 27.00870705 27.00356674 27.0128212 27.01364517 27.00958443 27.01039505 27.00988388 27.01063347 27.00866508 27.01344299 27.00344467 27.01084709 27.01181984 27.00681114 27.01232147 27.01391411 27.00499344 27.01629829 27.01001358 27.00086594 27.01530647 27.00969696 27.00875092 27.00844193 27.00537682 27.00906944 27.00586128 27.00461006 27.00487328 27.01238251 27.0118866 27.00379181 27.00343704 27.00676155 27.00940514 27.00533867 27.01066017 27.01318169 27.00678253 27.01138687 27.00981903 27.00655174 27.01422119 27.00511169 27.01155281 27.00912857 27.01278496 27.00483513 27.71746826 27.00610352 27.00963211 27.00513077 27.0093708 27.00406075 27.01425934 27.00924492 27.01129913 27.00808334 27.00671959 27.0087738 

-------
======================
selected experts : 7, 19, 21, 34, 38, 52, 
layer22_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df0e2e40>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0903192 0.42473 0.3125610.306603 0.951165 1.31895 0.790386 1.13406 0.257965]

layer22_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682dde69cd0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.9535 -0.116303 0.02787510.358305 -0.413771 0.373971 0.724891 1.32427 0.995078]

layer23_wq's input 
<N9nntrainer6TensorE at 0x5682de368560>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wq's output 
<N9nntrainer6TensorE at 0x5682de2bfbc0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.88475 1.19701 -2.95799-0.774949 -0.550968 3.72149 -2.80755 0.835098 0.0767813]
============================
layer23_wk's input 
<N9nntrainer6TensorE at 0x5682de266760>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wk's output 
<N9nntrainer6TensorE at 0x5682de82d610>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.16132 0.101492 -0.1736-0.0632329 0.00180998 0.100202 -0.12567 -0.0723858 0.0486436]
============================
layer23_wv's input 
<N9nntrainer6TensorE at 0x5682de40ebf0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.187497 -0.00760417 0.001845230.0220659 -0.0277268 0.0258715 0.0464117 0.0808353 0.0637107]
==============================
layer23_wv's output 
<N9nntrainer6TensorE at 0x5682de7736d0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.133239 0.0820239 -0.446299-0.364692 0.117455 0.266068 0.109828 0.368292 0.705527]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-1.76932 -2.57374 1.59415-2.60939 -1.803 3.30185 -1.15226 2.69296 -3.06059]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a32c1188
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer23_attention_out's input 
<N9nntrainer6TensorE at 0x5682ddf81aa0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer23_attention_out's output 
<N9nntrainer6TensorE at 0x5682de55e330>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer23_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0fe910>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.9535 -0.116303 0.02787510.358305 -0.413771 0.373971 0.724891 1.32427 0.995078]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.248394 -0.0111696 0.002646840.0340224 -0.0390645 0.037539 0.0719775 0.125744 0.0934063]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.4227033556 -0.08820123225 -1.093985319 -1.440326333 0.1767097861 -0.6456956863 -1.188692927 -2.515872002 -0.1630707234 0.6196206212 0.6059263349 -1.085564375 -0.3715315461 0.8512659073 0.2090708166 0.6669648886 1.468102455 -1.003164649 4.688289642 -1.688715458 -1.784513116 -0.9512995481 0.2725952566 -1.258306623 0.1121827066 -1.115008235 -1.628750801 -2.018517733 0.472153604 -0.4246005118 -0.5433605313 -0.1163094714 0.03554884717 -1.526789784 -1.247554541 -1.311082482 0.3014304638 -2.34950757 0.6530562043 -0.4077222347 -0.4513951242 -0.467533648 -1.078356385 0.04713717103 0.2013515085 -1.248224258 -0.7126752138 -1.343229294 -2.383528709 -0.6903945208 0.5946252346 -0.4792165756 0.7827592492 -0.3523043096 -1.912632704 -0.1119556129 -0.1083869934 0.8989235163 -1.450334668 0.4656749964 0.7065121531 -0.6281039715 0.8132551908 0.9489036798 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.009099072777 0.005459014326 0.001996675739 0.001412191894 0.007114813197 0.003126060357 0.001816254109 0.0004817149311 0.005065225065 0.01107942872 0.010928737 0.002013560617 0.004112116061 0.01396752708 0.007348821498 0.01161659043 0.02588262036 0.002186505357 0.6479145885 0.001101589063 0.001000956749 0.002302900888 0.007830799557 0.001694118953 0.00667021377 0.001955138287 0.001169666299 0.0007921153447 0.009560336359 0.003899579169 0.003462907393 0.005307705607 0.006178144366 0.00129521871 0.001712431898 0.001607028535 0.008059890009 0.0005689071259 0.01145613473 0.003965955228 0.003796479665 0.003735701554 0.002028127434 0.006250156555 0.007292313501 0.001711285789 0.002923537046 0.001556189149 0.0005498776445 0.002989406232 0.01080592722 0.003692311235 0.01304269768 0.004191944841 0.0008805895341 0.005330865271 0.005349923857 0.01464930177 0.00139812869 0.009498597123 0.01208519842 0.00318153901 0.01344657689 0.01540008187 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
26.92578888 26.92119408 26.91868591 26.91762352 26.92189598 26.91933823 26.9170742 26.91669464  26.921278 26.92776871 26.92761803 26.91536522 26.92032433 26.92874908 26.9235611 26.92639732 26.93541908 26.9183979 27.56221962 26.91397667 26.91721344 26.91851425 26.92452049 26.91838264 26.92335892 26.91721344 26.91547394 26.91748047 26.92624855 26.91963577 26.91919899 26.91961288 26.91952896 26.91464615 26.91697121 26.91734314 26.92474937 26.91630363 26.92766762 26.9168396 26.91762352 26.91994858 26.91871643 26.92198563 26.92302704 26.91792297 26.91627502 26.91347694 26.9167614 26.91729355 26.92749405 26.91990471 26.92973137 26.91945076 26.91375542 26.92011261 26.92060852 26.92466164 26.91761017 26.92523384 26.92877388 26.91748619 26.93013573 26.93065834 

-------
======================
selected experts : 13, 16, 18, 57, 62, 63, 
layer23_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682dee1eb60>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-0.0869226 -0.195127 -0.00683361-0.561033 0.658098 0.719169 0.109476 -0.258927 -0.228366]

layer23_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de7806d0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.86657 -0.31143 0.0210415-0.202728 0.244327 1.09314 0.834367 1.06534 0.766711]

layer24_wq's input 
<N9nntrainer6TensorE at 0x5682de5e9620>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wq's output 
<N9nntrainer6TensorE at 0x5682de23a580>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.336158 -0.169375 -0.425678-0.648299 -0.123858 -0.259336 0.708369 -0.032059 -0.618515]
============================
layer24_wk's input 
<N9nntrainer6TensorE at 0x5682de680bc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wk's output 
<N9nntrainer6TensorE at 0x5682de1e9fa0>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0118696 -0.0472703 0.113450.103728 0.0296149 -0.0224001 -0.0348054 0.0611872 -0.0188398]
============================
layer24_wv's input 
<N9nntrainer6TensorE at 0x5682de7cdb70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.375359 -0.0223357 0.00155483-0.0138788 0.0184524 0.078994 0.0575741 0.0703284 0.054572]
==============================
layer24_wv's output 
<N9nntrainer6TensorE at 0x5682de067420>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.0733123 0.0836663 -0.00333526-0.468789 0.0173092 0.0456101 -0.047658 0.045135 -0.0803263]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[-0.374204 -0.0407592 0.743437-0.220893 -0.0266138 -0.28616 0.428114 -0.565272 0.883872]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a36cb1a8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer24_attention_out's input 
<N9nntrainer6TensorE at 0x5682de40b530>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer24_attention_out's output 
<N9nntrainer6TensorE at 0x5682de646540>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer24_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de7c4940>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.86657 -0.31143 0.0210415-0.202728 0.244327 1.09314 0.834367 1.06534 0.766711]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.272563 -0.0340113 0.00226365-0.0220298 0.0260193 0.124133 0.094748 0.115767 0.0820663]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.929450631 -1.128785849 -0.6543552279 -0.8471324444 -1.39042747 -0.55434829 -0.02498121932 -0.4676400721 -2.470920801 -1.70237565 -0.9748182893 -1.800919175 -0.2439994067 -1.728101611 -1.238625407 -0.255404681 -0.2346673757 -1.047284842 -2.222267866 -0.4669069946 -0.6821814775 0.1248121113 -1.806736708 -0.9977571964 -0.1882074773 -1.306464791 -1.56954062 -1.755864024 -0.8727980852 -1.033334374 -1.979539037 5.464857101 -1.646643162 -0.4878594875 0.3052386045 -0.8554965258 -0.3183939159 -0.9714736342 1.016834497 -2.717564344 -1.23928678 -0.06641087681 0.3262445629 -1.273775458 -1.078132153 0.4311248064 0.4545654655 -2.53660512 -1.765888453 -1.713524938 -1.485613465 -1.774708033 -1.024132609 -1.954378843 0.06704782695 -0.327961266 0.04493098333 -2.279580355 0.0472863242 -0.5062567592 -1.145820975 -1.043580055 -1.944802403 -2.451274872 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a51551d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.0005397897912 0.001202122658 0.001931931009 0.001593196415 0.0009253784083 0.002135128016 0.003625144018 0.002328525297 0.0003140994813 0.0006773952045 0.001402220107 0.0006138258614 0.002912103198 0.0006601905916 0.001077075489 0.002879079431 0.002939406782 0.001304200152 0.0004027686082 0.002330232412 0.001878913492 0.004210945219 0.0006102650659 0.001370421145 0.003079192713 0.001006430946 0.0007736269617 0.0006421142025 0.001552826958 0.001322522294 0.0005134185776 0.8780751228 0.0007162198308 0.002281915629 0.00504356809 0.001579926931 0.002703321865 0.001406917698 0.01027495414 0.0002454432251 0.001076363376 0.003478022991 0.005150632001 0.001039873925 0.001264583552 0.005720176734 0.005855846219 0.0002941310522 0.00063570973 0.0006698846119 0.0008413577452 0.0006301276735 0.001334747649 0.0005264999345 0.003974594176 0.002677580575 0.003887654282 0.0003803341533 0.003896822687 0.002240319503 0.001181818079 0.001309041283 0.0005315663293 0.0003203311935 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.83124924 28.83095741 28.8326416 28.82610321 28.83115768 28.83141327 28.83481216 28.83351517 28.83102417 28.83138657 28.82925034 28.83180046 28.83409882 28.8275547 28.83083534 28.83406448 28.83317184 28.82772255 28.82777405 28.83351707 28.83306503 28.82967567 28.82846069 28.83255577 28.83426476 28.83219337 28.83005333 28.83182907 28.83273888 28.83203125 28.83169937 29.70830727 28.83190346 28.83251381 28.83622932 28.83276558 28.83436584 28.83259392 28.8352623 28.83143234 28.82844734 28.83466339 28.83633614 28.82984161 28.83054352 28.8364296 28.83704185 28.83004951 28.82896042 28.82994843 28.83107376 28.83181572 28.83156776 28.82980537 28.83516121 28.83195686 28.83507347 28.83156586 28.83555984 28.83342743 28.83236885 28.82963371 28.83171844 28.83102989 

-------
======================
selected experts : 31, 34, 38, 42, 45, 46, 
layer24_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df21d1f0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.833895 -0.802753 -0.3862-2.35492 0.648108 1.42702 0.936258 -1.31322 -0.598527]

layer24_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de2b2790>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.70047 -1.11418 -0.365158-2.55765 0.892435 2.52016 1.77062 -0.247877 0.168184]

layer25_wq's input 
<N9nntrainer6TensorE at 0x5682ddf10a30>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wq's output 
<N9nntrainer6TensorE at 0x5682de7d58a0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.64346 4.6151 -3.59633-1.6699 -4.39449 -0.0783202 -2.1087 -2.86507 -0.238884]
============================
layer25_wk's input 
<N9nntrainer6TensorE at 0x5682de480fc0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wk's output 
<N9nntrainer6TensorE at 0x5682de0aef30>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.0538789 0.0193812 -0.0043537-0.242867 0.037277 -0.198658 0.0676407 -0.0872147 0.0887407]
============================
layer25_wv's input 
<N9nntrainer6TensorE at 0x5682ddd64050>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0.86401 -0.120206 -0.0435118-0.2677 0.106341 0.263777 0.195304 -0.0269423 0.0205822]
==============================
layer25_wv's output 
<N9nntrainer6TensorE at 0x5682de58dbd0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.241149 -0.135526 -0.009660890.227738 -0.432866 0.166314 -0.223882 0.00738034 -0.38231]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.29266 -5.31049 2.63505-2.96288 -4.09672 -1.59202 -3.55125 -0.209551 -3.13907]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a38d01b8
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer25_attention_out's input 
<N9nntrainer6TensorE at 0x5682df211490>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer25_attention_out's output 
<N9nntrainer6TensorE at 0x5682dddde7f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer25_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de0184b0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.70047 -1.11418 -0.365158-2.55765 0.892435 2.52016 1.77062 -0.247877 0.168184]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[0.566076 -0.200941 -0.0646798-0.457149 0.156638 0.47074 0.325032 -0.0443051 0.0295192]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-2.033876419 -0.6662036777 -2.519889355 -1.634744644 -1.620467186 -1.470805049 -1.356907725 -0.6036100984 -2.662803173 -3.570815802 -0.7119606137 -2.638509989 -2.228242636 -2.593982458 -1.716693759 -1.688163757 -3.056198359 -2.286839008 -2.550026178 -0.5139263868 -0.06882531941 -1.386721492 -2.962647438 -2.006780863 -2.144985676 -2.108816862 -1.044886827 0.2158241868 1.383966804  -0.539756 -2.881628513 -1.352892756 -1.068458796 -0.9172226787 -1.361247182 -0.08626000583 -2.900213718 -2.272035122 -0.9135314226 -1.731878757 -2.158599854 -2.207988501 -1.664811611 -0.8823071718 -3.022545099 -0.1656448096 -2.413261414 -1.190886617 -0.6852507591 -0.8799331188 -2.690348148 -2.977132082 -2.799127102 -2.899184465 -2.980380535 -1.859682441 -1.973814964 -1.156326056 -1.944438696 -1.011434793 -0.5033848286 -1.838603735 -1.536196589 2.701905012 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.003711364232 0.01457157079 0.002282764297 0.005531900097 0.005611447617 0.006517372094 0.007303609047 0.01551281009 0.001978765707 0.0007980854134 0.01391984802 0.002027424518 0.003055776004 0.002119740704 0.00509664556 0.00524414517 0.001335195615 0.002881864319 0.002214994747 0.01696835272 0.0264816191 0.007089074235 0.001466133283 0.003813301679 0.003321082564 0.003443400143 0.00997806713 0.03520191088 0.1132098287 0.01653567515 0.001589863212 0.007332991809 0.009745614603 0.01133679319 0.007271982264 0.02602392063 0.001560588018 0.00292484439 0.01137871668 0.00501983799 0.003276173491 0.003118299181 0.005368050653 0.01173961349 0.001380893984 0.02403789014 0.002539620269 0.008622624911 0.01429665275 0.01176751871 0.00192500453 0.001445050235 0.00172659161 0.001562194782 0.001440364053 0.004417588003 0.003941104282 0.008925837465 0.004058597609 0.01031749882 0.01714816876 0.004511693027 0.006104826927 0.4229192436 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
28.69184685 28.70556831 28.69089508 28.69700432 28.69660759 28.69751358 28.69829941 28.70460129 28.69297409 28.69083977 28.70539284 28.69350052 28.69500542 28.69216156 28.69227791 28.69337845 28.69280815 28.69006348 28.6932106 28.70844078 28.71461678 28.69522476 28.69246292 28.6952858 28.6947937 28.6939621 28.70145035 28.72667503 28.79896164 28.70228577 28.6925869 28.69880676 28.70121956 28.70281029 28.69826889 28.71749687 28.69255638 28.69439697 28.70237541 28.69506264 28.69236565 28.69363785 28.69684029 28.70225906 28.69285393 28.71551132 28.69210434 28.69723511 28.70529366 28.70276451 28.69005966 28.6919651 28.68890762 28.69255829 28.69243622 28.6930294 28.69398308 28.7003994 28.69553185 28.70131302 28.70385361 28.69550705 28.69757843 29.11439133 

-------
======================
selected experts : 20, 27, 28, 35, 45, 63, 
layer25_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df270060>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.44193 3.30931 -0.1478391.66089 -1.97504 -0.568949 3.54565 0.684309 -1.95359]

layer25_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddfd81b0>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.1424 2.19513 -0.512997-0.896758 -1.0826 1.95121 5.31627 0.436431 -1.78541]

layer26_wq's input 
<N9nntrainer6TensorE at 0x5682de245ed0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wq's output 
<N9nntrainer6TensorE at 0x5682de21e590>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-7.19763 4.21139 1.345270.336204 -5.75587 3.75966 4.87192 1.62306 1.39669]
============================
layer26_wk's input 
<N9nntrainer6TensorE at 0x5682de23ab70>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wk's output 
<N9nntrainer6TensorE at 0x5682de320f60>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[0.146106 -0.197982 -0.1023530.20076 -0.00982388 -0.0815199 -0.115575 0.150995 -0.0874328]
============================
layer26_wv's input 
<N9nntrainer6TensorE at 0x5682dde7eae0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[1.52271 0.401063 -0.0904957-0.146894 -0.206892 0.342157 0.876417 0.0719481 -0.309332]
==============================
layer26_wv's output 
<N9nntrainer6TensorE at 0x5682ddeee690>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.787365 1.20748 2.441630.378884 -1.00658 -1.26723 0.465748 0.381196 -1.92399]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[8.33041 0.382004 -0.709461.19141 -6.70046 1.53911 4.36223 -2.7094 -1.42241]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a116e880
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer26_attention_out's input 
<N9nntrainer6TensorE at 0x5682df278ee0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer26_attention_out's output 
<N9nntrainer6TensorE at 0x5682df278e40>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer26_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682df27a260>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.1424 2.19513 -0.512997-0.896758 -1.0826 1.95121 5.31627 0.436431 -1.78541]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[1.23653 0.539361 -0.126048-0.221282 -0.258047 0.497869 1.323 0.106318 -0.433065]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.229813457 -0.05995209515 -2.346139908 -1.001055837 -0.8235158324 -0.05465627834 -0.1190630272 0.5707327127 0.606651783 0.7820273638 0.002560531255 -0.5726556778 -0.5510423183 -1.395941615 -0.6992129683 -0.1102071032 -0.01739729755 -1.311926961 -0.3690626919 0.4405331016 -0.3804124296 0.1966792345 -0.3727973402 -0.2154888511 0.1727482677 -0.1869333088 0.1713048369 1.859833717 -1.653277993 -1.194599271 -0.2070242614 -2.092623711 0.7438879013 -0.4336843491 -0.8664966226 -0.5564077497 -0.4844253659 -1.836260319 0.4542253315 4.332145214 0.1508646607 0.1188326254 -0.7216179967 -0.6991884112 0.1267536134 0.3779300153 -1.579019308 -0.1242448017 0.3456149697 -0.2343725562 -2.290715456 -0.7030614018 0.944742322 0.4067699015 0.230991438 -1.112182736 -0.7881058455 -1.062981129 -1.485591888 -0.741122663 -1.58641994 0.2200573087 0.5616708994 0.5927568078 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.002155417111 0.006943775341 0.000705857412 0.002709440188 0.003235818585 0.006980645005 0.006545219105 0.01304663718 0.01352377981 0.01611620188 0.007391705178 0.004158448894 0.004249306396 0.001825504005 0.003664107528 0.00660344027 0.007245643996 0.001985500567 0.005097421817 0.01145390794 0.005039894953 0.008975305595 0.005078420509 0.005943563767 0.008763066493 0.006115731318 0.008750427514 0.0473530665 0.00141131226 0.00223267125 0.005994088482 0.0009095313144 0.0155131137 0.004778436851 0.003099687397 0.004226566292 0.004542022478 0.001175316633 0.01161181554 0.5611246228 0.008573383093 0.00830311235 0.003582925536 0.003664198564 0.008369144984 0.01075883955 0.001520104008 0.006511391141 0.01041672565 0.005832380615 0.0007460833876 0.003650033148 0.01896395534 0.01107364334 0.009288612753 0.002424475737 0.003352451371 0.002546746517 0.00166896882 0.003513719188 0.001508895191 0.009187606163 0.01292894501 0.01333716605 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
33.06168747 33.06742859 33.06309891 33.06414795 33.06467438 33.06746674 33.06798553 33.06781006 33.07210159 33.07374191 33.06978607 33.06655121 33.06568909 33.06422043 33.06510544 33.06804276 33.06868362 33.06342316 33.06558228 33.06812668 33.06647873 33.0704155 33.06365585 33.06738281 33.0692482 33.06755447 33.06923676 33.10306931 33.06189728 33.06462479 33.06838608 33.06234741 33.07218552 33.06621933 33.06263351 33.06661987 33.06598282 33.06166077 33.07400513 33.61779404 33.06810379 33.06974411 33.06502151 33.06510544 33.07076263 33.07315063 33.06295776 33.06890488 33.07281113 33.06631851 33.06027985 33.06604385 33.08040237 33.07346725 33.06786728 33.06481934 33.06479263 33.06208038 33.06311035 33.06495285 33.06390381 33.06871796 33.07246017 33.07382202 

-------
======================
selected experts : 8, 9, 27, 32, 39, 52, 
layer26_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df27d4e0>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[3.09747 -1.72508 -0.102068-3.96982 0.264923 0.310013 0.223394 0.572912 -0.468745]

layer26_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682ddd52130>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[8.23987 0.470053 -0.615066-4.86658 -0.817679 2.26123 5.53967 1.00934 -2.25415]

layer27_wq's input 
<N9nntrainer6TensorE at 0x5682de328070>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wq's output 
<N9nntrainer6TensorE at 0x5682ddefef30>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-3.71408 1.9354 2.356543.03328 2.67895 4.20827 -1.76141 2.67573 -0.578456]
============================
layer27_wk's input 
<N9nntrainer6TensorE at 0x5682de1e5e50>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wk's output 
<N9nntrainer6TensorE at 0x5682ddfc8350>
data addr: 0x7fc0a59d51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.400105 -0.24232 0.401053-0.150454 0.0979789 0.371003 -0.358186 -0.0571382 0.698908]
============================
layer27_wv's input 
<N9nntrainer6TensorE at 0x5682de7969c0>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[2.20329 0.0908266 -0.123649-0.954599 -0.171563 0.461203 1.08122 0.202912 -0.45756]
==============================
layer27_wv's output 
<N9nntrainer6TensorE at 0x5682de46fef0>
data addr: 0x7fc0a5bd51d0
Shape: 1:1:1024:512 [ FP32 : NCHW ]
[-0.420768 -0.0722796 -0.2112940.196022 -0.195416 0.81495 0.146881 0.813715 -0.146626]
============================
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b72f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[4.16927 0.396602 -3.583521.38292 1.05974 4.87476 0.93196 3.06489 4.47084]
After rotary embedding Q
<N9nntrainer6TensorE at 0x7fff6a1b6e40>
data addr: 0x7fc0a0550820
Shape: 1:1:1:512 [ UINT16 : NCHW ]
         0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0 

-------
Scale factors: 0 
Zero points: 0 
layer27_attention_out's input 
<N9nntrainer6TensorE at 0x5682de426170>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
==============================
layer27_attention_out's output 
<N9nntrainer6TensorE at 0x5682de0d2950>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[0 0 00 0 0 0 0 0]
============================
layer27_decoder_add's OUTPUT
<N9nntrainer6TensorE at 0x5682de6e6390>
data addr: 0x7fc0a45d51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[8.23987 0.470053 -0.615066-4.86658 -0.817679 2.26123 5.53967 1.00934 -2.25415]

MoE Input :
<N9nntrainer6TensorE at 0x7fff6a1b7490>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1:2560 [ FP32 : NCHW ]
[2.05855 0.114221 -0.147658-1.16832 -0.203481 0.564918 1.35693 0.242312 -0.538953]
======================
before softmax :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
-1.987653255 -0.7842393517 -2.230341911 -0.758665204 -1.053579092 -1.312015295 1.44309485 -0.69209975 -1.784579635 -1.067586184 -0.6883801222 -1.15128839 -0.1300299764 -0.478109628 -0.1315491945 -0.6079538465 -0.1765194386 1.365325212 -1.465485215 -1.203162909 -0.4411250651 -0.5796673298 -0.9326632023 -0.09328451753 -2.341962814 -0.3186990917 -1.199958563 2.033224821 -0.1808017492 -1.539794326 1.491401196 -1.677116752 -0.9739207029 -0.5623084307 -0.4002993405 -1.290343404 -0.2136254013 2.042429447 0.2812911868 -0.07124047726 -0.1099433899 -0.68425107 -0.9261820316 -1.498537898 -1.244819045 -0.7785608768 0.3858971894 -1.06656611 -0.2841586769 -1.134593248 -2.137027025 -0.7241751552 -2.135964632 -1.843329668 -0.5121998787 -1.465894222 -2.073708057 -0.02629480883 -0.6666491628 -2.23829031 -0.3608047664 -1.097417712 -1.685164094 -0.1254190207 

-------
======================
before add bias :
<N9nntrainer6TensorE at 0x7fff6a1b74f0>
data addr: 0x7fc0a4fd51d0
Shape: 1:1:1:64 [ FP32 : NCHW ]
0.002409837907 0.008028305136 0.001890555723 0.008236270398 0.006132691167 0.004736021161 0.07446338981 0.008803178556 0.00295244297 0.006047389004 0.008835984394 0.005561813246 0.01544341724 0.0109037105 0.01541997306 0.009575990029 0.01474189386 0.06889185309 0.004062212072 0.00528065348 0.01131452806 0.009850728326 0.006920925807 0.01602144539 0.001690881327 0.01278808154 0.005297601689 0.1343485564 0.0146788964 0.003771294607 0.078148745 0.003287396161 0.00664119469 0.01002322044 0.01178601291 0.004839781206 0.01420490444 0.1355908811 0.02330117859 0.01637854613 0.01575675793 0.008872545324 0.006965926848 0.00393013889 0.005065199919 0.00807402283 0.02587066963 0.006053561345 0.01323750429 0.005655448884 0.002075465396 0.00852529332 0.002077671699 0.002783984412 0.01053826418 0.004060550593 0.002211132087 0.01713148504 0.009030101821 0.001875588438 0.01226080861 0.005869649351 0.003261048347 0.01551478729 

-------
======================
After add bias :
<N9nntrainer6TensorE at 0x7fff6a1b7520>
data addr: 0x5682df2fe8e0
Shape: 1:1:1:64 [ FP32 : NCHW ]
31.49386406 31.49948311 31.49334526 31.50016785 31.49615669 31.49428368 31.56687164 31.49978065 31.49393082 31.49798012 31.50076866 31.4955864 31.50546837 31.50283623 31.50639915 31.49960136 31.50619698 31.55700874 31.49599457 31.48624611 31.50324631 31.50178337 31.49885368 31.50413895 31.49219322 31.50424385 31.49675179 31.62341881 31.50661087 31.49188805 31.5700798 31.49426651 31.49809647 31.5014782 31.50133324 31.49629402 31.50089073 31.62180138 31.51571083 31.50783348 31.50768852 31.5008049 31.49746704 31.49586296 31.49747467 31.49905205 31.50683594  31.497509 31.50564575 31.4975872 31.49400711 31.49998093 31.49353218 31.4928093 31.50199318 31.4926548 31.49414253 31.50763321 31.5009613 31.49380684 31.50419235 31.49732399 31.49519348 31.50696945 

-------
======================
selected experts : 6, 17, 27, 30, 37, 46, 
layer27_ffn_down Moe output : 
<N9nntrainer6TensorE at 0x5682df2fed10>
data addr: 0x7fc0a51951d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[-2.73092 -1.75519 1.56366.56381 4.80255 3.19545 -10.1483 2.09887 -0.0882844]

layer27_decoder_output's OUTPUT
<N9nntrainer6TensorE at 0x5682de4dbd00>
data addr: 0x7fc0a3bd51d0
Shape: 1:1:1024:2560 [ FP32 : NCHW ]
[5.50894 -1.28514 0.9485321.69723 3.98487 5.45668 -4.60863 3.10822 -2.34244]

(93958)I

=================[ LLM with NNTrainer ]===================
prefill: 1 tokens, 1479 ms, 0.676133 TPS
generation: 10 tokens, 14706 ms, 0.679995 TPS
==========================================================
