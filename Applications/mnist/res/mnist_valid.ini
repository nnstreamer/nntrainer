# Network Section : Network
[Model]
Type = NeuralNetwork	# Network Type : Regression, KNN, NeuralNetwork
Learning_rate = 1e-4 	# Learning Rate
Epoch = 100		# Epoch
Optimizer = adam 	# Optimizer : sgd (stochastic gradien decent),
 	    		#             adam (Adamtive Moment Estimation)
Cost = cross  		# Cost(loss) function : mse (mean squared error)
                        #                       cross ( for cross entropy )
Model = "model.bin"  	# model path to save / read
minibatch = 32		# mini batch size
beta1 = 0.9 		# beta 1 for adam
beta2 = 0.999	# beta 2 for adam
epsilon = 1e-7	# epsilon for adam

# Layer Section : Name
[inputlayer]
Type = input
Input_Shape = 1:28:28

#Layer Section : Name
[conv2d_c1_layer]
Type = conv2d
kernel_size = 5,5
bias_init_zero=true
Activation=sigmoid
weight_ini = xavier_uniform
filter = 6
stride = 1,1
padding = 0,0

[pooling2d_p1]
Type=pooling2d
pooling_size = 2,2
stride =2,2
padding = 0,0
pooling = average

[conv2d_c2_layer]
Type = conv2d
kernel_size = 5,5
bias_init_zero=true
Activation=sigmoid
weight_ini = xavier_uniform
filter = 12
stride = 1,1
padding = 0,0

[pooling2d_p2]
Type=pooling2d
pooling_size = 2,2
stride =2,2
padding = 0,0
pooling = average

[flatten]
Type=flatten

[outputlayer]
Type = fully_connected
Unit = 10		# Output Layer Dimension ( = Weight Width )
weight_ini = xavier_uniform
bias_init_zero = true
Activation = softmax 	# activation : sigmoid, softmax
