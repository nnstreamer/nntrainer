# Network Section : Network
[Network]
Type = NeuralNetwork	# Network Type : Regression, KNN, NeuralNetwork
Layers = inputlayer \
         fc1layer \
	 outputlayer	#Layers of Neuralnetwork
Learning_rate = 0.01 	# Learning Rate
Decay_rate = 0.96	# for the decay_rate for the decayed learning rate
Decay_steps = 1000       # decay step for the exponential decayed learning rate
Epoch = 30000		# Epoch 
Optimizer = adam 	# Optimizer : sgd (stochastic gradien decent),
 	    		#             adam (Adamtive Moment Estimation)
Activation = sigmoid 	# activation : sigmoid, tanh
Cost = cross   		# Cost(loss) function : msr (mean square root error)
                        #                       categorical ( for logistic regression )
Model = "model.bin"  	# model path to save / read
minibatch = 32		# mini batch size
beta1 = 0.9 		# beta 1 for adam
beta2 = 0.9999	# beta 2 for adam
epsilon = 1e-8	# epsilon for adam

# Layer Section : Name
[inputlayer]
Type = InputLayer
Id = 0			# Layer Id
Height = 1		
Width = 62720		# Input Layer Dimension
Bias_zero = true	# Zero Bias

[fc1layer]
Type = FullyConnectedLayer
Id = 1
Height = 62720		# Input Dimension ( = Weight Height )
Width = 100		# Hidden Layer Dimension ( = Weight Width )
Bias_zero = true

[outputlayer]
Type = OutputLayer
Id = 2
Height = 100		# Hidden Layer Dimension ( = Weight Height )
Width = 10		# Output Layer Dimension ( = Weight Width )
Bias_zero = true
