{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef27acf1-cedc-4f01-9156-13a3f2819b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://bart.sec.samsung.net/artifactory/api/pypi/pypi-remote/simple, https://pypi.python.org/simple\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.local/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.local/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.local/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.local/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.local/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.local/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.local/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.local/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.local/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.local/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.local/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.local/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.local/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.local/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.local/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.local/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.local/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.local/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.local/lib/python3.12/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://bart.sec.samsung.net/artifactory/api/pypi/pypi-remote/simple, https://pypi.python.org/simple\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.12/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.12/site-packages (from torchvision) (2.3.5)\n",
      "Requirement already satisfied: torch==2.9.1 in ./.local/lib/python3.12/site-packages (from torchvision) (2.9.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.local/lib/python3.12/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (75.8.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.9.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch==2.9.1->torchvision) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://bart.sec.samsung.net/artifactory/api/pypi/pypi-remote/simple, https://pypi.python.org/simple\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.local/lib/python3.12/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.12/site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.12/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.local/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://bart.sec.samsung.net/artifactory/api/pypi/pypi-remote/simple, https://pypi.python.org/simple\n",
      "Requirement already satisfied: meson in ./.local/lib/python3.12/site-packages (1.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch \n",
    "%pip install torchvision\n",
    "%pip install transformers\n",
    "%pip install meson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74740146-c35e-447e-89aa-82b4c7c7fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNTrainer Already Exist\n",
      "ERNIE Already Exist\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "nntrainer_path = Path(\"./nntrainer\")\n",
    "ernie_path=Path(\"ERNIE\")\n",
    "\n",
    "if not nntrainer_path.is_dir():\n",
    "    print(\"Start Download NNTrainer\")\n",
    "    !git clone https://github.com/DonghakPark/nntrainer.git\n",
    "else:\n",
    "    print(\"NNTrainer Already Exist\")\n",
    "    \n",
    "if not ernie_path.is_dir():\n",
    "    print(\"Start Download ERNIE\")\n",
    "    ernie_path.mkdir(parents=True, exist_ok=True)\n",
    "    !hf download baidu/ERNIE-4.5-21B-A3B-Thinking --local-dir ./ERNIE\n",
    "else:\n",
    "    print(\"ERNIE Already Exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6db8cba-573f-45ed-a92e-3d9cf4fa39f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afdc79a-cf82-442b-819b-3d4332b537d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.9\n",
      "Torch : 2.9.1+cu128 CUDA available: False\n",
      "Transformers: 4.57.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Torch :\", torch.__version__, \"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Transformers:\", transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7ee4b8-fe55-4657-a228-9af7e6a20327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "Loading checkpoint shards: 100%|██████████| 9/9 [00:15<00:00,  1.76s/it]\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Model Load Complete===\n"
     ]
    }
   ],
   "source": [
    "data_dtype = \"float32\"\n",
    "model_path = \"./ERNIE\"\n",
    "output_name = \"./erine_21b_fp32.bin\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, dtype=\"float32\", trust_remote_code=True)\n",
    "print(\"===Model Load Complete===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce8f87e-0f89-4e1e-82f0-57b3debc134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1043/344963014.py:12: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  np.array(params[weight_name], dtype=dtype).tofile(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight torch.Size([103424, 2560]) dtype =  float32\n",
      "model.layers.0.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.0.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1043/344963014.py:10: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  np.array(params[weight_name].permute(1,0), dtype=dtype).tofile(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.0.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.0.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.0.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.0.mlp.up_proj.weight torch.Size([12288, 2560]) dtype =  float32\n",
      "model.layers.0.mlp.gate_proj.weight torch.Size([12288, 2560]) dtype =  float32\n",
      "model.layers.0.mlp.down_proj.weight torch.Size([2560, 12288]) dtype =  float32\n",
      "model.layers.1.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.1.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.1.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.1.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.1.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.1.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.1.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.1.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.1.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.1.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.1.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.2.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.2.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.2.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.2.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.2.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.2.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.2.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.2.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.2.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.2.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.3.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.3.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.3.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.3.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.3.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.3.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.3.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.3.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.3.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.3.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.4.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.4.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.4.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.4.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.4.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.4.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.4.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.4.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.4.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.4.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.5.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.5.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.5.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.5.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.5.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.5.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.5.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.5.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.5.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.5.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.6.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.6.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.6.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.6.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.6.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.6.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.6.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.6.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.6.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.6.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.7.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.7.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.7.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.7.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.7.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.7.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.7.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.7.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.7.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.7.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.8.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.8.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.8.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.8.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.8.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.8.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.8.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.8.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.8.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.8.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.9.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.9.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.9.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.9.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.9.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.9.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.9.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.9.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.9.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.9.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.10.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.10.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.10.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.10.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.10.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.10.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.10.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.10.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.10.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.10.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.11.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.11.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.11.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.11.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.11.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.11.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.11.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.11.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.11.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.11.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.12.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.12.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.12.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.12.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.12.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.12.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.12.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.12.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.12.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.12.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.13.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.13.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.13.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.13.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.13.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.13.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.13.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.13.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.13.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.13.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.14.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.14.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.14.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.14.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.14.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.14.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.14.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.14.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.14.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.14.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.15.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.15.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.15.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.15.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.15.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.15.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.15.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.15.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.15.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.15.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.16.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.16.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.16.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.16.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.16.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.16.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.16.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.16.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.16.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.16.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.17.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.17.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.17.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.17.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.17.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.17.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.17.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.17.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.17.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.17.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.18.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.18.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.18.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.18.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.18.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.18.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.18.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.18.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.18.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.18.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.19.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.19.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.19.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.19.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.19.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.19.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.19.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.19.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.19.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.19.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.20.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.20.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.20.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.20.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.20.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.20.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.20.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.20.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.20.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.20.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.21.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.21.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.21.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.21.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.21.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.21.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.21.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.21.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.21.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.21.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.22.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.22.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.22.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.22.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.22.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.22.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.22.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.22.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.22.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.22.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.23.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.23.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.23.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.23.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.23.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.23.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.23.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.23.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.23.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.23.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.24.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.24.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.24.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.24.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.24.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.24.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.24.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.24.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.24.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.24.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.25.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.25.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.25.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.25.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.25.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.25.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.25.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.25.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.25.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.25.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.26.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.26.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.26.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.26.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.26.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.26.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.26.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.26.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.26.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.26.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.input_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.27.self_attn.q_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.27.self_attn.k_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.27.self_attn.v_proj.weight torch.Size([512, 2560]) dtype =  float32\n",
      "model.layers.27.self_attn.o_proj.weight torch.Size([2560, 2560]) dtype =  float32\n",
      "model.layers.27.post_attention_layernorm.weight torch.Size([2560]) dtype =  float32\n",
      "model.layers.27.mlp.gate.weight torch.Size([64, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.moe_statics.e_score_correction_bias torch.Size([1, 64]) dtype =  float32\n",
      "model.layers.27.mlp.shared_experts.up_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.shared_experts.gate_proj.weight torch.Size([3072, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.shared_experts.down_proj.weight torch.Size([2560, 3072]) dtype =  float32\n",
      "model.layers.27.mlp.experts.0.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.0.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.0.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.1.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.1.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.1.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.2.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.2.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.2.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.3.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.3.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.3.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.4.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.4.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.4.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.5.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.5.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.5.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.6.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.6.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.6.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.7.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.7.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.7.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.8.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.8.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.8.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.9.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.9.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.9.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.10.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.10.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.10.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.11.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.11.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.11.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.12.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.12.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.12.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.13.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.13.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.13.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.14.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.14.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.14.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.15.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.15.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.15.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.16.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.16.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.16.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.17.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.17.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.17.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.18.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.18.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.18.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.19.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.19.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.19.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.20.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.20.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.20.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.21.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.21.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.21.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.22.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.22.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.22.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.23.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.23.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.23.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.24.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.24.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.24.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.25.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.25.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.25.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.26.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.26.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.26.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.27.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.27.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.27.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.28.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.28.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.28.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.29.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.29.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.29.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.30.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.30.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.30.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.31.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.31.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.31.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.32.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.32.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.32.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.33.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.33.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.33.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.34.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.34.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.34.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.35.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.35.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.35.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.36.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.36.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.36.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.37.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.37.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.37.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.38.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.38.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.38.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.39.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.39.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.39.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.40.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.40.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.40.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.41.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.41.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.41.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.42.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.42.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.42.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.43.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.43.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.43.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.44.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.44.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.44.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.45.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.45.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.45.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.46.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.46.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.46.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.47.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.47.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.47.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.48.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.48.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.48.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.49.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.49.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.49.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.50.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.50.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.50.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.51.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.51.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.51.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.52.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.52.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.52.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.53.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.53.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.53.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.54.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.54.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.54.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.55.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.55.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.55.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.56.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.56.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.56.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.57.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.57.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.57.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.58.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.58.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.58.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.59.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.59.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.59.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.60.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.60.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.60.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.61.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.61.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.61.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.62.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.62.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.62.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.layers.27.mlp.experts.63.up_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.63.gate_proj.weight torch.Size([1536, 2560]) dtype =  float32\n",
      "model.layers.27.mlp.experts.63.down_proj.weight torch.Size([2560, 1536]) dtype =  float32\n",
      "model.norm.weight torch.Size([2560]) dtype =  float32\n"
     ]
    }
   ],
   "source": [
    "def save_ernie_moe_for_nntrainer(params, config, dtype, file):  \n",
    "    \"\"\"Convert and save weights as nntrainer format for multi-head attention model\"\"\"  \n",
    "\n",
    "    n_layers = config.num_hidden_layers\n",
    "    n_experts = config.num_experts\n",
    "      \n",
    "    def save_weight(weight_name, is_transpose=False):\n",
    "        print(weight_name, params[weight_name].shape, \"dtype = \", dtype )\n",
    "        if is_transpose:\n",
    "            np.array(params[weight_name].permute(1,0), dtype=dtype).tofile(file)  \n",
    "        else:\n",
    "            np.array(params[weight_name], dtype=dtype).tofile(file)  \n",
    "\n",
    "    def save_projection(layer_name, proj_name):  \n",
    "        save_weight(f\"{layer_name}{proj_name}.weight\", True)  \n",
    "\n",
    "    def save_attention(layer_name):  \n",
    "        \"\"\"Save attention layer weights\"\"\"  \n",
    "          \n",
    "        # Save Q/K/V/O projections using helper  \n",
    "        for proj in [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]:  \n",
    "            save_projection(layer_name, f\"self_attn.{proj}\")  \n",
    "            proj_norm_name = f\"{layer_name}self_attn.{proj[0]}_norm.weight\"\n",
    "            if proj_norm_name in params:\n",
    "                save_weight(proj_norm_name)\n",
    "\n",
    "    def save_feed_forward(layer_name):  \n",
    "        \"\"\"Save feed forward layer weights\"\"\"\n",
    "        \n",
    "        # First Dense Layer\n",
    "        if layer_name == \"model.layers.0.\":\n",
    "            for proj in [\"up_proj\", \"gate_proj\", \"down_proj\"]:  \n",
    "                save_projection(layer_name, f\"mlp.{proj}\")  \n",
    "\n",
    "        else:\n",
    "            save_weight(f\"{layer_name}mlp.gate.weight\", True)\n",
    "            save_weight(f\"{layer_name}mlp.moe_statics.e_score_correction_bias\", False)\n",
    "                        \n",
    "            for proj in [\"up_proj\", \"gate_proj\", \"down_proj\"]:  \n",
    "                    save_projection(layer_name, f\"mlp.shared_experts.{proj}\")  \n",
    "                \n",
    "            # Save MoE projections using helper  \n",
    "            for expert_id in range(n_experts):\n",
    "                for proj in [\"up_proj\", \"gate_proj\", \"down_proj\"]:  \n",
    "                    save_projection(layer_name, f\"mlp.experts.{expert_id}.{proj}\")  \n",
    "\n",
    "\n",
    "    ##### START HERE FROM INITIAL LAYER ################################\n",
    "    ####################################################################\n",
    "    \n",
    "    # 1. Save embedding layer  \n",
    "    save_weight(\"model.embed_tokens.weight\")\n",
    "\n",
    "    # 2. Process all layers  \n",
    "    for layer_idx in range(n_layers):  \n",
    "        layer_prefix = f\"model.layers.{layer_idx}.\"  \n",
    "        save_weight(f\"{layer_prefix}input_layernorm.weight\")  \n",
    "        save_attention(layer_prefix)  \n",
    "        save_weight(f\"{layer_prefix}post_attention_layernorm.weight\")  \n",
    "        save_feed_forward(layer_prefix)  \n",
    "\n",
    "    # 3. Save Norm Weights\n",
    "    save_weight(\"model.norm.weight\")  \n",
    "    \n",
    "    print(\"mode save Done\")\n",
    "    \n",
    "    ##### SAVE END HERE ################################################\n",
    "    ####################################################################\n",
    "\n",
    "########################################################################################\n",
    "with open(output_name, \"wb\") as f_model :\n",
    "        save_ernie_moe_for_nntrainer(model.state_dict(), config, data_dtype, f_model)\n",
    "\n",
    "print(\"model save Success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad94d88d-8be8-4f22-a1c5-a3a80a00bef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
